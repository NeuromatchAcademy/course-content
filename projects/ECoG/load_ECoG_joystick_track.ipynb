{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_ECoG_joystick_track.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEqdz1ZUMaj1"
      },
      "source": [
        "## Loading of Miller ECoG data of the joystick track task\n",
        "\n",
        "includes some visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLWjKq8bLDqm",
        "cellView": "form"
      },
      "source": [
        "#@title Data retrieval\n",
        "import os, requests\n",
        "\n",
        "fname = 'joystick_track.npz'\n",
        "url = \"https://osf.io/6jncm/download\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raBVOEWgUK_B"
      },
      "source": [
        "#@title Install packages, import matplotlib and set defaults\n",
        "# install packages to visualize brains and electrode locations\n",
        "!pip install nilearn --quiet\n",
        "!pip install nimare --quiet\n",
        "\n",
        "from matplotlib import rcParams \n",
        "from matplotlib import pyplot as plt\n",
        "rcParams['figure.figsize'] = [20, 4]\n",
        "rcParams['font.size'] =15\n",
        "rcParams['axes.spines.top'] = False\n",
        "rcParams['axes.spines.right'] = False\n",
        "rcParams['figure.autolayout'] = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sffzC_hyLgWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21869b42-9752-4e82-903f-acefb296cb4d"
      },
      "source": [
        "#@title Data loading\n",
        "import numpy as np\n",
        "\n",
        "alldat = np.load(fname, allow_pickle=True)['dat']\n",
        "\n",
        "# Select just one of the recordings here. This is subject 1, block 1.\n",
        "dat = alldat[0]\n",
        "\n",
        "print(dat.keys())\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['V', 'targetX', 'targetY', 'cursorX', 'cursorY', 'locs'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K7UT7dyj_6R"
      },
      "source": [
        "# Dataset info #\n",
        "\n",
        "This is one of multiple ECoG datasets from Miller 2019, recorded in clinical settings with a variety of tasks. Raw data here:\n",
        "\n",
        "https://exhibits.stanford.edu/data/catalog/zk881ps0522\n",
        "\n",
        "`dat` contain 4 sessions from 4 subjects, and was used in these papers: \n",
        "\n",
        "*Schalk, G., et al. \"Decoding two-dimensional movement trajectories using electrocorticographic signals in humans.\" Journal of neural engineering 4.3 (2007): 264.*\n",
        "\n",
        "*Schalk, Gerwin, et al. \"Two-dimensional movement control using electrocorticographic signals in humans.\" Journal of neural engineering 5.1 (2008): 75.*\n",
        "\n",
        "From the dataset readme: \n",
        "\n",
        "*During the study, each patient was in a semi-recumbent position in a hospital bed about 1 m from a computer monitor. The patient used a joystick to maneuver a white cursor track a green target moving counter-clockwise in a circle of diameter 85% of monitor height ~1m away. The hand used to control the joystick was contralateral to the implanted electrode array.*\n",
        "\n",
        "We also know that subject 0 was implanted in the left temporal lobe, while subject 2 was implanted in the right frontal lobe. \n",
        "\n",
        "Sample rate is always 1000Hz, and the ECoG data has been notch-filtered at 60, 120, 180, 240 and 250Hz, followed by z-scoring across the entire recording and conversion to float16 to minimize size. \n",
        "\n",
        "Variables are: \n",
        "* `dat['V']`: continuous voltage data (time by channels)\n",
        "* `dat['targetX']`: position of the target on the screen\n",
        "* `dat['targetY']`: position of the target on the screen\n",
        "* `dat['cursorX']`: X position of the cursor controlled by the joystick \n",
        "* `dat['cursorY']`: X position of the cursor controlled by the joystick \n",
        "* `dat['locs`]: three-dimensional coordinates of the electrodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPY7ray-kKMh"
      },
      "source": [
        "from nilearn import plotting  \n",
        "from nimare import utils\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "locs = dat['locs']\n",
        "view = plotting.view_markers(utils.tal2mni(locs), marker_labels  = ['%d'%k for k in np.arange(locs.shape[0])], marker_color = 'purple', marker_size=5)\n",
        "view"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y72uLCt_KKG"
      },
      "source": [
        "# compute correlations between voltage data and X/Y position of cursor\n",
        "from scipy import signal\n",
        "dat = alldat[3]\n",
        "\n",
        "V = dat['V'].astype('float32')\n",
        "\n",
        "nt, nchan = V.shape\n",
        "\n",
        "targetX = dat['targetX'].flatten()\n",
        "targetY = dat['targetY'].flatten()\n",
        "\n",
        "cx = np.zeros(nchan,)\n",
        "cy = np.zeros(nchan,)\n",
        "for j in range(nchan):\n",
        "  cx[j] = np.corrcoef(V[:,j], targetX)[0,1]\n",
        "  cy[j] = np.corrcoef(V[:,j], targetY)[0,1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H9lIPCEZFWC"
      },
      "source": [
        "plt.subplot(1,4,1)\n",
        "plt.plot(cx)\n",
        "plt.plot(cy)\n",
        "\n",
        "plt.ylabel('correlation with\\n X / Y position of cursor')\n",
        "plt.xlabel('channel index')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QEuj9x-ZlAM"
      },
      "source": [
        "# this one needs a lot more plots! \n",
        "# for some reason, I only see meaningful correlations in subjects 2 and 3, \n",
        "# but it's possible that there is spectral information that is more useful in those subjects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nql4Zsow221"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}