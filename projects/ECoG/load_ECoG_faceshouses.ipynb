{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_ECoG_faceshouses.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEqdz1ZUMaj1"
      },
      "source": [
        "## Loading of Miller ECoG data of faces/houses (+ noise)\n",
        "\n",
        "includes some visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLWjKq8bLDqm"
      },
      "source": [
        "#@title Data retrieval\n",
        "import os, requests\n",
        "\n",
        "fname = 'faceshouses.npz'\n",
        "url = \"https://osf.io/78saz/download\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raBVOEWgUK_B"
      },
      "source": [
        "#@title Import matplotlib and set defaults\n",
        "from matplotlib import rcParams \n",
        "from matplotlib import pyplot as plt\n",
        "rcParams['figure.figsize'] = [20, 4]\n",
        "rcParams['font.size'] =15\n",
        "rcParams['axes.spines.top'] = False\n",
        "rcParams['axes.spines.right'] = False\n",
        "rcParams['figure.autolayout'] = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sffzC_hyLgWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e70ccd-5b73-4e96-9af8-f89fcca2d97d"
      },
      "source": [
        "#@title Data loading\n",
        "import numpy as np\n",
        "\n",
        "alldat = np.load(fname, allow_pickle=True)\n",
        "alldat1 = alldat['dat1']\n",
        "alldat2 = alldat['dat2']\n",
        "\n",
        "# select just one of the recordings here. 11 is nice because it has some neurons in vis ctx. \n",
        "dat1 = alldat1[0]\n",
        "dat2 = alldat2[0]\n",
        "\n",
        "print(dat1.keys())\n",
        "print(dat2.keys())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['t_off', 'stim_id', 't_on', 'srate', 'V'])\n",
            "dict_keys(['stim_id', 'stim_cat', 'stim_noise', 't_on', 't_off', 'key_press', 'V', 'categories'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K7UT7dyj_6R"
      },
      "source": [
        "# Dataset info #\n",
        "\n",
        "This is one of multiple ECoG datasets from Miller 2019, recorded in a clinical settings with a variety of tasks. We plan to curate a few more before NMA starts. Raw data here:\n",
        "\n",
        "https://exhibits.stanford.edu/data/catalog/zk881ps0522\n",
        "\n",
        "`dat1` and `dat2` contain 5 sessions from 5 subjects, and was originally used in this publication: \n",
        "\n",
        "*Miller, Kai J., Dora Hermes, Franco Pestilli, Gagan S. Wig, and Jeffrey G. Ojemann. \"Face percept formation in human ventral temporal cortex.\" Journal of neurophysiology 118, no. 5 (2017): 2614-2627.*\n",
        "\n",
        "In this task, subjects in a clinical settings (with ECoG implants) are passively shown faces and house during the first experiment (`dat1`). Then in the second experiment in the same subjects (`dat2`), noise is added to face and houses images and the subject has to detect the faces by pressing a key. \n",
        "\n",
        "Sample rate is always 1000Hz, and the ECoG data has been notch-filtered at 60, 120, 180, 240 and 250Hz, followed by z-scoring across time and conversion to float16 to minimize size. \n",
        "\n",
        "\n",
        "Experiment 1: \n",
        "* `dat1['V']`: continuous voltage data (time by channels)\n",
        "* `dat1['srate']`: acquisition rate (1000 Hz). All stimulus times are in units of this.  \n",
        "* `dat1['t_on']`: time of stimulus onset in data samples\n",
        "* `dat1['t_off']`: time of stimulus offset, always 400 samples after `t_on`\n",
        "* `dat1['stim_id`]: identity of stimulus from 1-100, with 1-50 being houses and 51-100 being faces\n",
        "\n",
        "Experiment 2: \n",
        "* `dat2['V`]: continuous voltage data (time by channels)\n",
        "* `dat2['srate']`: acquisition rate (1000 Hz). All stimulus times are in units of this.  \n",
        "* `dat2['t_on']`: time of stimulus onset in data samples\n",
        "* `dat2['t_off']`: time of stimulus offset, always 1000 samples after `t_on`, with no inter-stimulus interval\n",
        "* `dat2['stim_id`]: identity of stimulus from 1-600 (not really useful, since we don't know which ones are the same house/face)\n",
        "* `dat2['stim_cat']`: stimulus category (1 = house, 2 = face)\n",
        "* `dat2['stim_noise']`: percent noise from 0 to 100\n",
        "* `dat2['key_press']`: when the subject thought the image was a face\n",
        "* `dat2['categories']`: categories legend (1 = house, 2 = face)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSf8XWng6RyX"
      },
      "source": [
        "# quick way to get broadband power in time-varying windows\n",
        "from scipy import signal\n",
        "\n",
        "dat1 = alldat1[1]\n",
        "\n",
        "# filter in 10-100Hz\n",
        "b, a = signal.butter(3, [10, 100], btype = 'band', fs=1000)\n",
        "V = dat1['V']\n",
        "V = signal.filtfilt(b,a,V,0)\n",
        "\n",
        "# absolute value and then time-varying envelope of signal, low-passed at 50Hz\n",
        "V = np.abs(V)\n",
        "b, a = signal.butter(3, [50], btype = 'low', fs=1000)\n",
        "V = signal.filtfilt(b,a,V,0)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y72uLCt_KKG"
      },
      "source": [
        "# average the broadband power across all face stimuli and across all house stimuli\n",
        "\n",
        "nt, nchan = V.shape\n",
        "nstim = len(dat1['t_on'])\n",
        "\n",
        "ts = dat1['t_on'][:,np.newaxis] + np.arange(0, 400)\n",
        "V_epochs = np.reshape(V[ts, :], (nstim, 400, nchan))\n",
        "\n",
        "V_house = (np.diff(V_epochs[dat1['stim_id']<=50], 0)**2).mean(0)\n",
        "V_face  = (np.diff(V_epochs[dat1['stim_id']>50], 0)**2).mean(0)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmOarX5w16CR"
      },
      "source": [
        "# let's find the electrodes that distinguish faces from houses\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "for j in range(50):\n",
        "  ax = plt.subplot(10,5,j+1)\n",
        "  plt.plot(V_house[:,j])\n",
        "  plt.plot(V_face[:,j])\n",
        "  plt.ylim([0, .6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOifcmnVB0w-"
      },
      "source": [
        "# this is still work in progress! need to do a few more visualizations and we'll probably need to change the way the broadband power is computed to get better signals. "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}