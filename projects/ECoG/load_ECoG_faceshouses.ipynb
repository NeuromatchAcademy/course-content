{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_ECoG_faceshouses.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEqdz1ZUMaj1"
      },
      "source": [
        "## Loading of Miller ECoG data of faces/houses (+ noise)\n",
        "\n",
        "includes some visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "TLWjKq8bLDqm"
      },
      "source": [
        "#@title Data retrieval\n",
        "import os, requests\n",
        "\n",
        "fname = 'faceshouses.npz'\n",
        "url = \"https://osf.io/argh7/download\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "raBVOEWgUK_B"
      },
      "source": [
        "#@title Install packages, import matplotlib and set defaults\n",
        "# install packages to visualize brains and electrode locations\n",
        "!pip install nilearn --quiet\n",
        "!pip install nimare --quiet\n",
        "\n",
        "from matplotlib import rcParams \n",
        "from matplotlib import pyplot as plt\n",
        "rcParams['figure.figsize'] = [20, 4]\n",
        "rcParams['font.size'] =15\n",
        "rcParams['axes.spines.top'] = False\n",
        "rcParams['axes.spines.right'] = False\n",
        "rcParams['figure.autolayout'] = True"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3017344-d7e0-4b1d-90b5-ef1d2e57347d"
      },
      "source": [
        "#@title Data loading\n",
        "import numpy as np\n",
        "\n",
        "alldat = np.load(fname, allow_pickle=True)['dat']\n",
        "\n",
        "# select just one of the recordings here. \n",
        "dat1 = alldat[1][0]\n",
        "dat2 = alldat[1][1]\n",
        "\n",
        "print(dat1.keys())\n",
        "print(dat2.keys())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['t_off', 'stim_id', 't_on', 'srate', 'V', 'scale_uv', 'locs'])\n",
            "dict_keys(['stim_id', 'stim_cat', 'stim_noise', 't_on', 't_off', 'key_press', 'V', 'categories', 'scale_uv', 'locs'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K7UT7dyj_6R"
      },
      "source": [
        "# Dataset info #\n",
        "\n",
        "This is one of multiple ECoG datasets from Miller 2019, recorded in a clinical settings with a variety of tasks. We plan to curate a few more before NMA starts. Raw data here:\n",
        "\n",
        "https://exhibits.stanford.edu/data/catalog/zk881ps0522\n",
        "\n",
        "`alldat` contains 7 subjects each with two sessions `dat1` and `dat2`, and was originally used in these publications: \n",
        "\n",
        "*Miller, Kai J., et al. \"Face percept formation in human ventral temporal cortex.\" Journal of neurophysiology 118.5 (2017): 2614-2627.*\n",
        "\n",
        "*Miller, Kai J., et al. \"The physiology of perception in human temporal lobe is specialized for contextual novelty.\" Journal of neurophysiology 114.1 (2015): 256-263.*\n",
        "\n",
        "*Miller, Kai J., et al. \"Spontaneous decoding of the timing and content of human object perception from cortical surface recordings reveals complementary information in the event-related potential and broadband spectral change.\" PLoS computational biology 12.1 (2016): e1004660.*\n",
        "\n",
        "*Miller, Kai J., et al. \"The physiology of perception in human temporal lobe is specialized for contextual novelty.\" Journal of neurophysiology 114.1 (2015): 256-263.*\n",
        "\n",
        "*Miller, Kai J., et al. \"Spontaneous decoding of the timing and content of human object perception from cortical surface recordings reveals complementary information in the event-related potential and broadband spectral change.\" PLoS computational biology 12.1 (2016): e1004660.*\n",
        "\n",
        "In this task, subjects in a clinical settings (with ECoG implants) are passively shown faces and house during the first experiment (`dat1`). Then in the second experiment in the same subjects (`dat2`), noise is added to face and houses images and the subject has to detect the faces by pressing a key. Two of the subjects don't have keypresses. \n",
        "\n",
        "Sample rate is always 1000Hz, and the ECoG data has been notch-filtered at 60, 120, 180, 240 and 250Hz, followed by z-scoring across time and conversion to float16 to minimize size. \n",
        "\n",
        "Experiment 1: \n",
        "* `dat1['V']`: continuous voltage data (time by channels)\n",
        "* `dat1['srate']`: acquisition rate (1000 Hz). All stimulus times are in units of this.  \n",
        "* `dat1['t_on']`: time of stimulus onset in data samples\n",
        "* `dat1['t_off']`: time of stimulus offset, always 400 samples after `t_on`\n",
        "* `dat1['stim_id`]: identity of stimulus from 1-100, with 1-50 being houses and 51-100 being faces\n",
        "* `dat1['locs`]: 3D electrode positions on the brain surface\n",
        "\n",
        "Experiment 2: \n",
        "* `dat2['V`]: continuous voltage data (time by channels)\n",
        "* `dat2['srate']`: acquisition rate (1000 Hz). All stimulus times are in units of this.  \n",
        "* `dat2['t_on']`: time of stimulus onset in data samples\n",
        "* `dat2['t_off']`: time of stimulus offset, always 1000 samples after `t_on`, with no inter-stimulus interval\n",
        "* `dat2['stim_id`]: identity of stimulus from 1-600 (not really useful, since we don't know which ones are the same house/face)\n",
        "* `dat2['stim_cat']`: stimulus category (1 = house, 2 = face)\n",
        "* `dat2['stim_noise']`: percent noise from 0 to 100\n",
        "* `dat2['key_press']`: when the subject thought the image was a face\n",
        "* `dat2['categories']`: categories legend (1 = house, 2 = face)\n",
        "* `dat2['locs`]: 3D electrode positions on the brain surface\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXjAPMNlit0x"
      },
      "source": [
        "from nilearn import plotting  \n",
        "from nimare import utils\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "locs = dat1['locs']\n",
        "view = plotting.view_markers(utils.tal2mni(locs), marker_labels  = ['%d'%k for k in np.arange(locs.shape[0])], marker_color = 'purple', marker_size=5)\n",
        "view"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSf8XWng6RyX"
      },
      "source": [
        "# quick way to get broadband power in time-varying windows\n",
        "from scipy import signal\n",
        "\n",
        "V = dat1['V'].astype('float32')\n",
        "\n",
        "b, a = signal.butter(3, [50], btype = 'high', fs=1000)\n",
        "V = signal.filtfilt(b,a,V,0)\n",
        "V = np.abs(V)**2\n",
        "b, a = signal.butter(3, [10], btype = 'low', fs=1000)\n",
        "V = signal.filtfilt(b,a,V,0)\n",
        "\n",
        "V = V/V.mean(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y72uLCt_KKG"
      },
      "source": [
        "# average the broadband power across all face stimuli and across all house stimuli\n",
        "\n",
        "nt, nchan = V.shape\n",
        "nstim = len(dat1['t_on'])\n",
        "\n",
        "trange = np.arange(-200, 400)\n",
        "ts = dat1['t_on'][:,np.newaxis] + trange\n",
        "V_epochs = np.reshape(V[ts, :], (nstim, 600, nchan))\n",
        "\n",
        "V_house = (V_epochs[dat1['stim_id']<=50]).mean(0)\n",
        "V_face  = (V_epochs[dat1['stim_id']>50]).mean(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmOarX5w16CR",
        "scrolled": true
      },
      "source": [
        "# let's find the electrodes that distinguish faces from houses\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "for j in range(50):\n",
        "  ax = plt.subplot(5,10,j+1)\n",
        "  plt.plot(trange, V_house[:,j])\n",
        "  plt.plot(trange, V_face[:,j])\n",
        "  plt.title('ch%d'%j)\n",
        "  plt.xticks([-200, 0, 200])\n",
        "  plt.ylim([0, 4])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGSL0nujEJEt"
      },
      "source": [
        "# let's look at all the face trials for electrode 46 that has a good response to faces\n",
        "# we will sort trials by stimulus id (1-50 is houses, 51-100 is faces)\n",
        "plt.subplot(1,3,1)\n",
        "isort = np.argsort(dat1['stim_id'])\n",
        "plt.imshow(V_epochs[isort,:,46].astype('float32'), aspect='auto', vmax=7, vmin = 0, cmap = 'magma')\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9Ck9YmcEiNG"
      },
      "source": [
        "# Electrode 43 seems to respond to houses\n",
        "isort = np.argsort(dat1['stim_id'])\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(V_epochs[isort,:,43].astype('float32'), aspect='auto', vmax=10, vmin = 0, cmap = 'magma')\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}