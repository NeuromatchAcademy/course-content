
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Tutorial 1: Probability Distributions &#8212; Neuromatch Computational Neuroscience</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Tutorial 2: Statistical Inference" href="W0D5_Tutorial2.html" />
    <link rel="prev" title="W0D5 - Statistics" href="../intro_text.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      <img src="../../_static/nma-logo-square-4xp.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Neuromatch Computational Neuroscience</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Pre-reqs Refresher
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D1_PythonWorkshop1/intro_text.html">
   Python Workshop 1 (W0D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D1_PythonWorkshop1/student/W0D1_Tutorial1.html">
     Tutorial: LIF Neuron - Part I
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D2_PythonWorkshop2/intro_text.html">
   Python Workshop 2 (W0D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D2_PythonWorkshop2/student/W0D2_Tutorial1.html">
     Neuromatch Academy: Week 0, Day 2, Tutorial 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D3_LinearAlgebra/intro_text.html">
   Linear Algebra (W0D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial1.html">
     Tutorial 1: Vectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial2.html">
     Tutorial 2: Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial3.html">
     Bonus Tutorial: Discrete Dynamical Systems
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D4_Calculus/intro_text.html">
   Calculus (W0D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial1.html">
     Tutorial 1: Basics of Differential and Integral Calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial2.html">
     Tutorial 2: Differential Equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial3.html">
     Tutorial 3: Numerical Methods
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../intro_text.html">
   Statistics (W0D5)
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Tutorial 1: Probability Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="W0D5_Tutorial2.html">
     Tutorial 2: Statistical Inference
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Intro to Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D1_ModelTypes/intro_text.html">
   Model Types (W1D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial1.html">
     Tutorial 1: “What” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial2.html">
     Tutorial 2: “How” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial3.html">
     Tutorial 3: “Why” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/outro_vid.html">
     Intro Video
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D2_ModelingPractice/intro_text.html">
   Modeling Practice (W1D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_ModelingPractice/student/W1D2_Tutorial1.html">
     Tutorial: Framing the Question
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D3_ModelFitting/intro_text.html">
   Model Fitting (W1D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial1.html">
     Tutorial 1: Linear regression with MSE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial2.html">
     Tutorial 2: Linear regression with MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial3.html">
     Tutorial 3: Confidence intervals and bootstrapping
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial4.html">
     Tutorial 4: Multiple linear regression and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial5.html">
     Tutorial 5: Model Selection: Bias-variance trade-off
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial6.html">
     Tutorial 6: Model Selection: Cross-validation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D4_MachineLearning/intro_text.html">
   Machine Learning (W1D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_MachineLearning/student/W1D4_Tutorial1.html">
     Tutorial 1: GLMs for Encoding
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_MachineLearning/student/W1D4_Tutorial2.html">
     Tutorial 2: Classifiers and regularizers
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D5_DimensionalityReduction/intro_text.html">
   Dimensionality Reduction (W1D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial1.html">
     Tutorial 1: Geometric view of data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial2.html">
     Tutorial 2: Principal Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial3.html">
     Tutorial 3: Dimensionality Reduction &amp; Reconstruction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial4.html">
     Tutorial 4:  Nonlinear Dimensionality Reduction
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D1_DeepLearning/intro_text.html">
   Deep Learning (W2D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial3.html">
     Tutorial 2: Building and Evaluating Normative Encoding Models
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D2_LinearSystems/intro_text.html">
   Linear Systems (W2D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial1.html">
     Tutorial 1: Linear dynamical systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial2.html">
     Tutorial 2: Markov Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial3.html">
     Tutorial 3: Combining determinism and stochasticity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial4.html">
     Tutorial 4: Autoregressive models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D3_RealNeurons/intro_text.html">
   Real Neurons (W2D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_RealNeurons/student/W2D3_Tutorial1.html">
     Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_RealNeurons/student/W2D3_Tutorial2.html">
     Tutorial 2: Effects of Input Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_RealNeurons/student/W2D3_Tutorial3.html">
     Tutorial 3: Synaptic transmission - Models of static and dynamic synapses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_RealNeurons/student/W2D3_Tutorial4.html">
     Tutorial 4: Spike-timing dependent plasticity (STDP)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D4_DynamicNetworks/intro_text.html">
   Dynamic Networks (W2D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial1.html">
     Tutorial 1: Neural Rate Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial2.html">
     Tutorial 2: Wilson-Cowan Model
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Stochastic Processes
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D1_BayesianDecisions/intro_text.html">
   Bayesian Decisions (W3D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial1.html">
     Tutorial 1: Bayes with a binary hidden state
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial2.html">
     Tutorial 2: Bayesian inference and decisions with continuous hidden state
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial3.html">
     Bonus Tutorial:Fitting to data
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D2_HiddenDynamics/intro_text.html">
   Hidden Dynamics (W3D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial1.html">
     Tutorial 1: Sequential Probability Ratio Test
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial2.html">
     Tutorial 2: Hidden Markov Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial3.html">
     Tutorial 3: 1D Kalman Filter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial4.html">
     Tutorial 4: 2D Kalman Filter
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D3_OptimalControl/intro_text.html">
   Optimal Control (W3D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial1.html">
     Neuromatch Academy: Week 3, Day 3, Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial2.html">
     Tutorial 2: Optimal Control for Continuous State
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D4_ReinforcementLearning/intro_text.html">
   Reinforcement Learning (W3D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial4.html">
     Tutorial 4: From Reinforcement Learning to Planning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D5_NetworkCausality/intro_text.html">
   Network Causality (W3D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial1.html">
     Tutorial 1: Interventions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial2.html">
     Tutorial 2: Correlations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial3.html">
     Tutorial 3: Simultaneous fitting/regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial4.html">
     Tutorial 4: Instrumental Variables
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/W0D5_Statistics/student/W0D5_Tutorial1.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/NeuromatchAcademy/course_content/blob/master/book/W0D5_Statistics/student/W0D5_Tutorial1.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Tutorial 1: Probability Distributions
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-1-stochasticity-and-randomness">
   Section 1: Stochasticity and randomness
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-1-1-intro-to-randomness">
     Section 1.1: Intro to Randomness
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coding-exercise-1-1-create-randomness">
       Coding Exercise 1.1: Create randomness
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-demo-1-1-random-sample-generation-from-uniform-distribution">
       Interactive Demo 1.1: Random Sample Generation from Uniform Distribution
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-1-2-random-walk">
     Section 1.2: Random walk
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coding-exercise-1-2-modeling-a-random-walk">
       Coding Exercise 1.2: Modeling a random walk
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-demo-1-2-varying-parameters-of-a-random-walk">
       Interactive Demo 1.2: Varying parameters of a random walk
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-2-discrete-distributions">
   Section 2: Discrete distributions
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-2-1-binomial-distributions">
     Section 2.1: Binomial distributions
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#think-2-1-binomial-distribution-sampling">
       Think! 2.1: Binomial distribution sampling
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-2-2-poisson-distribution">
     Section 2.2: Poisson Distribution
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coding-exercise-2-2-poisson-distribution-sampling">
       Coding Exercise 2.2: Poisson distribution sampling
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-demo-2-2-varying-parameters-of-poisson-distribution">
       Interactive Demo 2.2: Varying parameters of Poisson distribution
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-3-continuous-distributions">
   Section 3: Continuous distributions
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-3-1-gaussian-distribution">
     Section 3.1: Gaussian Distribution
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coding-exercise-3-1a-gaussian-distribution">
       Coding Exercise 3.1A: Gaussian Distribution
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-demo-3-1-sampling-from-a-gaussian-distribution">
       Interactive Demo 3.1: Sampling from a Gaussian distribution
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bonus-markov-chains">
   Bonus: Markov chains
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/master/tutorials/W0D5_Statistics/student/W0D5_Tutorial1.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<div class="section" id="tutorial-1-probability-distributions">
<h1>Tutorial 1: Probability Distributions<a class="headerlink" href="#tutorial-1-probability-distributions" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 0, Day 5: Statistics</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Ulrik Beierholm</p>
<p><strong>Content reviewers:</strong> Ethan Cheng, Manisha Sinha</p>
<p>Name Surname, Name Surname. This includes both reviewers and editors. Add reviewers first then editors (paper-like seniority :) ).</p>
<hr class="docutils" />
<p>#Tutorial Objectives</p>
<p>We will here cover the basic ideas from probability and statistics, as a reminder of what you have hopefully previously been taught. These ideas will be important for almost every one of the following topics covered in the course.</p>
<p>There are many additional topics within probability and statistics that we will not cover as they are not central to the main course. We also do not have time to get into a lot of details, but hopefully this will help you recall material you have previously encountered.</p>
<p>By completing the exercises in this tutorial, you should:</p>
<ul class="simple">
<li><p>get some intuition about how stochastic randomly generated data can be</p></li>
<li><p>understand how to model data using simple probability distributions</p></li>
<li><p>understand the difference between discrete and continuous probability distributions</p></li>
<li><p>be able to plot a Gaussian distribution</p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<p>Make sure to run this before you get started.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>  <span class="c1"># the normal probability distribution</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Figure settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>    <span class="c1"># interactive display</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">HBox</span><span class="p">,</span> <span class="n">Layout</span><span class="p">,</span> <span class="n">VBox</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">Label</span><span class="p">,</span> <span class="n">interact_manual</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle&quot;</span><span class="p">)</span>
<span class="c1">#plt.style.use(&quot;https://raw.githubusercontent.com/NeuromatchAcademy/course-content/NMA2020/nma.mplstyle&quot;)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Plotting Functions</span>

<span class="k">def</span> <span class="nf">plot_random_sample</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">figtitle</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Plot the random sample between 0 and 1 for both the x and y axes.</span>

<span class="sd">    Args:</span>
<span class="sd">      x (ndarray): array of x coordinate values across the random sample</span>
<span class="sd">      y (ndarray): array of y coordinate values across the random sample</span>
<span class="sd">      figtitle (str): title of histogram plot (default is no title)</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">])</span> <span class="c1"># set x and y axis range to be a bit less than 0 and greater than 1</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">dataX</span><span class="p">,</span> <span class="n">dataY</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">figtitle</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">figtitle</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">plot_random_walk</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">figtitle</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Plots the random walk within the range 0 to 1 for both the x and y axes.</span>

<span class="sd">    Args:</span>
<span class="sd">      x (ndarray): array of steps in x direction</span>
<span class="sd">      y (ndarray): array of steps in y direction</span>
<span class="sd">      figtitle (str): title of histogram plot (default is no title)</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="s1">&#39;b-o&#39;</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">1.1</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">1.1</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x location&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;y location&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;go&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">figtitle</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">figtitle</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">plot_hist</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">xlabel</span><span class="p">,</span> <span class="n">figtitle</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">num_bins</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Plot the given data as a histogram.</span>

<span class="sd">    Args:</span>
<span class="sd">      data (ndarray): array with data to plot as histogram</span>
<span class="sd">      xlabel (str): label of x-axis</span>
<span class="sd">      figtitle (str): title of histogram plot (default is no title)</span>
<span class="sd">      num_bins (int): number of bins for histogram (default is 10)</span>

<span class="sd">    Returns:</span>
<span class="sd">      count (ndarray): number of samples in each histogram bin</span>
<span class="sd">      bins (ndarray): center of each histogram bin</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Count&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">num_bins</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">count</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="n">num_bins</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">count</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">-.</span><span class="mi">5</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">+.</span><span class="mi">6</span><span class="p">))</span> <span class="c1"># 10 bins default</span>
  <span class="k">if</span> <span class="n">figtitle</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">figtitle</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
  <span class="k">return</span> <span class="n">count</span><span class="p">,</span> <span class="n">bins</span>

<span class="k">def</span> <span class="nf">my_plot_single</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">px</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Plots normalized Gaussian distribution</span>

<span class="sd">    Args:</span>
<span class="sd">        x (numpy array of floats):     points at which the likelihood has been evaluated</span>
<span class="sd">        px (numpy array of floats):    normalized probabilities for prior evaluated at each `x`</span>

<span class="sd">    Returns:</span>
<span class="sd">        Nothing.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">px</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">px</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">px</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C2&#39;</span><span class="p">,</span> <span class="n">LineWidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Prior&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Orientation (Degrees)&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_gaussian_samples_true</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">xspace</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">xlabel</span><span class="p">,</span> <span class="n">ylabel</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Plot a histogram of the data samples on the same plot as the gaussian</span>
<span class="sd">  distribution specified by the give mu and sigma values.</span>

<span class="sd">    Args:</span>
<span class="sd">      samples (ndarray): data samples for gaussian distribution</span>
<span class="sd">      xspace (ndarray): x values to sample from normal distribution</span>
<span class="sd">      mu (scalar): mean parameter of normal distribution</span>
<span class="sd">      sigma (scalar): variance parameter of normal distribution</span>
<span class="sd">      xlabel (str): the label of the x-axis of the histogram</span>
<span class="sd">      ylabel (str): the label of the y-axis of the histogram</span>

<span class="sd">    Returns:</span>
<span class="sd">      Nothing.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">)</span>
  <span class="c1"># num_samples = samples.shape[0]</span>

  <span class="n">count</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xspace</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xspace</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">),</span><span class="s1">&#39;r-&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-1-stochasticity-and-randomness">
<h1>Section 1: Stochasticity and randomness<a class="headerlink" href="#section-1-stochasticity-and-randomness" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 1: Stochastic world</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;UCzDNJvChv8&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="section-1-1-intro-to-randomness">
<h2>Section 1.1: Intro to Randomness<a class="headerlink" href="#section-1-1-intro-to-randomness" title="Permalink to this headline">¶</a></h2>
<p>Before trying out different probability distributions, let’s start with the simple uniform distribution, U(a,b), which assigns equal probability to any value between a and b.</p>
<p>To show that we are drawing a random number <span class="math notranslate nohighlight">\(x\)</span> from a uniform distribution with lower and upper bounds <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> we will use this notation:
<span class="math notranslate nohighlight">\(x \sim U(a,b)\)</span>. Alternatively, we can say that all the potential values of <span class="math notranslate nohighlight">\(x\)</span> are distributed as a uniform distribution between <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span>.</p>
<div class="section" id="coding-exercise-1-1-create-randomness">
<h3>Coding Exercise 1.1: Create randomness<a class="headerlink" href="#coding-exercise-1-1-create-randomness" title="Permalink to this headline">¶</a></h3>
<p>Numpy has many functions and capabilities related to randomness.  We can draw random numbers from various probability distributions. For example, to draw 5 uniform numbers between 0 and 100, you would use <code class="docutils literal notranslate"><span class="pre">np.random.uniform(0,</span> <span class="pre">100,</span> <span class="pre">size</span> <span class="pre">=</span> <span class="pre">(5,))</span></code>.</p>
<p>We will use <code class="docutils literal notranslate"><span class="pre">np.random.seed</span></code> to set a specific seed for the random number generator. For example, <code class="docutils literal notranslate"><span class="pre">np.random.seed(0)</span></code> sets the seed as 0. By including this, we are actually making the random numbers reproducible, which may seem odd at first. Basically if we do the below code without that 0, we would get different random numbers every time we run it. By setting the seed to 0, we ensure we will get the same random numbers. There are lots of reasons we may want randomness to be reproducible. In NMA-world, it’s so your plots will match the solution plots exactly!</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">random_nums</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,))</span>
</pre></div>
</div>
<p>Below, you will complete a function <code class="docutils literal notranslate"><span class="pre">generate_random_sample</span></code> that randomly generates <code class="docutils literal notranslate"><span class="pre">num_points</span></code> <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> coordinate values, all within the range 0 to 1. You will then generate 10 points and visualize.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_random_sample</span><span class="p">(</span><span class="n">num_points</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Generate a random sample containing a desired number of points (num_points)</span>
<span class="sd">  in the range [0, 1] using a random number generator object.</span>

<span class="sd">  Args:</span>
<span class="sd">    num_points (int): number of points desired in random sample</span>

<span class="sd">  Returns:</span>
<span class="sd">    dataX, dataY (ndarray, ndarray): arrays of size (num_points,) containing x</span>
<span class="sd">    and y coordinates of sampled points</span>

<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1">###################################################################</span>
  <span class="c1">## TODO for students: Draw the uniform numbers</span>
  <span class="c1">## Fill out the following then remove</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student exercise: need to complete generate_random_sample&quot;</span><span class="p">)</span>
  <span class="c1">###################################################################</span>

  <span class="c1"># Generate desired number of points uniformly between 0 and 1 (using uniform) for</span>
  <span class="c1">#     both x and y</span>
  <span class="n">dataX</span> <span class="o">=</span> <span class="o">...</span>
  <span class="n">dataY</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">dataX</span><span class="p">,</span> <span class="n">dataY</span>

<span class="c1"># Set a seed</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Set number of points to draw</span>
<span class="n">num_points</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Draw random points</span>
<span class="n">dataX</span><span class="p">,</span> <span class="n">dataY</span> <span class="o">=</span> <span class="n">generate_random_sample</span><span class="p">(</span><span class="n">num_points</span><span class="p">)</span>

<span class="c1"># Visualize</span>
<span class="n">plot_random_sample</span><span class="p">(</span><span class="n">dataX</span><span class="p">,</span> <span class="n">dataY</span><span class="p">,</span> <span class="s2">&quot;Random sample of 10 points&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_0e972635.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=560 height=422 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W0D5_Statistics/static/W0D5_Tutorial1_Solution_0e972635_0.png>
</div>
<div class="section" id="interactive-demo-1-1-random-sample-generation-from-uniform-distribution">
<h3>Interactive Demo 1.1: Random Sample Generation from Uniform Distribution<a class="headerlink" href="#interactive-demo-1-1-random-sample-generation-from-uniform-distribution" title="Permalink to this headline">¶</a></h3>
<p>In practice this may not look very uniform, although that is of course part of the randomness! Uniform randomness does not mean smoothly uniform. When we have very little data it can be hard to see the distribution.</p>
<p>Below, you can adjust the number of points sampled with a slider. Does it look more uniform now? Try increasingly large numbers of sampled points.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title</span>

<span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>

<span class="k">def</span> <span class="nf">generate_random_sample</span><span class="p">(</span><span class="n">num_points</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Generate a random sample containing a desired number of points (num_points)</span>
<span class="sd">  in the range [0, 1] using a random number generator object.</span>

<span class="sd">  Args:</span>
<span class="sd">    num_points (int): number of points desired in random sample</span>

<span class="sd">  Returns:</span>
<span class="sd">    dataX, dataY (ndarray, ndarray): arrays of size (num_points,) containing x</span>
<span class="sd">    and y coordinates of sampled points</span>

<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1"># Generate desired number of points uniformly between 0 and 1 (using uniform) for</span>
  <span class="c1">#     both x and y</span>
  <span class="n">dataX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_points</span><span class="p">,))</span>
  <span class="n">dataY</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_points</span><span class="p">,))</span>

  <span class="k">return</span> <span class="n">dataX</span><span class="p">,</span> <span class="n">dataY</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span>
<span class="k">def</span> <span class="nf">gen_and_plot_random_sample</span><span class="p">(</span><span class="n">num_points</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">SelectionSlider</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;</span><span class="si">%g</span><span class="s2">&quot;</span><span class="o">%</span><span class="k">i</span>,i) for i in np.arange(0, 2000, 10)])):

  <span class="n">dataX</span><span class="p">,</span> <span class="n">dataY</span> <span class="o">=</span> <span class="n">generate_random_sample</span><span class="p">(</span><span class="n">num_points</span><span class="p">)</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">dataX</span><span class="p">,</span> <span class="n">dataY</span><span class="p">)</span>
  <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Random sample of &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_points</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; points&quot;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="section-1-2-random-walk">
<h2>Section 1.2: Random walk<a class="headerlink" href="#section-1-2-random-walk" title="Permalink to this headline">¶</a></h2>
<p>Stochastic models can be used to create models of behaviour. As an example, imagine that a rat is placed inside a novel environment, a box. We could try and model its exploration behaviour by assuming that for each time step it takes a random uniformly sampled step in any direction (simultaneous random step in x direction and random step in y direction)</p>
<div class="section" id="coding-exercise-1-2-modeling-a-random-walk">
<h3>Coding Exercise 1.2: Modeling a random walk<a class="headerlink" href="#coding-exercise-1-2-modeling-a-random-walk" title="Permalink to this headline">¶</a></h3>
<p>Use the <code class="docutils literal notranslate"><span class="pre">generate_random_sample</span></code> function from above to obtain the random steps the rat takes at each time step and complete the generate_random_walk function below. For plotting, the box will be represented graphically as the unit square enclosed by the points (0, 0) and (1, 1).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_random_walk</span><span class="p">(</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">step_size</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Generate the points of a random walk within a 1 X 1 box.</span>

<span class="sd">  Args:</span>
<span class="sd">    num_steps (int): number of steps in the random walk</span>
<span class="sd">    step_size (float): how much each random step size is weighted</span>

<span class="sd">  Returns:</span>
<span class="sd">    x, y (ndarray, ndarray): the (x, y) locations reached at each time step of the walk</span>

<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

  <span class="c1">###################################################################</span>
  <span class="c1">## TODO for students: Collect random step values with function from before</span>
  <span class="c1">## Fill out the following then remove</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student exercise: need to complete generate_random_walk&quot;</span><span class="p">)</span>
  <span class="c1">###################################################################</span>

  <span class="c1"># Generate the uniformly random x, y steps for the walk</span>
  <span class="n">random_x_steps</span><span class="p">,</span> <span class="n">random_y_steps</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># Take steps according to the randomly sampled steps above</span>
  <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">):</span>

    <span class="c1"># take a random step in x and y. We remove 0.5 to make it centered around 0</span>
    <span class="n">x</span><span class="p">[</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">random_x_steps</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">*</span><span class="n">step_size</span>
    <span class="n">y</span><span class="p">[</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">random_y_steps</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">*</span><span class="n">step_size</span>

    <span class="c1"># restrict to be within the 1 x 1 unit box</span>
    <span class="n">x</span><span class="p">[</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span><span class="p">[</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

<span class="c1"># Set a random seed</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Select parameters</span>
<span class="n">num_steps</span> <span class="o">=</span> <span class="mi">100</span>   <span class="c1"># number of steps in random walk</span>
<span class="n">step_size</span> <span class="o">=</span> <span class="mf">0.5</span>   <span class="c1"># size of each step</span>

<span class="c1"># Generate the random walk</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">generate_random_walk</span><span class="p">(</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">step_size</span><span class="p">)</span>

<span class="c1"># Visualize</span>
<span class="n">plot_random_walk</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;Rat&#39;s location throughout random walk&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_84dec82b.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=560 height=422 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W0D5_Statistics/static/W0D5_Tutorial1_Solution_84dec82b_0.png>
<p>We put a little green dot for the starting point and a red point for the ending point.</p>
</div>
<div class="section" id="interactive-demo-1-2-varying-parameters-of-a-random-walk">
<h3>Interactive Demo 1.2: Varying parameters of a random walk<a class="headerlink" href="#interactive-demo-1-2-varying-parameters-of-a-random-walk" title="Permalink to this headline">¶</a></h3>
<p>In the interactive demo below, you can examine random walks with different numbers of steps or step sizes, using the sliders. Make sure to hit “Run Simulation” after each change.</p>
<ol class="simple">
<li><p>What could an increased step size mean for the actual rat’s movement we are simulating?</p></li>
<li><p>For a given number of steps, is the rat be more likely to visit all general areas of the arena with a big step size or small step size?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>
<span class="k">def</span> <span class="nf">gen_and_plot_random_walk</span><span class="p">(</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">step_size</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">generate_random_walk</span><span class="p">(</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">step_size</span><span class="p">)</span>
  <span class="n">plot_random_walk</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;Rat&#39;s location throughout random walk&quot;</span><span class="p">)</span>


<span class="n">widget</span><span class="o">=</span><span class="n">interactive</span><span class="p">(</span><span class="n">gen_and_plot_random_walk</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;manual&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">},</span>
                <span class="n">num_steps</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="n">step_size</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">))</span>

<span class="n">widget</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;Run Simulation&#39;</span>
<span class="n">widget</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">button_color</span><span class="o">=</span><span class="s1">&#39;lightgreen&#39;</span>
<span class="n">controls</span> <span class="o">=</span> <span class="n">HBox</span><span class="p">(</span><span class="n">widget</span><span class="o">.</span><span class="n">children</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">layout</span><span class="o">=</span><span class="n">Layout</span><span class="p">(</span><span class="n">flex_flow</span><span class="o">=</span><span class="s1">&#39;row wrap&#39;</span><span class="p">))</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">widget</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">display</span><span class="p">(</span><span class="n">VBox</span><span class="p">([</span><span class="n">controls</span><span class="p">,</span> <span class="n">output</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_6e912c89.py"><em>Click for solution</em></a></p>
<p>In practice a uniform random movement is too simple an assumption. Rats do not move completely randomly; even if you could assume that, you would need to approximate with a more complex probability distribution.</p>
<p>Nevertheless, this example highlights how you can use sampling to approximate behaviour.</p>
<p><strong>Main course preview:</strong> On day W3D2 we will see how random walk models can be used to also model accumulation of information in decision making.</p>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-2-discrete-distributions">
<h1>Section 2: Discrete distributions<a class="headerlink" href="#section-2-discrete-distributions" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 2: Discrete distributions</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;-_5DtYgwtaA&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>The uniform distribution is very simple, and can only be used in some rare cases. If we only had access to this distribution, our statistical toolbox would be very empty. Thankfully we do have some more advanced distributions!</p>
<p>The uniform distribution that we looked at above is an example of a continuous distribution. The value of <span class="math notranslate nohighlight">\(X\)</span> that we draw from this distribution can take <strong>any value</strong> between <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span>.</p>
<p>However, sometimes we want to be able to look at discrete events. Imagine that the rat from before is now placed in a T-maze, with food placed at the end of both arms. Initially, we would expect the rat to be choosing randomly between the two arms, but after learning it should choose more consistently.</p>
<p>A simple way to model such random behaviour is with a single <strong>Bernoulli trial</strong>, that has two outcomes, {<span class="math notranslate nohighlight">\(Left, Right\)</span>}, with probability <span class="math notranslate nohighlight">\(P(Left)=p\)</span> and <span class="math notranslate nohighlight">\(P(Right)=1-p\)</span> as the two mutually exclusive possibilities (whether the rat goes down the left or right arm of the maze).</p>
<div class="section" id="section-2-1-binomial-distributions">
<h2>Section 2.1: Binomial distributions<a class="headerlink" href="#section-2-1-binomial-distributions" title="Permalink to this headline">¶</a></h2>
<p>The binomial distribution simulates <span class="math notranslate nohighlight">\(n\)</span> number of binary events, such as the <span class="math notranslate nohighlight">\(Left, Right\)</span> choices of the random rat in the T-maze. Imagine that you have done an experiment and found that your rat turned left in 7 out of 10 trials. What is the probability of the rat turning left 7 times (<span class="math notranslate nohighlight">\(k = 7\)</span>)?</p>
<p>This is given by:</p>
<div class="math notranslate nohighlight">
\[\begin{split} P(k|n,p)= \left( \begin{array} \\n \\ k\end{array} \right) p^k (1-p)^{n-k}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\binom {n}{k}={\frac {n!}{k!(n-k)!}}\]</div>
<p>In this formula, <span class="math notranslate nohighlight">\(p\)</span> is the probability of turning left, <span class="math notranslate nohighlight">\(n\)</span> is the number of binary events, or trials, and <span class="math notranslate nohighlight">\(k\)</span> is the number of times the rat turned left. The term <span class="math notranslate nohighlight">\(\binom {n}{k}\)</span> is the binomial coefficient.</p>
<p>If we assume an equal chance of turning left or right, then <span class="math notranslate nohighlight">\(p=0.5\)</span>. Note that if we only have a single trial <span class="math notranslate nohighlight">\(n=1\)</span> this is equivalent to a single Bernoulli trial (feel free to do the math!).</p>
<div class="section" id="think-2-1-binomial-distribution-sampling">
<h3>Think! 2.1: Binomial distribution sampling<a class="headerlink" href="#think-2-1-binomial-distribution-sampling" title="Permalink to this headline">¶</a></h3>
<p>We will draw a desired number of random samples from a binomial distribution, with <span class="math notranslate nohighlight">\(n = 10\)</span> and <span class="math notranslate nohighlight">\(p = 0.5\)</span>. Each sample returns the number of trials, <span class="math notranslate nohighlight">\(k\)</span>, a rat turns left out of <span class="math notranslate nohighlight">\(n\)</span> trials.</p>
<p>We will draw 1000 samples of this (so it is as if we are observing 10 trials of the rat, 1000 different times). We can do this using numpy: <code class="docutils literal notranslate"><span class="pre">np.random.binomial(n,</span> <span class="pre">p,</span> <span class="pre">size</span> <span class="pre">=</span> <span class="pre">(n_samples,))</span></code></p>
<p>See below to visualize a histogram of the different values of <span class="math notranslate nohighlight">\(k\)</span>, or the number of times the rat turned left in each of the 1000 samples and discuss the following questions.</p>
<ol class="simple">
<li><p>What are the x-axis limits of the histogram and why?</p></li>
<li><p>What is the shape of the histogram?</p></li>
<li><p>Looking at the histogram, how would you interpret the outcome of the simulation if you didn’t know what p was? Would you have guessed p = 0.5?</p></li>
<li><p>What do you think the histogram would look like if the probability of turning left is 0.8 (<span class="math notranslate nohighlight">\(p = 0.8\)</span>)?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to see visualization</span>

<span class="c1"># Select parameters for conducting binomial trials</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># Set random seed</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Now draw 1000 samples by calling the function again</span>
<span class="n">left_turn_samples_1000</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,))</span>

<span class="c1"># Visualize</span>
<span class="n">count</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="n">plot_hist</span><span class="p">(</span><span class="n">left_turn_samples_1000</span><span class="p">,</span> <span class="s1">&#39;Number of left turns in sample&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>What are the limits for this histogram? How would you describe the shape?</p>
<p>Looking at the histogram, how would you interepret the outcome of the simulation? Do you think it is likely that the rat chose with equal probability?</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_06a79c9b.py"><em>Click for solution</em></a></p>
<p>Note that in the more general case where there are <span class="math notranslate nohighlight">\(n\)</span> possible outcomes (our rat is an n-armed maze) each with their own associated probability <span class="math notranslate nohighlight">\(p_1, p_2, p_3, p_4, ...\)</span> , we do have to make sure that the probabilities sum to one:</p>
<div class="math notranslate nohighlight">
\[\sum_i P(x=i)=\sum_i p_i =1\]</div>
<p>This is the <strong>categorical distribution</strong>; draws from this distribution are a simple extension of the Bernoulli trial.</p>
<p>If we sample from this distribution multiple times, we can then describe the distribution of outcomes from each sample as the <strong>multinomial distribution</strong> (generalisation from the binomial distribution).</p>
</div>
</div>
<div class="section" id="section-2-2-poisson-distribution">
<h2>Section 2.2: Poisson Distribution<a class="headerlink" href="#section-2-2-poisson-distribution" title="Permalink to this headline">¶</a></h2>
<p>For some phenomena there may not be a natural limit on the maximum number of possible events or outcomes.</p>
<p>The Poisson distribution is a ‘<strong>point-process</strong>’, meaning that it determines the number of discrete ‘point’, or binary, events that happen within a fixed space or time, allowing for the occurence of a potentially infinite number of events. The Poisson distribution is specified by a single parameter <span class="math notranslate nohighlight">\(\lambda\)</span> that encapsulates the mean number of events that can occur in a single time or space interval (there will be more on this concept of the ‘mean’ later!). The formula for a Poisson distribution on x is:</p>
<div class="math notranslate nohighlight">
\[P(x)=\frac{\lambda^x e^{-\lambda}}{x!}\]</div>
<p>Relevant to us, we can model the number of times a neuron spikes within a time interval using a Poisson distribution. In fact, neuroscientists often do! As an example, if we are recording from a neuron that tends to fire at an average rate of 4 spikes per second, then the Poisson distribution specifies the distribution of recorded spikes over one second, where <span class="math notranslate nohighlight">\(\lambda=4\)</span>.</p>
<div class="section" id="coding-exercise-2-2-poisson-distribution-sampling">
<h3>Coding Exercise 2.2: Poisson distribution sampling<a class="headerlink" href="#coding-exercise-2-2-poisson-distribution-sampling" title="Permalink to this headline">¶</a></h3>
<p>In the exercise below we will draw some samples from the Poisson distribution and see what the histogram looks.</p>
<p>In the code, fill in the missing line so we draw 5 samples from a Poisson distribution with <span class="math notranslate nohighlight">\(\lambda = 4\)</span>. Use <code class="docutils literal notranslate"><span class="pre">np.random.poisson</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set random seed</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Draw 5 samples from a Poisson distribution with lambda = 4</span>
<span class="n">sampled_spike_counts</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># Print the counts</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The samples drawn from the Poisson distribution are &quot;</span> <span class="o">+</span>
          <span class="nb">str</span><span class="p">(</span><span class="n">sampled_spike_counts</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_90422623.py"><em>Click for solution</em></a></p>
<p>You should see that the neuron spiked 6 times, 7 times, 1 time, 8 times, and 4 times in 5 different intervals.</p>
</div>
<div class="section" id="interactive-demo-2-2-varying-parameters-of-poisson-distribution">
<h3>Interactive Demo 2.2: Varying parameters of Poisson distribution<a class="headerlink" href="#interactive-demo-2-2-varying-parameters-of-poisson-distribution" title="Permalink to this headline">¶</a></h3>
<p>Use the interactive demo below to vary <span class="math notranslate nohighlight">\(\lambda\)</span> and the number of samples, and then visualize the resulting histogram.</p>
<ol class="simple">
<li><p>What effect does increasing the number of samples have?</p></li>
<li><p>What effect does changing <span class="math notranslate nohighlight">\(\lambda\)</span> have?</p></li>
<li><p>With a small lambda, why is the distribution asymmetric?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">lambda_value</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
                  <span class="n">n_samples</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">gen_and_plot_possion_samples</span><span class="p">(</span><span class="n">lambda_value</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
  <span class="n">sampled_spike_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">lambda_value</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
  <span class="n">count</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="n">plot_hist</span><span class="p">(</span><span class="n">sampled_spike_counts</span><span class="p">,</span> <span class="s1">&#39;Recorded spikes per second&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_faea9d3e.py"><em>Click for solution</em></a></p>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-3-continuous-distributions">
<h1>Section 3: Continuous distributions<a class="headerlink" href="#section-3-continuous-distributions" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 3: Continuous distributions</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;nAYbAXDF9h4&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>We do not have to restrict ourselves to only probabilistic models of discrete events. While some events in neuroscience are discrete (e.g. number of spikes by a neuron), many others are continuous (e.g. neuroimaging signals in EEG or fMRI, distance traveled by an animal, human pointing in a direction of a stimulus).</p>
<p>With continuous distributions we have to replace the normalising sum $<span class="math notranslate nohighlight">\(\sum_i P(x=p_i) =1\)</span><span class="math notranslate nohighlight">\( over all possible events, with an integral
\)</span><span class="math notranslate nohighlight">\(\int_a^b P(x) =1\)</span><span class="math notranslate nohighlight">\( where a and b are the limits of the random variable \)</span>X<span class="math notranslate nohighlight">\( (often \)</span>-\infty<span class="math notranslate nohighlight">\( and \)</span>\infty$).</p>
<p>If we want to make predictions about possible outcomes (“I believe the BOLD signal from the area will be in the range <span class="math notranslate nohighlight">\(x_1\)</span> to <span class="math notranslate nohighlight">\( x_2 \)</span>“) we can use the integral <span class="math notranslate nohighlight">\(\int_{x_1}^{x_2} P(x) =1\)</span>.
<span class="math notranslate nohighlight">\(P(x)\)</span> is now a probability density function.</p>
<p>While for discrete outcomes we can ask about the probability of an specific event (“what is the probability this neuron will fire 4 times in the next second”), this is not defined for a continuous distribution (“what is the probability of the BOLD signal being exactly 4.000000000…”). Hence we need to focus on intervals when calculating probabilities from a continuous distribution.</p>
<div class="section" id="section-3-1-gaussian-distribution">
<h2>Section 3.1: Gaussian Distribution<a class="headerlink" href="#section-3-1-gaussian-distribution" title="Permalink to this headline">¶</a></h2>
<p>(<em><strong>Exercise moved  from NMA2020 Bayes day, all credit to original creators!)</strong></em></p>
<p>The most widely used continuous distribution is probably the Gaussian (also known as Normal) distribution. It is extremely common across all kinds of statistical analyses. Because of the central limit theorem, many quantities are Gaussian distributed. Gaussians also have some nice mathematical properties that permit simple closed-form solutions to several important problems.</p>
<p>As a working example, imagine that a human participant is asked to point in the direction where they perceived a sound coming from. As an approximation, we can assume that the variability in the direction/orientation they point towards is Gaussian distributed.</p>
<div class="section" id="coding-exercise-3-1a-gaussian-distribution">
<h3>Coding Exercise 3.1A: Gaussian Distribution<a class="headerlink" href="#coding-exercise-3-1a-gaussian-distribution" title="Permalink to this headline">¶</a></h3>
<p>In this exercise, you will implement a Gaussian by filling in the missing portions of code for the function <code class="docutils literal notranslate"><span class="pre">my_gaussian</span></code> below. Gaussians have two parameters. The <strong>mean</strong> <span class="math notranslate nohighlight">\(\mu\)</span>, which sets the location of its center, and its “scale” or spread is controlled by its <strong>standard deviation</strong> <span class="math notranslate nohighlight">\(\sigma\)</span>, or <strong>variance</strong> <span class="math notranslate nohighlight">\(\sigma^2\)</span> (i.e. the square of standard deviation). <strong>Be careful not to use one when the other is required.</strong></p>
<p>The equation for a Gaussian is:
$<span class="math notranslate nohighlight">\(
\mathcal{N}(\mu,\sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(\frac{-(x-\mu)^2}{2\sigma^2}\right)
\)</span><span class="math notranslate nohighlight">\(
Also, don't forget that this is a probability distribution and should therefore sum to one. While this happens &quot;automatically&quot; when integrated from \)</span>-\infty<span class="math notranslate nohighlight">\( to \)</span>\infty$, your Gaussian will only be computed over a finite number of points (for the cell below we will sample from -8 to 9 in step sizes of 0.1). You therefore need to explicitly normalize it to sum to one yourself.</p>
<p>Test out your implementation with a <span class="math notranslate nohighlight">\(\mu = -1\)</span> and <span class="math notranslate nohighlight">\(\sigma = 1\)</span>. After you have it working, play with the parameters to develop an intuition for how changing <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> alter the shape of the Gaussian. You may want to revisit this when learning about Bayesian statistics in the main course.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_gaussian</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Returns normalized Gaussian estimated at points `x_points`, with</span>
<span class="sd">  parameters: mean `mu` and standard deviation `sigma`</span>

<span class="sd">  Args:</span>
<span class="sd">      x_points (ndarray of floats): points at which the gaussian is evaluated</span>
<span class="sd">      mu (scalar): mean of the Gaussian</span>
<span class="sd">      sigma (scalar): standard deviation of the gaussian</span>

<span class="sd">  Returns:</span>
<span class="sd">      (numpy array of floats) : normalized Gaussian evaluated at `x`</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1">###################################################################</span>
  <span class="c1">## TODO for students: Implement the formula for a Gaussian</span>
  <span class="c1">## Add code to calculate the gaussian px as a function of mu and sigma,</span>
  <span class="c1">## for every x in x_points</span>
  <span class="c1">## Function Hints: exp -&gt; np.exp()</span>
  <span class="c1">##                 power -&gt; z**2</span>
  <span class="c1">##</span>
  <span class="c1">## Fill out the following then remove</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student exercise: need to implement Gaussian&quot;</span><span class="p">)</span>
  <span class="c1">###################################################################</span>
  <span class="n">px</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># as we are doing numerical integration we may have to remember to normalise</span>
  <span class="c1"># taking into account the stepsize (0.1)</span>
  <span class="n">px</span> <span class="o">=</span> <span class="n">px</span><span class="o">/</span><span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">px</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">px</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="c1"># Generate Gaussian</span>
<span class="n">px</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Visualize</span>
<span class="n">my_plot_single</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">px</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_f415a4a6.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=557 height=414 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W0D5_Statistics/static/W0D5_Tutorial1_Solution_f415a4a6_1.png>
</div>
<div class="section" id="interactive-demo-3-1-sampling-from-a-gaussian-distribution">
<h3>Interactive Demo 3.1: Sampling from a Gaussian distribution<a class="headerlink" href="#interactive-demo-3-1-sampling-from-a-gaussian-distribution" title="Permalink to this headline">¶</a></h3>
<p>Now that we have gained a bit of intuition about the shape of the Gaussian, let’s imagine that a human participant is asked to point in the direction of a sound source, which we then measure in horizontal degrees. To simulate that we draw samples from a Normal distribution:</p>
<div class="math notranslate nohighlight">
\[x \sim \mathcal{N}(\mu,\sigma) \]</div>
<p>We can sample from a Gaussian with mean mu and standard deviation sigma using <code class="docutils literal notranslate"><span class="pre">np.random.normal(mu,</span> <span class="pre">sigma,</span> <span class="pre">size</span> <span class="pre">=</span> <span class="pre">(n_samples,))</span></code>.</p>
<p>In the demo below, you can change the mean and standard deviation of the Gaussian, and the number of samples, we can compare the histogram of the samples to the true analytical distribution (in red).</p>
<ol class="simple">
<li><p>With what number of samples would you say that the full distribution (in red) is well approximated by the histogram?</p></li>
<li><p>What if you just wanted to approximate the variables that defined the distribution, i.e. mean and variance?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>


<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">5</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
                  <span class="n">standard_dev</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
                  <span class="n">n_samples</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">gen_and_plot_normal_samples</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">standard_dev</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">standard_dev</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,))</span>
  <span class="n">xspace</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
  <span class="n">plot_gaussian_samples_true</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">xspace</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">standard_dev</span><span class="p">,</span>
                            <span class="s1">&#39;orientation (degrees)&#39;</span><span class="p">,</span> <span class="s1">&#39;probability&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Main course preview:</strong> Gaussian distriutions are everywhere and are critical for filtering, linear systems (W2D2), optimal control (W3D3) and almost any statistical model of continuous data (W3D1, W3D2, etc.).</p>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p>Across the different exercises you should now:</p>
<ul class="simple">
<li><p>have gotten some intuition about how stochastic randomly generated data can be</p></li>
<li><p>understand how to model data using simple distributions</p></li>
<li><p>understand the difference between discrete and continuous distributions</p></li>
<li><p>be able to plot a Gaussian distribution</p></li>
</ul>
<p>For more reading on these topics see:
Textbook</p>
</div>
<hr class="docutils" />
<div class="section" id="bonus-markov-chains">
<h1>Bonus: Markov chains<a class="headerlink" href="#bonus-markov-chains" title="Permalink to this headline">¶</a></h1>
<p>If you have the time, here is an extra exercise.</p>
<p>Next we examine a example Markov chain.
Imagine that a rat is able to move freely between 3 areas: a dark rest area
(1), a nesting area (2) and a bright area for collecting food (3). Every 5 minutes we record the rat’s location. The table below shows the probability of the rat transitioning from one area to another (<span class="math notranslate nohighlight">\(state_i\)</span> to <span class="math notranslate nohighlight">\(state_{i+1}\)</span>).</p>
<p>\begin{array}{|l |  l | l | l |} \hline
state_{i} &amp;P(state_{i+1}=1|state_i=<em>) &amp;P(state_{i+1}=2|state_i=</em>) &amp; P(state_{i+1}=3|state=<em>i*) \ \hline
state</em>{i}=1&amp; 0.2  &amp;0.6 &amp;0.2\
state_{i}=2&amp; .6 &amp;0.3&amp; 0.1\
state_{i}=3&amp; 0.8 &amp;0.2 &amp;0\ \hline
\end{array}</p>
<p>We are modeling this as a Markov chain, so the animal is only in one of the states at a time and can transition between the states.</p>
<p>If the animal starts in area 2, what is the probability the animal will again be in area 2 when we check on it 20 minutes (4 transitions) later?</p>
<p>Fill in the transition matrix below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">###################################################################</span>
<span class="c1">## TODO for student: Fill transition matrix with table values</span>
<span class="c1">## Fill out the following then remove</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student exercise: need to fill transition matrix&quot;</span><span class="p">)</span>
<span class="c1">###################################################################</span>

<span class="c1"># Fill out transition matrix with matching table values</span>
<span class="c1"># in the form np.array([ [...], [...], [...] ])</span>
<span class="n">transition_matrix</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># Initial state, x0</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="c1"># Then multiply initial state by the matrix 4 times, or equivalently raise the</span>
<span class="c1"># matrix to the 4th power before multiplying it to the initial state</span>
<span class="n">x4</span> <span class="o">=</span> <span class="n">x0</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_power</span><span class="p">(</span><span class="n">transition_matrix</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="c1"># The second area is indexed as 1 (Python starts indexing at 0)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The probability the rat will be in area 2 after 4 transitions is: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x4</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_e52c73c6.py"><em>Click for solution</em></a></p>
<p>You should get a probability of 0.4311, i.e. there is a 43.11% chance that you will find the rat in area 2 in 20 minutes.</p>
<p>What is the average amount of time spent by the rat in each of the states Implicit in the question is the idea that we can start off with a random initial state and then measure how much relative time is spent in each area. If we make a few assumptions (e.g. ergodic system) we can instead start with an initial random distribution and see how that changes after 100 time steps/transitions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize random initial distribution</span>
<span class="n">x_random</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span><span class="o">/</span><span class="mi">3</span>

<span class="c1">###################################################################</span>
<span class="c1">## TODO for student: Fill compute the state matrix after 100 transitions</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student exercise: need to complete computation below&quot;</span><span class="p">)</span>
<span class="c1">###################################################################</span>

<span class="c1"># Fill in the missing line to get the state matrix after 100 transitions, like above</span>
<span class="n">x_average_time_spent</span> <span class="o">=</span> <span class="o">...</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The proportion of time spend by the rat in each of the three states is: &quot;</span>
            <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x_average_time_spent</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_f7d895fb.py"><em>Click for solution</em></a></p>
<p>The proportion of time spend in each of the three areas are 0.4473, 0.4211, and 0.1316, respectively.</p>
<p>If the animal is satiated and tired the transitions change to:</p>
<p>\begin{array}{|l |  l | l | l |} \hline
state_{i} &amp;P(state_{i+1}=1|state_i=<em>) &amp;P(state_{i+1}=2|state_i=</em>) &amp;P(state_{i+1}=3|state_i=*) \ \hline
state_{i}=1&amp; 0.2  &amp;0.7 &amp;0.1\
state_{i}=2&amp; .3 &amp;0.7&amp; 0.\
state_{i}=3&amp; 0.8 &amp;0.2 &amp;0\ \hline
\end{array}</p>
<p>Try repeating the questions above for this table of transitions by changing the transition matrix. See how much time the rat spends on average in each area.
What would you predict?</p>
<p><strong>Main course preview:</strong> The Markov property is extremely important for many models, particularly Hidden Markov Models, discussed on day W3D2, and for methods such as Markov Chain Monte Carlo sampling.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./W0D5_Statistics/student"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../intro_text.html" title="previous page">W0D5 - Statistics</a>
    <a class='right-next' id="next-link" href="W0D5_Tutorial2.html" title="next page">Tutorial 2: Statistical Inference</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Neuromatch<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>