Search.setIndex({"docnames": ["prereqs/ComputationalNeuroscience", "projects/ECoG/ECoG_videos", "projects/ECoG/README", "projects/README", "projects/behavior_and_theory/README", "projects/behavior_and_theory/behavior_and_theory_videos", "projects/docs/ECoG", "projects/docs/behavior_and_theory", "projects/docs/datasets_overview", "projects/docs/fMRI", "projects/docs/neurons", "projects/docs/project_2020_highlights", "projects/docs/project_guidance", "projects/docs/projects_2020/behavior", "projects/docs/projects_2020/eeg", "projects/docs/projects_2020/fMRI", "projects/docs/projects_2020/neurons", "projects/docs/projects_2020/theory", "projects/fMRI/README", "projects/fMRI/fMRI_videos", "projects/modelingsteps/ModelingSteps_1through4", "projects/modelingsteps/ModelingSteps_5through10", "projects/modelingsteps/TrainIllusionDataProject", "projects/modelingsteps/TrainIllusionModel", "projects/modelingsteps/intro", "projects/neurons/README", "projects/neurons/neurons_videos", "tutorials/Bonus_Autoencoders/chapter_title", "tutorials/Bonus_Autoencoders/student/Bonus_Intro", "tutorials/Bonus_Autoencoders/student/Bonus_Outro", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial1", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial2", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial3", "tutorials/Module_WrapUps/DynamicalSystems", "tutorials/Module_WrapUps/MachineLearning", "tutorials/Module_WrapUps/StochasticProcesses", "tutorials/Schedule/daily_schedules", "tutorials/Schedule/schedule_intro", "tutorials/Schedule/shared_calendars", "tutorials/Schedule/timezone_widget", "tutorials/TechnicalHelp/Discord", "tutorials/TechnicalHelp/Jupyterbook", "tutorials/TechnicalHelp/Links_Policy", "tutorials/TechnicalHelp/Tutorial_colab", "tutorials/TechnicalHelp/Tutorial_kaggle", "tutorials/TechnicalHelp/tech_intro", "tutorials/W0D0_NeuroVideoSeries/chapter_title", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial1", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial10", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial11", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial12", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial2", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial3", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial4", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial5", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial6", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial7", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial8", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial9", "tutorials/W0D1_PythonWorkshop1/chapter_title", "tutorials/W0D1_PythonWorkshop1/student/W0D1_Tutorial1", "tutorials/W0D2_PythonWorkshop2/chapter_title", "tutorials/W0D2_PythonWorkshop2/student/W0D2_Tutorial1", "tutorials/W0D3_LinearAlgebra/chapter_title", "tutorials/W0D3_LinearAlgebra/student/W0D3_DaySummary", "tutorials/W0D3_LinearAlgebra/student/W0D3_Outro", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial1", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial2", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial3", "tutorials/W0D4_Calculus/chapter_title", "tutorials/W0D4_Calculus/student/W0D4_DaySummary", "tutorials/W0D4_Calculus/student/W0D4_Tutorial1", "tutorials/W0D4_Calculus/student/W0D4_Tutorial2", "tutorials/W0D4_Calculus/student/W0D4_Tutorial3", "tutorials/W0D5_Statistics/chapter_title", "tutorials/W0D5_Statistics/student/W0D5_DaySummary", "tutorials/W0D5_Statistics/student/W0D5_Outro", "tutorials/W0D5_Statistics/student/W0D5_Tutorial1", "tutorials/W0D5_Statistics/student/W0D5_Tutorial2", "tutorials/W1D1_ModelTypes/chapter_title", "tutorials/W1D1_ModelTypes/further_reading", "tutorials/W1D1_ModelTypes/student/W1D1_DaySummary", "tutorials/W1D1_ModelTypes/student/W1D1_Intro", "tutorials/W1D1_ModelTypes/student/W1D1_Outro", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial1", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial2", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial3", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial4", "tutorials/W1D2_ModelFitting/chapter_title", "tutorials/W1D2_ModelFitting/further_reading", "tutorials/W1D2_ModelFitting/student/W1D2_DaySummary", "tutorials/W1D2_ModelFitting/student/W1D2_Intro", "tutorials/W1D2_ModelFitting/student/W1D2_Outro", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial1", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial2", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial3", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial4", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial5", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial6", "tutorials/W1D3_GeneralizedLinearModels/chapter_title", "tutorials/W1D3_GeneralizedLinearModels/further_reading", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_DaySummary", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Intro", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Outro", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Tutorial1", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Tutorial2", "tutorials/W1D4_DimensionalityReduction/chapter_title", "tutorials/W1D4_DimensionalityReduction/further_reading", "tutorials/W1D4_DimensionalityReduction/student/W1D4_DaySummary", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Intro", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Outro", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial1", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial2", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial3", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial4", "tutorials/W1D5_DeepLearning/chapter_title", "tutorials/W1D5_DeepLearning/further_reading", "tutorials/W1D5_DeepLearning/student/W1D5_DaySummary", "tutorials/W1D5_DeepLearning/student/W1D5_Intro", "tutorials/W1D5_DeepLearning/student/W1D5_Outro", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial1", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial2", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial3", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial4", "tutorials/W2D1_ModelingPractice/chapter_title", "tutorials/W2D1_ModelingPractice/student/W2D1_DaySummary", "tutorials/W2D1_ModelingPractice/student/W2D1_Intro", "tutorials/W2D1_ModelingPractice/student/W2D1_Outro", "tutorials/W2D1_ModelingPractice/student/W2D1_Tutorial1", "tutorials/W2D2_LinearSystems/chapter_title", "tutorials/W2D2_LinearSystems/further_reading", "tutorials/W2D2_LinearSystems/student/W2D2_DaySummary", "tutorials/W2D2_LinearSystems/student/W2D2_Intro", "tutorials/W2D2_LinearSystems/student/W2D2_Outro", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial1", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial2", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial3", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial4", "tutorials/W2D3_BiologicalNeuronModels/chapter_title", "tutorials/W2D3_BiologicalNeuronModels/further_reading", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_DaySummary", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Intro", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Outro", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial1", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial2", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial3", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial4", "tutorials/W2D4_DynamicNetworks/chapter_title", "tutorials/W2D4_DynamicNetworks/further_reading", "tutorials/W2D4_DynamicNetworks/student/W2D4_DaySummary", "tutorials/W2D4_DynamicNetworks/student/W2D4_Intro", "tutorials/W2D4_DynamicNetworks/student/W2D4_Outro", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial1", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial2", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial3", "tutorials/W3D1_BayesianDecisions/chapter_title", "tutorials/W3D1_BayesianDecisions/further_reading", "tutorials/W3D1_BayesianDecisions/student/W3D1_DaySummary", "tutorials/W3D1_BayesianDecisions/student/W3D1_Intro", "tutorials/W3D1_BayesianDecisions/student/W3D1_Outro", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial1", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial2", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial3", "tutorials/W3D2_HiddenDynamics/chapter_title", "tutorials/W3D2_HiddenDynamics/further_reading", "tutorials/W3D2_HiddenDynamics/student/W3D2_DaySummary", "tutorials/W3D2_HiddenDynamics/student/W3D2_Intro", "tutorials/W3D2_HiddenDynamics/student/W3D2_Outro", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial1", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial2", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial3", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial4", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial5", "tutorials/W3D3_OptimalControl/chapter_title", "tutorials/W3D3_OptimalControl/further_reading", "tutorials/W3D3_OptimalControl/student/W3D3_DaySummary", "tutorials/W3D3_OptimalControl/student/W3D3_Intro", "tutorials/W3D3_OptimalControl/student/W3D3_Outro", "tutorials/W3D3_OptimalControl/student/W3D3_Tutorial1", "tutorials/W3D3_OptimalControl/student/W3D3_Tutorial2", "tutorials/W3D4_ReinforcementLearning/chapter_title", "tutorials/W3D4_ReinforcementLearning/further_reading", "tutorials/W3D4_ReinforcementLearning/student/W3D4_DaySummary", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Intro", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Outro", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial1", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial2", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial3", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial4", "tutorials/W3D5_NetworkCausality/chapter_title", "tutorials/W3D5_NetworkCausality/further_reading", "tutorials/W3D5_NetworkCausality/student/W3D5_DaySummary", "tutorials/W3D5_NetworkCausality/student/W3D5_Intro", "tutorials/W3D5_NetworkCausality/student/W3D5_Outro", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial1", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial2", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial3", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial4", "tutorials/intro"], "filenames": ["prereqs/ComputationalNeuroscience.md", "projects/ECoG/ECoG_videos.ipynb", "projects/ECoG/README.md", "projects/README.md", "projects/behavior_and_theory/README.md", "projects/behavior_and_theory/behavior_and_theory_videos.ipynb", "projects/docs/ECoG.md", "projects/docs/behavior_and_theory.md", "projects/docs/datasets_overview.md", "projects/docs/fMRI.md", "projects/docs/neurons.md", "projects/docs/project_2020_highlights.md", "projects/docs/project_guidance.md", "projects/docs/projects_2020/behavior.md", "projects/docs/projects_2020/eeg.md", "projects/docs/projects_2020/fMRI.md", "projects/docs/projects_2020/neurons.md", "projects/docs/projects_2020/theory.md", "projects/fMRI/README.md", "projects/fMRI/fMRI_videos.ipynb", "projects/modelingsteps/ModelingSteps_1through4.ipynb", "projects/modelingsteps/ModelingSteps_5through10.ipynb", "projects/modelingsteps/TrainIllusionDataProject.ipynb", "projects/modelingsteps/TrainIllusionModel.ipynb", "projects/modelingsteps/intro.md", "projects/neurons/README.md", "projects/neurons/neurons_videos.ipynb", "tutorials/Bonus_Autoencoders/chapter_title.md", "tutorials/Bonus_Autoencoders/student/Bonus_Intro.ipynb", "tutorials/Bonus_Autoencoders/student/Bonus_Outro.ipynb", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial1.ipynb", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial2.ipynb", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial3.ipynb", "tutorials/Module_WrapUps/DynamicalSystems.ipynb", "tutorials/Module_WrapUps/MachineLearning.ipynb", "tutorials/Module_WrapUps/StochasticProcesses.ipynb", "tutorials/Schedule/daily_schedules.md", "tutorials/Schedule/schedule_intro.md", "tutorials/Schedule/shared_calendars.md", "tutorials/Schedule/timezone_widget.md", "tutorials/TechnicalHelp/Discord.md", "tutorials/TechnicalHelp/Jupyterbook.md", "tutorials/TechnicalHelp/Links_Policy.md", "tutorials/TechnicalHelp/Tutorial_colab.md", "tutorials/TechnicalHelp/Tutorial_kaggle.md", "tutorials/TechnicalHelp/tech_intro.md", "tutorials/W0D0_NeuroVideoSeries/chapter_title.md", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial1.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial10.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial11.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial12.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial2.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial3.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial4.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial5.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial6.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial7.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial8.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial9.ipynb", "tutorials/W0D1_PythonWorkshop1/chapter_title.md", "tutorials/W0D1_PythonWorkshop1/student/W0D1_Tutorial1.ipynb", "tutorials/W0D2_PythonWorkshop2/chapter_title.md", "tutorials/W0D2_PythonWorkshop2/student/W0D2_Tutorial1.ipynb", "tutorials/W0D3_LinearAlgebra/chapter_title.md", "tutorials/W0D3_LinearAlgebra/student/W0D3_DaySummary.ipynb", "tutorials/W0D3_LinearAlgebra/student/W0D3_Outro.ipynb", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial1.ipynb", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial2.ipynb", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial3.ipynb", "tutorials/W0D4_Calculus/chapter_title.md", "tutorials/W0D4_Calculus/student/W0D4_DaySummary.ipynb", "tutorials/W0D4_Calculus/student/W0D4_Tutorial1.ipynb", "tutorials/W0D4_Calculus/student/W0D4_Tutorial2.ipynb", "tutorials/W0D4_Calculus/student/W0D4_Tutorial3.ipynb", "tutorials/W0D5_Statistics/chapter_title.md", "tutorials/W0D5_Statistics/student/W0D5_DaySummary.ipynb", "tutorials/W0D5_Statistics/student/W0D5_Outro.ipynb", "tutorials/W0D5_Statistics/student/W0D5_Tutorial1.ipynb", "tutorials/W0D5_Statistics/student/W0D5_Tutorial2.ipynb", "tutorials/W1D1_ModelTypes/chapter_title.md", "tutorials/W1D1_ModelTypes/further_reading.md", "tutorials/W1D1_ModelTypes/student/W1D1_DaySummary.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Intro.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Outro.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial1.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial2.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial3.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial4.ipynb", "tutorials/W1D2_ModelFitting/chapter_title.md", "tutorials/W1D2_ModelFitting/further_reading.md", "tutorials/W1D2_ModelFitting/student/W1D2_DaySummary.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Intro.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Outro.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial1.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial2.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial3.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial4.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial5.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial6.ipynb", "tutorials/W1D3_GeneralizedLinearModels/chapter_title.md", "tutorials/W1D3_GeneralizedLinearModels/further_reading.md", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_DaySummary.ipynb", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Intro.ipynb", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Outro.ipynb", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Tutorial1.ipynb", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Tutorial2.ipynb", "tutorials/W1D4_DimensionalityReduction/chapter_title.md", "tutorials/W1D4_DimensionalityReduction/further_reading.md", "tutorials/W1D4_DimensionalityReduction/student/W1D4_DaySummary.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Intro.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Outro.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial1.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial2.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial3.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial4.ipynb", "tutorials/W1D5_DeepLearning/chapter_title.md", "tutorials/W1D5_DeepLearning/further_reading.md", "tutorials/W1D5_DeepLearning/student/W1D5_DaySummary.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Intro.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Outro.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial1.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial2.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial3.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial4.ipynb", "tutorials/W2D1_ModelingPractice/chapter_title.md", "tutorials/W2D1_ModelingPractice/student/W2D1_DaySummary.ipynb", "tutorials/W2D1_ModelingPractice/student/W2D1_Intro.ipynb", "tutorials/W2D1_ModelingPractice/student/W2D1_Outro.ipynb", "tutorials/W2D1_ModelingPractice/student/W2D1_Tutorial1.ipynb", "tutorials/W2D2_LinearSystems/chapter_title.md", "tutorials/W2D2_LinearSystems/further_reading.md", "tutorials/W2D2_LinearSystems/student/W2D2_DaySummary.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Intro.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Outro.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial1.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial2.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial3.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial4.ipynb", "tutorials/W2D3_BiologicalNeuronModels/chapter_title.md", "tutorials/W2D3_BiologicalNeuronModels/further_reading.md", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_DaySummary.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Intro.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Outro.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial1.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial2.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial3.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial4.ipynb", "tutorials/W2D4_DynamicNetworks/chapter_title.md", "tutorials/W2D4_DynamicNetworks/further_reading.md", "tutorials/W2D4_DynamicNetworks/student/W2D4_DaySummary.ipynb", "tutorials/W2D4_DynamicNetworks/student/W2D4_Intro.ipynb", "tutorials/W2D4_DynamicNetworks/student/W2D4_Outro.ipynb", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial1.ipynb", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial2.ipynb", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial3.ipynb", "tutorials/W3D1_BayesianDecisions/chapter_title.md", "tutorials/W3D1_BayesianDecisions/further_reading.md", "tutorials/W3D1_BayesianDecisions/student/W3D1_DaySummary.ipynb", "tutorials/W3D1_BayesianDecisions/student/W3D1_Intro.ipynb", "tutorials/W3D1_BayesianDecisions/student/W3D1_Outro.ipynb", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial1.ipynb", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial2.ipynb", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial3.ipynb", "tutorials/W3D2_HiddenDynamics/chapter_title.md", "tutorials/W3D2_HiddenDynamics/further_reading.md", "tutorials/W3D2_HiddenDynamics/student/W3D2_DaySummary.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Intro.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Outro.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial1.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial2.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial3.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial4.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial5.ipynb", "tutorials/W3D3_OptimalControl/chapter_title.md", "tutorials/W3D3_OptimalControl/further_reading.md", "tutorials/W3D3_OptimalControl/student/W3D3_DaySummary.ipynb", "tutorials/W3D3_OptimalControl/student/W3D3_Intro.ipynb", "tutorials/W3D3_OptimalControl/student/W3D3_Outro.ipynb", "tutorials/W3D3_OptimalControl/student/W3D3_Tutorial1.ipynb", "tutorials/W3D3_OptimalControl/student/W3D3_Tutorial2.ipynb", "tutorials/W3D4_ReinforcementLearning/chapter_title.md", "tutorials/W3D4_ReinforcementLearning/further_reading.md", "tutorials/W3D4_ReinforcementLearning/student/W3D4_DaySummary.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Intro.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Outro.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial1.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial2.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial3.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial4.ipynb", "tutorials/W3D5_NetworkCausality/chapter_title.md", "tutorials/W3D5_NetworkCausality/further_reading.md", "tutorials/W3D5_NetworkCausality/student/W3D5_DaySummary.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Intro.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Outro.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial1.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial2.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial3.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial4.ipynb", "tutorials/intro.ipynb"], "titles": ["Prerequisites and preparatory materials for NMA Computational Neuroscience", "Overview videos", "Guide to choosing an EEG/ECoG/LFP dataset", "Projects", "Guide to choosing a Behavior And Theory dataset", "Overview videos", "ECoG", "Behavior and Theory", "Datasets and Project Templates", "fMRI", "Neurons", "Projects 2020", "Daily guide for projects", "Behavior", "EEG", "fMRI", "Neurons", "Theory", "Guide to choosing an FMRI dataset", "Overview videos", "Modeling Steps 1 - 4", "Modeling Steps 5 - 10", "Example Data Project: the Train Illusion", "Example Model Project: the Train Illusion", "Modeling Step-by-Step Guide", "Guide to choosing a Neurons dataset", "Overview videos", "Autoencoders", "Intro", "Outro", "Tutorial 1: Intro to Autoencoders", "Tutorial 2: Autoencoder extensions", "Tutorial 3: Autoencoders applications", "Dynamical Systems Wrap-Up", "Machine Learning Wrap-Up", "Stochastic Processes Wrap-Up", "General schedule", "Schedule", "Shared calendars", "Timezone widget", "Using discord", "Using jupyterbook", "Quick links and policies", "Using Google Colab", "Using Kaggle", "Technical Help", "Neuro Video Series", "Intro", "Stimulus Representation", "Neurotransmitters", "Neurons to Consciousness", "Human Psychophysics", "Behavioral Readout", "Live in Lab", "Brain Signals: Spiking Activity", "Brain Signals: LFP", "Brain Signals: EEG &amp; MEG", "Brain Signals: fMRI", "Brain Signals: Calcium Imaging", "Python Workshop 1", "Tutorial: LIF Neuron Part I", "Python Workshop 2", "Tutorial 1: LIF Neuron Part II", "Linear Algebra", "Day Summary", "Outro", "Tutorial 1: Vectors", "Tutorial 2: Matrices", "Bonus Tutorial: Discrete Dynamical Systems", "Calculus", "Day Summary", "Tutorial 1: Differentiation and Integration", "Tutorial 2: Differential Equations", "Tutorial 3: Numerical Methods", "Statistics", "Day Summary", "Outro", "Tutorial 1: Probability Distributions", "Tutorial 2: Statistical Inference", "Model Types", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: \u201cWhat\u201d models", "Tutorial 2: \u201cHow\u201d models", "Tutorial 3: \u201cWhy\u201d models", "Tutorial 4: Model Discussions", "Model Fitting", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Linear regression with MSE", "Tutorial 2: Linear regression with MLE", "Tutorial 3: Confidence intervals and bootstrapping", "Tutorial 4: Multiple linear regression and polynomial regression", "Tutorial 5: Model Selection: Bias-variance trade-off", "Tutorial 6: Model Selection: Cross-validation", "Generalized Linear Models", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: GLMs for Encoding", "Tutorial 2: Classifiers and regularizers", "Dimensionality Reduction", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Geometric view of data", "Tutorial 2: Principal Component Analysis", "Tutorial 3: Dimensionality Reduction &amp; Reconstruction", "Tutorial 4:  Nonlinear Dimensionality Reduction", "Deep Learning", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Decoding Neural Responses", "Tutorial 2: Convolutional Neural Networks", "Tutorial 3: Building and Evaluating Normative Encoding Models", "Bonus Tutorial: Diving Deeper into Decoding &amp; Encoding", "Modeling Practice", "Day Summary", "Intro", "Outro", "Tutorial 1: Framing the Question", "Linear Systems", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Linear dynamical systems", "Tutorial 2: Markov Processes", "Tutorial 3: Combining determinism and stochasticity", "Tutorial 4: Autoregressive models", "Biological Neuron Models", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model", "Tutorial 2: Effects of Input Correlation", "Tutorial 3: Synaptic transmission - Models of static and dynamic synapses", "Bonus Tutorial: Spike-timing dependent plasticity (STDP)", "Dynamic Networks", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Neural Rate Models", "Tutorial 2: Wilson-Cowan Model", "Bonus Tutorial: Extending the Wilson-Cowan Model", "Bayesian Decisions", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Bayes with a binary hidden state", "Tutorial 2: Bayesian inference and decisions with continuous hidden state", "Bonus Tutorial: Fitting to data", "Hidden Dynamics", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Sequential Probability Ratio Test", "Tutorial 2: Hidden Markov Model", "Tutorial 3: The Kalman Filter", "Bonus Tutorial 4: The Kalman Filter, part 2", "Bonus Tutorial 5: Expectation Maximization for spiking neurons", "Optimal Control", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Optimal Control for Discrete States", "Tutorial 2: Optimal Control for Continuous State", "Reinforcement Learning", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Learning to Predict", "Tutorial 2: Learning to Act: Multi-Armed Bandits", "Tutorial 3: Learning to Act: Q-Learning", "Tutorial 4: Model-Based Reinforcement Learning", "Network Causality", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Interventions", "Tutorial 2: Correlations", "Tutorial 3: Simultaneous fitting/regression", "Tutorial 4: Instrumental Variables", "Introduction"], "terms": {"welcom": [0, 102, 198], "neuromatch": [0, 12, 20, 30, 31, 32, 33, 34, 35, 42, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 75, 77, 78, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 102, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197, 198], "academi": [0, 2, 18, 20, 30, 31, 32, 33, 34, 35, 42, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 116, 120, 121, 122, 123, 128, 130, 134, 135, 136, 137, 139, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 174, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "we": [0, 2, 4, 12, 20, 21, 22, 23, 30, 31, 36, 38, 44, 60, 62, 67, 68, 73, 77, 78, 82, 84, 85, 86, 91, 93, 94, 95, 96, 97, 98, 102, 104, 109, 111, 112, 113, 114, 118, 120, 121, 122, 123, 126, 128, 132, 134, 135, 136, 137, 141, 143, 144, 145, 146, 150, 152, 153, 154, 158, 160, 161, 162, 166, 168, 169, 170, 171, 172, 176, 178, 179, 183, 185, 186, 187, 188, 190, 192, 194, 195, 196, 197, 198], "re": [0, 12, 20, 21, 23, 32, 44, 60, 62, 66, 67, 71, 72, 73, 78, 84, 91, 96, 98, 104, 105, 109, 111, 112, 114, 120, 121, 122, 123, 128, 135, 137, 145, 152, 153, 154, 161, 169, 170, 172, 178, 185, 194, 195, 197], "realli": [0, 12, 20, 21, 23, 66, 78, 91, 95, 102, 105, 116, 120, 122, 128, 137, 160, 161, 164, 198], "excit": [0, 12, 25, 66, 71, 73, 82, 85, 116, 130, 134, 139, 145, 148, 154, 188], "bring": [0, 4, 22, 160, 183, 185], "wide": [0, 2, 77, 95, 102, 118, 120, 158, 168, 172, 183], "vari": [0, 4, 23, 66, 78, 84, 85, 86, 91, 94, 96, 97, 111, 120, 130, 143, 145, 146, 152, 154, 160, 162, 168, 171, 186, 195], "audienc": [0, 12, 21], "an": [0, 4, 12, 20, 21, 22, 23, 30, 32, 41, 43, 44, 62, 66, 67, 71, 72, 77, 78, 82, 85, 86, 91, 93, 94, 95, 96, 97, 98, 102, 104, 105, 109, 112, 113, 114, 116, 118, 120, 121, 122, 123, 126, 128, 130, 134, 135, 136, 137, 141, 144, 145, 150, 152, 153, 154, 160, 161, 164, 166, 170, 171, 172, 176, 178, 181, 183, 185, 187, 188, 192, 194, 195, 196, 198], "amaz": 0, "set": [0, 2, 4, 12, 20, 21, 22, 23, 28, 44, 109, 166, 190], "lectur": [0, 36, 112, 113, 123, 135, 141, 143, 144, 150, 156, 172, 179], "tutori": [0, 36, 39, 44, 82, 91, 102, 107, 109, 118, 126, 141, 150, 156, 158, 164, 166, 176, 183, 192], "you": [0, 2, 4, 12, 20, 21, 22, 23, 28, 30, 31, 32, 36, 38, 41, 43, 44, 60, 62, 65, 66, 67, 68, 71, 72, 73, 76, 77, 78, 82, 84, 85, 86, 87, 91, 93, 94, 95, 96, 97, 98, 102, 104, 105, 109, 111, 112, 113, 114, 118, 120, 121, 122, 123, 126, 128, 134, 135, 136, 137, 141, 143, 144, 145, 146, 150, 152, 153, 154, 158, 160, 161, 162, 166, 168, 169, 170, 171, 172, 176, 179, 183, 185, 186, 187, 188, 194, 195, 196, 197, 198], "peopl": [0, 12, 20, 22, 23, 89, 98, 128, 130, 185, 194, 196], "ar": [0, 2, 4, 11, 12, 18, 20, 21, 22, 23, 25, 28, 30, 31, 32, 36, 44, 60, 62, 66, 67, 68, 71, 72, 77, 78, 80, 82, 84, 85, 86, 91, 93, 94, 95, 96, 97, 98, 102, 104, 105, 111, 112, 113, 114, 118, 120, 121, 122, 123, 128, 134, 135, 136, 139, 141, 143, 144, 145, 146, 150, 152, 153, 154, 156, 158, 160, 161, 162, 164, 168, 169, 170, 171, 172, 176, 179, 185, 186, 187, 188, 190, 192, 194, 195, 196, 197, 198], "come": [0, 12, 20, 21, 22, 25, 60, 67, 71, 73, 77, 78, 84, 96, 98, 105, 120, 128, 145, 156, 160, 161, 162, 168, 169, 172, 185, 186, 187, 188, 192], "thi": [0, 2, 4, 11, 12, 18, 20, 21, 22, 23, 28, 30, 31, 32, 33, 34, 35, 36, 39, 41, 43, 44, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 82, 84, 85, 86, 87, 91, 93, 94, 95, 96, 97, 98, 102, 104, 105, 109, 111, 112, 113, 114, 118, 120, 121, 122, 123, 128, 134, 135, 136, 137, 141, 143, 144, 145, 146, 150, 152, 153, 154, 156, 158, 160, 161, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 190, 192, 194, 195, 196, 197, 198], "from": [0, 2, 4, 11, 12, 18, 20, 21, 22, 23, 25, 28, 29, 30, 31, 32, 33, 34, 35, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 68, 70, 71, 72, 73, 75, 78, 80, 81, 82, 83, 84, 85, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 154, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 172, 175, 176, 177, 179, 182, 183, 184, 185, 187, 188, 190, 191, 192, 193, 195, 196, 197, 198], "rang": [0, 4, 12, 20, 21, 22, 23, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 93, 95, 96, 97, 98, 102, 104, 105, 111, 113, 114, 118, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "disciplin": [0, 30], "level": [0, 2, 12, 18, 20, 21, 23, 30, 31, 72, 78, 84, 105, 118, 120, 121, 122, 123, 143, 152, 168, 169, 170, 174, 179, 181, 186, 195, 196], "background": [0, 12, 18, 21], "want": [0, 4, 12, 20, 21, 22, 23, 43, 44, 60, 67, 72, 73, 77, 78, 82, 84, 94, 96, 97, 98, 102, 104, 105, 120, 121, 123, 128, 134, 135, 143, 144, 145, 152, 158, 160, 161, 162, 168, 171, 172, 179, 186, 188, 194, 195, 196, 197], "make": [0, 12, 18, 20, 21, 22, 23, 30, 43, 44, 60, 66, 68, 71, 72, 73, 77, 78, 82, 84, 85, 86, 93, 94, 96, 97, 98, 100, 102, 104, 105, 111, 112, 113, 114, 118, 120, 121, 122, 123, 126, 128, 130, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 158, 161, 162, 168, 169, 170, 171, 172, 174, 178, 179, 183, 185, 186, 187, 188, 192, 194, 195, 196, 197, 198], "sure": [0, 12, 20, 21, 23, 44, 66, 68, 72, 73, 77, 78, 84, 86, 93, 94, 104, 111, 112, 113, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 168, 169, 171, 172, 178, 179, 185, 186, 195, 197], "everybodi": 0, "abl": [0, 12, 23, 66, 67, 71, 72, 77, 78, 84, 85, 91, 111, 113, 114, 120, 137, 150, 160, 161, 162, 168, 169, 171, 179, 186, 188, 192, 197], "follow": [0, 12, 20, 21, 22, 23, 28, 30, 31, 32, 36, 44, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 87, 94, 96, 97, 98, 102, 104, 105, 111, 112, 113, 114, 120, 121, 122, 126, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 179, 183, 185, 186, 187, 188, 194, 195, 196, 197], "enjoi": [0, 20, 32, 102, 128, 144], "school": [0, 12, 128, 160, 169, 178, 196], "dai": [0, 20, 22, 28, 30, 31, 32, 60, 62, 66, 67, 68, 71, 77, 78, 82, 84, 85, 86, 87, 91, 93, 94, 95, 96, 97, 98, 102, 104, 105, 109, 111, 112, 113, 114, 118, 120, 121, 122, 123, 126, 128, 130, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 158, 160, 161, 162, 166, 168, 169, 170, 171, 172, 176, 178, 179, 185, 186, 187, 188, 192, 194, 195, 196, 197, 198], "1": [0, 2, 4, 21, 22, 28, 29, 36, 38, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 64, 70, 75, 80, 81, 82, 83, 89, 90, 91, 92, 100, 101, 102, 103, 108, 109, 110, 117, 118, 125, 126, 127, 130, 131, 132, 133, 139, 140, 141, 142, 148, 149, 150, 151, 157, 158, 159, 165, 166, 167, 174, 175, 176, 177, 182, 183, 184, 190, 191, 192, 193], "mean": [0, 12, 20, 21, 22, 23, 30, 31, 32, 36, 62, 66, 68, 71, 72, 73, 77, 78, 85, 86, 94, 95, 96, 97, 98, 102, 104, 105, 109, 111, 112, 113, 118, 120, 121, 122, 123, 126, 128, 134, 135, 137, 141, 143, 146, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 186, 188, 194, 195, 196, 197], "need": [0, 12, 20, 21, 22, 23, 44, 60, 62, 66, 67, 71, 72, 77, 78, 84, 85, 86, 91, 95, 96, 97, 98, 102, 104, 105, 109, 111, 113, 114, 118, 120, 121, 122, 123, 126, 128, 134, 135, 136, 143, 144, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 192, 196, 197, 198], "know": [0, 12, 20, 21, 30, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 95, 98, 102, 104, 105, 121, 122, 128, 134, 136, 143, 145, 146, 160, 161, 162, 169, 171, 172, 176, 179, 183, 186, 187, 194, 195], "basic": [0, 12, 21, 22, 30, 43, 62, 66, 67, 68, 71, 77, 80, 82, 84, 85, 91, 96, 102, 105, 118, 121, 136, 143, 160, 161, 187, 190, 192, 198], "python": [0, 12, 20, 22, 62, 66, 67, 72, 73, 77, 78, 84, 102, 104, 120, 122, 123, 128, 134, 136, 152, 156, 195, 196, 198], "some": [0, 12, 20, 21, 22, 23, 30, 32, 66, 67, 68, 71, 72, 77, 78, 82, 84, 85, 86, 91, 93, 94, 95, 96, 97, 98, 102, 104, 105, 113, 114, 116, 118, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 153, 154, 160, 161, 168, 170, 171, 179, 183, 185, 186, 187, 188, 194, 195, 196, 197], "core": [0, 20, 66, 109, 128, 160, 166, 170, 176, 178, 183], "concept": [0, 4, 12, 20, 21, 32, 60, 68, 71, 73, 77, 86, 91, 97, 102, 105, 111, 112, 137, 141, 144, 145, 146, 152, 153, 158, 160, 161, 166, 178, 179, 183, 185, 187, 192], "exposur": [0, 78], "below": [0, 2, 4, 12, 21, 22, 25, 30, 31, 32, 33, 34, 35, 38, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 94, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 135, 136, 137, 143, 144, 145, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 178, 179, 185, 186, 188, 194, 195, 196, 197], "provid": [0, 2, 4, 12, 20, 21, 25, 30, 32, 60, 62, 66, 67, 78, 82, 85, 86, 89, 91, 94, 102, 104, 111, 112, 120, 121, 122, 123, 126, 136, 141, 144, 145, 150, 152, 154, 158, 161, 162, 166, 168, 169, 170, 171, 172, 176, 178, 179, 183, 185, 194, 195, 196, 197], "more": [0, 2, 4, 12, 20, 21, 22, 23, 30, 31, 32, 36, 60, 62, 66, 67, 68, 71, 72, 77, 78, 82, 84, 85, 86, 91, 93, 95, 96, 97, 98, 102, 104, 109, 112, 113, 114, 118, 120, 121, 122, 123, 128, 134, 137, 141, 143, 145, 152, 153, 158, 162, 164, 168, 169, 170, 171, 172, 178, 179, 183, 185, 186, 187, 188, 194, 195, 196, 197, 198], "detail": [0, 2, 12, 20, 21, 22, 30, 60, 62, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 102, 120, 121, 122, 126, 128, 139, 143, 160, 170, 179, 188], "run": [0, 2, 4, 12, 18, 20, 21, 22, 23, 25, 30, 32, 41, 43, 44, 60, 62, 67, 68, 71, 73, 77, 84, 85, 86, 95, 102, 104, 105, 111, 112, 113, 120, 121, 122, 123, 128, 134, 135, 136, 143, 144, 145, 146, 152, 166, 168, 171, 176, 179, 185, 186, 187, 188, 192, 194, 195, 196, 197], "us": [0, 2, 4, 11, 12, 18, 20, 21, 22, 23, 25, 28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 64, 67, 70, 72, 75, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 107, 108, 109, 110, 111, 112, 117, 118, 119, 121, 122, 123, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 171, 172, 175, 176, 177, 178, 182, 183, 184, 186, 187, 188, 190, 191, 192, 193, 195, 198], "If": [0, 4, 12, 20, 21, 22, 23, 32, 38, 43, 44, 60, 66, 67, 68, 71, 72, 77, 78, 84, 85, 86, 93, 96, 98, 105, 111, 112, 114, 120, 121, 122, 123, 128, 134, 135, 137, 143, 144, 145, 146, 152, 153, 160, 161, 168, 169, 171, 178, 186, 187, 188, 190, 194, 195, 196, 197], "ve": [0, 12, 21, 32, 62, 66, 68, 78, 84, 86, 105, 109, 112, 113, 114, 122, 123, 135, 136, 137, 143, 145, 146, 152, 154, 160, 162, 166, 168, 171, 178, 186, 188, 195, 196, 197], "never": [0, 12, 18, 21, 104, 105, 120, 137, 146, 153, 171, 185, 186, 195], "now": [0, 12, 20, 21, 22, 23, 31, 32, 62, 66, 68, 71, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 102, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 176, 178, 179, 186, 187, 188, 194, 195, 196, 197, 198], "good": [0, 12, 20, 21, 22, 23, 30, 60, 67, 72, 78, 86, 93, 94, 95, 97, 98, 102, 104, 105, 112, 120, 122, 123, 126, 128, 136, 137, 139, 150, 156, 161, 168, 171, 172, 176, 178, 179, 181, 185, 186, 192, 194, 195, 197], "time": [0, 2, 4, 18, 20, 21, 22, 23, 30, 31, 38, 39, 44, 62, 66, 67, 68, 71, 72, 73, 77, 78, 82, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 104, 105, 109, 111, 112, 113, 114, 120, 121, 122, 123, 128, 130, 134, 136, 137, 141, 145, 152, 154, 160, 161, 162, 164, 166, 169, 171, 172, 178, 185, 186, 187, 188, 192, 194, 195, 196, 197, 198], "start": [0, 20, 21, 22, 30, 31, 32, 36, 44, 60, 62, 66, 67, 68, 71, 72, 77, 78, 82, 84, 85, 86, 91, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 118, 120, 121, 122, 128, 134, 135, 136, 137, 141, 143, 144, 145, 150, 152, 153, 154, 156, 160, 161, 166, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197, 198], "practic": [0, 12, 22, 30, 60, 62, 71, 77, 78, 89, 93, 94, 95, 96, 104, 105, 120, 122, 123, 128, 160, 172, 179, 186, 188, 190, 196, 197, 198], "expect": [0, 12, 20, 21, 22, 23, 32, 62, 71, 73, 77, 78, 84, 86, 104, 105, 120, 121, 122, 123, 128, 136, 137, 143, 144, 146, 152, 153, 154, 160, 161, 164, 176, 178, 185, 186, 187, 188, 194, 195, 196], "student": [0, 2, 4, 11, 12, 30, 31, 36, 42, 60, 62, 66, 68, 71, 73, 77, 78, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 105, 111, 112, 113, 114, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 162, 168, 170, 171, 178, 185, 186, 187, 188, 194, 195, 197], "familiar": [0, 2, 12, 25, 71, 78, 136, 153, 196], "variabl": [0, 2, 4, 12, 20, 21, 22, 25, 30, 31, 32, 60, 62, 73, 77, 78, 84, 85, 86, 91, 93, 94, 95, 96, 97, 104, 105, 111, 112, 113, 118, 120, 121, 122, 123, 128, 134, 135, 136, 137, 144, 145, 146, 148, 153, 154, 160, 161, 162, 166, 168, 169, 170, 171, 172, 176, 178, 179, 185, 186, 190, 192, 194, 195], "list": [0, 4, 12, 20, 22, 23, 30, 31, 32, 62, 66, 67, 68, 71, 78, 84, 96, 97, 98, 105, 114, 116, 120, 122, 123, 128, 134, 135, 162, 168, 169, 172, 185, 194, 195, 197], "dict": [0, 23, 84, 96, 97, 98, 104, 105, 120, 121, 122, 123, 169, 171, 186, 187, 188, 196, 197], "numpi": [0, 20, 22, 23, 30, 31, 32, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "scipi": [0, 20, 22, 23, 32, 71, 77, 78, 85, 86, 94, 122, 123, 128, 134, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 187, 188], "librari": [0, 12, 20, 71, 84, 102, 105, 116, 120, 128, 146, 171, 197], "well": [0, 2, 4, 12, 20, 21, 22, 23, 25, 30, 31, 32, 62, 72, 73, 77, 78, 84, 85, 86, 95, 96, 97, 98, 105, 111, 112, 116, 120, 121, 122, 123, 128, 134, 136, 137, 145, 158, 160, 161, 162, 170, 171, 178, 179, 185, 186, 187, 188, 196, 197], "plot": [0, 12, 23, 30, 31, 32], "matplotlib": [0, 20, 22, 23, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "littl": [0, 12, 22, 23, 25, 30, 32, 66, 68, 71, 77, 78, 84, 123, 136, 137, 160, 168, 170, 179, 185, 195], "bit": [0, 20, 22, 30, 71, 72, 73, 77, 78, 84, 85, 86, 104, 123, 134, 160, 161, 186, 188, 195], "everi": [0, 4, 12, 21, 44, 66, 67, 71, 77, 78, 82, 84, 86, 87, 104, 105, 120, 121, 135, 136, 137, 143, 145, 156, 162, 172, 178, 185, 186, 187, 194, 195, 196], "ll": [0, 12, 20, 21, 22, 30, 31, 60, 62, 66, 67, 68, 71, 72, 77, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 109, 111, 112, 113, 114, 120, 121, 122, 123, 132, 145, 152, 154, 160, 161, 162, 166, 168, 169, 172, 176, 178, 185, 194, 195, 196, 197, 198], "great": [0, 12, 18, 21, 25, 30, 72, 73, 78, 82, 85, 94, 102, 104, 156, 186], "shape": [0, 20, 22, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 82, 84, 85, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 122, 123, 128, 135, 141, 144, 145, 146, 150, 152, 153, 154, 161, 162, 168, 169, 171, 172, 178, 179, 185, 187, 188, 194, 195, 196, 197], "class": [0, 22, 30, 31, 66, 67, 84, 85, 93, 104, 105, 120, 121, 122, 123, 171, 178, 179, 187, 188], "have": [0, 2, 4, 12, 20, 21, 22, 23, 25, 28, 30, 31, 32, 36, 38, 41, 43, 44, 60, 66, 67, 68, 71, 72, 73, 77, 78, 82, 84, 85, 86, 93, 94, 95, 96, 97, 98, 102, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 126, 128, 134, 135, 136, 137, 141, 143, 144, 145, 146, 150, 152, 153, 154, 158, 160, 161, 162, 164, 168, 169, 171, 172, 176, 178, 179, 183, 185, 186, 187, 188, 194, 195, 196, 197, 198], "workshop": [0, 12, 36, 60, 62], "w0d1": [0, 72], "w0d2": [0, 72], "here": [0, 4, 12, 20, 21, 22, 23, 30, 32, 33, 34, 35, 36, 40, 42, 44, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 82, 84, 85, 86, 91, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 166, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "should": [0, 2, 4, 12, 20, 21, 22, 23, 25, 38, 44, 60, 62, 67, 68, 71, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 98, 104, 105, 111, 112, 113, 120, 122, 123, 126, 128, 134, 135, 136, 137, 141, 143, 144, 145, 146, 150, 158, 160, 161, 166, 168, 169, 171, 176, 179, 185, 186, 187, 188, 192, 194, 195, 196, 197, 198], "go": [0, 4, 12, 18, 20, 21, 22, 23, 31, 44, 67, 71, 73, 77, 78, 84, 93, 96, 97, 102, 104, 105, 120, 121, 123, 126, 136, 137, 143, 144, 152, 160, 161, 171, 172, 178, 181, 186, 187, 188, 194, 195, 198], "through": [0, 12, 20, 21, 22, 23, 30, 67, 68, 71, 78, 82, 84, 96, 97, 98, 102, 105, 109, 120, 121, 122, 123, 126, 128, 130, 134, 135, 136, 137, 139, 152, 158, 160, 161, 162, 166, 168, 169, 172, 181, 185, 186, 187, 195, 197, 198], "made": [0, 12, 21, 84, 94, 120, 121, 123, 161, 162, 168, 171, 187, 197, 198], "content": [0, 2, 20, 21, 25, 30, 31, 32, 33, 34, 35, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 65, 66, 67, 68, 71, 72, 73, 76, 77, 78, 82, 84, 85, 86, 87, 91, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 116, 120, 121, 122, 123, 128, 134, 135, 136, 137, 141, 143, 144, 145, 146, 150, 152, 153, 154, 158, 160, 161, 162, 166, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "your": [0, 4, 21, 22, 23, 38, 39, 43, 44, 65, 76, 198], "own": [0, 12, 21, 22, 23, 77, 82, 105, 121, 126, 128, 144, 145, 146, 161, 172, 188, 196, 198], "pace": 0, "befor": [0, 12, 20, 21, 22, 30, 36, 60, 62, 65, 67, 68, 71, 73, 76, 77, 78, 82, 84, 85, 86, 93, 94, 97, 98, 104, 105, 112, 114, 120, 123, 128, 136, 137, 143, 145, 146, 152, 153, 160, 168, 170, 171, 172, 176, 178, 179, 185, 186, 187, 188, 196], "besid": [0, 30, 170], "recommend": [0, 12, 44, 114, 123, 160, 190], "softwar": [0, 4, 67, 104], "carpentri": 0, "free": [0, 4, 12, 20, 23, 32, 77, 114, 120, 122, 156, 160, 170, 178, 185, 187, 188], "edx": 0, "research": [0, 2, 4, 12, 20, 21, 22, 23, 30, 32, 43, 82, 91, 118, 120, 128, 174, 188, 190, 195], "For": [0, 2, 12, 20, 21, 23, 25, 30, 31, 32, 62, 66, 67, 68, 71, 73, 77, 78, 85, 86, 87, 93, 95, 96, 98, 104, 105, 109, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 141, 143, 144, 145, 146, 152, 154, 160, 161, 162, 166, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 192, 197], "depth": [0, 30, 31, 89, 112, 122, 156, 161], "intro": [0, 12, 20, 21, 23, 36, 43, 121, 169, 172, 190, 198], "see": [0, 3, 4, 12, 20, 21, 22, 23, 25, 30, 32, 38, 41, 42, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 82, 84, 85, 86, 91, 93, 94, 95, 96, 97, 98, 104, 105, 109, 111, 112, 113, 114, 120, 121, 122, 123, 126, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 154, 160, 161, 162, 166, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 192, 194, 195, 196, 197], "note": [0, 12, 20, 21, 22, 23, 36, 43, 44, 60, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 100, 104, 105, 111, 112, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 156, 160, 161, 162, 168, 169, 170, 171, 172, 174, 178, 179, 185, 190, 194, 195, 196, 197], "final": [0, 21, 30, 31, 32, 44, 66, 78, 82, 93, 95, 96, 98, 102, 104, 105, 109, 111, 112, 118, 122, 141, 144, 145, 146, 150, 153, 160, 161, 168, 171, 172, 178, 179, 183, 185, 188, 197, 198], "can": [0, 2, 4, 12, 18, 20, 21, 22, 23, 28, 30, 31, 32, 36, 41, 43, 44, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 82, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 102, 104, 109, 111, 112, 113, 114, 116, 118, 120, 121, 122, 123, 126, 128, 130, 134, 135, 136, 137, 141, 143, 144, 145, 146, 150, 152, 153, 154, 160, 161, 162, 164, 168, 169, 170, 171, 172, 178, 179, 183, 185, 186, 187, 188, 190, 192, 194, 195, 196, 197, 198], "data": [0, 2, 4, 18, 21, 23, 25, 30, 31, 32, 60, 62, 66, 67, 71, 77, 78, 80, 82, 85, 89, 91, 93, 94, 95, 96, 98, 102, 109, 114, 118, 130, 136, 144, 150, 160, 166, 168, 169, 170, 190, 192, 194, 195, 196, 197, 198], "scienc": [0, 2, 12, 18, 20, 21, 22, 25, 72, 73, 80, 89, 93, 95, 116, 128, 130, 139, 148, 170, 171, 174, 181, 183, 185, 190, 192, 194, 198], "handbook": [0, 80, 185], "which": [0, 2, 12, 18, 20, 21, 22, 23, 25, 28, 30, 31, 32, 36, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 82, 84, 85, 86, 87, 91, 93, 94, 95, 96, 98, 102, 104, 105, 111, 112, 113, 114, 116, 118, 120, 121, 122, 123, 126, 128, 134, 135, 136, 141, 143, 144, 145, 146, 152, 153, 154, 156, 158, 160, 161, 162, 166, 168, 169, 170, 171, 172, 176, 178, 179, 183, 185, 186, 187, 188, 194, 195, 196, 197, 198], "also": [0, 2, 11, 12, 20, 21, 22, 23, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 82, 84, 85, 86, 91, 93, 94, 95, 96, 97, 98, 102, 104, 105, 109, 111, 112, 113, 114, 120, 121, 122, 123, 126, 128, 135, 136, 137, 141, 143, 144, 145, 146, 150, 152, 153, 154, 156, 160, 161, 162, 166, 168, 169, 170, 171, 172, 176, 178, 179, 185, 186, 187, 188, 192, 195, 196, 197], "ha": [0, 2, 4, 12, 18, 20, 21, 22, 23, 30, 31, 32, 33, 34, 35, 43, 44, 66, 68, 71, 72, 73, 77, 78, 82, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 169, 170, 171, 172, 178, 179, 183, 185, 186, 187, 188, 194, 195, 196, 197], "print": [0, 20, 22, 23, 30, 31, 32, 62, 67, 71, 77, 78, 84, 86, 93, 94, 95, 96, 104, 105, 112, 120, 121, 122, 123, 128, 135, 137, 143, 144, 145, 146, 152, 153, 154, 162, 168, 169, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "edit": [0, 12, 36, 43, 72, 73, 162], "matlab": [0, 89, 104], "quickli": [0, 12, 30, 84, 85, 93, 112, 145, 152, 169, 179, 185, 186, 188], "get": [0, 11, 20, 21, 22, 23, 30, 44, 60, 66, 67, 68, 71, 72, 73, 77, 78, 85, 86, 93, 94, 95, 96, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 136, 137, 143, 144, 145, 146, 152, 153, 154, 156, 160, 161, 162, 168, 169, 170, 171, 172, 176, 178, 179, 185, 186, 187, 188, 190, 194, 195, 196, 197], "up": [0, 4, 12, 20, 21, 22, 23, 60, 66, 67, 68, 71, 72, 73, 77, 78, 86, 94, 95, 96, 98, 104, 109, 111, 113, 120, 121, 123, 128, 137, 143, 145, 152, 160, 161, 162, 166, 168, 169, 170, 171, 178, 185, 186, 187, 188, 194, 195, 196, 197, 198], "speed": [0, 22, 60, 85, 104, 116, 123, 170, 174, 185, 186, 188], "cheatsheet": 0, "mai": [0, 12, 21, 22, 23, 30, 31, 32, 44, 60, 62, 66, 67, 71, 72, 73, 77, 78, 84, 85, 86, 95, 96, 98, 105, 113, 114, 116, 120, 121, 122, 123, 128, 134, 135, 136, 141, 143, 144, 145, 146, 150, 160, 161, 162, 168, 169, 171, 178, 179, 185, 186, 187, 188, 192, 195, 196, 197], "paperback": 0, "neural": [0, 12, 18, 22, 28, 30, 72, 77, 78, 80, 84, 85, 86, 89, 91, 100, 102, 104, 107, 109, 113, 116, 118, 128, 130, 139, 141, 144, 145, 148, 158, 164, 166, 168, 169, 170, 172, 174, 181, 190, 195, 198], "both": [0, 12, 20, 22, 23, 30, 31, 32, 36, 66, 71, 72, 77, 78, 85, 96, 97, 98, 105, 111, 112, 113, 121, 123, 134, 135, 136, 141, 143, 144, 145, 153, 154, 160, 161, 166, 169, 171, 178, 179, 185, 186, 187, 194, 196, 197, 198], "version": [0, 2, 4, 12, 25, 28, 30, 31, 32, 43, 60, 66, 73, 78, 104, 109, 111, 122, 136, 162, 166, 170, 172, 192], "analysi": [0, 2, 4, 18, 20, 21, 22, 71, 78, 80, 82, 91, 95, 100, 102, 104, 109, 116, 118, 120, 122, 128, 130, 135, 150, 162, 166, 170, 190, 195, 197], "reli": [0, 12, 21, 22, 23, 91, 93, 95, 160, 161, 171, 196], "linear": [0, 12, 20, 22, 23, 30, 31, 32, 36, 68, 71, 73, 77, 78, 82, 84, 86, 91, 95, 97, 98, 100, 102, 105, 109, 114, 118, 120, 121, 122, 132, 135, 136, 137, 141, 143, 144, 150, 153, 154, 166, 169, 170, 178, 190, 197, 198], "algebra": [0, 60, 67, 68, 78, 93, 96, 109, 130, 134, 171, 198], "probabl": [0, 12, 20, 21, 22, 23, 30, 38, 82, 84, 85, 91, 94, 98, 102, 104, 105, 122, 123, 126, 136, 144, 145, 146, 158, 166, 169, 170, 171, 172, 178, 183, 185, 186, 187, 188, 192, 196, 198], "statist": [0, 4, 21, 62, 77, 89, 91, 95, 97, 100, 104, 121, 135, 141, 143, 144, 146, 150, 152, 158, 161, 164, 166, 169, 170, 172, 178, 179, 192, 194, 198], "calculu": [0, 72, 73, 93, 134, 143, 153, 198], "deriv": [0, 21, 30, 60, 72, 78, 82, 86, 89, 94, 95, 98, 105, 118, 120, 134, 135, 152, 153, 154, 161, 168, 171, 183, 185, 186], "od": [0, 60, 134, 145], "highli": [0, 21, 97, 120, 146, 152, 190], "our": [0, 12, 20, 21, 22, 23, 30, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 82, 84, 85, 86, 93, 94, 95, 96, 97, 98, 102, 104, 105, 111, 113, 114, 120, 121, 122, 123, 126, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 158, 160, 161, 162, 166, 168, 169, 170, 171, 172, 176, 178, 179, 183, 185, 186, 187, 188, 195, 196], "refresh": [0, 68, 104, 111, 112, 113, 161, 162, 178, 179, 198], "w0d3": [0, 78, 91, 102], "w0d4": [0, 82], "w0d5": [0, 82, 91, 102, 158, 161], "ask": [0, 12, 22, 23, 25, 32, 36, 72, 77, 82, 84, 98, 105, 137, 145, 161, 192, 194, 195, 196, 198], "question": [0, 21, 25, 30, 32, 66, 67, 68, 72, 73, 77, 78, 82, 84, 85, 86, 87, 91, 95, 102, 113, 118, 120, 122, 123, 126, 141, 143, 144, 145, 150, 152, 160, 161, 169, 170, 178, 192, 194, 195, 198], "discord": [0, 12, 36], "grasp": 0, "along": [0, 12, 20, 66, 67, 71, 84, 93, 95, 111, 112, 120, 121, 153, 154, 161, 162, 186], "crucial": [0, 12, 20, 21, 32, 91, 123, 128, 152, 176], "almost": [0, 20, 77, 78, 91, 105, 120, 136, 146, 160, 187, 188, 194], "anyth": [0, 22, 43, 72, 120, 123, 126, 137, 145, 162, 171, 185, 186], "quantit": [0, 20, 21, 104, 121, 128, 130, 139, 152], "involv": [0, 21, 71, 78, 104, 118, 120, 122, 135, 161, 178, 188], "than": [0, 12, 20, 21, 22, 25, 30, 32, 60, 62, 68, 71, 72, 77, 78, 84, 86, 93, 94, 96, 97, 98, 104, 113, 114, 120, 121, 122, 123, 128, 134, 135, 137, 143, 144, 145, 146, 154, 158, 160, 161, 162, 168, 170, 171, 172, 178, 179, 185, 186, 187, 188, 190, 195, 196, 197], "one": [0, 2, 4, 12, 18, 20, 21, 22, 23, 25, 30, 31, 36, 43, 44, 62, 66, 67, 68, 71, 73, 77, 78, 82, 84, 85, 86, 87, 91, 93, 94, 95, 96, 97, 98, 102, 104, 105, 111, 112, 118, 120, 121, 122, 123, 126, 128, 130, 134, 135, 136, 137, 143, 145, 146, 152, 153, 154, 160, 161, 162, 164, 168, 169, 170, 171, 172, 178, 179, 183, 185, 186, 187, 188, 192, 194, 195, 197, 198], "number": [0, 20, 22, 30, 31, 32, 44, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 98, 104, 105, 109, 111, 112, 114, 120, 121, 122, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 156, 160, 161, 168, 169, 170, 171, 172, 178, 179, 185, 186, 188, 190, 194, 197], "vector": [0, 22, 23, 30, 31, 32, 67, 68, 71, 78, 84, 91, 93, 94, 95, 96, 97, 98, 102, 104, 105, 112, 113, 114, 120, 121, 122, 123, 134, 135, 137, 143, 144, 145, 146, 152, 154, 161, 162, 168, 169, 170, 172, 178, 194, 195], "matrix": [0, 20, 22, 30, 68, 71, 72, 78, 97, 98, 102, 105, 107, 111, 114, 120, 121, 123, 128, 134, 135, 136, 144, 145, 146, 153, 160, 169, 170, 171, 172, 179, 188, 195, 196, 197], "addit": [0, 12, 18, 20, 21, 25, 30, 31, 32, 36, 60, 62, 66, 73, 77, 85, 96, 97, 102, 104, 105, 121, 128, 134, 143, 144, 154, 161, 170, 171, 172, 179, 187, 188, 197], "multipl": [0, 12, 25, 60, 62, 66, 68, 77, 78, 84, 93, 94, 95, 97, 98, 102, 111, 120, 121, 122, 130, 134, 137, 144, 145, 150, 161, 162, 168, 172, 186, 187, 188, 190, 196, 197], "rank": [0, 112, 120, 130, 195], "base": [0, 2, 4, 12, 20, 21, 22, 30, 66, 67, 68, 71, 73, 77, 78, 86, 94, 95, 96, 98, 100, 104, 109, 112, 113, 116, 120, 126, 128, 134, 135, 137, 146, 150, 152, 153, 160, 161, 164, 168, 169, 170, 171, 172, 179, 181, 185, 186, 187, 190, 192, 198], "determin": [0, 12, 21, 22, 23, 30, 31, 32, 66, 71, 77, 82, 98, 105, 113, 114, 118, 120, 121, 123, 126, 134, 135, 143, 145, 146, 148, 150, 152, 153, 154, 160, 161, 168, 169, 170, 174, 178, 179, 185, 186, 194, 195, 196, 197, 198], "invers": [0, 66, 67, 84, 86, 96, 105, 143, 153, 154, 161, 162, 168, 170, 196, 197], "eigenvalu": [0, 112, 113, 135], "decomposit": [0, 30, 114, 122, 130], "In": [0, 12, 20, 21, 22, 23, 30, 31, 32, 36, 44, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 80, 82, 84, 85, 86, 87, 91, 93, 94, 95, 96, 97, 98, 100, 102, 104, 105, 109, 111, 112, 113, 114, 116, 118, 120, 121, 122, 123, 128, 130, 134, 135, 136, 137, 139, 141, 143, 144, 145, 146, 150, 152, 153, 154, 158, 160, 161, 162, 164, 166, 168, 169, 170, 171, 172, 176, 178, 179, 183, 185, 186, 187, 188, 190, 192, 194, 195, 196, 197, 198], "beauti": [0, 30, 72, 73, 80, 144, 156, 190], "seri": [0, 2, 12, 23, 30, 33, 34, 35, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 71, 72, 73, 78, 82, 84, 85, 86, 93, 94, 95, 96, 97, 98, 102, 104, 105, 137, 141, 143, 144, 168, 169, 171, 188, 190, 197, 198], "anoth": [0, 12, 18, 20, 22, 23, 30, 31, 32, 43, 44, 62, 66, 67, 71, 72, 73, 78, 84, 85, 86, 93, 96, 98, 104, 113, 120, 121, 123, 128, 135, 136, 143, 144, 160, 161, 162, 171, 179, 185, 190, 192, 195, 197], "resourc": [0, 71, 72, 77, 78, 85, 145, 156], "khan": 0, "exercis": [0, 12, 20, 21, 72, 161], "understand": [0, 12, 21, 22, 30, 31, 32, 60, 66, 72, 77, 78, 80, 84, 85, 86, 96, 97, 104, 105, 107, 111, 112, 118, 120, 123, 134, 135, 141, 144, 145, 150, 152, 153, 154, 160, 161, 164, 166, 169, 170, 171, 172, 176, 179, 185, 186, 188, 192, 194, 195, 196, 197], "import": [0, 12, 20, 21, 22, 23, 33, 34, 35, 44, 75, 89, 198], "comfort": [0, 30, 158], "varianc": [0, 60, 77, 78, 93, 94, 95, 96, 98, 105, 111, 112, 144, 161, 168, 169, 170, 179, 186, 194], "normal": [0, 12, 20, 22, 23, 30, 31, 32, 62, 68, 71, 72, 73, 77, 78, 84, 86, 93, 94, 95, 97, 98, 104, 105, 111, 112, 113, 116, 120, 121, 122, 123, 128, 136, 137, 160, 161, 168, 169, 170, 172, 186, 194, 195], "distribut": [0, 4, 12, 20, 22, 25, 30, 31, 32, 60, 62, 82, 85, 91, 93, 95, 97, 98, 102, 104, 105, 121, 122, 128, 136, 137, 141, 143, 144, 145, 158, 166, 168, 169, 170, 172, 181, 185, 186, 195], "select": [0, 2, 4, 12, 30, 31, 32, 44, 62, 77, 78, 84, 91, 93, 94, 95, 96, 113, 120, 123, 130, 148, 160, 161, 176, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "read": [0, 23, 30, 51, 60, 62, 77, 95, 96, 97, 161, 162, 168, 172, 186], "i": [0, 4, 12, 20, 21, 22, 23, 25, 30, 31, 32, 36, 62, 66, 67, 68, 71, 72, 73, 77, 78, 80, 82, 84, 85, 86, 93, 94, 95, 96, 100, 102, 104, 105, 107, 111, 112, 113, 114, 116, 120, 121, 122, 123, 128, 130, 134, 136, 137, 144, 146, 148, 150, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 190, 194, 195, 196, 197], "e": [0, 2, 4, 12, 18, 20, 21, 22, 23, 25, 30, 31, 32, 43, 60, 62, 66, 67, 71, 72, 73, 77, 78, 80, 82, 84, 85, 86, 89, 91, 94, 95, 96, 97, 98, 100, 102, 105, 107, 111, 112, 113, 114, 116, 118, 120, 121, 122, 123, 128, 130, 134, 139, 143, 144, 146, 148, 150, 156, 160, 161, 162, 164, 168, 169, 170, 171, 174, 178, 179, 185, 186, 187, 188, 190, 192, 194, 195, 196], "chapter": [0, 12, 89, 139, 148, 156, 171, 185], "6": [0, 18, 20, 22, 23, 30, 31, 36, 67, 68, 72, 77, 84, 86, 89, 91, 93, 94, 95, 96, 97, 104, 105, 112, 113, 114, 116, 120, 121, 122, 123, 130, 134, 135, 136, 137, 139, 143, 144, 145, 146, 152, 153, 154, 164, 171, 172, 174, 179, 181, 185, 186, 187, 188, 194, 195, 196], "7": [0, 18, 20, 22, 23, 28, 30, 36, 67, 68, 71, 72, 73, 77, 80, 84, 85, 93, 94, 95, 100, 104, 105, 112, 113, 114, 121, 122, 123, 128, 134, 135, 136, 137, 144, 145, 146, 152, 153, 154, 171, 172, 174, 179, 185, 186, 190, 194, 195, 196, 197], "russ": 0, "poldrack": 0, "s": [0, 2, 4, 12, 18, 20, 21, 22, 23, 25, 28, 30, 31, 32, 43, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 80, 82, 84, 85, 86, 89, 91, 93, 94, 95, 96, 100, 102, 104, 105, 107, 111, 112, 113, 116, 120, 123, 126, 128, 130, 134, 135, 136, 137, 139, 141, 143, 144, 145, 146, 148, 152, 153, 154, 156, 160, 161, 162, 166, 168, 169, 171, 172, 174, 176, 178, 179, 181, 183, 185, 186, 187, 188, 190, 192, 194, 195, 196, 197, 198], "book": [0, 12, 80, 104, 143, 156, 172, 190], "think": [0, 12, 21, 22, 23, 60, 68, 71, 82, 96, 97, 98, 102, 105, 109, 113, 120, 126, 128, 141, 156, 161, 168, 169, 170, 171, 178, 179, 187, 188, 194, 196], "21st": 0, "centuri": 0, "what": [0, 11, 12, 20, 21, 22, 23, 25, 30, 31, 60, 62, 67, 68, 72, 77, 78, 82, 85, 86, 87, 89, 93, 94, 96, 97, 98, 102, 104, 111, 112, 113, 114, 116, 118, 120, 122, 123, 126, 128, 134, 135, 136, 137, 143, 145, 146, 148, 150, 152, 153, 154, 158, 161, 162, 166, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 190, 192, 194, 195, 196, 197, 198], "integr": [0, 12, 20, 22, 62, 77, 78, 82, 121, 130, 139, 141, 144, 145, 148, 156, 160, 161, 162, 168, 170, 171, 172, 198], "differenti": [0, 60, 98, 113, 116, 120, 123, 135, 136, 139, 145, 152, 153, 172], "equat": [0, 21, 23, 31, 60, 62, 66, 68, 71, 77, 78, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 121, 122, 123, 135, 136, 137, 143, 144, 145, 146, 152, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 185, 186, 187, 194, 196, 197], "memori": [0, 18, 67, 68, 120, 136, 153, 181, 188], "gilbert": 0, "strang": 0, "studi": [0, 4, 12, 71, 72, 73, 84, 102, 120, 121, 122, 123, 135, 136, 143, 144, 145, 146, 152, 153, 154, 161, 183, 185, 188, 197], "0": [0, 2, 20, 22, 23, 28, 36, 60, 62, 67, 68, 73, 77, 78, 80, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 116, 121, 122, 123, 130, 134, 135, 136, 137, 139, 143, 144, 146, 152, 153, 154, 162, 170, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "includ": [0, 4, 12, 21, 22, 23, 25, 30, 60, 66, 67, 68, 72, 77, 78, 86, 96, 104, 105, 111, 112, 113, 118, 120, 123, 134, 136, 137, 141, 152, 153, 154, 158, 162, 168, 169, 171, 172, 178, 179, 185, 186, 194, 196, 197, 198], "jiri": 0, "lebl": 0, "engin": [0, 2, 21, 30, 72, 73, 116, 130, 164, 176, 179], "outsid": [0, 20, 22, 23, 94, 120, 128, 136, 146], "fundament": [0, 12, 32, 80, 95, 104, 105, 160, 161, 186, 197], "watch": [0, 2, 36, 112, 128, 143, 156, 160, 178, 198], "neuro": [0, 12, 18, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 68, 82, 102, 105, 116, 130, 198], "video": [0, 2, 12, 18, 23, 36, 41, 156], "w0d0": 0, "short": [0, 12, 21, 32, 60, 71, 78, 84, 112, 121, 134, 135, 136, 141, 144, 161, 179], "subject": [0, 4, 12, 18, 32, 91, 153, 160, 162, 168, 171, 174, 185], "brain": [0, 4, 12, 18, 20, 22, 23, 32, 33, 34, 35, 71, 72, 80, 82, 84, 105, 109, 118, 120, 121, 122, 123, 128, 130, 141, 144, 145, 150, 152, 153, 160, 161, 162, 164, 166, 168, 169, 170, 171, 172, 174, 176, 178, 183, 185, 192, 194, 195, 196, 198], "fact": [0, 12, 20, 22, 66, 67, 77, 78, 94, 111, 113, 120, 121, 136, 143, 144, 145, 146, 152, 153, 158, 160, 161, 168, 171, 186, 187, 188, 195, 197], "societi": [0, 190], "so": [0, 12, 20, 22, 23, 60, 66, 67, 68, 71, 72, 73, 77, 78, 82, 84, 85, 86, 87, 91, 93, 94, 95, 96, 97, 98, 102, 104, 105, 109, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 190, 194, 195, 196, 197, 198], "look": [0, 4, 20, 22, 23, 30, 66, 67, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 97, 102, 104, 105, 109, 111, 112, 113, 114, 120, 121, 122, 123, 134, 135, 136, 137, 143, 145, 154, 160, 161, 162, 168, 169, 171, 172, 178, 186, 187, 188, 194, 195, 197, 198], "forward": [0, 31, 32, 73, 121, 122, 123, 136, 152, 171], "meet": [0, 12, 21, 104], "soon": [0, 22, 30], "The": [0, 2, 12, 18, 20, 21, 22, 23, 25, 31, 32, 36, 44, 62, 67, 68, 71, 77, 78, 80, 82, 84, 89, 91, 93, 94, 95, 96, 97, 98, 100, 102, 104, 107, 111, 112, 113, 114, 118, 120, 121, 122, 123, 130, 134, 135, 137, 139, 141, 144, 145, 146, 148, 150, 152, 153, 154, 156, 158, 160, 162, 164, 166, 169, 172, 174, 176, 178, 185, 186, 187, 188, 190, 192, 194, 195, 196, 197, 198], "team": [0, 4, 12, 30, 31, 32, 60, 62, 86, 87, 128, 137, 144, 145], "two": [2, 12, 18, 20, 21, 22, 30, 31, 32, 62, 66, 67, 68, 71, 72, 73, 77, 78, 82, 84, 86, 91, 94, 96, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 135, 137, 139, 143, 144, 145, 146, 150, 153, 154, 158, 160, 161, 162, 166, 168, 169, 171, 172, 176, 178, 179, 185, 186, 187, 188, 195], "type": [2, 12, 20, 21, 22, 30, 36, 60, 66, 68, 71, 72, 73, 78, 84, 85, 87, 91, 96, 97, 102, 104, 105, 109, 114, 118, 120, 121, 122, 123, 126, 128, 130, 135, 136, 137, 139, 144, 145, 146, 150, 152, 154, 170, 172, 186, 188, 190, 195, 198], "each": [2, 4, 12, 20, 21, 22, 23, 25, 30, 31, 32, 36, 38, 41, 43, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 82, 84, 85, 86, 91, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 118, 120, 121, 122, 123, 126, 128, 134, 135, 136, 137, 141, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "lab": 2, "scroll": [2, 4, 25], "down": [2, 4, 12, 20, 21, 25, 44, 71, 72, 73, 77, 85, 120, 122, 128, 137, 152, 172, 187, 188], "paper": [2, 12, 18, 23, 67, 72, 73, 80, 86, 100, 114, 128, 139, 143, 144, 153, 154, 160, 164, 195], "inform": [2, 4, 12, 18, 20, 21, 22, 23, 30, 32, 62, 67, 72, 77, 78, 82, 84, 85, 89, 100, 104, 105, 112, 113, 114, 116, 118, 120, 121, 122, 123, 128, 130, 135, 143, 145, 150, 152, 153, 156, 160, 162, 164, 168, 169, 170, 171, 172, 174, 178, 185, 186, 188], "about": [2, 12, 21, 22, 23, 30, 32, 44, 60, 62, 67, 68, 73, 77, 78, 82, 84, 85, 86, 91, 94, 95, 97, 102, 104, 109, 112, 113, 118, 120, 121, 122, 123, 126, 134, 135, 136, 137, 141, 143, 144, 145, 146, 150, 152, 153, 154, 158, 160, 161, 162, 166, 168, 169, 170, 171, 176, 178, 179, 183, 185, 186, 187, 188, 190, 192, 194, 195, 196, 198], "peterson": 2, "m": [2, 12, 18, 20, 22, 25, 66, 73, 80, 85, 89, 94, 100, 105, 107, 116, 120, 122, 123, 128, 130, 137, 139, 145, 146, 148, 153, 154, 156, 160, 161, 164, 168, 169, 170, 174, 179, 181, 185, 190], "singh": [2, 52], "h": [2, 30, 67, 71, 78, 80, 86, 100, 104, 105, 116, 120, 121, 122, 123, 130, 139, 148, 153, 154, 156, 171, 174, 181], "wang": [2, 67, 130, 139, 148, 181, 185, 186, 187, 188], "n": [2, 18, 20, 22, 23, 25, 30, 31, 60, 62, 66, 68, 71, 72, 73, 77, 78, 80, 84, 86, 89, 93, 94, 95, 96, 97, 98, 100, 104, 105, 107, 111, 112, 113, 116, 120, 121, 122, 123, 128, 130, 134, 136, 137, 139, 143, 144, 145, 146, 148, 152, 153, 154, 156, 160, 161, 162, 168, 169, 170, 171, 172, 174, 178, 179, 181, 185, 186, 187, 188, 190, 194, 195, 196, 197], "x": [2, 12, 20, 22, 23, 25, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 80, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 116, 120, 121, 122, 123, 128, 134, 135, 136, 137, 144, 145, 148, 152, 153, 154, 160, 161, 169, 170, 171, 172, 178, 179, 181, 185, 187, 188, 194, 195, 196, 197], "rao": [2, 130], "r": [2, 18, 20, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 80, 84, 85, 86, 89, 93, 94, 95, 100, 104, 105, 107, 111, 112, 116, 120, 121, 122, 123, 128, 130, 134, 136, 137, 139, 143, 144, 145, 146, 148, 152, 153, 154, 156, 161, 162, 164, 168, 169, 171, 172, 174, 178, 179, 181, 185, 187, 188, 190, 194, 195, 196, 197], "p": [2, 18, 20, 25, 31, 32, 42, 66, 67, 71, 72, 73, 77, 78, 80, 86, 89, 94, 96, 100, 104, 105, 107, 116, 120, 122, 123, 128, 130, 135, 137, 139, 144, 160, 161, 162, 168, 169, 170, 171, 172, 174, 178, 179, 181, 185, 186, 190, 194, 195, 196, 197], "brunton": [2, 33, 130, 134, 135, 136, 137], "b": [2, 12, 18, 20, 21, 22, 23, 25, 30, 31, 62, 66, 67, 68, 71, 73, 77, 80, 84, 85, 86, 87, 94, 95, 100, 104, 107, 111, 112, 116, 120, 123, 130, 134, 135, 136, 137, 139, 143, 144, 145, 146, 148, 152, 153, 154, 156, 160, 161, 162, 168, 169, 170, 171, 172, 174, 178, 179, 185, 186, 188, 190, 194, 195, 196, 197], "w": [2, 18, 30, 66, 67, 68, 71, 73, 78, 80, 89, 100, 105, 111, 112, 113, 116, 120, 121, 122, 123, 130, 139, 148, 152, 154, 156, 164, 169, 170, 174, 181, 190, 196, 197], "2021": [2, 4, 11, 18, 25, 72, 73, 116, 120, 121, 122, 130, 148, 154], "behavior": [2, 12, 18, 20, 21, 30, 71, 73, 80, 82, 85, 86, 89, 91, 100, 102, 118, 122, 128, 134, 135, 136, 143, 146, 148, 152, 153, 154, 158, 160, 162, 168, 170, 172, 179, 181, 183, 185, 186, 187, 188, 192], "naturalist": [2, 122], "arm": [2, 77, 130, 162, 187, 188], "movement": [2, 20, 22, 23, 77, 128, 130, 161, 164, 174, 179, 187], "eneuro": [2, 20, 21, 80, 100, 128], "8": [2, 20, 22, 23, 30, 31, 32, 36, 67, 68, 71, 72, 73, 77, 78, 80, 84, 85, 86, 89, 94, 95, 96, 97, 98, 100, 104, 105, 111, 112, 113, 114, 116, 121, 122, 123, 128, 130, 134, 136, 144, 146, 148, 152, 153, 154, 168, 169, 171, 172, 178, 179, 181, 185, 186, 187, 188, 194, 196, 197], "3": [2, 12, 18, 21, 22, 28, 36, 38, 44, 80, 82, 89, 91, 93, 97, 98, 100, 102, 104, 107, 109, 112, 114, 116, 118, 130, 137, 139, 148, 153, 174, 183, 192], "doi": [2, 18, 20, 21, 25, 72, 73, 80, 89, 100, 107, 116, 128, 130, 139, 144, 148, 153, 154, 164, 174, 181, 190], "10": [2, 12, 18, 20, 22, 23, 25, 30, 31, 32, 66, 68, 71, 72, 73, 77, 78, 80, 84, 85, 86, 89, 93, 94, 95, 96, 97, 98, 100, 104, 105, 107, 112, 113, 114, 116, 120, 121, 122, 123, 128, 130, 134, 136, 137, 139, 143, 144, 145, 146, 148, 152, 153, 154, 161, 162, 164, 168, 169, 172, 174, 178, 179, 181, 185, 186, 187, 188, 190, 194, 195, 196, 197], "1523": [2, 20, 21, 80, 100, 116, 128, 139, 144, 148, 174], "0007": 2, "21": [2, 23, 62, 68, 73, 77, 78, 80, 85, 86, 89, 93, 94, 95, 96, 97, 98, 104, 105, 107, 111, 112, 116, 120, 123, 130, 134, 135, 136, 137, 143, 144, 146, 148, 152, 153, 154, 160, 162, 168, 169, 172, 178, 179, 181, 186, 187, 188, 194, 195, 196, 197], "mine": 2, "human": [2, 18, 30, 32, 72, 77, 116, 118, 120, 121, 130, 136, 137, 160, 161, 168, 181, 183, 185, 190], "long": [2, 12, 31, 66, 68, 84, 120, 136, 143, 145, 146, 171, 178, 186, 197], "term": [2, 12, 21, 30, 31, 60, 66, 67, 71, 73, 77, 78, 84, 86, 96, 98, 104, 112, 120, 121, 122, 123, 134, 135, 136, 137, 141, 144, 146, 150, 152, 153, 154, 160, 168, 170, 179, 185, 187, 197], "record": [2, 4, 12, 20, 22, 25, 62, 66, 67, 72, 77, 78, 84, 85, 86, 91, 96, 100, 104, 105, 107, 111, 118, 120, 121, 122, 123, 130, 139, 143, 144, 145, 146, 153, 170, 171, 172, 179, 186], "journal": [2, 12, 18, 21, 73, 80, 89, 100, 116, 130, 139, 144, 148, 153, 154, 164, 174, 190], "neurosci": [2, 4, 12, 18, 20, 21, 22, 25, 32, 42, 44, 60, 66, 67, 77, 80, 84, 91, 96, 98, 100, 102, 105, 109, 111, 116, 118, 122, 123, 128, 134, 136, 139, 141, 143, 144, 148, 150, 158, 160, 161, 166, 168, 171, 174, 176, 183, 188, 190, 192, 194, 195, 198], "method": [2, 12, 20, 21, 30, 60, 62, 66, 68, 71, 72, 78, 80, 82, 85, 86, 91, 93, 94, 95, 98, 102, 104, 105, 109, 120, 123, 128, 130, 134, 135, 139, 143, 144, 145, 152, 153, 154, 162, 168, 171, 176, 179, 186, 187, 188, 190, 192, 194, 195, 196, 197, 198], "358": 2, "109199": 2, "1016": [2, 12, 18, 25, 80, 89, 100, 107, 116, 130, 139, 148, 153, 154, 164, 174, 181], "j": [2, 12, 18, 25, 30, 31, 32, 60, 62, 66, 67, 68, 71, 78, 80, 89, 96, 100, 104, 105, 107, 112, 116, 130, 139, 144, 148, 153, 154, 156, 160, 164, 169, 171, 172, 174, 179, 181, 185, 190, 194, 195, 196, 197], "jneumeth": [2, 130, 139], "credit": [2, 4, 18, 25, 67], "curat": [2, 4, 18, 25, 198], "nima": 2, "dehghani": 2, "view": [2, 4, 12, 18, 20, 21, 22, 23, 25, 66, 71, 80, 84, 86, 94, 120, 121, 122, 123, 128, 152, 169, 172], "smaller": [2, 60, 68, 71, 73, 86, 105, 120, 121, 122, 123, 137, 144, 145, 146, 153, 154], "youtub": [2, 4, 18, 25, 156], "intracrani": 2, "electrocorticograph": 2, "clinic": [2, 118, 130], "pleas": [2, 12, 20, 21, 30, 31, 32, 39, 40, 43, 44, 60, 62, 65, 67, 68, 76, 82, 84, 85, 86, 87, 91, 93, 97, 104, 105, 114, 120, 121, 123, 152, 154, 158, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 194, 195, 196, 197], "ted": 2, "talk": [2, 12, 66, 86, 91, 94, 102, 121, 176, 192, 197], "yourself": [2, 12, 21, 67, 72, 77, 137, 143, 160, 161, 168, 170, 197], "less": [2, 12, 23, 32, 68, 71, 77, 78, 82, 84, 104, 105, 113, 120, 160, 169, 186, 187, 195, 197], "same": [2, 4, 12, 20, 21, 22, 30, 31, 43, 60, 62, 66, 67, 68, 71, 73, 77, 78, 82, 84, 86, 87, 93, 94, 95, 96, 97, 104, 105, 114, 118, 120, 121, 122, 123, 128, 134, 135, 136, 139, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196], "difficulti": [2, 30], "all": [2, 12, 18, 20, 21, 22, 23, 25, 28, 30, 31, 32, 60, 62, 66, 67, 68, 71, 77, 78, 82, 84, 85, 86, 89, 91, 94, 95, 96, 98, 102, 104, 105, 109, 111, 112, 113, 116, 120, 121, 122, 123, 126, 128, 134, 135, 136, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 185, 186, 187, 188, 192, 194, 195, 196, 197, 198], "group": [2, 4, 18, 20, 22, 25, 43, 66, 67, 84, 85, 86, 87, 122, 123, 126, 128, 146, 178, 185, 192, 197], "standard": [2, 4, 20, 21, 23, 28, 66, 67, 71, 77, 78, 93, 94, 95, 97, 98, 104, 105, 120, 122, 136, 137, 143, 145, 156, 162, 168, 169, 170, 171, 172, 185, 192, 194, 195, 197], "protocol": 2, "particular": [2, 12, 20, 22, 23, 67, 84, 86, 93, 98, 102, 105, 109, 111, 120, 121, 122, 123, 128, 134, 135, 137, 143, 144, 153, 158, 169, 187, 188, 194, 197], "interest": [2, 12, 18, 20, 21, 22, 23, 82, 84, 85, 86, 91, 104, 114, 121, 123, 134, 136, 141, 144, 145, 150, 152, 160, 161, 162, 185, 187, 188, 194, 195, 197], "sensori": [2, 4, 12, 20, 22, 72, 100, 120, 121, 128, 148, 156, 161, 168, 169, 170, 171, 172], "bci": 2, "slightli": [2, 12, 60, 121, 136, 145, 154, 160, 162, 168, 170, 171, 186, 187], "advanc": [2, 4, 18, 20, 25, 67, 77, 78, 89, 98, 100, 116, 128, 130, 153, 158, 164, 170, 196], "definit": [2, 21, 31, 62, 67, 71, 72, 73, 85, 86, 134, 135, 143, 145, 153, 154, 160, 161, 168, 174, 185, 192, 194, 195, 196, 197], "consid": [2, 4, 12, 21, 66, 72, 73, 78, 84, 85, 86, 94, 96, 97, 105, 113, 120, 123, 128, 134, 135, 136, 146, 152, 154, 160, 161, 162, 168, 170, 171, 172, 179, 185, 186, 187, 194, 195, 196, 197], "steinmetz": [2, 4, 86, 105], "much": [2, 12, 20, 21, 22, 23, 31, 60, 62, 68, 71, 72, 73, 77, 78, 85, 86, 93, 98, 102, 104, 105, 112, 113, 114, 118, 120, 121, 126, 143, 145, 146, 160, 161, 162, 168, 171, 172, 179, 185, 186, 190, 195], "better": [2, 12, 20, 21, 22, 30, 31, 32, 60, 62, 66, 68, 71, 72, 78, 82, 91, 93, 94, 98, 104, 105, 109, 114, 120, 121, 122, 123, 128, 134, 137, 144, 146, 150, 153, 160, 161, 168, 170, 171, 178, 179, 185, 186, 192, 195, 196, 197], "suit": [2, 12, 30, 98, 109, 120, 121, 122], "exploratori": [2, 12, 25], "analys": [2, 4, 12, 18, 21, 25, 77, 120, 154, 162, 198], "divers": [2, 12, 21, 25, 80, 82, 116, 123, 152], "topic": [2, 4, 12, 20, 66, 67, 77, 128, 136, 158, 168, 183, 185, 188, 198], "thei": [2, 4, 12, 20, 21, 22, 23, 25, 38, 66, 67, 72, 73, 77, 78, 82, 84, 85, 86, 94, 95, 96, 97, 102, 104, 105, 109, 111, 112, 114, 118, 120, 121, 122, 123, 128, 134, 135, 136, 137, 144, 145, 146, 153, 160, 161, 162, 170, 171, 172, 178, 185, 186, 187, 188, 194, 195, 196, 197], "comput": [2, 4, 12, 20, 21, 22, 23, 30, 42, 44, 60, 62, 66, 68, 71, 77, 80, 84, 89, 91, 94, 95, 100, 104, 105, 109, 111, 113, 116, 120, 121, 123, 128, 130, 134, 137, 139, 141, 145, 148, 150, 158, 161, 162, 164, 166, 168, 170, 171, 172, 174, 176, 178, 179, 183, 185, 186, 187, 190, 196, 198], "becaus": [2, 12, 18, 20, 21, 22, 23, 25, 71, 72, 77, 78, 82, 84, 86, 94, 96, 98, 104, 105, 112, 113, 114, 120, 121, 122, 123, 126, 128, 136, 137, 143, 144, 145, 146, 150, 152, 160, 161, 162, 168, 170, 171, 176, 178, 186, 187, 194, 195, 196, 197], "high": [2, 12, 21, 25, 30, 31, 71, 97, 98, 109, 111, 112, 114, 116, 120, 122, 123, 130, 134, 137, 139, 143, 145, 152, 154, 160, 164, 168, 169, 178, 179, 185, 186, 195, 196], "dimension": [2, 12, 25, 28, 30, 32, 36, 66, 67, 71, 82, 96, 104, 109, 111, 112, 120, 123, 130, 136, 144, 152, 161, 169, 171, 178, 179, 192, 194, 195, 198], "lot": [2, 11, 12, 18, 20, 21, 22, 66, 68, 71, 77, 78, 95, 97, 98, 120, 122, 136, 160, 161, 168, 195, 198], "neuron": [2, 12, 18, 20, 22, 32, 36, 66, 67, 68, 72, 73, 77, 78, 82, 91, 94, 100, 102, 104, 105, 111, 112, 116, 118, 120, 121, 122, 123, 128, 130, 134, 135, 141, 150, 153, 154, 161, 164, 168, 174, 176, 178, 185, 192, 198], "trial": [2, 4, 12, 20, 22, 23, 77, 105, 111, 121, 123, 128, 130, 143, 144, 145, 162, 168, 172, 185, 186, 187, 188, 195, 196, 197], "support": [2, 4, 12, 25, 60, 66, 72, 84, 86, 91, 105, 179, 195], "nma": [2, 11, 12, 22, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 82, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 156, 158, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 183, 185, 186, 187, 188, 194, 195, 196, 197], "been": [2, 12, 20, 21, 22, 23, 43, 44, 66, 68, 72, 77, 78, 95, 97, 98, 102, 111, 112, 120, 121, 122, 123, 128, 136, 145, 146, 152, 153, 154, 160, 161, 162, 164, 171, 172, 178, 185, 188, 194, 195, 197], "annot": [2, 18, 67, 105, 186], "gener": [2, 12, 21, 22, 30, 31, 32, 60, 62, 66, 71, 72, 73, 82, 84, 85, 86, 91, 93, 94, 95, 96, 97, 98, 100, 102, 105, 112, 118, 120, 121, 122, 135, 136, 137, 141, 144, 145, 146, 152, 153, 154, 160, 161, 168, 169, 170, 171, 178, 185, 186, 187, 188, 194, 195, 196, 197, 198], "mariu": [2, 12, 18, 20, 21, 22, 23, 25, 128], "pachitariu": [2, 12, 18, 20, 25, 116, 128], "ta": [2, 36, 73], "faceshous": 2, "joysticktrack": 2, "memorynback": 2, "motorimageri": 2, "exploreajile12": 2, "k": [2, 12, 18, 20, 21, 23, 25, 60, 62, 66, 67, 68, 73, 77, 80, 89, 94, 96, 98, 100, 105, 107, 111, 112, 113, 114, 116, 121, 122, 123, 128, 130, 134, 135, 136, 137, 139, 143, 144, 145, 146, 148, 152, 153, 154, 156, 161, 162, 164, 170, 171, 172, 179, 181, 185, 186, 188, 190, 194, 195, 196, 197], "herm": 2, "d": [2, 18, 20, 21, 22, 23, 25, 30, 60, 66, 67, 68, 71, 72, 73, 80, 89, 93, 96, 100, 104, 105, 107, 116, 122, 123, 128, 130, 136, 137, 139, 143, 148, 152, 153, 154, 156, 164, 169, 170, 171, 172, 174, 179, 181, 185, 187, 188, 190, 195], "pestilli": 2, "f": [2, 18, 20, 22, 23, 28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 144, 145, 146, 149, 150, 151, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197], "wig": 2, "g": [2, 12, 18, 20, 21, 22, 23, 43, 66, 67, 68, 71, 72, 73, 77, 78, 80, 84, 85, 86, 89, 91, 93, 94, 95, 96, 97, 98, 100, 102, 104, 113, 114, 116, 118, 120, 121, 122, 123, 128, 130, 134, 139, 143, 145, 146, 148, 150, 152, 161, 162, 168, 169, 170, 171, 174, 178, 179, 181, 185, 186, 187, 188, 190, 192, 195], "ojemann": [2, 130], "2017": [2, 18, 21, 80, 89, 100, 116, 130, 190], "format": [2, 4, 12, 23, 66, 84, 112, 120, 136, 137, 144, 168, 169, 171, 172, 179, 197], "ventral": [2, 116], "tempor": [2, 21, 100, 104, 116, 130, 143, 144, 153, 170, 171, 187, 188, 197], "cortex": [2, 78, 100, 105, 116, 118, 120, 121, 122, 123, 130, 148, 150, 172, 181], "neurophysiolog": [2, 73, 89, 100, 130, 139, 148, 174], "118": [2, 116], "5": [2, 12, 18, 22, 23, 28, 30, 32, 36, 38, 68, 80, 85, 93, 94, 95, 96, 98, 100, 104, 107, 111, 112, 113, 114, 116, 120, 121, 122, 123, 130, 134, 135, 136, 137, 139, 143, 144, 145, 146, 148, 152, 153, 154, 164, 174, 179, 185, 186, 187, 188, 190, 195, 196], "2614": 2, "2627": 2, "1152": [2, 89, 100, 130, 139, 148, 174], "jn": [2, 89, 100, 130, 139, 148, 174], "00113": 2, "witthoft": 2, "2015": [2, 107, 116, 130, 144, 148, 181, 190], "physiolog": [2, 4, 71, 84, 85, 100, 130, 139], "lobe": 2, "special": [2, 66, 67, 68, 78, 102, 104, 105, 120, 122, 123, 134, 143, 145, 152, 161, 168, 188], "contextu": 2, "novelti": [2, 25], "114": [2, 18, 80, 187], "256": [2, 104, 195], "263": [2, 78], "2fjn": 2, "00131": 2, "schalk": 2, "2016": [2, 80, 100, 107, 114, 116, 130, 181, 190], "spontan": [2, 25, 72, 73, 120, 121, 122, 123], "decod": [2, 12, 22, 30, 31, 32, 67, 94, 100, 102, 109, 118, 121, 144, 156, 164, 198], "object": [2, 18, 22, 23, 78, 116, 118, 166, 176], "cortic": [2, 25, 116, 121, 130, 143, 145, 148, 156], "surfac": [2, 32, 71, 94], "reveal": [2, 116], "complementari": [2, 20, 21, 25, 78, 82], "event": [2, 38, 67, 77, 78, 85, 86, 134, 135, 143, 144, 145, 146, 160, 161, 172], "relat": [2, 4, 12, 18, 20, 21, 30, 32, 66, 67, 71, 72, 73, 77, 84, 97, 100, 102, 105, 113, 122, 130, 134, 135, 136, 139, 152, 153, 154, 160, 161, 168, 170, 174, 194, 196, 198], "potenti": [2, 12, 20, 62, 73, 77, 78, 82, 84, 85, 86, 95, 96, 98, 102, 104, 120, 122, 128, 141, 143, 144, 146, 160, 161, 162, 172, 186, 187, 188, 197], "broadband": 2, "spectral": [2, 12], "chang": [2, 12, 20, 21, 22, 25, 28, 30, 31, 32, 43, 62, 66, 67, 77, 78, 85, 86, 91, 93, 94, 95, 96, 97, 104, 105, 109, 112, 114, 120, 123, 134, 135, 136, 141, 143, 144, 145, 150, 152, 153, 160, 161, 162, 166, 168, 170, 171, 172, 178, 179, 185, 187, 194, 195, 196, 197, 198], "plo": [2, 4, 21, 73, 80, 100, 116, 130, 164], "biologi": [2, 4, 72, 73, 80, 100, 116, 130, 174, 198], "12": [2, 4, 22, 23, 30, 31, 32, 66, 68, 71, 72, 73, 77, 78, 84, 85, 93, 94, 95, 96, 97, 98, 100, 104, 105, 107, 111, 116, 120, 121, 122, 123, 130, 134, 136, 137, 143, 144, 145, 146, 148, 152, 153, 154, 160, 161, 162, 168, 169, 172, 178, 179, 181, 185, 186, 187, 188, 190, 194, 195, 196, 197, 198], "e1004660": 2, "1371": [2, 21, 73, 80, 100, 116, 130, 164], "pcbi": [2, 21, 80, 100, 116, 130], "1004660": 2, "zano": 2, "fetz": 2, "den": [2, 181], "nij": 2, "2009": [2, 18, 80, 89, 130, 139, 148, 171, 174, 190], "decoupl": 2, "power": [2, 12, 31, 77, 78, 93, 95, 96, 102, 114, 120, 153, 161, 162, 168, 172, 197], "spectrum": [2, 143, 145], "real": [2, 12, 20, 22, 32, 66, 68, 78, 82, 85, 86, 91, 93, 96, 105, 112, 113, 121, 123, 134, 137, 143, 152, 154, 161, 168, 171, 179, 188, 190, 195, 196], "represent": [2, 4, 18, 21, 31, 32, 62, 67, 73, 80, 84, 94, 102, 104, 105, 109, 114, 116, 118, 120, 121, 123, 135, 152, 156, 161, 162, 172, 185, 187, 188], "individu": [2, 12, 18, 21, 36, 62, 66, 84, 113, 120, 122, 123, 141, 152, 153, 154, 160, 168, 187, 188, 197, 198], "finger": 2, "29": [2, 23, 66, 73, 77, 84, 86, 93, 96, 97, 98, 100, 104, 113, 116, 120, 122, 123, 134, 135, 136, 144, 145, 146, 152, 153, 162, 168, 170, 171, 178, 179, 185, 186, 187, 188, 194, 195, 197], "3132": 2, "3137": 2, "2fjneurosci": 2, "5506": 2, "08": [2, 12, 66, 68, 93, 104, 181], "honei": 2, "c": [2, 18, 20, 22, 23, 25, 66, 67, 68, 71, 80, 89, 93, 95, 100, 104, 107, 114, 116, 121, 122, 123, 130, 135, 137, 139, 144, 145, 148, 153, 154, 156, 160, 161, 162, 164, 168, 169, 171, 172, 174, 178, 179, 181, 188, 190, 194, 195, 196, 197], "hebb": 2, "A": [2, 4, 12, 18, 20, 21, 22, 23, 25, 28, 30, 32, 60, 62, 66, 67, 72, 77, 80, 84, 85, 86, 89, 91, 98, 100, 104, 105, 107, 116, 118, 120, 121, 128, 130, 135, 136, 139, 143, 144, 145, 146, 148, 152, 153, 156, 160, 164, 168, 170, 171, 172, 174, 178, 179, 181, 185, 186, 188, 194, 196], "o": [2, 60, 66, 71, 72, 73, 77, 93, 96, 100, 104, 105, 112, 113, 116, 120, 121, 122, 123, 130, 135, 144, 145, 153, 154, 156, 168, 170, 172, 187, 188, 190, 194], "ramsei": 2, "knight": 2, "t": [2, 12, 18, 20, 21, 22, 23, 25, 30, 31, 32, 44, 60, 62, 65, 66, 67, 68, 71, 72, 73, 76, 77, 78, 80, 84, 85, 86, 93, 95, 96, 97, 98, 100, 104, 105, 107, 109, 112, 113, 116, 120, 121, 122, 123, 126, 128, 130, 134, 136, 137, 139, 143, 144, 145, 146, 148, 152, 153, 154, 156, 160, 161, 162, 166, 168, 169, 170, 171, 172, 174, 178, 179, 185, 186, 187, 188, 190, 194, 195, 196, 197], "2012": [2, 80, 100, 130, 174], "phase": [2, 30, 97, 121, 122, 123, 134, 150, 152, 185, 188], "entrain": 2, "underli": [2, 22, 66, 67, 82, 93, 94, 105, 107, 109, 130, 137, 148, 150, 161, 164, 171, 172, 185, 195, 198], "rhythm": 2, "e1002655": 2, "1002655": 2, "kubanek": 2, "anderson": 2, "leuthardt": 2, "wolpaw": 2, "2007": [2, 72, 73, 100, 130, 139, 144], "trajectori": [2, 68, 136, 137, 154, 169, 170, 171, 179], "signal": [2, 12, 20, 21, 22, 71, 73, 77, 94, 96, 100, 128, 130, 139, 168, 170, 183, 185, 186, 187, 188, 197], "4": [2, 12, 18, 21, 22, 23, 28, 36, 38, 44, 68, 80, 85, 89, 91, 93, 95, 97, 98, 100, 104, 107, 109, 112, 116, 120, 121, 122, 123, 130, 135, 136, 139, 143, 144, 145, 146, 148, 152, 153, 174, 183, 185, 187, 190, 192], "264": 2, "275": [2, 116, 130, 181], "1088": [2, 100], "1741": 2, "2560": 2, "012": [2, 67, 174], "wilson": [2, 80, 89, 116, 130, 148, 150, 174], "smyth": 2, "2008": [2, 18, 89, 100, 116, 130, 139, 174, 181, 190], "control": [2, 12, 20, 36, 43, 60, 73, 77, 78, 82, 85, 86, 91, 104, 107, 111, 120, 121, 122, 123, 128, 130, 144, 145, 150, 152, 153, 154, 158, 160, 161, 166, 168, 169, 170, 176, 181, 183, 185, 187, 188, 192, 196, 197, 198], "75": [2, 62, 67, 71, 72, 73, 93, 95, 121, 122, 123, 143, 144, 145, 146, 168, 169, 172, 185, 188, 196], "84": [2, 130, 168, 188], "008": [2, 60, 100, 146], "brouwer": 2, "hogervorst": 2, "van": [2, 18, 20, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 66, 67, 72, 73, 77, 78, 116, 128, 130, 139, 148, 168, 181], "erp": [2, 4], "heffelaar": 2, "zimmerman": 2, "oostenveld": 2, "estim": [2, 20, 23, 66, 67, 71, 72, 73, 77, 84, 85, 86, 87, 91, 97, 98, 100, 102, 104, 105, 111, 112, 113, 114, 118, 120, 121, 122, 123, 130, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 160, 168, 169, 171, 172, 178, 179, 185, 186, 187, 188, 190, 192, 198], "workload": 2, "back": [2, 20, 21, 22, 23, 30, 31, 72, 94, 96, 97, 104, 118, 120, 123, 128, 136, 137, 145, 154, 160, 161, 168, 170, 171, 172, 179, 187, 197], "task": [2, 30, 31, 32, 78, 82, 93, 95, 102, 104, 105, 118, 121, 130, 137, 168, 171, 179, 185, 186, 187, 188, 197, 198], "9": [2, 22, 23, 30, 31, 66, 68, 71, 72, 73, 77, 78, 80, 93, 95, 96, 100, 105, 113, 114, 116, 120, 122, 123, 130, 134, 135, 136, 137, 139, 143, 144, 145, 146, 148, 152, 153, 154, 162, 164, 171, 172, 174, 178, 179, 185, 186, 187, 188, 190, 194, 195, 196, 197], "045008": 2, "grissmann": 2, "faller": 2, "scharing": 2, "sp\u00fcler": 2, "gerjet": 2, "electroencephalographi": 2, "work": [2, 12, 18, 20, 21, 22, 23, 25, 30, 44, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 96, 97, 104, 113, 116, 120, 122, 123, 128, 134, 137, 153, 158, 160, 161, 162, 168, 170, 171, 172, 176, 178, 179, 186, 188, 190, 192, 194, 195, 196], "load": [2, 12, 32, 84, 86, 112, 113, 114, 128, 185], "affect": [2, 12, 32, 68, 71, 72, 73, 78, 94, 98, 105, 111, 113, 114, 120, 134, 136, 141, 143, 145, 152, 161, 168, 169, 170, 174, 179, 185, 186, 187, 188, 192, 194, 196, 197, 198], "valenc": 2, "emot": [2, 18], "stimuli": [2, 20, 22, 25, 78, 100, 118, 120, 121, 122, 123, 128, 171, 174], "frontier": [2, 18, 116, 188], "11": [2, 68, 77, 78, 84, 93, 94, 95, 96, 98, 100, 104, 105, 107, 111, 112, 113, 114, 116, 120, 121, 122, 123, 130, 134, 136, 139, 143, 144, 145, 146, 148, 152, 153, 154, 161, 162, 169, 179, 181, 185, 186, 187, 188, 197], "616": [2, 107], "3389": [2, 18, 116], "2ffnhum": 2, "00616": 2, "2010": [2, 31, 89, 100, 164], "dure": [2, 12, 22, 30, 31, 32, 36, 60, 62, 66, 67, 68, 71, 77, 78, 82, 91, 97, 98, 100, 118, 121, 126, 128, 130, 135, 143, 160, 162, 164, 171, 174, 185, 188, 198], "execut": [2, 28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "onlin": [2, 12, 71, 77, 80, 126, 128, 148, 156, 171], "feedback": [2, 12, 36, 130, 174], "proceed": [2, 18, 72, 73, 100, 116, 130, 139, 174], "nation": [2, 18, 72, 73, 116, 130, 139, 174], "107": [2, 153, 169], "4430": 2, "4435": 2, "1073": [2, 18, 72, 73, 116, 130, 139, 174], "pna": [2, 18, 72, 73, 116, 130, 139, 174], "0913697107": 2, "click": [2, 4, 20, 21, 25, 30, 31, 32, 38, 40, 43, 44, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "imag": [2, 4, 25, 30, 31, 62, 66, 68, 78, 94, 105, 109, 113, 114, 116, 118, 120, 121, 122, 123, 166, 171, 192, 194, 198], "full": [2, 4, 12, 21, 22, 23, 25, 30, 31, 32, 42, 68, 71, 72, 73, 77, 78, 85, 94, 95, 104, 112, 116, 120, 121, 122, 123, 126, 156, 160, 168, 179, 187, 195, 196, 197], "browser": [2, 4, 25, 43, 72, 73], "daili": 3, "guid": [3, 20, 21, 36, 40, 67, 80, 82, 105, 123, 126, 128, 136, 161, 166, 198], "combin": [4, 12, 22, 23, 28, 68, 71, 73, 78, 86, 100, 123, 141, 144, 154, 156, 160, 161, 162, 166, 168, 169, 171, 172, 176, 178, 179, 185, 186, 187, 188, 190], "focus": [4, 25, 66, 67, 78, 84, 98, 126, 143, 156, 190], "pure": [4, 12, 78, 136, 154, 172], "where": [4, 12, 20, 21, 22, 23, 30, 43, 44, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 96, 97, 98, 104, 105, 109, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 158, 161, 162, 166, 168, 169, 170, 171, 172, 176, 179, 183, 185, 186, 187, 188, 192, 194, 196, 197], "implement": [4, 12, 20, 30, 31, 32, 60, 62, 66, 67, 71, 73, 77, 86, 93, 94, 95, 96, 104, 111, 114, 120, 121, 122, 123, 134, 135, 136, 143, 145, 153, 154, 160, 161, 166, 168, 169, 176, 185, 188, 195, 197], "like": [4, 11, 12, 20, 21, 22, 23, 25, 30, 31, 62, 66, 67, 71, 72, 73, 77, 78, 82, 84, 85, 86, 87, 93, 94, 98, 102, 104, 105, 114, 116, 118, 120, 121, 122, 123, 126, 128, 135, 136, 137, 143, 145, 146, 152, 153, 158, 160, 161, 162, 166, 168, 169, 170, 171, 178, 179, 183, 185, 186, 187, 188, 194, 195, 197], "usual": [4, 12, 20, 22, 23, 82, 104, 120, 128, 143, 152, 172, 185], "pursu": [4, 12, 21], "rel": [4, 12, 20, 22, 23, 25, 30, 32, 62, 78, 84, 86, 98, 120, 121, 122, 128, 135, 146, 160, 161, 170, 186, 188], "new": [4, 12, 21, 25, 30, 32, 60, 62, 66, 68, 71, 78, 80, 89, 95, 98, 102, 105, 112, 113, 114, 120, 128, 135, 136, 139, 143, 144, 145, 148, 152, 153, 154, 156, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 188, 190, 195], "do": [4, 12, 18, 20, 21, 22, 23, 25, 30, 31, 32, 36, 43, 44, 60, 67, 68, 73, 77, 78, 82, 84, 86, 87, 91, 93, 94, 95, 96, 97, 98, 104, 111, 113, 114, 118, 120, 121, 122, 123, 126, 128, 134, 136, 137, 143, 145, 146, 150, 152, 153, 154, 156, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 190, 192, 194, 195, 196, 197, 198], "compon": [4, 12, 20, 21, 22, 23, 30, 32, 36, 66, 67, 71, 91, 94, 109, 114, 120, 121, 128, 130, 134, 136, 160, 161, 162, 169, 188, 197], "discuss": [4, 12, 20, 28, 36, 66, 67, 71, 72, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 109, 113, 120, 121, 123, 128, 132, 143, 144, 152, 153, 154, 161, 187, 190, 194, 195], "sever": [4, 12, 22, 30, 31, 62, 66, 67, 71, 77, 84, 93, 98, 102, 105, 109, 120, 121, 141, 145, 146, 150, 152, 154, 161, 172, 179, 185, 188, 198], "exampl": [4, 11, 12, 21, 30, 31, 43, 60, 62, 67, 68, 71, 73, 77, 82, 84, 85, 86, 91, 93, 95, 96, 97, 98, 102, 104, 105, 109, 111, 112, 113, 114, 120, 121, 122, 123, 126, 134, 135, 136, 137, 141, 143, 144, 145, 152, 153, 156, 158, 160, 162, 166, 168, 169, 170, 171, 172, 176, 178, 179, 185, 186, 187, 188, 192, 194, 195, 196], "code": [4, 12, 18, 20, 21, 22, 25, 41, 42, 43, 44, 72, 82, 100, 107, 116, 156, 161, 181, 190, 198], "howev": [4, 12, 22, 23, 32, 60, 67, 71, 77, 78, 82, 84, 85, 86, 93, 95, 97, 102, 105, 112, 113, 114, 120, 122, 128, 134, 135, 136, 137, 144, 145, 152, 154, 161, 162, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196], "ani": [4, 12, 20, 21, 22, 23, 30, 31, 44, 60, 66, 67, 68, 71, 72, 77, 78, 82, 84, 86, 91, 94, 97, 98, 104, 105, 112, 113, 114, 116, 120, 121, 122, 123, 128, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 171, 178, 179, 185, 186, 187, 195, 196, 197], "direct": [4, 21, 22, 23, 30, 31, 66, 67, 71, 72, 73, 77, 86, 89, 95, 112, 116, 120, 123, 134, 135, 145, 153, 154, 161, 162, 168, 171, 187, 194, 195], "pose": [4, 12, 118, 198], "track": [4, 12, 30, 31, 32, 62, 68, 120, 122, 123, 135, 143, 166, 170, 185], "interact": [4, 20, 41, 43, 44, 60, 67, 114, 137, 144, 148, 150, 158, 166, 172, 187, 188, 194], "ann": [4, 31, 53, 116], "kennedi": 4, "loader": 4, "notebook": [4, 12, 20, 21, 25, 41, 43, 44, 60, 66, 67, 84, 98, 105, 111, 112, 113, 114, 121, 122, 123, 128, 160, 161, 162, 171, 185, 188, 194, 196, 197], "visual": [4, 12, 18, 20, 21, 22, 23, 32, 60, 62, 66, 67, 68, 72, 73, 77, 78, 85, 86, 93, 94, 95, 96, 97, 98, 100, 104, 105, 109, 111, 112, 116, 118, 128, 130, 134, 135, 136, 137, 143, 144, 145, 148, 150, 153, 154, 160, 162, 166, 168, 169, 170, 171, 172, 174, 178, 179, 185, 186, 187, 194, 195, 196, 197, 198], "veri": [4, 12, 20, 21, 22, 23, 25, 30, 32, 60, 67, 68, 71, 72, 73, 77, 78, 84, 95, 96, 97, 98, 102, 104, 105, 120, 122, 123, 134, 136, 141, 145, 146, 150, 154, 160, 161, 168, 172, 178, 179, 186, 187, 188, 190, 194, 195, 196, 197], "similar": [4, 18, 20, 22, 23, 30, 31, 32, 60, 62, 66, 71, 72, 78, 84, 85, 96, 97, 104, 111, 112, 116, 118, 120, 121, 123, 136, 144, 146, 152, 153, 154, 160, 162, 168, 169, 186, 187, 188, 196, 197], "eric": [4, 20, 128, 160, 161, 185, 186, 187, 188], "dewitt": [4, 20, 128, 160, 161, 185, 186, 187, 188], "current": [4, 12, 21, 23, 28, 30, 62, 67, 71, 72, 73, 78, 85, 107, 118, 120, 123, 130, 139, 144, 145, 152, 153, 154, 168, 169, 170, 171, 172, 174, 178, 179, 181, 185, 186, 187, 188, 194, 195, 197], "avail": [4, 12, 21, 25, 30, 31, 84, 89, 120, 123, 128, 137, 145, 156, 168, 171, 172, 186, 197], "psychometr": 4, "These": [4, 12, 18, 20, 25, 30, 31, 32, 60, 62, 66, 68, 72, 73, 77, 78, 84, 97, 98, 104, 111, 120, 121, 122, 123, 135, 137, 141, 145, 154, 160, 161, 162, 170, 171, 172, 178, 179, 185, 192, 196, 197, 198], "next": [4, 12, 22, 30, 60, 62, 66, 67, 68, 71, 72, 77, 78, 82, 84, 85, 86, 87, 96, 97, 98, 104, 105, 111, 112, 113, 114, 118, 120, 121, 122, 123, 128, 135, 136, 137, 143, 144, 145, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 178, 179, 185, 187, 188, 194, 195, 196, 197, 198], "week": [4, 20, 36, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "explor": [4, 12, 22, 30, 31, 73, 77, 78, 85, 86, 95, 96, 97, 98, 111, 114, 118, 120, 123, 134, 135, 136, 137, 141, 144, 154, 169, 171, 176, 183, 185, 186, 187, 195, 196], "contain": [4, 11, 12, 20, 21, 22, 23, 25, 30, 32, 44, 71, 77, 78, 84, 86, 93, 94, 95, 96, 104, 114, 118, 120, 121, 122, 123, 128, 144, 156, 171, 186, 187, 188, 194, 196], "collect": [4, 12, 20, 21, 22, 60, 62, 66, 72, 73, 77, 78, 95, 128, 160, 168, 169, 170, 171, 172, 179], "motion": [4, 20, 22, 23, 128, 136, 164, 168], "reaction": [4, 164], "variou": [4, 66, 77, 78, 84, 85, 93, 94, 95, 96, 97, 98, 109, 121, 123, 143, 150, 160, 171, 178, 188, 196], "83": [4, 78, 168, 188], "214": [4, 80, 190], "author": [4, 12, 23, 104, 105], "strength": [4, 20, 23, 66, 71, 72, 73, 78, 105, 121, 139, 145, 152, 153, 154, 188, 194, 195, 196], "evid": [4, 12, 20, 22, 23, 72, 95, 105, 114, 128, 130, 137, 141, 145, 153, 154, 160, 168, 169, 170], "coher": [4, 130, 168], "prior": [4, 20, 21, 77, 100, 104, 105, 158, 160, 168, 169, 170, 172, 179], "compar": [4, 18, 20, 22, 30, 31, 32, 66, 71, 73, 77, 78, 85, 86, 91, 93, 94, 95, 98, 102, 104, 105, 111, 112, 113, 114, 118, 120, 121, 122, 128, 134, 135, 136, 137, 143, 145, 154, 160, 161, 168, 169, 171, 172, 178, 179, 186, 187, 188, 194, 197, 198], "predict": [4, 12, 20, 21, 22, 23, 30, 31, 32, 68, 71, 73, 77, 78, 86, 93, 96, 97, 98, 100, 102, 105, 116, 120, 121, 122, 123, 128, 130, 135, 136, 137, 168, 170, 171, 178, 179, 181, 187, 188, 190, 197], "observ": [4, 20, 22, 23, 30, 31, 32, 68, 71, 72, 77, 78, 82, 85, 86, 93, 94, 95, 97, 104, 121, 122, 123, 134, 135, 137, 144, 145, 146, 152, 154, 158, 160, 161, 166, 168, 169, 170, 171, 172, 176, 178, 183, 185, 186, 187, 188, 190, 194, 195], "built": [4, 22, 23, 85, 120, 121, 122, 123, 128, 134, 136, 143, 150, 178, 183, 185, 198], "feulner": 4, "clopath": 4, "propos": [4, 12, 72, 73, 82, 85, 95, 143], "how": [4, 12, 20, 21, 22, 23, 30, 31, 32, 44, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 80, 82, 84, 86, 87, 91, 93, 94, 95, 96, 97, 98, 102, 104, 105, 107, 109, 111, 112, 113, 114, 118, 120, 121, 122, 123, 126, 128, 130, 134, 135, 136, 137, 141, 143, 145, 146, 150, 152, 153, 154, 158, 160, 161, 162, 168, 169, 171, 172, 174, 176, 183, 185, 186, 187, 190, 192, 194, 195, 196, 198], "connect": [4, 12, 18, 30, 32, 44, 66, 68, 100, 102, 109, 116, 118, 120, 121, 134, 135, 144, 145, 148, 152, 153, 154, 158, 166, 169, 170, 176, 183, 185], "complex": [4, 12, 21, 32, 71, 72, 77, 78, 85, 91, 96, 97, 98, 104, 105, 116, 118, 120, 122, 130, 134, 141, 143, 152, 154, 160, 162, 164, 183, 185, 187, 188, 198], "cool": [4, 21, 120, 136, 137, 160, 197], "might": [4, 12, 18, 20, 21, 22, 23, 67, 68, 72, 73, 78, 84, 85, 93, 102, 104, 105, 120, 121, 122, 123, 128, 137, 143, 144, 145, 160, 161, 164, 171, 187, 196, 197], "exist": [4, 12, 23, 66, 71, 77, 82, 84, 87, 96, 102, 109, 152, 195], "process": [4, 12, 20, 21, 22, 23, 25, 30, 32, 62, 67, 72, 73, 77, 78, 80, 82, 84, 85, 89, 95, 97, 98, 100, 104, 107, 116, 121, 122, 123, 128, 130, 144, 145, 150, 152, 154, 162, 164, 166, 168, 169, 170, 171, 176, 178, 185, 197, 198], "tool": [4, 12, 21, 25, 30, 31, 32, 82, 84, 91, 96, 109, 118, 128, 137, 145, 161, 172, 192], "name": [4, 12, 20, 28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "descript": [4, 18, 20, 25, 60, 71, 80, 82, 91, 130, 134, 139, 141, 160, 161, 168, 169, 170, 178, 179, 183, 185, 186], "biomodel": 4, "repositori": [4, 21, 116], "mathemat": [4, 12, 21, 22, 23, 60, 66, 71, 72, 73, 77, 80, 84, 89, 96, 102, 120, 134, 136, 139, 141, 143, 145, 152, 158, 161, 162, 168, 169, 170, 171, 178, 190, 194, 196], "biolog": [4, 32, 36, 68, 72, 73, 85, 116, 118, 121, 130, 139, 141, 143, 144, 145, 146, 150, 152, 185, 197, 198], "biomed": [4, 130, 190, 194], "system": [4, 18, 20, 21, 23, 30, 32, 36, 66, 71, 72, 77, 78, 80, 82, 86, 89, 100, 116, 121, 122, 123, 132, 135, 136, 137, 139, 141, 143, 144, 150, 153, 161, 164, 169, 170, 178, 181, 192, 198], "It": [4, 12, 20, 21, 22, 23, 44, 66, 67, 68, 72, 73, 77, 78, 82, 84, 93, 95, 104, 105, 111, 113, 120, 121, 122, 123, 134, 136, 145, 152, 153, 154, 158, 160, 161, 162, 166, 168, 170, 171, 176, 178, 183, 186, 187, 194, 195, 196, 197], "host": [4, 33, 34, 35, 72, 73], "vast": 4, "literatur": [4, 12, 21, 22, 23, 36, 126], "pharmaceut": 4, "relev": [4, 12, 21, 22, 30, 31, 32, 62, 72, 73, 77, 89, 94, 96, 98, 105, 120, 121, 122, 123, 134, 152, 153, 156, 160, 161, 185], "mechanist": [4, 20, 23, 141, 178, 198], "modeldb": 4, "access": [4, 12, 20, 25, 36, 43, 44, 77, 94, 104, 112, 120, 153, 169, 170, 179, 181, 196], "locat": [4, 30, 32, 77, 78, 86, 94, 145, 152, 162, 170, 171, 172, 176, 178, 179, 187, 188], "store": [4, 22, 30, 31, 32, 78, 84, 85, 105, 113, 114, 120, 122, 123, 135, 137, 143, 168, 178, 185, 195], "effici": [4, 12, 30, 31, 62, 93, 96, 120, 121, 122, 136, 145, 172, 174, 183, 197], "retriev": [4, 30, 31, 32, 80, 143, 144, 145, 146, 152, 154], "entri": [4, 78, 84, 86, 104, 169, 196], "sourc": [4, 28, 32, 77, 78, 97, 136, 144, 161, 171, 179, 197], "concis": [4, 12, 30], "citat": 4, "articl": [4, 12, 20, 30, 80, 100, 107, 116, 121, 128, 130, 148, 168, 174, 181], "publish": [4, 72, 73, 190], "open": [4, 12, 21, 38, 43, 95, 104, 105, 120, 121, 122, 123, 135, 145, 152, 169, 171, 188], "share": [4, 12, 30, 32, 36, 62, 66, 84, 86, 105, 121, 122, 128, 144, 160, 161, 170, 174], "collabor": [4, 33, 34, 35, 43, 78], "develop": [4, 12, 20, 21, 84, 94, 97, 105, 112, 120, 121, 126, 128, 136, 137, 141, 144, 145, 150, 152, 156, 162, 171, 172, 185], "crcn": 4, "websit": [4, 42, 121], "marketplac": 4, "forum": [4, 116], "eegbas": 4, "storag": [4, 60, 85], "manag": [4, 66, 146], "eeg": [4, 73, 77, 169, 170, 192, 195], "metadata": 4, "document": [4, 67, 105, 114, 120, 121, 122, 123, 161, 164], "electrophysiolog": [4, 143, 152], "incf": 4, "endors": 4, "nitrc": 4, "neuroimag": [4, 18, 77], "collaboratori": 4, "award": 4, "win": [4, 20, 22, 72], "web": [4, 89, 185], "offer": [4, 25, 82, 105], "comprehens": [4, 60], "ever": [4, 44, 84, 85, 86, 87, 126, 146, 161, 171, 185, 186], "expand": [4, 30, 31, 84, 120, 141], "scope": 4, "neuroinformat": 4, "figshar": 4, "everyth": [4, 20, 78, 84, 96, 104, 160, 161, 171, 197], "openli": 4, "googl": [4, 12, 38, 44, 120, 121, 122, 123, 196], "search": [4, 12, 20, 23, 89, 93, 120, 181, 188, 190, 197], "let": [4, 20, 22, 23, 30, 31, 32, 60, 66, 67, 68, 71, 72, 73, 77, 78, 84, 86, 93, 94, 95, 96, 98, 104, 105, 113, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 186, 187, 188, 194, 195, 196, 197], "specif": [4, 12, 18, 21, 22, 23, 25, 30, 66, 68, 71, 77, 78, 82, 84, 85, 86, 94, 104, 109, 111, 120, 121, 122, 126, 135, 144, 145, 152, 160, 161, 168, 179, 185, 188, 196, 198], "find": [4, 12, 21, 22, 23, 25, 32, 39, 66, 67, 71, 72, 73, 93, 95, 96, 97, 98, 104, 105, 112, 113, 114, 120, 123, 134, 144, 146, 153, 160, 161, 162, 168, 171, 172, 178, 179, 185, 186, 187, 188, 195, 196, 197], "neurovault": 4, "public": [4, 104, 126, 190], "unthreshold": 4, "map": [4, 23, 30, 31, 32, 71, 105, 134, 135, 144, 153, 168, 169, 185, 187, 188], "parcel": 4, "atlas": 4, "mri": [4, 116], "pet": 4, "knowledgespac": 4, "global": [4, 73, 114, 161, 169, 178, 179, 185], "commun": [4, 12, 21, 86, 123, 126, 130, 141, 156, 190], "driven": [4, 71, 85, 130, 139, 143, 145, 146, 152, 198], "encyclopedia": 4, "them": [4, 12, 20, 21, 22, 30, 31, 32, 38, 60, 62, 66, 67, 71, 78, 82, 84, 85, 86, 98, 102, 105, 112, 113, 114, 118, 120, 121, 122, 123, 128, 136, 137, 145, 152, 158, 161, 162, 169, 171, 172, 178, 179, 183, 185, 188, 192, 194, 196, 197, 198], "page": [11, 41, 43, 44, 78, 105, 114], "last": [11, 12, 20, 25, 30, 31, 32, 43, 44, 60, 66, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 130, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "year": [11, 12, 25, 72, 73, 80, 160, 185], "sens": [11, 12, 20, 22, 23, 32, 72, 84, 96, 97, 113, 118, 123, 128, 137, 160, 166, 171, 178, 186, 188], "brainstorm": [11, 12, 20, 22, 23, 128], "idea": [11, 12, 20, 21, 22, 66, 68, 71, 77, 78, 84, 94, 95, 96, 102, 104, 122, 128, 143, 145, 146, 150, 158, 160, 161, 166, 168, 169, 170, 176, 179, 183, 185, 187, 190, 196], "creator": [12, 20, 21, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 84, 85, 86, 87, 90, 93, 94, 95, 96, 97, 98, 101, 104, 105, 108, 111, 112, 113, 114, 117, 120, 121, 122, 123, 125, 128, 131, 134, 135, 136, 137, 140, 143, 144, 145, 146, 149, 152, 153, 154, 157, 160, 161, 162, 165, 168, 169, 170, 171, 172, 175, 178, 179, 182, 185, 186, 187, 188, 191, 194, 195, 196, 197], "scott": [12, 25, 97, 100], "linderman": [12, 25, 130], "courtnei": 12, "dean": 12, "kathryn": 12, "bonnen": 12, "konrad": [12, 35, 84, 85, 86, 87, 128, 162, 194, 195, 196, 197], "kord": [12, 20, 21, 35, 80, 84, 85, 86, 87, 89, 100, 116, 128, 156, 162, 190, 194, 195, 196, 197], "goal": [12, 20, 21, 22, 23, 72, 80, 82, 96, 97, 104, 105, 112, 120, 122, 126, 128, 135, 136, 137, 145, 146, 161, 162, 178, 185, 186, 187, 188, 194], "cours": [12, 22, 23, 30, 31, 32, 42, 44, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 102, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 130, 134, 135, 136, 137, 143, 144, 145, 146, 150, 152, 153, 154, 156, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197, 198], "give": [12, 20, 21, 22, 23, 25, 60, 66, 71, 72, 73, 77, 78, 84, 85, 86, 102, 104, 105, 113, 120, 126, 128, 137, 141, 143, 144, 145, 150, 152, 153, 154, 160, 161, 162, 168, 169, 171, 178, 185, 186, 188, 192, 194, 195], "opportun": [12, 82], "answer": [12, 20, 21, 22, 23, 32, 67, 72, 73, 82, 105, 118, 126, 128, 143, 145, 160, 178, 192, 194, 195, 196, 198], "those": [12, 20, 21, 22, 23, 30, 66, 71, 77, 78, 82, 93, 102, 105, 109, 120, 121, 122, 123, 128, 135, 136, 145, 160, 161, 168, 171, 172, 178, 186, 188], "plan": [12, 126, 128, 162, 176, 181, 185], "explicitli": [12, 22, 23, 77, 84, 91, 122, 126, 156, 158], "encourag": [12, 21, 23, 105, 187], "iter": [12, 30, 31, 32, 60, 62, 98, 120, 122, 123, 126, 172, 179, 185, 196], "natur": [12, 25, 60, 68, 77, 80, 85, 96, 100, 107, 116, 121, 130, 139, 143, 144, 145, 158, 174, 181, 186, 190, 192, 197], "gradual": [12, 30, 135, 145, 169, 178, 185], "refin": [12, 22], "hypothes": [12, 21, 82, 120, 126, 160, 162, 168, 185], "As": [12, 20, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 93, 96, 97, 98, 105, 111, 112, 120, 121, 122, 123, 128, 135, 136, 137, 143, 145, 152, 154, 160, 161, 162, 168, 169, 170, 171, 185, 187, 188, 195, 196, 197], "part": [12, 20, 21, 22, 23, 30, 32, 71, 77, 84, 85, 86, 94, 96, 102, 104, 105, 120, 121, 122, 128, 134, 136, 137, 152, 153, 154, 160, 161, 172, 179, 186, 187, 188, 192, 194], "experi": [12, 20, 21, 22, 23, 25, 30, 31, 32, 44, 72, 73, 77, 78, 84, 102, 104, 105, 113, 120, 128, 137, 154, 160, 161, 162, 168, 170, 171, 183, 185, 188, 192], "deal": [12, 31, 60, 62, 72, 73, 91, 93, 94, 160, 161], "often": [12, 20, 21, 22, 23, 30, 32, 67, 71, 77, 78, 82, 84, 86, 94, 96, 97, 98, 102, 113, 118, 120, 121, 123, 128, 136, 145, 152, 154, 160, 161, 162, 166, 168, 169, 170, 171, 172, 178, 185, 186, 187, 190, 192, 195, 198], "big": [12, 36, 68, 71, 73, 77, 96, 120, 134, 152, 154, 161, 171, 187, 188, 194, 195, 197, 198], "challeng": [12, 18, 31, 32, 94, 120, 171, 172, 179, 186, 187], "its": [12, 20, 21, 22, 30, 60, 66, 68, 71, 73, 77, 78, 84, 85, 86, 91, 93, 94, 98, 104, 105, 112, 113, 120, 121, 122, 123, 130, 134, 135, 136, 139, 143, 145, 146, 152, 153, 154, 161, 162, 166, 170, 171, 172, 178, 179, 185, 186, 187, 188, 190, 195], "when": [12, 20, 21, 22, 23, 30, 31, 32, 44, 60, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 87, 91, 93, 94, 96, 97, 98, 102, 104, 105, 111, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 143, 144, 145, 146, 152, 153, 154, 160, 161, 168, 169, 170, 171, 178, 179, 183, 185, 187, 192, 194, 195, 196, 197, 198], "conduct": [12, 42, 72, 73, 77, 100, 130, 139, 143, 144, 160], "assign": [12, 30, 31, 32, 77, 84, 86, 93, 96, 97, 98, 104, 121, 122, 123, 162, 192], "broad": [12, 170, 183, 185, 192, 198], "fmri": [12, 77, 105, 192, 195], "ecog": 12, "theori": [12, 20, 67, 86, 89, 97, 105, 128, 156, 174, 178, 188], "With": [12, 68, 71, 72, 77, 96, 141, 154, 161, 168, 169, 185, 188], "help": [12, 20, 21, 25, 30, 31, 32, 38, 39, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 118, 120, 121, 122, 123, 128, 137, 143, 144, 145, 146, 150, 152, 153, 154, 160, 161, 162, 166, 169, 171, 172, 178, 179, 183, 187, 188, 197, 198], "split": [12, 20, 22, 30, 31, 32, 86, 98, 105, 121, 122, 123, 128, 186], "balanc": [12, 82, 85, 86, 97, 150, 186, 187, 188], "onc": [12, 20, 21, 22, 23, 44, 68, 73, 78, 84, 85, 95, 98, 102, 113, 114, 120, 122, 123, 128, 135, 145, 153, 171, 172, 179, 185, 186, 187, 188, 194, 197, 198], "form": [12, 20, 22, 28, 30, 31, 32, 42, 60, 66, 68, 71, 72, 73, 77, 85, 86, 91, 93, 96, 104, 105, 109, 111, 112, 120, 122, 123, 134, 136, 137, 144, 158, 160, 161, 162, 170, 171, 172, 179, 185, 186, 195, 196, 197], "try": [12, 20, 23, 25, 30, 31, 44, 66, 67, 68, 71, 72, 77, 78, 84, 86, 93, 94, 95, 97, 104, 105, 113, 114, 120, 121, 122, 123, 128, 134, 135, 137, 143, 144, 145, 146, 153, 154, 160, 161, 162, 170, 171, 178, 179, 185, 186, 187, 188, 196, 197], "preliminari": [12, 20, 179], "dataset": [12, 20, 22, 78, 82, 86, 93, 94, 96, 104, 105, 113, 114, 118, 120, 121, 122, 128, 137, 162, 171, 172], "dedic": [12, 25], "teach": [12, 30, 102, 170, 176, 192], "strategi": [12, 20, 68, 86, 135, 136, 168, 178, 186, 187, 188, 192, 194], "approach": [12, 20, 21, 22, 23, 30, 71, 78, 93, 94, 95, 96, 98, 102, 105, 118, 122, 123, 126, 137, 152, 153, 156, 158, 160, 161, 162, 171, 172, 178, 183, 185, 187, 190, 192], "appli": [12, 21, 22, 30, 31, 62, 68, 71, 73, 78, 84, 86, 91, 94, 96, 98, 104, 105, 113, 118, 120, 121, 122, 128, 130, 144, 152, 154, 158, 161, 171, 179, 185, 187, 190, 194, 195, 196, 197, 198], "rest": [12, 62, 72, 73, 78, 84, 85, 86, 96, 97, 98, 120, 123, 128, 143, 145, 154, 194, 196, 198], "second": [12, 20, 22, 23, 30, 33, 60, 62, 66, 68, 71, 72, 73, 77, 78, 84, 85, 86, 102, 104, 105, 109, 111, 112, 113, 114, 118, 120, 121, 122, 123, 128, 134, 136, 137, 141, 144, 145, 150, 152, 153, 154, 160, 168, 170, 171, 172, 178, 179, 185, 188, 196, 197], "continu": [12, 20, 60, 62, 68, 71, 73, 78, 84, 85, 86, 91, 98, 136, 137, 144, 153, 158, 160, 166, 168, 170, 172, 176, 188], "analyz": [12, 22, 23, 25, 32, 114, 121, 122, 136, 162, 194, 198], "result": [12, 20, 21, 22, 23, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 80, 82, 84, 86, 93, 94, 96, 104, 111, 114, 120, 121, 122, 123, 135, 136, 137, 143, 144, 145, 154, 161, 162, 168, 170, 171, 178, 179, 185, 186, 187, 188, 194, 196, 198], "least": [12, 23, 66, 68, 78, 94, 95, 97, 98, 104, 120, 123, 136, 154, 171, 178, 195], "testabl": [12, 21], "hypothesi": [12, 21, 22, 23, 60, 84, 91, 95, 122, 197], "swap": [12, 30, 36, 60, 196], "receiv": [12, 21, 32, 62, 85, 121, 143, 144, 145, 152, 161, 178, 183, 185, 186, 187, 188, 194], "focu": [12, 21, 60, 66, 67, 68, 77, 78, 84, 85, 94, 96, 105, 111, 120, 122, 126, 134, 143, 145, 146, 150, 160, 161, 171, 178, 188, 194, 195, 196, 197, 198], "against": [12, 21, 23, 91, 93, 102, 136, 137, 153, 179, 192, 197], "other": [12, 20, 21, 22, 23, 30, 32, 36, 43, 60, 66, 68, 71, 72, 73, 77, 78, 80, 84, 85, 86, 87, 94, 98, 102, 104, 105, 114, 118, 120, 121, 122, 123, 128, 135, 136, 137, 141, 143, 144, 145, 146, 152, 153, 154, 158, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 183, 185, 186, 187, 188, 190, 192, 194, 195, 196, 197], "megapod": 12, "organ": [12, 30, 32, 60, 62, 84, 104, 116, 128, 130], "lead": [12, 20, 23, 31, 62, 67, 72, 78, 94, 120, 122, 144, 146, 150, 152, 154, 160, 168, 179, 185, 186, 187, 188], "tell": [12, 21, 67, 71, 78, 84, 91, 94, 98, 102, 105, 118, 120, 122, 123, 128, 135, 152, 160, 161, 171, 179, 195], "stori": [12, 178], "low": [12, 30, 71, 84, 97, 105, 109, 113, 114, 122, 130, 143, 145, 160, 161, 164, 168, 169, 171, 178, 179, 185], "kei": [12, 21, 22, 23, 32, 62, 66, 93, 94, 96, 97, 98, 109, 111, 118, 120, 122, 161, 166, 188, 197, 198], "wai": [12, 20, 21, 22, 23, 30, 31, 60, 66, 67, 71, 72, 73, 77, 78, 82, 84, 85, 86, 91, 93, 94, 95, 96, 97, 98, 102, 104, 109, 111, 113, 118, 120, 121, 122, 123, 126, 128, 130, 135, 136, 137, 144, 145, 146, 152, 158, 160, 161, 162, 171, 179, 186, 187, 188, 190, 192, 194, 195, 197], "meant": [12, 22, 23, 118, 120, 121], "product": [12, 20, 21, 23, 30, 31, 32, 60, 62, 67, 68, 72, 73, 77, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 188, 195, 196, 197], "valu": [12, 20, 21, 22, 23, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 77, 78, 84, 85, 86, 91, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 134, 136, 137, 144, 145, 146, 150, 160, 161, 162, 164, 168, 169, 170, 171, 172, 174, 179, 181, 183, 187, 188, 194, 195, 196, 197], "airtabl": [12, 42], "conjunct": 12, "varieti": [12, 20, 22, 66, 67, 118, 121, 128, 134], "starter": 12, "just": [12, 18, 20, 21, 23, 32, 36, 66, 67, 68, 71, 73, 77, 78, 84, 85, 86, 93, 94, 95, 97, 98, 102, 104, 105, 111, 113, 120, 121, 122, 123, 128, 134, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 186, 187, 188, 194, 195, 196, 197, 198], "keyword": [12, 30, 31, 104, 123, 162], "reus": [12, 62, 78, 87, 169, 178], "extens": [12, 30, 32, 77, 96, 105, 111, 161, 185, 186, 188], "don": [12, 20, 21, 23, 44, 65, 66, 72, 76, 78, 84, 85, 86, 96, 97, 98, 104, 105, 112, 113, 114, 120, 123, 126, 128, 144, 160, 161, 162, 169, 170, 171, 172, 178, 185, 186, 194, 195, 196, 197], "design": [12, 18, 20, 22, 25, 32, 62, 72, 73, 97, 98, 128, 171], "enough": [12, 20, 21, 60, 84, 93, 97, 104, 120, 161, 168, 178, 188, 195, 197], "structur": [12, 20, 21, 30, 32, 36, 67, 68, 84, 85, 100, 102, 105, 109, 113, 114, 121, 122, 123, 128, 130, 137, 164, 169, 170, 171, 178, 197, 198], "option": [12, 20, 21, 22, 28, 30, 31, 32, 36, 44, 60, 62, 67, 71, 77, 78, 105, 118, 120, 121, 123, 128, 134, 145, 152, 160, 161, 162, 168, 170, 171, 172, 178, 179, 186, 195, 196, 197, 198], "keep": [12, 20, 21, 30, 31, 32, 60, 62, 68, 71, 73, 84, 97, 105, 113, 122, 128, 130, 134, 135, 143, 145, 160, 161, 162, 168, 171, 172, 176, 178, 179, 185, 186], "stick": [12, 21, 186], "Or": [12, 20, 21, 122, 128], "diverg": [12, 152, 154], "test": [12, 20, 30, 31, 32, 60, 71, 77, 78, 82, 86, 91, 98, 104, 105, 111, 120, 121, 122, 128, 137, 139, 146, 162, 171, 178, 179, 185, 187, 188, 197], "flow": [12, 21, 60, 72, 145], "easi": [12, 21, 71, 72, 111, 120, 161, 186, 194, 195, 197], "hard": [12, 20, 21, 22, 77, 196, 198], "hesit": 12, "skip": [12, 60, 62, 114, 120, 121, 123, 168, 185], "complet": [12, 20, 30, 31, 32, 36, 62, 65, 66, 67, 68, 71, 73, 76, 77, 78, 84, 97, 98, 100, 104, 105, 111, 112, 114, 116, 120, 121, 122, 123, 126, 128, 130, 134, 135, 136, 143, 144, 145, 146, 160, 162, 168, 169, 170, 172, 178, 179, 185, 188, 194, 195, 196, 197, 198], "flexibl": [12, 21, 62, 94, 105, 116, 118, 120, 161], "friendli": [12, 25], "expert": [12, 198], "consult": [12, 20, 71, 72, 104, 188, 194], "issu": [12, 22, 23, 28, 30, 32, 73, 134, 160, 171], "aspect": [12, 20, 21, 30, 31, 32, 60, 62, 71, 82, 84, 94, 120, 123, 128, 136, 148, 171, 187, 188, 197], "approxim": [12, 30, 60, 62, 71, 77, 78, 84, 113, 118, 120, 134, 139, 152, 154, 160, 161, 171, 196], "someth": [12, 20, 21, 22, 23, 60, 71, 72, 73, 84, 86, 87, 104, 105, 121, 122, 144, 150, 160, 161, 162, 170, 185, 186, 198], "sometim": [12, 21, 23, 30, 60, 66, 67, 71, 72, 77, 78, 98, 102, 112, 135, 136, 160, 161, 171, 185, 186, 188, 192, 195, 196], "arriv": [12, 68, 85, 86, 93, 94, 95, 145, 146, 160, 170], "unannounc": 12, "late": [12, 121, 156], "earli": [12, 21, 116, 121, 153, 185], "busi": [12, 67], "stop": [12, 20, 22, 60, 62, 104, 128, 143, 172, 186], "were": [12, 20, 21, 22, 30, 71, 78, 84, 85, 86, 98, 104, 118, 120, 121, 122, 123, 128, 137, 144, 145, 146, 160, 161, 168, 169, 171, 172, 178, 179, 183, 185, 195, 197, 198], "resum": 12, "leav": [12, 66, 85, 95, 122, 144, 152, 160, 168], "onli": [12, 18, 20, 21, 22, 23, 30, 31, 32, 44, 60, 66, 67, 68, 71, 73, 77, 78, 84, 85, 86, 95, 96, 98, 104, 105, 112, 113, 114, 118, 120, 121, 122, 126, 128, 135, 137, 143, 144, 145, 146, 150, 152, 153, 154, 156, 160, 161, 162, 166, 168, 169, 170, 171, 178, 179, 183, 185, 186, 187, 188, 194, 195, 196, 197], "earlier": [12, 60, 67, 71, 104, 134, 136, 160, 185], "later": [12, 20, 23, 60, 67, 68, 71, 72, 73, 77, 78, 85, 111, 120, 121, 126, 128, 137, 144, 152, 160, 161, 166, 172, 176, 178, 179, 187, 194], "reach": [12, 22, 23, 31, 77, 84, 85, 94, 113, 130, 136, 143, 145, 146, 152, 153, 154, 168, 179], "out": [12, 20, 21, 22, 23, 30, 31, 36, 39, 43, 60, 62, 67, 68, 71, 72, 77, 78, 84, 85, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 120, 121, 122, 123, 128, 134, 135, 137, 143, 144, 145, 146, 150, 152, 154, 156, 160, 161, 162, 168, 170, 171, 172, 176, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197, 198], "extra": [12, 21, 78, 96, 120, 143, 154, 168, 172, 185, 188, 194], "whenev": [12, 62, 105, 122, 146, 178, 185, 188], "post": [12, 36, 68, 71, 84, 86, 87, 116, 137, 144, 145, 146], "channel": [12, 62, 72, 121, 122, 123, 135, 145, 169, 172], "coupl": [12, 66, 68, 73, 78, 86, 145, 152, 153, 154, 161], "throughout": [12, 20, 68, 77, 91, 93, 111, 128, 135, 144, 146, 150, 152, 161, 179, 185, 195, 198], "three": [12, 22, 30, 32, 60, 72, 73, 78, 82, 84, 86, 93, 104, 105, 118, 120, 122, 123, 150, 152, 153, 154, 161, 169, 171, 172, 178, 196, 197], "activ": [12, 18, 20, 22, 25, 31, 32, 66, 67, 71, 72, 78, 85, 86, 91, 100, 102, 105, 109, 111, 112, 118, 123, 130, 139, 141, 143, 145, 148, 150, 164, 166, 169, 170, 172, 176, 188, 194, 196, 197], "field": [12, 18, 20, 21, 84, 85, 86, 100, 102, 104, 121, 122, 123, 128, 152, 154, 156, 161, 188, 192, 197, 198], "scientif": [12, 20, 21, 22, 23, 60, 80, 84, 116, 128, 174, 179], "step": [12, 22, 23, 30, 31, 32, 60, 62, 66, 67, 68, 72, 77, 78, 84, 85, 86, 93, 98, 104, 105, 111, 112, 113, 114, 120, 122, 123, 126, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 164, 166, 168, 169, 170, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197, 198], "intention": [12, 186], "creat": [12, 20, 21, 22, 23, 30, 32, 44, 60, 62, 66, 71, 78, 84, 86, 93, 95, 96, 97, 98, 105, 118, 120, 121, 122, 128, 134, 144, 146, 153, 160, 161, 162, 169, 171, 172, 178, 185, 194, 196, 197], "skillset": 12, "who": [12, 21, 196], "confid": [12, 93, 94, 96, 97, 98, 169, 170, 190], "learn": [12, 20, 21, 22, 23, 25, 30, 31, 32, 36, 43, 44, 60, 62, 66, 67, 71, 72, 77, 82, 84, 85, 86, 89, 91, 93, 94, 95, 96, 97, 98, 100, 102, 104, 107, 109, 111, 112, 113, 114, 118, 120, 122, 123, 126, 128, 130, 134, 135, 137, 139, 141, 143, 144, 145, 146, 150, 152, 153, 154, 156, 158, 160, 161, 162, 166, 168, 169, 170, 171, 174, 176, 178, 179, 181, 183, 192, 194, 195, 196, 197, 198], "togeth": [12, 21, 22, 23, 36, 66, 67, 71, 78, 84, 94, 95, 97, 104, 114, 120, 121, 122, 123, 128, 144, 146, 154, 160, 172, 187, 194], "strengthen": [12, 130, 146], "skill": [12, 20, 78], "member": 12, "chanc": [12, 20, 36, 77, 78, 137, 146, 160, 178], "folk": [12, 102], "handoff": 12, "peer": [12, 21], "improv": [12, 21, 30, 31, 32, 60, 62, 73, 85, 116, 120, 121, 128, 160, 170, 185, 188, 195], "15": [12, 36, 60, 62, 66, 67, 68, 71, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 100, 104, 105, 111, 112, 113, 114, 116, 120, 121, 122, 123, 128, 130, 134, 136, 137, 144, 145, 146, 152, 153, 154, 160, 161, 162, 164, 169, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "min": [12, 20, 22, 30, 31, 32, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "introduct": [12, 21, 96, 134, 135, 181], "sai": [12, 21, 36, 66, 67, 71, 72, 77, 78, 86, 91, 94, 98, 122, 123, 134, 135, 160, 161, 168, 186, 194, 197], "few": [12, 22, 23, 30, 31, 32, 60, 62, 68, 72, 73, 78, 84, 104, 113, 114, 120, 121, 122, 123, 137, 141, 143, 144, 146, 158, 160, 170, 171, 185, 195, 196], "thing": [12, 20, 66, 68, 78, 94, 102, 123, 128, 134, 136, 145, 164, 166, 171, 172, 186, 188, 195, 196, 197, 198], "area": [12, 18, 25, 30, 32, 62, 66, 68, 71, 77, 78, 82, 85, 86, 118, 120, 121, 122, 123, 130, 144, 145, 168, 183, 185, 188, 195, 198], "curiou": [12, 84, 145, 194], "listen": [12, 33, 34, 35, 72, 73], "carefulli": [12, 21, 134, 185, 194, 198], "20": [12, 23, 25, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 100, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 130, 134, 135, 136, 143, 144, 145, 146, 152, 153, 154, 160, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "brows": 12, "booklet": [12, 20, 21], "skim": 12, "entir": [12, 25, 84, 95, 121, 128, 135, 136, 137, 152, 153, 162, 171, 179, 187, 196], "slide": [12, 68, 121, 143], "doc": [12, 30, 42, 43, 97], "further": [12, 21, 22, 30, 31, 71, 72, 73, 78, 93, 97, 98, 104, 109, 120, 121, 123, 128, 134, 136, 160, 161, 168, 171, 186, 187, 188], "60": [12, 20, 22, 30, 71, 72, 78, 104, 120, 123, 128, 135, 144, 145, 146, 178, 187, 188], "within": [12, 20, 21, 22, 23, 60, 66, 77, 84, 86, 95, 105, 120, 121, 122, 123, 135, 146, 185, 187, 194, 195, 197, 198], "choos": [12, 21, 32, 67, 71, 77, 78, 82, 86, 93, 94, 95, 96, 97, 98, 113, 120, 123, 134, 136, 145, 154, 160, 161, 168, 170, 171, 174, 176, 178, 187, 188, 198], "concret": [12, 20, 120, 122, 128, 135, 194], "either": [12, 22, 25, 30, 31, 32, 68, 71, 78, 84, 85, 86, 91, 95, 98, 135, 145, 152, 153, 161, 168, 169, 178, 187, 194], "yourselv": [12, 128, 171], "directli": [12, 30, 43, 60, 84, 86, 94, 112, 121, 122, 123, 135, 161, 166, 169, 170, 171, 176, 178, 187, 194, 196, 198], "tip": [12, 21, 66, 94, 179, 186], "No": [12, 20, 28, 29, 30, 31, 32, 36, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "after": [12, 20, 21, 22, 30, 31, 44, 60, 62, 65, 66, 67, 68, 76, 77, 78, 84, 85, 86, 93, 94, 96, 97, 102, 111, 112, 113, 116, 120, 122, 123, 128, 135, 137, 144, 145, 146, 153, 154, 161, 168, 170, 172, 178, 185, 186, 187, 188, 194, 195, 196, 197, 198], "feasibl": [12, 95, 120], "That": [12, 20, 21, 22, 30, 67, 68, 71, 84, 86, 104, 105, 120, 121, 126, 128, 137, 143, 146, 152, 153, 154, 160, 161, 162, 195], "culmin": [12, 122], "peek": [12, 60, 136], "plai": [12, 20, 21, 30, 62, 66, 68, 71, 72, 78, 84, 85, 105, 113, 123, 128, 144, 160, 161, 168, 169, 178, 179, 185, 186], "One": [12, 31, 62, 66, 72, 85, 86, 95, 96, 97, 98, 105, 113, 120, 121, 122, 123, 136, 141, 153, 156, 161, 169, 171, 186, 187, 197], "sort": [12, 32, 66, 84, 96, 104, 111, 112, 113, 120, 123, 130, 144, 172, 194, 198], "actual": [12, 20, 21, 22, 23, 60, 71, 77, 78, 86, 95, 96, 98, 104, 120, 121, 122, 123, 128, 137, 161, 168, 170, 171, 178, 185, 186, 187, 195, 196, 197], "There": [12, 20, 21, 22, 23, 30, 62, 71, 77, 78, 84, 85, 86, 98, 105, 118, 120, 121, 144, 145, 153, 156, 160, 161, 166, 168, 170, 178, 179, 185, 188, 192, 197], "interspers": 12, "among": [12, 31, 32, 86, 174, 186], "even": [12, 23, 30, 32, 60, 66, 67, 68, 72, 73, 77, 84, 86, 93, 102, 104, 105, 118, 120, 121, 122, 130, 135, 136, 145, 146, 153, 158, 161, 162, 168, 169, 171, 178, 186, 187, 188, 190, 194, 196, 197], "especi": [12, 21, 44, 67, 78, 93, 98, 121, 143, 160, 171, 198], "being": [12, 60, 68, 71, 77, 78, 86, 93, 105, 112, 120, 121, 122, 123, 135, 161, 162, 168, 171, 179], "axi": [12, 20, 22, 30, 31, 32, 60, 62, 66, 67, 68, 71, 73, 77, 78, 85, 105, 111, 112, 113, 121, 122, 123, 128, 134, 136, 137, 145, 152, 153, 160, 161, 162, 168, 169, 170, 172, 178, 179, 186, 187, 188, 194, 195, 196, 197], "y": [12, 20, 22, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 93, 94, 95, 96, 97, 98, 100, 104, 105, 107, 111, 112, 113, 114, 116, 120, 121, 122, 123, 128, 130, 134, 136, 139, 144, 148, 152, 154, 160, 161, 162, 164, 170, 171, 172, 178, 179, 181, 185, 187, 188, 194, 195, 196, 197], "Is": [12, 21, 71, 72, 73, 78, 84, 93, 104, 105, 114, 122, 144, 145, 185], "mani": [12, 18, 20, 21, 22, 23, 25, 32, 66, 67, 71, 72, 73, 77, 78, 84, 85, 86, 95, 96, 102, 104, 105, 109, 111, 113, 120, 121, 122, 123, 135, 144, 145, 146, 152, 153, 158, 160, 161, 162, 168, 170, 178, 179, 183, 185, 186, 187, 194, 196, 197], "pai": [12, 72, 73, 145, 178, 186, 187, 188], "attent": [12, 72, 73, 145, 148, 154, 179, 188], "bin": [12, 20, 22, 30, 62, 68, 77, 78, 84, 85, 86, 95, 104, 120, 121, 122, 123, 136, 143, 144, 146, 170, 172, 178], "align": [12, 20, 22, 23, 31, 60, 66, 67, 68, 71, 72, 73, 77, 78, 85, 86, 93, 94, 95, 96, 104, 105, 111, 112, 113, 120, 122, 123, 143, 144, 152, 153, 154, 160, 161, 168, 169, 170, 171, 172, 179, 185, 196, 197], "element": [12, 21, 22, 30, 31, 32, 60, 62, 66, 67, 71, 72, 84, 85, 96, 97, 104, 105, 112, 113, 120, 122, 126, 134, 135, 136, 137, 154, 160, 162, 169, 171, 172, 178, 186, 190, 194, 195, 196, 197], "small": [12, 20, 22, 60, 62, 65, 68, 71, 72, 76, 77, 78, 84, 85, 94, 105, 120, 121, 122, 123, 128, 134, 136, 137, 144, 145, 150, 152, 160, 168, 171, 179, 185, 188, 196], "appear": [12, 62, 66, 68, 84, 104, 105, 113, 114, 120, 121, 122, 123, 144, 171, 185, 187, 188, 195], "Be": [12, 20, 21, 66, 77, 84, 197], "lookout": 12, "notic": [12, 20, 21, 22, 23, 30, 60, 71, 78, 102, 105, 120, 122, 135, 136, 137, 143, 144, 146, 152, 154, 179, 185, 187, 188, 196], "unexpect": 12, "dig": [12, 20], "deeper": [12, 20, 60, 102, 112, 120, 121, 145, 154], "must": [12, 21, 67, 72, 78, 84, 85, 86, 98, 112, 114, 120, 123, 135, 160, 168, 169, 179, 186, 187, 188, 196, 197], "mind": [12, 20, 21, 30, 60, 72, 73, 97, 105, 128, 161], "trick": [12, 72, 78, 120, 122, 172], "hardest": [12, 20, 82, 128], "technic": [12, 31, 66, 67, 121, 178, 185], "wrestl": 12, "easier": [12, 20, 21, 30, 60, 123, 126, 128, 137, 162, 170, 179], "equal": [12, 22, 30, 60, 66, 67, 68, 71, 73, 77, 78, 85, 86, 93, 94, 105, 111, 112, 114, 122, 136, 143, 152, 160, 161, 168, 170, 172, 178, 179, 185, 186, 194, 195, 196, 197], "network": [12, 18, 28, 30, 31, 32, 36, 72, 73, 78, 80, 82, 91, 100, 107, 109, 118, 130, 139, 141, 145, 146, 150, 153, 181, 190, 194, 196, 197, 198], "simul": [12, 20, 21, 22, 23, 62, 68, 72, 73, 77, 78, 80, 85, 91, 93, 94, 95, 96, 97, 98, 111, 128, 134, 135, 137, 144, 154, 162, 171, 178, 179, 185, 186, 188, 196], "still": [12, 20, 23, 25, 30, 31, 66, 68, 78, 84, 85, 93, 95, 96, 120, 121, 123, 128, 130, 135, 145, 152, 156, 178, 179, 186, 194, 196, 197], "becom": [12, 30, 32, 67, 68, 71, 72, 73, 78, 86, 136, 143, 145, 154, 169, 170, 172, 179, 195, 196, 197], "opposit": [12, 30, 66, 71, 120, 145, 168, 194, 195, 197], "happen": [12, 21, 43, 67, 68, 71, 72, 73, 77, 84, 85, 96, 104, 105, 111, 112, 123, 134, 143, 144, 145, 146, 150, 152, 153, 154, 160, 161, 168, 170, 178, 179, 185, 194, 195, 198], "realiz": [12, 60, 62, 144, 145], "alwai": [12, 21, 22, 23, 30, 31, 66, 67, 68, 71, 73, 78, 84, 86, 93, 94, 95, 96, 102, 120, 122, 135, 144, 145, 146, 152, 153, 154, 158, 160, 169, 178, 186, 187, 188, 197], "bug": 12, "too": [12, 20, 21, 22, 23, 72, 77, 78, 84, 85, 97, 104, 105, 112, 120, 128, 161, 171, 179, 185, 186, 188, 195, 196], "true": [12, 20, 22, 23, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 168, 169, 171, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "train": [12, 20, 21, 98, 104, 114, 116, 118, 120, 121, 122, 126, 128, 137, 139, 143, 145, 146, 185], "simpl": [12, 21, 22, 23, 30, 31, 60, 66, 68, 71, 72, 77, 78, 80, 84, 85, 86, 89, 91, 93, 94, 95, 96, 97, 98, 102, 104, 105, 109, 111, 118, 120, 121, 122, 126, 134, 135, 137, 139, 141, 143, 144, 145, 146, 148, 153, 158, 160, 161, 162, 164, 166, 169, 178, 183, 185, 186, 187, 188, 194, 196, 197, 198], "matter": [12, 20, 21, 23, 30, 62, 66, 78, 105, 120, 128, 145, 152, 154, 160, 161, 190, 197], "tune": [12, 100, 118, 120, 121, 148, 174], "curv": [12, 20, 22, 71, 72, 78, 84, 96, 100, 104, 105, 120, 121, 143, 144, 154, 169, 170, 172, 179], "doe": [12, 20, 21, 22, 23, 25, 28, 32, 43, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 91, 94, 95, 104, 105, 111, 113, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 185, 186, 187, 188, 192, 194, 195, 196, 197], "rememb": [12, 20, 21, 66, 67, 68, 71, 77, 78, 86, 105, 112, 120, 123, 128, 134, 135, 137, 143, 144, 160, 161, 172, 178, 179, 186, 188, 194, 195, 197], "quick": [12, 86, 107, 161, 195], "survei": [12, 20, 36, 89], "thought": [12, 20, 30, 67, 71, 87, 121, 123, 126, 128, 158, 172, 185, 186, 190], "past": [12, 73, 104, 116, 137, 169, 170, 171, 172, 178, 188], "origin": [12, 21, 23, 30, 31, 32, 62, 66, 67, 68, 71, 72, 84, 93, 94, 95, 96, 111, 112, 113, 141, 154, 161, 162, 171, 172, 186, 196], "situat": [12, 66, 71, 94, 96, 105, 121, 160, 161, 168, 178, 179, 185, 188, 195], "hint": [12, 20, 71, 77, 78, 84, 86, 95, 96, 97, 104, 105, 112, 113, 120, 123, 128, 134, 135, 136, 143, 145, 152, 154, 160, 161, 162, 168, 169, 172, 178, 185, 197], "suggest": [12, 23, 62, 71, 84, 95, 96, 105, 113, 114, 162, 168, 172], "depend": [12, 20, 21, 23, 28, 30, 32, 62, 68, 73, 77, 78, 82, 84, 85, 91, 93, 94, 95, 96, 97, 98, 104, 105, 114, 120, 121, 126, 128, 130, 135, 136, 137, 141, 143, 144, 145, 153, 154, 160, 161, 162, 168, 169, 170, 179, 185, 194], "could": [12, 20, 21, 22, 23, 30, 32, 67, 68, 71, 72, 73, 77, 78, 80, 82, 84, 85, 86, 91, 96, 98, 104, 109, 111, 114, 120, 121, 122, 123, 128, 144, 146, 152, 158, 160, 161, 162, 169, 170, 171, 178, 179, 185, 186, 196, 197], "wrangl": 12, "simpli": [12, 20, 23, 68, 71, 73, 84, 86, 94, 105, 120, 122, 123, 137, 143, 156, 171, 178, 186, 188, 197], "right": [12, 20, 21, 22, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 86, 93, 95, 97, 98, 104, 105, 120, 121, 122, 123, 128, 135, 136, 145, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 186, 187, 188, 194, 195, 196, 197], "psth": 12, "scatter": [12, 20, 22, 62, 68, 72, 73, 77, 93, 94, 95, 96, 105, 111, 112, 114, 122, 128, 134, 137, 162, 169, 170, 171, 194, 195, 196, 197], "differ": [12, 18, 20, 21, 22, 23, 30, 31, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 82, 84, 85, 91, 93, 94, 95, 97, 98, 102, 104, 111, 112, 120, 121, 122, 123, 126, 128, 134, 135, 136, 137, 144, 146, 152, 154, 156, 160, 162, 168, 169, 170, 171, 172, 179, 186, 187, 188, 190, 194, 195, 196, 197], "across": [12, 18, 20, 22, 23, 25, 60, 67, 72, 77, 82, 84, 85, 86, 93, 97, 105, 111, 112, 116, 120, 121, 122, 123, 130, 145, 146, 160, 162, 168, 171, 172, 178, 185, 187, 188, 192], "most": [12, 18, 21, 25, 30, 60, 62, 66, 68, 71, 72, 73, 77, 78, 82, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 116, 118, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 176, 178, 179, 183, 185, 186, 187, 188, 194, 195, 196, 197, 198], "session": [12, 32, 33, 34, 35, 36, 44, 84, 187, 188], "pick": [12, 22, 71, 78, 93, 98, 105, 120, 122, 123, 178, 186, 198], "qualiti": [12, 32, 78, 95, 97, 98, 171, 178, 195, 197], "deep": [12, 18, 21, 28, 30, 32, 36, 44, 80, 82, 91, 102, 109, 118, 123, 181, 183, 185, 198], "stage": [12, 20], "popul": [12, 18, 22, 25, 66, 67, 71, 84, 91, 100, 102, 109, 111, 118, 120, 121, 122, 123, 130, 146, 148, 150, 154, 174, 194], "voxel": [12, 18, 105], "encod": [12, 30, 31, 32, 66, 100, 102, 105, 118, 120, 121, 130, 172, 195, 198], "certain": [12, 20, 22, 32, 71, 72, 73, 78, 85, 86, 105, 128, 135, 143, 144, 154, 161, 168, 169, 171, 178, 186, 187, 188, 195], "By": [12, 20, 21, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 66, 67, 68, 71, 72, 77, 78, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 158, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "far": [12, 20, 22, 68, 94, 96, 112, 120, 128, 134, 136, 146, 153, 161, 186], "regress": [12, 20, 22, 91, 95, 97, 98, 102, 109, 120, 122, 128, 137, 192, 194, 195], "pca": [12, 31, 32, 109, 111, 122], "cluster": [12, 30, 31, 84, 114], "binari": [12, 20, 23, 30, 31, 32, 77, 78, 91, 105, 121, 137, 144, 145, 146, 158, 161, 166, 168, 172, 176, 178, 179, 195, 197], "categor": [12, 77, 78, 116, 122], "pipelin": [12, 20, 22, 128, 162], "switch": [12, 30, 66, 78, 120, 130, 169, 172, 178], "predictor": [12, 137], "scikit": [12, 22, 30, 98, 196, 197], "reduc": [12, 30, 31, 78, 86, 98, 105, 112, 113, 116, 120, 121, 154, 162, 171, 179, 185], "kind": [12, 18, 20, 22, 72, 77, 82, 87, 98, 104, 113, 120, 122, 126, 134, 143, 145, 161, 179, 185, 186, 192], "pc": 12, "size": [12, 20, 23, 30, 31, 32, 62, 66, 67, 72, 73, 77, 78, 95, 98, 104, 111, 112, 113, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 168, 169, 172, 178, 185, 186, 194, 196, 197], "averag": [12, 18, 20, 22, 23, 71, 73, 77, 78, 84, 85, 93, 98, 102, 104, 105, 120, 121, 122, 123, 128, 135, 136, 143, 144, 145, 146, 150, 152, 153, 154, 160, 161, 168, 169, 170, 172, 178, 185, 186, 188, 194], "simplest": [12, 23, 85, 136, 143, 144, 145, 152, 186, 188], "complic": [12, 73, 85, 96, 102, 122, 160, 164, 185], "nonlinear": [12, 22, 28, 72, 73, 100, 130, 152, 164, 170, 194, 195, 196, 197], "fail": [12, 20, 21, 30, 32, 84, 104, 105, 120, 121, 122, 123, 128, 171, 172, 194, 195, 196, 197], "choic": [12, 18, 20, 22, 23, 25, 30, 31, 32, 77, 82, 86, 91, 93, 95, 98, 102, 104, 105, 111, 113, 114, 120, 122, 123, 128, 130, 152, 158, 161, 164, 168, 169, 179, 185, 186, 187, 188, 194, 195, 196, 197], "fanci": [12, 71], "tsne": [12, 114, 122], "dead": 12, "end": [12, 20, 22, 23, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 77, 78, 85, 86, 93, 94, 95, 96, 97, 98, 102, 104, 105, 111, 112, 113, 120, 121, 122, 123, 126, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 158, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 196, 197, 198], "die": [12, 154], "progress": [12, 30, 72, 100, 120, 122, 123, 128, 136, 145, 185, 187], "greatli": 12, "reason": [12, 67, 72, 73, 77, 82, 85, 93, 96, 109, 120, 121, 143, 144, 145, 146, 152, 161, 162, 169, 178, 187, 188], "interpret": [12, 20, 21, 22, 32, 77, 102, 105, 114, 116, 120, 121, 122, 128, 135, 166, 168, 170, 171, 179, 194, 197], "function": [12, 18, 21, 23, 60, 82, 100, 102, 116, 118, 130, 141, 166, 176], "black": [12, 30, 60, 62, 72, 73, 121, 136, 144, 145, 146, 160, 164, 169, 170, 172], "box": [12, 21, 62, 66, 68, 77, 98, 145, 169, 178], "paramet": [12, 20, 21, 22, 23, 30, 31, 32, 62, 67, 71, 73, 84, 85, 91, 93, 94, 95, 96, 97, 98, 102, 104, 111, 112, 114, 120, 121, 122, 123, 128, 134, 135, 144, 145, 146, 153, 160, 162, 168, 169, 170, 171, 179, 185, 186, 187, 188, 194, 196, 197], "replac": [12, 28, 30, 31, 32, 73, 77, 98, 113, 120, 122, 123, 145, 152, 179, 185, 186], "sne": [12, 107, 109, 122], "umap": [12, 107], "leiden": 12, "louvain": 12, "unlik": [12, 30, 43, 78, 85, 104, 105, 114, 136, 178, 187], "noisi": [12, 20, 22, 23, 30, 78, 93, 95, 96, 97, 113, 128, 134, 154, 161, 162, 169, 170, 171, 172, 179, 186], "reduct": [12, 28, 30, 32, 36, 80, 82, 109, 111, 112, 121, 143, 144, 192, 198], "instead": [12, 62, 66, 67, 68, 71, 72, 73, 78, 84, 86, 93, 94, 95, 98, 104, 105, 109, 120, 122, 123, 136, 137, 144, 145, 152, 153, 154, 160, 161, 168, 169, 171, 178, 186, 187, 188, 195, 196, 197, 198], "valid": [12, 22, 72, 89, 91, 93, 94, 95, 96, 97, 102, 121, 123, 183, 185, 197], "simpler": [12, 97, 112, 118, 120, 121], "algorithm": [12, 20, 22, 30, 31, 71, 84, 89, 95, 102, 104, 105, 107, 113, 120, 122, 123, 128, 152, 153, 154, 156, 166, 169, 176, 183, 185, 186, 188, 190], "hdbscan": 12, "tend": [12, 21, 77, 84, 85, 96, 97, 113, 121, 123, 153, 185], "unstabl": [12, 94, 154, 179], "difficult": [12, 44, 78, 97, 109, 122, 123, 197], "configur": 12, "resembl": [12, 30, 60, 121, 122, 161, 168, 185], "30": [12, 36, 62, 66, 68, 71, 72, 73, 78, 84, 89, 93, 94, 95, 96, 97, 98, 104, 105, 111, 113, 114, 120, 122, 123, 134, 135, 137, 143, 144, 145, 146, 152, 153, 154, 160, 162, 168, 170, 171, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "spend": [12, 20, 78, 87, 134, 160, 194], "minut": [12, 66, 67, 71, 72, 73, 78, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 135, 136, 137, 144, 152, 153, 160, 161, 168, 169, 170, 195, 197], "todai": [12, 20, 22, 66, 67, 71, 78, 80, 82, 91, 93, 96, 102, 105, 109, 120, 126, 128, 132, 134, 141, 150, 158, 160, 166, 168, 169, 170, 172, 176, 179, 192, 194, 195, 196, 197], "reflect": [12, 22, 36, 65, 67, 71, 76, 78, 87, 113, 145, 153, 161, 168, 174], "done": [12, 20, 21, 22, 23, 43, 71, 77, 78, 84, 85, 86, 91, 118, 120, 122, 123, 128, 134, 146, 178, 179, 188], "guidanc": [12, 128], "identifi": [12, 18, 20, 21, 30, 31, 32, 62, 66, 98, 121, 123, 137, 141, 143, 146, 150, 153, 179, 185, 186, 187, 188, 197], "would": [12, 20, 21, 22, 23, 25, 30, 60, 66, 67, 71, 72, 73, 77, 78, 84, 86, 87, 95, 96, 98, 104, 105, 113, 120, 121, 123, 126, 128, 135, 137, 144, 146, 152, 160, 161, 162, 168, 169, 170, 171, 179, 186, 187, 188, 194, 195, 197], "ramp": [12, 164, 179], "introduc": [12, 30, 31, 32, 60, 68, 71, 72, 73, 78, 86, 102, 105, 109, 118, 126, 128, 135, 141, 143, 144, 145, 146, 150, 152, 153, 158, 160, 161, 168, 171, 172, 178, 188, 192, 194, 196, 197], "review": [12, 21, 30, 31, 32, 36, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 66, 67, 71, 72, 73, 77, 78, 80, 82, 84, 85, 86, 91, 93, 94, 95, 96, 97, 98, 104, 105, 109, 111, 112, 113, 114, 120, 121, 122, 123, 126, 130, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 158, 160, 161, 162, 168, 169, 170, 172, 178, 179, 185, 186, 187, 188, 190, 194, 195, 196, 197], "llm": 12, "app": [12, 128], "categori": [12, 114, 121, 141], "etc": [12, 18, 21, 23, 30, 32, 43, 66, 68, 82, 85, 96, 98, 104, 143, 150, 152, 160, 162, 183, 185, 192, 195, 196], "hour": [12, 36, 66, 67, 104, 105, 120, 122, 134, 143, 145, 152, 153, 160, 161, 169, 170, 185, 197], "outro": [12, 32, 36, 91, 102, 109, 118, 141, 150, 176, 192], "four": [12, 31, 60, 66, 73, 134, 154, 187], "hypothet": [12, 21, 86], "illus": [12, 20, 126, 128], "phenomenon": [12, 21, 82, 84, 97, 126, 145, 168], "state": [12, 21, 22, 23, 32, 62, 66, 73, 78, 85, 120, 130, 134, 145, 146, 150, 153, 154, 158, 166, 168, 169, 171, 172, 176, 183, 185, 186, 187, 188, 194, 195, 197, 198], "art": [12, 22, 23, 120], "ingredi": [12, 21, 126], "formul": [12, 60, 91, 113, 137, 172], "defin": [12, 21, 23, 30, 31, 62, 67, 71, 73, 77, 78, 84, 85, 86, 93, 104, 105, 112, 113, 114, 120, 122, 123, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 158, 160, 161, 162, 168, 171, 178, 179, 183, 185, 186, 187, 188, 195, 196, 197], "illustr": [12, 30, 32, 68, 71, 72, 73, 86, 91, 93, 97, 112, 121, 123, 143, 145, 156, 168, 187], "planner": [12, 126, 188], "between": [12, 20, 22, 23, 30, 31, 32, 60, 66, 67, 71, 72, 73, 77, 78, 82, 84, 85, 86, 91, 93, 94, 95, 96, 97, 98, 102, 104, 111, 113, 114, 120, 121, 122, 123, 128, 134, 136, 137, 139, 143, 145, 146, 154, 160, 161, 168, 169, 170, 171, 172, 181, 185, 186, 187, 188, 192, 194, 195, 196, 197], "beyond": [12, 68, 96, 97, 171, 188], "At": [12, 62, 105, 120, 136, 145, 150, 160, 178, 185, 186, 187, 188, 197], "section": [12, 20, 21, 89, 126, 128, 198], "feel": [12, 20, 22, 23, 30, 72, 73, 77, 111, 122, 128, 158, 160, 170, 178, 187], "order": [12, 20, 21, 22, 41, 44, 62, 66, 72, 84, 86, 94, 97, 98, 105, 111, 112, 113, 120, 121, 122, 123, 126, 128, 144, 145, 146, 152, 154, 162, 171, 172, 179, 185, 186, 187, 195, 197, 198], "rare": [12, 77, 93, 126, 197], "prescript": 12, "wherev": 12, "freeli": [12, 78, 89, 171], "summer": [12, 18, 128], "context": [12, 30, 67, 71, 85, 94, 130, 144, 160, 161, 168, 172, 198], "acquir": [12, 20, 30, 66, 128, 187, 188], "timelin": [12, 170, 178, 179], "On": [12, 22, 30, 73, 78, 80, 91, 98, 105, 114, 145, 160, 168, 185, 186, 198], "scholar": 12, "promis": 12, "ones": [12, 20, 21, 22, 60, 62, 66, 72, 73, 78, 86, 96, 97, 98, 105, 123, 128, 137, 143, 144, 145, 146, 152, 153, 154, 169, 171, 172, 178, 179, 185, 187, 188, 194], "report": [12, 62, 78, 98, 116, 120, 121, 122, 123, 171, 186], "whole": [12, 21, 22, 78, 84, 91, 105, 113, 120, 122, 130, 134, 145, 161, 169, 187, 194, 197], "found": [12, 20, 28, 44, 71, 77, 86, 94, 104, 105, 111, 113, 120, 143, 152, 162, 171, 186, 197], "pool": [12, 121, 144, 145], "contradictori": 12, "wa": [12, 18, 20, 21, 22, 23, 25, 30, 32, 60, 67, 72, 73, 77, 78, 84, 85, 86, 94, 95, 96, 97, 104, 105, 114, 118, 120, 121, 122, 123, 128, 135, 143, 145, 146, 160, 161, 162, 171, 172, 178, 185, 186, 197], "common": [12, 20, 68, 71, 77, 78, 84, 86, 98, 100, 102, 105, 113, 118, 120, 134, 141, 144, 145, 160, 161, 162, 185, 187, 188, 192, 195, 196], "edu": [12, 18, 67, 80, 89, 104, 107, 156, 164, 174, 181, 185, 190], "domain": [12, 30, 31, 32, 168, 169, 170], "vpn": 12, "preprint": [12, 80, 89, 100, 105, 107, 116, 120, 121, 122, 123, 130, 139, 148, 181, 190], "server": [12, 28], "arxiv": [12, 100, 105, 107, 116, 128, 130, 148, 190], "biorxiv": [12, 25, 89, 105, 116, 120, 121, 122, 123, 148, 181], "turn": [12, 30, 66, 68, 72, 73, 77, 78, 94, 96, 102, 105, 120, 121, 122, 123, 137, 143, 144, 152, 154, 170, 171, 179, 187, 188, 195], "someon": [12, 78, 160, 168, 171], "univers": [12, 38, 80, 89, 139, 148, 156, 171, 190], "pretti": [12, 73, 91, 95, 111, 137, 162, 194, 195, 197], "describ": [12, 20, 21, 60, 66, 67, 72, 73, 77, 78, 82, 84, 85, 94, 95, 111, 112, 120, 123, 134, 135, 136, 143, 144, 145, 146, 152, 153, 154, 158, 160, 161, 162, 166, 168, 169, 171, 176, 178, 185, 186, 187, 194], "methodolog": [12, 190], "signific": [12, 32, 113, 195, 197], "And": [12, 22, 23, 60, 66, 68, 71, 80, 104, 134, 143, 168, 170, 186, 194], "why": [12, 20, 21, 22, 30, 31, 32, 60, 62, 67, 73, 77, 78, 80, 82, 84, 87, 102, 107, 116, 120, 122, 123, 128, 134, 136, 143, 144, 145, 146, 152, 153, 160, 161, 168, 169, 170, 171, 178, 179, 185, 187, 188, 190, 194, 195, 196, 198], "point": [12, 20, 21, 22, 23, 30, 60, 66, 68, 71, 72, 73, 77, 78, 80, 84, 85, 86, 93, 94, 95, 96, 100, 104, 105, 111, 118, 120, 122, 128, 134, 135, 136, 137, 143, 144, 145, 146, 150, 153, 161, 162, 168, 169, 171, 172, 178, 179, 185, 187, 192, 194, 195], "messag": [12, 21, 32, 78, 84], "convei": [12, 21, 68], "address": [12, 20, 21, 22, 23, 30, 32, 72, 82, 84, 91, 104, 123, 128, 150, 171, 178, 197], "60min": 12, "understood": [12, 120, 134, 135, 143, 154], "word": [12, 20, 21, 66, 67, 68, 71, 72, 73, 77, 86, 118, 120, 134, 136, 137, 145, 152, 153, 160, 161, 169, 179, 188, 195], "break": [12, 36, 67, 71, 72, 73, 85, 187, 188], "text": [12, 23, 28, 29, 30, 31, 32, 36, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "written": [12, 66, 68, 72, 73, 77, 78, 96, 120, 121, 134, 135, 136, 137, 152, 153, 162, 170, 185, 195], "worri": [12, 72, 84, 85, 128, 197], "paragraph": [12, 22, 23], "200": [12, 22, 23, 67, 84, 86, 104, 120, 123, 137, 143, 144, 145, 146, 168, 170, 171, 186, 188, 197], "300": [12, 77, 135, 136, 143, 145, 146, 172], "possibl": [12, 21, 22, 23, 28, 30, 31, 60, 66, 67, 68, 71, 73, 77, 78, 84, 85, 86, 93, 102, 105, 109, 120, 123, 135, 136, 144, 146, 152, 154, 160, 161, 162, 169, 170, 178, 179, 185, 186, 187, 188, 192, 194, 195, 196, 197], "readi": [12, 20, 21, 78, 84, 86, 136, 145], "submit": 12, "mandatori": 12, "won": [12, 78, 105, 120, 122, 128, 134, 161, 162, 187, 196], "evalu": [12, 20, 30, 31, 32, 62, 71, 77, 78, 82, 86, 93, 97, 98, 120, 126, 128, 134, 137, 161, 162, 186, 187, 188], "overal": [12, 18, 20, 21, 22, 30, 78, 98, 102, 114, 128, 145, 168, 192, 194], "vagu": 12, "take": [12, 20, 21, 23, 28, 30, 31, 32, 43, 60, 67, 71, 72, 77, 78, 84, 85, 86, 93, 94, 98, 104, 105, 111, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 144, 145, 146, 152, 154, 160, 161, 162, 168, 169, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197, 198], "best": [12, 20, 21, 22, 23, 30, 71, 73, 82, 84, 87, 91, 93, 94, 96, 97, 98, 105, 118, 120, 123, 126, 128, 136, 137, 143, 144, 145, 152, 153, 154, 156, 170, 178, 185, 186, 187], "thesi": 12, "confer": [12, 116], "intermedi": [12, 18, 60, 105], "wait": [12, 73, 84, 179], "requir": [12, 18, 20, 21, 22, 28, 30, 31, 32, 36, 44, 60, 67, 71, 77, 84, 86, 113, 116, 120, 121, 128, 152, 161, 171, 178, 186, 187, 188, 195, 197], "lack": [12, 20, 21, 30, 128], "oomph": 12, "sound": [12, 77, 78, 105, 162], "check": [12, 20, 21, 22, 30, 31, 32, 39, 43, 62, 65, 66, 67, 71, 76, 78, 84, 85, 95, 104, 105, 111, 112, 121, 122, 128, 137, 143, 144, 145, 152, 153, 154, 161, 162, 168, 171, 178, 179, 185, 187, 194, 196, 197], "facet": [12, 72, 82], "enjoy": 12, "sinc": [12, 22, 23, 30, 31, 32, 43, 60, 62, 86, 94, 96, 97, 105, 111, 113, 118, 120, 121, 122, 123, 128, 135, 137, 143, 144, 146, 154, 160, 161, 162, 168, 169, 172, 178, 179, 186, 188, 195, 196, 197], "abc": 12, "build": [12, 20, 21, 22, 23, 28, 30, 32, 66, 72, 73, 78, 82, 85, 93, 94, 95, 96, 97, 98, 102, 104, 111, 113, 118, 120, 121, 123, 128, 136, 137, 141, 143, 146, 150, 152, 154, 158, 160, 162, 170, 178, 185, 188, 198], "ten": [12, 21, 32, 80, 89, 185], "rule": [12, 21, 68, 78, 80, 89, 93, 118, 120, 134, 136, 146, 154, 158, 161, 164, 170, 185, 186, 187, 188, 194, 197], "close": [12, 21, 30, 36, 71, 72, 73, 77, 78, 84, 93, 102, 104, 120, 121, 122, 123, 135, 136, 137, 143, 144, 145, 146, 152, 160, 161, 169, 171, 172, 185, 194, 195, 196, 197], "figur": [12, 20, 21, 22, 23, 176], "specifi": [12, 20, 21, 22, 30, 31, 32, 60, 62, 68, 77, 78, 84, 85, 93, 111, 112, 120, 121, 122, 123, 128, 134, 152, 169, 171, 178, 185, 188, 194, 195, 196, 197], "refer": [12, 21, 22, 23, 30, 32, 66, 68, 78, 85, 86, 96, 97, 98, 102, 104, 120, 121, 122, 123, 134, 135, 136, 137, 144, 145, 153, 154, 161, 162, 168, 169, 170, 171, 172, 179, 185, 186, 187, 188, 196], "principl": [12, 21, 78, 80, 82, 118, 120, 139, 162, 176, 179, 198], "problem": [12, 20, 21, 22, 67, 71, 73, 77, 78, 82, 85, 86, 89, 93, 94, 96, 98, 104, 105, 120, 121, 128, 137, 141, 150, 158, 160, 161, 168, 170, 172, 174, 179, 183, 185, 186, 187, 192, 196], "solut": [12, 21, 30, 31, 32, 60, 62, 66, 67, 68, 71, 77, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 123, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "45": [12, 36, 62, 66, 71, 72, 73, 77, 85, 86, 87, 93, 104, 112, 121, 122, 123, 134, 135, 136, 137, 145, 152, 153, 162, 168, 170, 171, 178, 179, 186, 188, 195, 196, 197], "style": [12, 23, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 190, 194, 195, 196, 197], "scientist": [12, 96, 160, 161], "writer": [12, 21, 30], "importantli": [12, 20, 68, 82, 98, 102, 104, 121, 135, 136, 158, 160, 183, 198], "sentenc": [12, 21], "previou": [12, 20, 21, 22, 23, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 78, 85, 86, 94, 96, 105, 112, 113, 114, 120, 121, 122, 123, 128, 134, 136, 137, 143, 144, 145, 146, 152, 153, 154, 162, 168, 169, 170, 171, 172, 178, 185, 187, 188, 194, 195, 198], "left": [12, 20, 21, 22, 23, 30, 31, 32, 44, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 86, 93, 97, 98, 104, 105, 120, 121, 122, 123, 128, 134, 135, 136, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 186, 187, 188, 194], "jargon": 12, "without": [12, 20, 21, 30, 32, 60, 66, 77, 94, 98, 104, 112, 120, 123, 128, 130, 136, 162, 169, 171, 178, 179, 188, 194, 197], "cohes": 12, "copi": [12, 22, 30, 31, 32, 43, 78, 122, 123, 153, 154], "put": [12, 21, 22, 23, 73, 77, 96, 104, 111, 120, 135, 145, 154, 160, 161], "did": [12, 20, 21, 22, 23, 78, 84, 85, 87, 97, 123, 128, 135, 146, 152, 153, 160, 161, 178, 179, 185, 186, 187, 195, 196], "show": [12, 20, 21, 22, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 102, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 150, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 190, 194, 195, 196, 197], "explicit": [12, 20, 21, 98, 153, 160], "shorter": [12, 84, 86, 195], "30min": 12, "1h": 12, "mode": [12, 31, 130, 150, 161, 162, 172, 174, 187, 188, 196], "2h": 12, "alreadi": [12, 18, 20, 23, 30, 32, 68, 71, 84, 86, 97, 98, 102, 109, 111, 112, 113, 122, 126, 128, 136, 143, 145, 146, 162, 169, 171, 176, 178, 179, 186, 187, 188, 195, 196, 197], "mayb": [12, 20, 21, 22, 23, 72, 78, 105, 128, 195, 196], "match": [12, 20, 32, 60, 67, 71, 77, 78, 84, 85, 105, 120, 121, 122, 123, 128, 135, 144, 160, 162, 170, 172], "mondai": [12, 36], "inspir": [12, 33, 34, 35, 67, 85, 93, 104, 121, 190], "speak": [12, 21, 22, 23, 160, 185, 194], "cover": [12, 20, 21, 30, 33, 34, 35, 66, 67, 68, 71, 72, 77, 78, 91, 93, 94, 96, 109, 118, 120, 121, 134, 135, 145, 146, 152, 156, 160, 161, 162, 168, 171, 178, 183, 185, 195, 196, 197, 198], "materi": [12, 21, 42, 66, 67, 71, 72, 77, 82, 91, 109, 152, 153, 158, 162, 166, 168, 171, 172, 185, 192, 198], "afraid": [12, 21], "sparsiti": [12, 100, 123], "spark": 12, "mix": [12, 20, 22, 30, 78, 128, 161, 162], "respond": [12, 67, 71, 73, 78, 104, 120, 121, 143, 145, 152, 168, 188], "stimulu": [12, 22, 73, 77, 78, 94, 102, 104, 105, 118, 120, 121, 122, 123, 148, 154, 171, 185, 192], "increas": [12, 22, 23, 30, 31, 71, 72, 73, 77, 78, 84, 85, 86, 94, 105, 111, 120, 121, 123, 134, 136, 143, 144, 145, 152, 154, 160, 161, 169, 171, 172, 179, 185, 187, 195, 196], "facilit": [12, 21, 139], "arbitrari": [12, 20, 23, 71, 86, 105, 111, 112, 120, 121, 122, 161, 162, 179], "transform": [12, 20, 22, 30, 31, 32, 68, 78, 84, 94, 105, 109, 111, 112, 114, 118, 120, 121, 122, 123, 128, 144, 160, 161, 169, 170, 194, 195, 196, 197], "toi": [12, 22, 23, 68, 86, 120, 179], "label": [12, 18, 20, 22, 23, 30, 31, 32, 60, 62, 66, 68, 71, 72, 73, 77, 78, 84, 86, 93, 94, 95, 97, 98, 104, 105, 111, 112, 114, 120, 121, 122, 123, 135, 136, 137, 143, 144, 145, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196], "line": [12, 20, 22, 30, 31, 32, 60, 62, 66, 67, 68, 71, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "perform": [12, 20, 21, 22, 23, 28, 30, 31, 32, 62, 66, 67, 71, 78, 93, 98, 104, 105, 109, 114, 116, 118, 120, 121, 122, 130, 136, 137, 143, 145, 162, 168, 169, 171, 172, 179, 185, 186, 187, 188, 194, 195, 197], "rather": [12, 20, 22, 30, 32, 60, 84, 86, 113, 120, 122, 123, 135, 145, 161, 168, 171, 185, 187, 192, 194, 196], "input": [12, 20, 21, 22, 23, 30, 31, 32, 62, 66, 67, 68, 73, 78, 84, 86, 93, 94, 95, 96, 97, 98, 100, 104, 105, 111, 118, 120, 121, 122, 123, 128, 130, 134, 139, 141, 148, 150, 153, 154, 168, 170, 171, 178, 195, 196, 197], "dynam": [12, 20, 21, 30, 36, 62, 71, 72, 73, 77, 78, 82, 85, 91, 100, 102, 116, 135, 136, 137, 141, 143, 144, 146, 148, 150, 153, 154, 158, 160, 164, 166, 169, 172, 174, 176, 183, 185, 187, 195, 196, 197, 198], "fire": [12, 20, 22, 60, 62, 71, 77, 84, 86, 111, 120, 128, 139, 141, 144, 145, 150, 152, 153, 154, 172, 194, 198], "ch": [12, 139, 148], "dayan": [12, 72, 73, 80, 82, 139, 143, 181], "abbott": [12, 72, 73, 82, 139, 143], "theoret": [12, 72, 73, 80, 139, 143, 150, 174, 179, 198], "critic": [12, 21, 67, 77, 154, 186], "assumpt": [12, 20, 77, 78, 85, 94, 105, 121, 145, 160, 162, 185, 186, 196, 197], "impli": [12, 67, 84, 96, 144, 195, 196], "region": [12, 18, 30, 32, 44, 71, 84, 121, 153, 161, 168, 188, 192], "transfer": [12, 72, 130, 141, 143, 152, 153, 154], "basi": [12, 67, 68, 71, 85, 86, 93, 113, 123, 144, 158], "dictionari": [12, 30, 31, 32, 96, 97, 98, 104, 143, 144, 145, 146, 152, 153, 154, 171, 185, 186, 187, 188, 196, 197], "featur": [12, 22, 33, 34, 35, 84, 96, 97, 98, 114, 116, 121, 123, 145, 154, 185, 196], "ensembl": [12, 100, 130], "syllabl": 12, "suffici": [12, 21, 60, 123, 136, 143, 154, 171, 179, 186], "band": [12, 73, 152], "alpha": [12, 30, 31, 32, 60, 62, 66, 67, 68, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 120, 136, 137, 143, 144, 145, 146, 152, 153, 154, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 187, 188, 194, 195, 196, 197], "associ": [12, 23, 25, 31, 77, 78, 144, 186, 188, 194, 195], "gamma": [12, 73, 161, 172, 185, 187, 188], "cell": [12, 25, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 100, 105, 111, 112, 113, 114, 116, 120, 122, 123, 130, 134, 135, 136, 137, 139, 143, 144, 145, 146, 152, 153, 154, 160, 161, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "1146": [12, 130, 190], "annurev": [12, 130, 190], "26": [12, 60, 62, 66, 68, 73, 84, 86, 93, 95, 96, 97, 104, 105, 113, 120, 122, 123, 134, 135, 136, 144, 145, 146, 152, 153, 154, 162, 168, 170, 171, 172, 179, 185, 187, 188, 194, 195, 196, 197], "041002": 12, "131022": 12, "mcn": 12, "2006": [12, 89, 139, 170, 171, 190], "001": [12, 23, 60, 62, 66, 78, 120, 134, 135, 174, 185, 186, 196, 197], "narrow": [12, 120], "posit": [12, 20, 22, 30, 32, 60, 66, 67, 68, 71, 72, 73, 78, 84, 98, 104, 105, 113, 120, 121, 122, 123, 134, 136, 137, 145, 146, 152, 153, 156, 158, 161, 168, 170, 171, 174, 178, 179, 185, 187, 188], "neg": [12, 30, 62, 66, 68, 71, 72, 73, 78, 84, 85, 86, 94, 100, 104, 105, 111, 113, 120, 121, 122, 123, 137, 145, 146, 152, 154, 160, 161, 162, 168, 170, 171, 187, 197], "toward": [12, 68, 77, 84, 85, 135, 136, 145, 146, 152, 153, 160, 161, 168, 187, 188], "discourag": 12, "month": [12, 20], "toolkit": [12, 20, 128, 198], "otherwis": [12, 20, 43, 60, 67, 78, 84, 98, 105, 114, 120, 123, 144, 145, 146, 160, 161, 170, 178, 186, 187, 194, 195, 197], "scratch": [12, 32, 143, 198], "knowledg": [12, 21, 30, 66, 67, 78, 84, 104, 109, 112, 123, 135, 136, 158, 160, 161, 162, 168, 176, 195, 198], "absolut": [12, 62, 68, 86, 98, 105, 123, 160, 161, 168], "ok": [12, 23, 104, 105, 120, 121, 122, 123, 171], "Then": [12, 20, 21, 67, 72, 84, 91, 96, 111, 112, 113, 120, 121, 122, 123, 137, 141, 144, 152, 154, 160, 169, 197, 198], "initi": [12, 20, 31, 32, 60, 62, 66, 73, 77, 78, 85, 95, 98, 104, 105, 111, 114, 120, 121, 122, 123, 130, 135, 136, 143, 144, 145, 146, 154, 160, 162, 169, 170, 171, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "limit": [12, 21, 22, 23, 30, 60, 67, 68, 71, 72, 77, 78, 82, 86, 94, 98, 102, 113, 123, 136, 145, 160, 161, 162, 170, 172, 179, 187, 188, 196, 197], "somebodi": 12, "somedai": 12, "shuffl": [12, 30, 31, 32, 144], "logic": [12, 20, 80, 120, 123, 128, 156, 178, 194], "accident": [12, 197], "peak": [12, 20, 22, 71, 84, 86, 123, 128, 136, 144, 146, 161], "respons": [12, 18, 60, 66, 67, 68, 71, 72, 73, 78, 85, 86, 93, 94, 95, 96, 100, 102, 104, 105, 116, 121, 122, 123, 150, 152, 153, 154, 161, 164, 168, 170, 185, 197], "sequenc": [12, 30, 60, 71, 84, 93, 94, 95, 96, 120, 121, 137, 143, 144, 145, 146, 164, 168, 169, 170, 171, 178, 179, 185, 187, 188], "circular": [12, 111, 123], "obviou": [12, 160, 186], "catch": [12, 160, 168, 176, 179], "experienc": [12, 20, 22, 23, 128, 187, 188], "off": [12, 30, 31, 32, 67, 78, 93, 94, 95, 96, 98, 104, 105, 111, 112, 121, 122, 123, 160, 161, 168, 171, 172, 194, 195, 196, 197], "guard": 12, "branch": [12, 18, 71, 116, 123], "again": [12, 20, 31, 68, 71, 73, 77, 78, 84, 85, 91, 94, 95, 97, 98, 105, 109, 120, 122, 123, 135, 137, 146, 153, 161, 171, 186, 187, 188, 194, 195, 197, 198], "necessari": [12, 20, 21, 60, 66, 82, 86, 91, 105, 113, 123, 128, 158, 162], "calendar": 12, "http": [12, 20, 25, 28, 29, 30, 31, 32, 33, 34, 35, 39, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "compneuro": [12, 42], "io": [12, 20, 39, 42, 80, 84, 86, 104, 105, 107, 116, 120, 121, 122, 123, 128, 171], "daily_schedul": 12, "html": [12, 18, 39, 97, 98, 100, 105, 114, 116, 148, 164, 169, 170, 172, 178, 179, 185, 190, 197], "screen": [12, 104, 120, 128, 171], "graphic": [12, 21, 77, 78, 97, 130, 152, 153, 162, 174], "told": [12, 71, 137, 162], "everyon": [12, 72, 82, 128, 185], "had": [12, 22, 23, 68, 72, 77, 78, 85, 86, 94, 105, 135, 136, 137, 144, 160, 161, 162, 168, 171, 179, 185], "taught": [12, 126, 172], "via": [12, 71, 78, 93, 111, 116, 120, 122, 123, 130, 139, 144, 161, 169, 171, 179, 188, 196], "greet": 12, "round": [12, 71, 122, 136, 161, 169, 172], "call": [12, 20, 21, 22, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 102, 104, 105, 109, 111, 112, 113, 114, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "zoom": [12, 36, 113, 135, 150], "themselv": [12, 21, 66, 67, 71, 144], "hi": [12, 86, 93, 102, 104, 141, 161, 185], "jonni": 12, "wiggli": 12, "caterpillar": 12, "am": [12, 130, 197], "phd": 12, "notr": 12, "dame": 12, "pari": 12, "fli": [12, 136], "my": [12, 20, 21, 62, 82, 91, 102, 128, 137, 171], "bike": [12, 71], "ride": 12, "40": [12, 20, 22, 62, 68, 71, 73, 77, 78, 84, 85, 89, 96, 104, 105, 111, 112, 113, 120, 121, 123, 128, 136, 143, 145, 146, 152, 154, 160, 161, 168, 170, 172, 179, 185, 187, 188, 194, 195, 197], "approx": [12, 30, 73, 86, 94, 104, 105, 152, 194], "per": [12, 18, 20, 22, 30, 31, 32, 72, 77, 84, 85, 96, 114, 128, 135, 144, 168, 178, 187, 188, 195, 197], "person": [12, 43, 128, 160, 171], "wast": [12, 188], "join": [12, 32, 104, 134, 145], "appropri": [12, 18, 20, 21, 22, 104, 128, 160, 168, 179, 186, 197], "breakout": 12, "room": [12, 30, 85, 120], "miss": [12, 20, 21, 32, 77, 78, 84, 85, 87, 93, 98, 104, 105, 120, 123, 126, 128, 171, 178, 185, 186], "anyon": [12, 32], "futur": [12, 21, 22, 23, 28, 60, 62, 66, 67, 73, 116, 122, 136, 137, 144, 160, 171, 172, 183, 185, 187, 188], "perhap": [12, 32, 123, 179, 186, 194], "surpris": [12, 21, 86, 105, 171], "techniqu": [12, 30, 31, 32, 60, 62, 86, 91, 93, 109, 118, 120, 121, 122, 170, 187, 192, 196, 197], "immedi": [12, 20, 22, 73, 128, 187, 188], "subgroup": 12, "separ": [12, 21, 22, 25, 30, 31, 60, 71, 114, 121, 160, 161, 162, 168, 178, 179], "larg": [12, 31, 32, 68, 71, 73, 77, 78, 84, 104, 107, 113, 116, 118, 120, 121, 122, 123, 126, 128, 130, 134, 136, 144, 145, 150, 152, 154, 156, 160, 161, 170, 171, 178, 179, 183, 185, 188], "powerpoint": 12, "primarili": [12, 171], "ensur": [12, 20, 21, 30, 62, 71, 77, 85, 93, 94, 95, 96, 104, 120, 122, 123, 126, 136, 137, 145, 195], "superpod": 12, "cutoff": 12, "mark": [12, 162], "conclus": [12, 120, 154], "floor": [12, 68, 94, 122], "seem": [12, 20, 22, 23, 30, 68, 72, 73, 77, 84, 120, 121, 123, 128, 136, 146, 153, 154, 160, 161, 185, 186, 187, 192, 197], "imposs": [12, 20, 21, 22, 32, 105, 161], "elev": 12, "pitch": 12, "poster": 12, "zuckerberg": 12, "secur": 12, "million": [12, 31, 72, 73], "dollar": 12, "fund": 12, "act": [12, 66, 71, 86, 121, 123, 176, 183, 185, 188], "music": [12, 72, 73], "instrument": [12, 192, 194, 195, 196], "rehears": 12, "doesn": [12, 18, 20, 21, 22, 23, 30, 68, 71, 72, 85, 86, 104, 105, 112, 120, 123, 128, 152, 166, 172, 178, 186, 188, 197], "WILL": 12, "annoi": 12, "tenth": [12, 145], "secret": 12, "professor": 12, "prepar": [12, 66, 78, 121, 130, 171], "anecdot": 12, "magic": 12, "engag": [12, 25], "passiv": 12, "bore": 12, "grab": 12, "smart": 12, "while": [12, 20, 22, 30, 31, 36, 41, 68, 71, 72, 73, 77, 78, 84, 93, 95, 105, 112, 114, 118, 120, 123, 143, 144, 145, 146, 150, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 178, 179, 186, 187, 188, 192, 194, 196, 197], "main": [12, 20, 21, 22, 23, 25, 60, 62, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 91, 93, 94, 95, 96, 97, 98, 104, 105, 109, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 168, 170, 171, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "anywai": 12, "bind": 12, "didn": [12, 20, 21, 71, 77, 84, 93, 122, 128], "hear": [12, 72, 73, 109, 135, 136], "furthermor": [12, 188], "clear": [12, 20, 78, 120, 122, 123, 128, 145, 154], "got": [12, 30, 93, 137, 168, 186], "dream": [12, 188], "whether": [12, 20, 22, 23, 30, 31, 32, 67, 68, 71, 73, 77, 78, 91, 104, 105, 109, 114, 120, 121, 122, 128, 141, 144, 145, 146, 152, 154, 160, 161, 178, 197], "pictur": [12, 66, 84, 121, 154], "oppos": [12, 22, 71, 78, 95, 161, 162], "except": [12, 36, 66, 68, 104, 105, 120, 121, 122, 123, 146, 170, 171, 185, 194, 197], "rambl": 12, "avoid": [12, 20, 21, 30, 32, 60, 62, 86, 120, 122, 123, 128, 134, 161, 162, 185, 186, 187, 188], "life": [12, 96, 112, 136, 161], "given": [12, 20, 22, 60, 62, 66, 67, 68, 71, 73, 77, 78, 84, 85, 86, 93, 94, 96, 97, 98, 104, 105, 111, 112, 120, 121, 122, 123, 134, 135, 136, 137, 143, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 197], "constraint": [12, 20, 30, 31, 78, 84, 107, 121, 190], "juli": 18, "23": [18, 62, 68, 73, 77, 80, 85, 86, 93, 94, 95, 96, 97, 104, 112, 116, 121, 122, 123, 130, 134, 135, 136, 137, 146, 152, 153, 162, 168, 169, 170, 172, 174, 179, 187, 188, 194, 196, 197], "2020": [18, 20, 21, 32, 60, 62, 72, 73, 80, 100, 111, 112, 113, 114, 116, 128, 130, 136, 137, 143, 144, 146, 148, 152, 154, 156, 162, 171, 172, 174, 181, 185], "gambl": 18, "languag": [18, 20, 21, 126, 128, 195], "social": [18, 190, 194], "preprocess": [18, 98, 171], "john": [18, 64, 70, 71, 72, 73, 75, 81, 90, 101, 108, 111, 112, 113, 114, 117, 125, 131, 134, 135, 136, 137, 140, 143, 144, 145, 146, 149, 152, 153, 154, 157, 165, 168, 169, 172, 175, 182, 191, 198], "murrai": [18, 111, 112, 113, 114, 143, 144, 145, 146, 152, 153, 154], "saad": 18, "jbabdi": 18, "barch": 18, "burgess": [18, 80], "harm": 18, "petersen": 18, "schlaggar": 18, "l": [18, 30, 31, 60, 72, 73, 78, 89, 94, 98, 100, 105, 116, 120, 122, 123, 130, 139, 144, 146, 148, 161, 164, 168, 169, 171, 172, 174, 179, 181, 185, 187, 188], "corbetta": 18, "essen": 18, "2013": [18, 80, 100, 130, 148, 156, 190], "connectom": 18, "80": [18, 62, 67, 71, 143, 145, 168, 185], "169": [18, 66, 78, 139], "189": 18, "05": [18, 30, 31, 32, 60, 62, 66, 68, 71, 78, 86, 100, 113, 121, 122, 123, 130, 136, 143, 144, 146, 154, 160, 162, 168, 169, 172, 178, 179, 188, 196, 197], "033": 18, "complement": 18, "brainwid": [18, 25], "none": [18, 22, 30, 31, 32, 44, 62, 66, 67, 68, 71, 77, 78, 85, 94, 96, 97, 98, 104, 105, 114, 120, 121, 122, 123, 134, 137, 144, 145, 146, 152, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "project": [18, 21, 30, 31, 32, 39, 42, 43, 44, 66, 67, 71, 96, 109, 113, 114, 126, 150, 171, 198], "recept": [18, 100, 102, 104, 121, 161], "model": [18, 30, 31, 67, 68, 71, 78, 80, 82, 91, 93, 95, 100, 102, 109, 111, 114, 118, 120, 121, 126, 128, 134, 135, 141, 144, 150, 158, 160, 161, 166, 170, 171, 174, 176, 178, 179, 183, 185, 186, 187, 190, 192, 195, 197, 198], "ml": [18, 102, 190], "savi": 18, "hierarchi": [18, 121], "benson": 18, "jamison": 18, "arcaro": 18, "vu": 18, "glasser": 18, "coalson": 18, "2018": [18, 30, 31, 32, 80, 100, 107, 116, 130, 148, 174, 181, 190], "tesla": 18, "vision": [18, 20, 22, 23, 30, 32, 116, 128], "18": [18, 60, 62, 66, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 114, 120, 121, 122, 123, 134, 135, 136, 139, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 181, 186, 187, 188, 194, 195, 196, 197], "13": [18, 21, 28, 66, 77, 78, 80, 84, 93, 95, 96, 97, 98, 104, 105, 107, 111, 112, 113, 116, 120, 121, 122, 123, 130, 134, 136, 144, 146, 148, 152, 153, 154, 160, 162, 169, 171, 178, 179, 185, 186, 188, 195, 196, 197], "1167": 18, "michael": [18, 30, 31, 32, 53, 60, 62, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 152, 153, 154, 162, 168, 169, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "waskom": [18, 30, 31, 32, 60, 62, 84, 85, 86, 93, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 152, 153, 154, 162, 168, 169, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "v1": [18, 25, 67, 105, 116, 120, 121, 122, 123, 197], "v2": [18, 197], "v3": 18, "v4": [18, 121], "naselari": 18, "prenger": 18, "gallant": 18, "452": 18, "7185": 18, "352": 18, "355": 18, "1038": [18, 25, 80, 100, 107, 116, 130, 139, 144, 174, 181, 190], "nature06713": 18, "oliv": 18, "bayesian": [18, 36, 89, 100, 156, 158, 162, 169, 170, 171, 190, 192, 198], "reconstruct": [18, 30, 31, 114], "63": [18, 78, 123, 152, 178, 188], "902": 18, "915": 18, "09": [18, 89, 100], "006": [18, 60, 139], "di": [18, 71, 122, 153, 154], "static": [18, 68, 120, 179, 187], "navig": [18, 100, 120, 136, 161, 179, 187], "templat": 18, "kshitij": [18, 30, 31, 32, 120, 121, 122, 123], "dwivedi": [18, 30, 31, 32, 120, 121, 122, 123], "anim": [18, 68, 73, 77, 78, 102, 105, 120, 123, 137, 160, 168, 176, 178, 183, 185, 192], "clip": [18, 32, 62, 170, 196, 197], "kriegeskort": [18, 116], "mur": [18, 116, 168], "bandettini": [18, 116], "2": [18, 21, 22, 28, 36, 38, 44, 80, 82, 89, 91, 98, 100, 102, 109, 118, 130, 139, 148, 174, 181, 183, 190, 192], "06": [18, 60, 116, 152], "004": [18, 60, 116, 171], "epstein": 18, "afford": [18, 30, 96, 120], "4793": 18, "4798": 18, "1618228114": 18, "pantazi": [18, 116], "oliva": [18, 116, 118, 121], "2014": [18, 30, 31, 32, 72, 73, 100, 107, 116, 139, 148, 156, 174, 190], "resolv": [18, 20, 22, 23, 28, 84, 128], "recognit": [18, 89, 116, 118, 121, 122, 170, 171], "space": [18, 20, 68, 77, 84, 105, 109, 111, 113, 114, 121, 130, 134, 145, 158, 160, 161, 171], "17": [18, 62, 66, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 100, 104, 105, 107, 111, 112, 113, 120, 121, 122, 123, 134, 136, 139, 144, 146, 148, 152, 153, 154, 160, 162, 168, 169, 171, 172, 174, 178, 179, 186, 187, 188, 190, 195, 197], "455": [18, 172], "462": 18, "nn": [18, 30, 31, 32, 100, 107, 120, 121, 122, 123, 196], "3635": 18, "url": [18, 20, 25, 28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197], "csail": 18, "mit": [18, 80, 100, 130, 139, 156, 171, 174, 181, 185, 190], "hart": [20, 21, 22, 23, 128], "megan": [20, 21, 22, 23, 128], "peter": [20, 21, 22, 23, 128, 143, 190], "paul": [20, 21, 22, 23, 33, 34, 35, 128], "schrater": [20, 21, 22, 23, 80, 128], "gunnar": [20, 21, 22, 23, 34, 128], "blohm": [20, 21, 22, 23, 34, 80, 128], "tara": [20, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 128], "viegen": [20, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 128], "editor": [20, 21, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 143, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 188, 194, 195, 196, 197], "ella": [20, 21, 52, 57, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 152, 153, 154, 160, 161, 168, 169, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "batti": [20, 21, 52, 57, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 116, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 152, 153, 154, 160, 161, 168, 169, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "w1d2": 20, "eas": [20, 32, 153], "yesterdai": [20, 71, 105, 143, 145, 152, 168, 169, 170, 179], "gain": [20, 21, 22, 23, 68, 77, 85, 96, 111, 118, 128, 134, 136, 152, 153, 154, 160, 161, 169, 170, 171, 188], "bui": [20, 128], "But": [20, 22, 23, 71, 72, 73, 78, 82, 94, 98, 104, 113, 114, 120, 122, 128, 136, 137, 143, 144, 154, 160, 161, 164, 170, 186, 188, 195, 196, 197], "clarifi": [20, 128, 161], "assum": [20, 22, 68, 71, 77, 78, 85, 86, 94, 95, 104, 105, 111, 112, 128, 135, 136, 143, 145, 146, 152, 160, 161, 162, 168, 169, 171, 172, 176, 185, 188, 195, 196], "first": [20, 21, 22, 23, 30, 31, 32, 34, 36, 44, 60, 62, 66, 67, 71, 72, 73, 77, 78, 82, 84, 85, 86, 93, 95, 96, 97, 98, 102, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 126, 128, 134, 135, 136, 137, 141, 143, 144, 145, 146, 150, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 183, 185, 186, 188, 190, 194, 196, 197, 198], "et": [20, 23, 25, 84, 86, 105, 114, 120, 121, 122, 123, 128, 171], "al": [20, 23, 25, 84, 86, 105, 114, 120, 121, 122, 123, 128, 171], "2019": [20, 21, 23, 25, 67, 80, 84, 86, 89, 100, 105, 116, 120, 121, 122, 123, 128, 130, 148, 164, 174, 190], "frame": [20, 21, 22, 23, 66, 67, 104, 161], "remain": [20, 21, 32, 67, 86, 111, 135, 136, 145, 146, 152, 154, 162, 179, 185, 186], "revit": 20, "move": [20, 22, 23, 66, 68, 73, 77, 78, 84, 120, 121, 128, 136, 153, 154, 161, 162, 168, 169, 170, 176, 178, 185, 187, 188, 195, 196, 198], "maxim": [20, 30, 66, 71, 78, 86, 94, 95, 105, 112, 122, 123, 160, 162, 164, 176, 178, 185, 186, 187], "succeed": [20, 123], "tabl": [20, 71, 78, 160, 187, 188], "side": [20, 30, 32, 60, 66, 72, 73, 85, 113, 121, 122, 123, 134, 143, 153, 161, 168, 178, 187, 194], "introductori": 20, "explain": [20, 21, 22, 23, 66, 67, 78, 84, 85, 86, 93, 94, 102, 111, 112, 116, 122, 123, 128, 135, 141, 144, 148, 153, 160, 161, 164, 168, 170, 178, 181, 188, 196], "roleplai": 20, "showcas": [20, 32], "pitfal": [20, 21, 102, 128], "around": [20, 22, 31, 66, 73, 77, 84, 85, 86, 93, 94, 95, 96, 97, 98, 112, 113, 128, 134, 136, 144, 148, 152, 154, 160, 161, 162, 169, 170, 171, 178, 179, 187, 195, 197], "appreci": [20, 21, 80, 82, 128, 141, 150], "np": [20, 22, 23, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "pyplot": [20, 22, 23, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "plt": [20, 22, 23, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "random": [20, 22, 23, 30, 31, 32, 71, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 120, 122, 123, 128, 135, 137, 143, 144, 145, 146, 152, 154, 160, 161, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 192, 195, 196, 197], "stat": [20, 22, 23, 77, 78, 85, 86, 94, 122, 128, 161, 168, 169, 170, 171, 172], "norm": [20, 22, 23, 30, 31, 66, 68, 77, 78, 94, 104, 121, 128, 153, 158, 160, 168, 169, 170], "poisson": [20, 22, 85, 100, 102, 105, 128, 135, 143, 144, 145, 146], "logist": [20, 22, 100, 102, 104, 122, 128], "sklearn": [20, 22, 30, 31, 32, 98, 102, 105, 113, 114, 122, 128, 196, 197], "linear_model": [20, 22, 105, 128, 196, 197], "logisticregress": [20, 22, 105, 128], "model_select": [20, 22, 98, 105, 128], "cross_val_scor": [20, 22, 105, 128], "titl": [20, 22, 28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "def": [20, 22, 23, 28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "rasterplot": [20, 22, 128], "spike": [20, 22, 30, 32, 71, 73, 77, 82, 91, 96, 100, 102, 105, 128, 130, 141, 145, 150, 152, 164, 192], "timepoint": [20, 22, 78, 104, 128], "trial_spik": [20, 22, 128], "trial_ev": [20, 22, 128], "nonzero": [20, 22, 105, 112, 128, 143, 172], "150": [20, 22, 33, 34, 35, 60, 66, 128, 168, 194, 195, 196, 197], "100": [20, 21, 22, 23, 33, 34, 35, 72, 73, 77, 78, 85, 94, 104, 105, 109, 113, 120, 122, 123, 128, 136, 137, 143, 144, 145, 152, 153, 154, 162, 168, 169, 171, 178, 179, 185, 187, 188, 194, 195, 196, 197], "dt": [20, 22, 23, 60, 62, 71, 72, 73, 85, 104, 128, 134, 135, 143, 144, 145, 146, 152, 154, 172], "eventplot": [20, 22, 84, 128], "linewidth": [20, 22, 62, 66, 67, 71, 77, 78, 94, 95, 96, 104, 111, 112, 123, 128, 134, 137, 161, 162, 169, 170, 171, 172, 178], "ylabel": [20, 22, 23, 30, 31, 32, 60, 62, 66, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 170, 171, 172, 179, 186, 187, 188, 194, 195, 196, 197], "xlabel": [20, 22, 23, 30, 31, 32, 60, 62, 66, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 170, 171, 172, 179, 186, 187, 188, 194, 195, 196, 197], "plotcrossvalaccuraci": [20, 22, 128], "accuraci": [20, 22, 73, 95, 116, 118, 123, 128, 139, 164, 171, 179, 186], "ax": [20, 22, 23, 30, 31, 32, 66, 67, 68, 71, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 104, 105, 113, 120, 121, 122, 123, 128, 134, 136, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "subplot": [20, 22, 23, 30, 31, 32, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 104, 105, 113, 120, 121, 122, 123, 128, 134, 136, 143, 145, 146, 153, 154, 161, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "figsiz": [20, 22, 23, 30, 31, 32, 62, 66, 67, 68, 71, 72, 73, 85, 86, 93, 94, 95, 104, 105, 111, 112, 120, 121, 122, 123, 128, 134, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 186, 187, 188, 194, 195, 196, 197], "boxplot": [20, 22, 98, 105, 128], "vert": [20, 22, 105, 128], "fals": [20, 21, 22, 30, 31, 32, 60, 62, 66, 67, 68, 71, 78, 85, 98, 102, 104, 105, 113, 114, 120, 121, 122, 123, 128, 134, 143, 144, 145, 146, 152, 154, 160, 161, 168, 169, 170, 171, 178, 179, 185, 187, 194, 195, 196, 197], "width": [20, 22, 33, 34, 35, 66, 67, 68, 71, 72, 73, 84, 97, 105, 121, 122, 123, 128, 134, 143, 145, 146, 160, 161, 169, 170, 178, 179, 194, 195, 196, 197], "ytick": [20, 22, 31, 32, 66, 67, 68, 71, 72, 73, 84, 105, 123, 128, 135, 145, 160, 161, 172], "spine": [20, 22, 66, 67, 68, 71, 104, 105, 121, 122, 128, 160, 168, 178], "set_vis": [20, 22, 66, 68, 105, 121, 122, 128, 146, 160, 168], "generatespiketrain": [20, 22, 128], "50": [20, 22, 23, 60, 62, 66, 72, 73, 78, 84, 86, 94, 95, 96, 97, 98, 104, 105, 111, 113, 114, 120, 122, 123, 128, 143, 144, 145, 146, 153, 154, 160, 162, 168, 169, 170, 171, 172, 179, 185, 195, 196, 197], "repetit": [20, 22, 23, 128], "800": [20, 22, 128], "seed": [20, 22, 30, 60, 62, 77, 78, 85, 93, 94, 95, 96, 97, 98, 105, 111, 112, 113, 120, 122, 123, 128, 135, 136, 137, 143, 144, 145, 146, 152, 154, 168, 169, 170, 171, 172, 178, 185, 186, 187, 188, 194, 195, 196, 197], "37": [20, 22, 68, 77, 78, 84, 85, 86, 95, 96, 98, 104, 105, 107, 111, 112, 123, 128, 136, 139, 143, 146, 152, 160, 168, 172, 174, 178, 179, 186, 188, 194, 195], "arang": [20, 22, 30, 31, 32, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 97, 98, 104, 105, 112, 113, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 172, 178, 179, 185, 187, 188], "interv": [20, 22, 62, 67, 68, 71, 73, 77, 82, 85, 86, 93, 94, 96, 97, 98, 128, 143, 144, 145, 146, 170, 172, 185, 190], "velocity_sigma": [20, 22, 128], "std": [20, 22, 60, 78, 95, 123, 128, 136, 137, 143, 162, 168, 179, 195, 197], "dev": [20, 22, 78, 128], "veloc": [20, 22, 23, 71, 128, 174], "profil": [20, 22, 128], "velocity_profil": [20, 22, 128], "pdf": [20, 22, 62, 77, 78, 80, 86, 94, 100, 107, 116, 128, 130, 139, 148, 161, 164, 168, 169, 170, 174, 181, 190], "gaussian": [20, 22, 30, 71, 95, 111, 112, 121, 122, 123, 128, 130, 136, 145, 158, 166, 168, 170, 176, 186, 190], "properti": [20, 21, 22, 60, 67, 71, 77, 78, 82, 95, 113, 120, 121, 122, 123, 128, 135, 136, 141, 144, 148, 150, 158, 160, 161, 168, 169, 170, 194], "rand": [20, 22, 93, 94, 95, 122, 128, 144, 145, 146, 172], "sensit": [20, 22, 71, 78, 114, 121, 128, 144], "fr": [20, 22, 93, 94, 128], "rate": [20, 22, 30, 31, 62, 66, 71, 73, 77, 84, 85, 86, 104, 105, 111, 120, 122, 123, 128, 134, 135, 136, 137, 144, 150, 153, 154, 168, 172, 174, 186, 187, 188], "output": [20, 21, 22, 23, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 122, 123, 128, 130, 134, 135, 136, 137, 141, 143, 145, 146, 152, 153, 154, 160, 162, 168, 169, 170, 171, 178, 185, 186, 187, 188, 194, 195, 197], "target_shap": [20, 22, 128], "len": [20, 22, 23, 30, 31, 32, 62, 67, 68, 71, 72, 73, 78, 84, 85, 86, 93, 94, 96, 98, 104, 105, 112, 113, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 153, 154, 162, 168, 169, 170, 171, 172, 178, 179, 186, 187, 188, 194, 195, 196, 197], "repeat": [20, 22, 60, 68, 78, 95, 98, 121, 128, 146, 153, 160, 162, 168, 169, 178, 188], "reshap": [20, 22, 30, 31, 32, 67, 96, 113, 128, 160, 162, 172, 187, 188, 195, 197], "multipli": [20, 22, 66, 67, 68, 71, 72, 78, 94, 113, 120, 122, 123, 128, 144, 162, 170, 172, 179, 185], "s_gain": [20, 22, 128], "s_move": [20, 22, 128], "arrai": [20, 22, 23, 30, 31, 32, 62, 66, 67, 68, 71, 73, 77, 78, 84, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "top": [20, 22, 30, 32, 43, 44, 66, 67, 68, 71, 72, 73, 84, 91, 93, 96, 104, 105, 111, 112, 113, 114, 120, 122, 128, 136, 137, 146, 153, 168, 187, 188, 195, 196], "baselin": [20, 22, 32, 102, 128, 143, 144, 145], "s_fr": [20, 22, 128], "lower": [20, 22, 23, 30, 31, 32, 62, 66, 77, 78, 85, 94, 96, 97, 105, 109, 121, 123, 128, 153, 154, 160, 161, 168, 171, 172, 178, 179, 186, 187, 188, 195, 198], "correct": [20, 22, 60, 62, 68, 78, 86, 97, 104, 105, 123, 128, 130, 152, 154, 160, 161, 168, 169, 170, 171, 185, 192, 194, 195, 196, 197], "rv": [20, 22, 23, 85, 94, 128, 168, 169, 171, 172, 178], "return": [20, 22, 23, 28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "subsetpercept": [20, 22, 128], "400": [20, 22, 25, 128, 143, 144, 145, 146, 161, 185, 188], "subset": [20, 22, 62, 66, 86, 95, 98, 105, 120, 123, 128, 171, 196], "hwin": [20, 22, 128], "num_mov": [20, 22, 128], "decis": [20, 21, 22, 36, 72, 73, 77, 78, 80, 82, 91, 100, 102, 105, 120, 123, 128, 130, 136, 158, 168, 174, 178, 183, 185, 186, 198], "zero": [20, 22, 30, 31, 32, 62, 66, 67, 68, 71, 73, 77, 78, 84, 85, 86, 93, 94, 95, 97, 98, 104, 105, 111, 112, 113, 121, 122, 123, 128, 134, 135, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "ground": [20, 22, 30, 31, 32, 95, 112, 128, 144, 161, 169, 194, 195, 198], "truth": [20, 22, 30, 31, 32, 80, 95, 112, 128, 144, 161, 169, 194, 197], "y_train": [20, 22, 30, 31, 32, 97, 98, 123, 128], "y_test": [20, 22, 30, 31, 32, 97, 98, 123, 128], "m_train": [20, 22, 128], "m_test": [20, 22, 128], "reproduc": [20, 21, 22, 30, 77, 84, 85, 96, 120, 122, 123, 128, 145, 171, 186, 187, 188, 194, 195, 196, 197], "w_idx": [20, 22, 128], "ab": [20, 22, 30, 31, 32, 66, 67, 68, 86, 121, 122, 123, 128, 152, 161, 162, 168, 170, 194, 195, 196], "w_0": [20, 22, 128], "w_1": [20, 22, 111, 128], "max": [20, 21, 22, 30, 31, 32, 60, 62, 66, 67, 68, 72, 73, 77, 78, 84, 85, 86, 93, 94, 96, 97, 98, 104, 105, 111, 120, 121, 123, 128, 134, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "total": [20, 22, 71, 86, 104, 105, 113, 120, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 168, 169, 170, 172, 178, 186, 187, 188, 195], "count": [20, 22, 30, 31, 32, 62, 72, 73, 77, 78, 85, 86, 91, 95, 105, 128, 135, 143, 144, 145, 172, 178, 186], "stationari": [20, 22, 23, 128, 145, 146], "spikes_stat": [20, 22, 128], "sum": [20, 22, 23, 60, 66, 68, 77, 78, 84, 86, 94, 96, 98, 104, 105, 113, 120, 121, 122, 123, 128, 134, 135, 136, 144, 145, 146, 154, 160, 161, 162, 168, 169, 170, 172, 178, 179, 185, 186, 187, 188, 194], "spikes_mov": [20, 22, 128], "train_spikes_stat": [20, 22, 128], "train_spikes_mov": [20, 22, 128], "test_spikes_stat": [20, 22, 128], "test_spikes_mov": [20, 22, 128], "x_train": [20, 22, 30, 31, 32, 97, 98, 128], "concaten": [20, 22, 32, 84, 104, 121, 122, 123, 128, 168, 194, 195, 196, 197], "x_test": [20, 22, 30, 31, 32, 97, 98, 128, 137], "fit": [20, 21, 22, 23, 30, 36, 62, 67, 72, 78, 82, 91, 93, 94, 95, 97, 98, 102, 109, 114, 116, 118, 120, 121, 122, 123, 128, 150, 158, 160, 187, 192, 194, 195, 197, 198], "population_model": [20, 22, 128], "solver": [20, 22, 105, 128, 134], "liblinear": [20, 22, 128], "random_st": [20, 22, 114, 122, 128, 194, 195, 196, 197], "newton": [20, 22, 128], "cg": [20, 22, 128], "lbfg": [20, 22, 128], "sag": [20, 22, 128], "saga": [20, 22, 105, 128], "coef_": [20, 22, 105, 128, 196, 197], "slope": [20, 22, 30, 71, 84, 93, 94, 95, 96, 120, 128, 144, 154], "intercept_": [20, 22, 128], "intercept": [20, 22, 84, 96, 104, 120, 128, 137, 196, 197], "ground_truth": [20, 22, 128], "percept": [20, 22, 23, 80, 100, 128, 156, 162, 170, 178], "getdata": [20, 22, 128], "ipywidget": [20, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 105, 111, 112, 113, 114, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 195, 196, 197], "widget": [20, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 105, 111, 112, 113, 114, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 195, 196, 197], "ipython": [20, 33, 34, 35, 66, 72, 73, 105, 120, 121, 128, 160, 161, 169, 170, 172, 178, 179], "displai": [20, 21, 22, 30, 31, 32, 33, 34, 35, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 105, 111, 112, 113, 114, 120, 121, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 168, 169, 170, 171, 172, 178, 179, 185, 186, 194, 195, 196, 197], "markdown": [20, 22, 30, 33, 34, 35, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 105, 111, 112, 113, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 178, 179, 185, 186, 187, 194, 195, 196, 197], "markdown1": [20, 128], "br": [20, 128], "font": [20, 66, 67, 71, 78, 128], "3pt": [20, 128], "occur": [20, 22, 23, 62, 66, 71, 77, 85, 86, 123, 128, 134, 135, 137, 146, 160, 185, 194, 197], "sit": [20, 22, 23, 86, 128, 137], "window": [20, 22, 23, 66, 104, 128, 135, 145], "suddenli": [20, 22, 23, 128], "wrong": [20, 21, 22, 23, 68, 73, 78, 86, 160, 162, 168, 194, 195], "vice": [20, 22, 23, 30, 73, 122, 128, 153, 154], "versa": [20, 22, 23, 30, 73, 122, 128, 153, 154], "surround": [20, 22, 23, 121, 122, 123, 128, 148, 150], "disambigu": [20, 22, 23, 128], "strong": [20, 21, 22, 23, 62, 78, 105, 113, 128, 143, 145, 186, 190, 197], "vibrat": [20, 22, 23, 128], "indic": [20, 22, 23, 30, 66, 72, 73, 78, 95, 98, 105, 111, 112, 120, 122, 123, 128, 134, 153, 154, 168, 171, 185, 188], "inde": [20, 22, 23, 77, 78, 85, 91, 94, 104, 105, 121, 123, 128, 143, 144, 152], "vestibular": [20, 22, 128], "illusori": [20, 23], "self": [20, 22, 23, 31, 32, 62, 66, 78, 86, 120, 121, 122, 123, 128, 130, 134, 137, 178, 179, 185, 187, 188], "markdown2": [20, 128], "colab": [20, 22, 44, 120, 121, 122, 123, 128], "accumul": [20, 22, 23, 72, 77, 120, 128, 130, 162, 168, 187, 188], "case": [20, 21, 22, 23, 30, 44, 60, 62, 66, 67, 68, 71, 77, 78, 84, 86, 93, 94, 96, 102, 104, 105, 120, 121, 122, 123, 128, 134, 143, 144, 145, 152, 154, 160, 161, 166, 168, 170, 171, 178, 179, 185, 186, 187, 188, 194], "pretend": [20, 22, 128, 171, 194], "hold": [20, 22, 23, 86, 96, 120, 121, 123, 128, 197], "condit": [20, 22, 23, 32, 60, 62, 68, 73, 82, 91, 111, 120, 128, 135, 136, 143, 144, 145, 152, 153, 154, 160, 161, 169, 170, 178, 179, 185, 187, 194, 196, 197], "slowli": [20, 22, 128, 179], "acceler": [20, 22, 23, 44, 116, 123, 128], "faster": [20, 22, 32, 104, 114, 122, 128, 154, 162, 168, 170, 178, 195], "correl": [20, 22, 23, 100, 104, 109, 130, 143, 168, 171, 174, 192, 194, 196, 197, 198], "judgement": [20, 22, 128], "out2": [20, 128], "out1": [20, 128], "tab": [20, 21, 128, 179], "set_titl": [20, 23, 30, 31, 32, 67, 71, 86, 105, 121, 122, 123, 128, 146, 162, 168, 169, 178, 179, 185, 194, 195, 197], "25": [20, 28, 32, 36, 60, 62, 66, 68, 73, 77, 78, 84, 85, 86, 96, 97, 98, 100, 104, 105, 112, 113, 120, 122, 123, 134, 135, 136, 137, 139, 144, 146, 148, 152, 153, 154, 160, 161, 162, 168, 169, 170, 172, 179, 186, 187, 188, 194, 195, 196, 197], "write": [20, 22, 23, 32, 41, 43, 44, 60, 66, 67, 68, 72, 73, 78, 85, 86, 93, 94, 104, 105, 111, 112, 120, 121, 122, 123, 128, 134, 136, 137, 143, 144, 145, 152, 153, 160, 162, 168, 171, 172, 178, 185, 186, 187, 188, 194], "remind": [20, 77, 78, 93, 121, 128, 134], "exact": [20, 22, 68, 71, 73, 77, 82, 94, 97, 98, 114, 121, 123, 128, 135, 152, 161], "clearli": [20, 21, 22, 23, 84, 136, 145, 171, 187], "precis": [20, 21, 25, 78, 84, 112, 116, 128, 134, 168, 171, 186, 196], "lost": [20, 21, 98, 171], "guarante": [20, 105, 152, 168, 172, 174, 196], "yet": [20, 23, 95, 98, 104, 120, 146, 152, 153, 160, 161, 186, 188], "comparison": [20, 21, 23, 30, 78, 91, 116, 118, 128, 170, 172, 195, 197], "essenti": [20, 21, 22, 23, 60, 66, 71, 77, 78, 97, 98, 120, 121, 123, 141, 152, 160, 161, 179, 190], "interfac": [20, 21, 28, 84, 104, 109, 130, 164, 170, 171, 176], "phenomena": [20, 21, 22, 23, 77, 84, 105, 139, 146, 150, 154, 169, 185, 188], "investig": [20, 23, 32, 73, 84, 109, 122, 136, 143, 145, 146, 152, 153, 154, 171, 179, 185, 188], "recap": [20, 21, 66, 67, 68, 71, 72, 73, 77, 78, 93, 94, 96, 97, 105, 111, 120, 121, 128, 134, 135, 143, 152, 153, 160, 161, 168, 194], "unclear": [20, 128], "meaning": [20, 128, 178], "chosen": [20, 71, 73, 78, 120, 128, 152, 153, 162, 178, 185, 186, 187, 188, 198], "prevent": [20, 21, 128, 145], "deepli": [20, 21, 128], "behind": [20, 68, 109, 120, 123, 128, 136, 160, 162, 168, 186, 198], "properli": [20, 84, 128], "BUT": [20, 67, 128, 194], "anywher": [20, 66, 121, 128, 187, 188], "revisit": [20, 78, 94, 128, 161], "frequent": [20, 23, 71, 128, 192], "necess": [20, 128], "bad": [20, 21, 22, 78, 89, 120, 121, 123, 128, 137, 161, 170, 181, 187], "nest": [20, 78, 105], "known": [20, 22, 23, 32, 72, 73, 77, 78, 84, 86, 93, 96, 104, 126, 134, 135, 136, 137, 145, 146, 168, 170, 171, 179, 185, 187, 188], "examin": [20, 22, 23, 68, 71, 77, 78, 82, 112, 123, 126, 134, 143, 152, 153, 154, 161, 169, 171, 179, 195, 196, 197], "attempt": [20, 23, 105, 162, 185, 188, 195], "perceptu": [20, 23, 130], "markdown21": 20, "4d": [20, 22, 121, 172], "integ": [20, 22, 30, 31, 32, 60, 67, 85, 91, 104, 122, 136, 137], "2d": [20, 22, 32, 66, 67, 68, 104, 105, 112, 113, 120, 122, 153, 162, 169, 172, 178, 187], "markdown22": 20, "dimens": [20, 22, 30, 67, 71, 84, 85, 96, 97, 104, 109, 111, 113, 120, 121, 122, 123, 130, 136, 137, 152, 153, 161, 170, 171, 172], "simultan": [20, 22, 25, 77, 100, 120, 130, 135, 144, 188, 192, 194, 195, 197], "third": [20, 22, 31, 35, 96, 113, 134, 141, 152, 154], "ms": [20, 22, 62, 71, 72, 73, 84, 104, 143, 144, 145, 146, 152, 153, 154], "fourth": [20, 22, 153], "perfect": [20, 22, 23, 72, 156, 194, 195, 197], "closer": [20, 22, 85, 93, 96, 113, 121, 122, 136, 161], "mi": [20, 22, 128, 171], "markdown23": 20, "blue": [20, 22, 60, 66, 71, 72, 73, 78, 96, 111, 112, 113, 120, 121, 134, 136, 146, 152, 153, 160, 161, 168, 169, 185], "produc": [20, 21, 22, 30, 31, 62, 82, 85, 86, 93, 94, 95, 96, 98, 104, 105, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 154, 160, 161, 168, 172, 179, 185, 187, 192, 195], "flat": [20, 22, 78, 161], "orang": [20, 22, 67, 71, 78, 84, 94, 136, 146, 153, 154, 168, 169, 170, 171, 185], "green": [20, 22, 66, 67, 72, 73, 77, 121, 160, 161, 169, 171, 179, 185, 188], "bell": [20, 22, 30, 185], "correspond": [20, 22, 23, 30, 31, 60, 66, 67, 68, 71, 77, 78, 84, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 116, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 179, 186, 187, 188, 194, 195, 197], "consider": [20, 21, 22, 98, 192], "nois": [20, 22, 23, 30, 71, 78, 93, 95, 96, 97, 98, 100, 104, 105, 114, 120, 123, 128, 137, 145, 146, 148, 152, 154, 162, 168, 169, 170, 171, 178, 194, 197], "exactli": [20, 22, 60, 72, 73, 77, 85, 86, 104, 120, 121, 122, 136, 152, 154, 156, 161, 171, 185, 197], "singl": [20, 22, 30, 31, 32, 60, 62, 66, 68, 71, 72, 77, 78, 85, 86, 93, 94, 96, 100, 102, 104, 111, 113, 118, 120, 121, 122, 123, 130, 134, 136, 137, 139, 143, 145, 146, 148, 153, 160, 161, 162, 168, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "markdown24": 20, "abov": [20, 22, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 96, 97, 98, 105, 111, 112, 114, 120, 121, 122, 123, 128, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 168, 170, 171, 172, 178, 179, 185, 186, 187, 188, 192, 194, 195, 196, 197], "distinguish": [20, 22, 30, 77, 114, 190], "ey": [20, 22, 104, 113, 130, 134, 172, 194, 195, 196, 197], "ball": [20, 22, 161], "seen": [20, 22, 62, 66, 68, 71, 72, 84, 85, 86, 95, 97, 98, 104, 105, 112, 113, 122, 123, 135, 137, 143, 144, 145, 152, 153, 154, 158, 160, 161, 162, 169, 178, 179, 183, 185, 186, 187, 192, 197], "extract": [20, 22, 60, 82, 84, 104, 114, 122, 123, 128, 130, 136, 137, 194, 195, 196, 197], "move_no": [20, 22], "legend": [20, 21, 22, 23, 30, 60, 62, 66, 68, 71, 72, 73, 77, 78, 84, 93, 94, 95, 96, 97, 104, 111, 112, 122, 123, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 196, 197], "thorough": 20, "exhaust": [20, 197], "emit": [20, 78, 86, 104, 169], "altern": [20, 23, 30, 32, 66, 71, 77, 91, 104, 113, 122, 135, 137, 172, 187, 192, 195, 196, 197], "math": [20, 21, 67, 77, 85, 109, 120, 128, 137, 144, 152, 162, 168, 171, 178, 179], "v": [20, 23, 30, 31, 32, 60, 62, 66, 67, 68, 71, 73, 78, 85, 89, 100, 122, 130, 134, 135, 139, 143, 144, 145, 146, 148, 160, 169, 170, 174, 178, 181, 185, 187, 188, 196, 197], "threshold": [20, 60, 62, 71, 72, 85, 113, 139, 143, 144, 145, 146, 152, 153, 154], "\u03b8": 20, "filter": [20, 23, 77, 104, 122, 123, 143, 145], "mechan": [20, 21, 22, 28, 32, 60, 82, 85, 86, 128, 148, 150, 172, 178, 179, 195, 197], "somehow": [20, 22, 128], "classic": [20, 22, 67, 78, 95, 113, 120, 122, 123, 128, 161, 168, 170, 185, 187, 197], "classif": [20, 22, 30, 102, 105, 121, 123, 128], "raw": [20, 22, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "pre": [20, 22, 60, 68, 72, 84, 85, 86, 104, 121, 128, 134, 135, 141, 143, 144, 145, 153, 160, 161, 162, 169, 198], "10m": [20, 22], "sub": [20, 30, 71, 186], "perceiv": [20, 22, 32, 77, 105, 128], "classifi": [20, 22, 82, 122, 123, 198], "render": [20, 28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "allow": [20, 21, 22, 23, 60, 66, 68, 73, 77, 78, 82, 84, 91, 93, 95, 96, 98, 102, 104, 105, 112, 118, 120, 121, 123, 143, 145, 158, 160, 161, 162, 166, 168, 169, 170, 178, 183, 185, 188, 192, 196, 197], "constant": [20, 23, 60, 66, 71, 72, 73, 84, 85, 86, 96, 98, 104, 123, 135, 143, 144, 145, 146, 152, 154, 160, 161, 162, 168, 170, 179, 185, 194], "over": [20, 22, 23, 60, 62, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 120, 121, 122, 123, 128, 134, 135, 136, 143, 144, 145, 146, 152, 154, 160, 161, 162, 166, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 190, 194, 195, 196, 197, 198], "omit": [20, 185], "measur": [20, 21, 30, 66, 71, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 112, 128, 135, 137, 139, 143, 154, 160, 161, 168, 171, 172, 178, 185, 194, 195, 196, 197, 198], "latent": [20, 91, 113, 166, 168, 169, 170, 172, 178, 179, 186], "abstract": [20, 22, 68, 72, 100, 116, 120, 121, 122, 123, 126, 143, 164, 174, 188, 196], "instanti": [20, 120, 170], "util": [20, 82, 145, 158, 176, 178, 188], "uncertainti": [20, 86, 91, 94, 95, 158, 161, 169, 170, 181], "cost": [20, 31, 84, 86, 93, 94, 102, 120, 178, 186, 187, 188, 197], "salienc": [20, 171], "plant": 20, "intuit": [20, 21, 67, 68, 71, 72, 73, 77, 78, 82, 85, 105, 111, 112, 113, 120, 122, 134, 136, 137, 143, 144, 154, 156, 158, 160, 161, 162, 166, 169, 170, 171, 172, 178, 179, 185, 192, 196], "inventori": 20, "anymor": [20, 128, 152], "link": [20, 22, 36, 38, 44, 66, 78, 98, 105, 123, 128, 130, 145, 154, 161, 162, 192], "Not": [20, 21, 86, 128, 137, 145, 156, 188, 190, 197], "latex": [20, 128], "jupyterbook": [20, 128], "relationship": [20, 21, 22, 23, 32, 66, 68, 72, 73, 78, 84, 94, 96, 105, 122, 135, 137, 143, 144, 145, 154, 160, 161, 170, 194, 195, 196], "amplitud": [20, 23, 68, 71, 144, 145, 154], "div": 20, "center": [20, 30, 31, 32, 66, 67, 68, 71, 77, 78, 105, 112, 116, 121, 122, 123, 136, 145, 153, 154, 160, 161, 162, 168, 169, 171, 178], "em": [20, 164], "frequenc": [20, 23, 62, 71, 72, 73, 121, 122, 123, 143, 145, 148, 152, 153, 154, 169], "occurr": [20, 23, 135, 146], "deviat": [20, 23, 30, 71, 77, 78, 94, 122, 123, 136, 137, 143, 145, 154, 161, 162, 168, 169, 170], "sup": 20, "stand": [20, 23, 85, 162, 172], "\u03c3": [20, 161], "drive": [20, 22, 25, 43, 71, 85, 89, 128, 143, 145, 154, 171, 192], "strongest": [20, 22, 123, 128, 160], "decid": [20, 21, 22, 23, 97, 105, 120, 128, 161, 168, 171, 178, 186, 187], "period": [20, 21, 22, 32, 60, 73, 84, 86, 128, 135, 143, 145, 154, 185, 186], "ratio": [20, 22, 23, 31, 71, 84, 111, 128, 144, 145, 146, 160, 170, 171, 196, 197], "higher": [20, 22, 23, 71, 86, 96, 97, 113, 116, 120, 121, 128, 130, 145, 146, 160, 178, 179, 187, 197], "came": [20, 22, 23, 72], "focuss": [20, 21, 22, 128], "hyp": [20, 22], "vs": [20, 21, 22, 23, 30, 67, 93, 94, 105, 114, 123, 136, 137, 143, 144, 146, 153, 154, 160, 161, 162, 170, 171, 178, 186, 192, 194, 196, 198], "slower": [20, 22, 143, 168, 170, 186], "simplic": [20, 22, 80, 94, 96, 104, 111, 114, 137, 146, 179, 186, 188, 197], "accum": [20, 22], "fast": [20, 22, 71, 120, 148, 153, 171, 185, 187], "slow": [20, 22, 71, 104, 172, 185], "denot": [20, 22, 60, 67, 73, 113, 120, 122, 123, 145, 146, 152, 161, 169, 170, 171, 179, 186], "argument": [20, 22, 30, 31, 32, 60, 62, 66, 84, 85, 93, 104, 120, 121, 122, 123, 152, 154, 162, 170, 187, 192, 196, 197], "outcom": [20, 21, 22, 23, 72, 77, 78, 105, 135, 160, 168, 179, 187, 188, 194, 195, 196, 197], "consist": [20, 21, 66, 67, 68, 73, 77, 96, 113, 118, 120, 121, 134, 135, 145, 153, 168, 171, 174, 188, 194], "consecut": [20, 84], "influenc": [20, 21, 23, 85, 93, 98, 104, 105, 143, 146, 152, 160, 185, 186, 192, 196], "express": [20, 21, 31, 32, 60, 67, 71, 86, 93, 96, 104, 105, 111, 112, 113, 122, 134, 135, 146, 152, 153, 154, 170, 171, 172, 179, 185, 186, 187, 188], "z": [20, 23, 30, 31, 32, 66, 68, 71, 77, 105, 116, 120, 121, 123, 144, 161, 170, 171, 181, 197], "captur": [20, 30, 31, 66, 71, 84, 85, 91, 96, 97, 100, 112, 113, 116, 122, 123, 143, 146, 161, 195, 196, 197], "hand": [20, 21, 22, 30, 67, 72, 73, 78, 86, 93, 120, 121, 130, 134, 136, 145, 152, 154, 158, 162, 172, 187, 197], "justifi": 20, "loop": [20, 21, 31, 62, 68, 73, 85, 93, 95, 96, 97, 98, 105, 116, 120, 122, 123, 128, 135, 136, 143, 162, 168, 170, 178, 187, 188, 194, 195, 197], "clariti": [20, 21, 128, 192], "OR": [20, 67, 128, 135, 160], "kp": [20, 21, 128], "pr": [20, 21, 78, 128, 168], "0352": [20, 21, 80, 128], "19": [20, 21, 62, 66, 68, 73, 77, 78, 80, 85, 86, 93, 94, 95, 96, 97, 98, 100, 104, 111, 112, 120, 121, 123, 128, 134, 135, 136, 144, 146, 152, 153, 154, 160, 162, 168, 169, 170, 171, 172, 178, 179, 186, 187, 188, 195, 197], "kai": [20, 80, 128], "nbdt": [20, 128], "scholasticahq": [20, 128], "com": [20, 28, 29, 30, 31, 32, 33, 34, 35, 42, 43, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "16723": [20, 128], "mk": [20, 128], "osf": [20, 21, 80, 84, 86, 104, 105, 120, 121, 122, 123, 128, 171], "w56vt": [20, 80, 128], "jean": [21, 22], "lauren": [21, 22], "dive": [21, 31, 60, 67, 78, 82, 104, 120, 152, 154, 161, 162, 168, 198], "satisfact": 21, "empow": 21, "chose": [21, 23, 105], "physic": [21, 72, 73, 84, 85, 130, 145, 166, 178], "repres": [21, 23, 30, 62, 66, 67, 71, 72, 73, 77, 78, 84, 86, 109, 111, 112, 113, 118, 120, 121, 122, 123, 130, 134, 144, 145, 146, 152, 153, 154, 158, 160, 161, 162, 169, 171, 172, 178, 185, 186, 188, 194, 195, 196, 197], "granular": [21, 93], "scale": [21, 23, 30, 67, 71, 77, 84, 85, 86, 105, 107, 118, 120, 123, 130, 135, 136, 150, 153, 154, 161, 162, 168, 169, 170, 171, 172, 179, 194, 196], "stai": [21, 67, 118, 135, 136, 152, 154, 169, 178, 187, 188], "span": [21, 30, 31, 67, 153, 172, 198], "wider": [21, 97, 120, 121, 136], "behaviour": [21, 28, 77, 78, 102, 105, 162, 190], "lumpabl": 21, "solv": [21, 30, 66, 71, 72, 73, 78, 94, 95, 96, 104, 120, 121, 122, 123, 134, 137, 152, 153, 154, 170, 171, 178, 183, 185, 187, 188], "analyt": [21, 30, 72, 73, 77, 93, 94, 95, 96, 104, 136, 152, 160, 161, 168, 171, 185], "numer": [21, 30, 31, 60, 66, 72, 77, 78, 82, 85, 93, 94, 96, 98, 104, 114, 134, 143, 146, 160, 162, 172, 179, 186], "spatial": [21, 116, 121, 122, 123, 130, 143, 187], "resolut": [21, 23, 121, 122, 123, 172], "regard": [21, 23, 102], "els": [21, 22, 30, 31, 32, 62, 66, 67, 68, 71, 72, 77, 78, 84, 85, 86, 95, 104, 105, 120, 121, 122, 123, 143, 144, 145, 146, 152, 153, 154, 160, 161, 168, 169, 170, 171, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "sake": [21, 162], "dl": [21, 120, 172, 190], "Being": 21, "w1d1": [21, 141], "meaningfulli": 21, "constrain": [21, 31, 86, 123], "add": [21, 23, 30, 31, 38, 60, 62, 66, 67, 71, 72, 73, 77, 78, 84, 85, 96, 97, 98, 104, 105, 120, 121, 122, 134, 136, 137, 143, 145, 146, 152, 153, 154, 160, 168, 169, 170, 171, 179, 186, 188], "needless": 21, "care": [21, 30, 77, 98, 105, 120, 160, 161, 192, 197], "highlight": [21, 23, 71, 77, 102, 188, 190], "outlin": [21, 73, 93, 122, 195, 196, 197], "draw": [21, 32, 60, 66, 67, 72, 77, 86, 93, 95, 96, 105, 120, 122, 123, 136, 143, 145, 162, 176, 178, 186], "diagram": [21, 98, 120, 135, 197], "sketch": 21, "formal": [21, 66, 71, 84, 122, 123, 160, 161, 176, 178, 183, 185, 187], "thu": [21, 66, 71, 78, 82, 86, 96, 97, 98, 105, 120, 121, 122, 123, 143, 145, 146, 162, 168, 172, 179, 185, 187, 188], "huge": [21, 150, 188], "broken": 21, "portenti": 21, "ideal": [21, 85, 86, 97, 120, 123, 186], "arrow": [21, 66, 67, 68, 134, 153, 194, 195, 196, 197], "intern": [21, 31, 32, 62, 104, 109, 116, 118, 121, 122, 174, 179, 188], "place": [21, 67, 73, 77, 82, 104, 160, 161, 178, 179, 186, 187, 188], "explan": [21, 80, 112, 121, 145, 185, 194, 195], "rough": [21, 78], "forget": [21, 65, 66, 76, 78, 104, 105, 113, 114, 144, 162, 170, 179, 197], "recurs": [21, 168, 169, 170, 172, 185], "insid": [21, 60, 62, 77, 84, 120, 154], "icon": [21, 178], "unit": [21, 22, 23, 31, 32, 60, 66, 67, 77, 84, 85, 86, 94, 104, 111, 118, 120, 121, 122, 134, 137, 143, 144, 145, 168, 170, 178, 185, 186], "easiest": [21, 82, 160, 197], "ad": [21, 28, 31, 32, 66, 71, 78, 84, 85, 94, 96, 104, 105, 120, 122, 134, 136, 137, 154, 161, 168, 170, 172, 179, 188, 194, 196], "accomplish": [21, 97, 197], "surprisingli": [21, 188], "remov": [21, 28, 30, 31, 60, 62, 66, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 120, 122, 123, 134, 136, 143, 144, 145, 146, 152, 153, 160, 162, 168, 170, 171, 179, 186, 187, 188, 194, 195, 196, 197], "insight": [21, 23, 30, 73, 82, 109, 121, 141], "isn": [21, 67, 93, 123, 161, 178, 186], "stabil": [21, 71, 94, 134, 135, 150, 153, 172, 179, 185], "equilibrium": [21, 73, 136, 137, 154, 170], "asymptot": [21, 187], "isol": [21, 28, 30, 60, 130, 134, 161], "mistak": [21, 169, 171], "debug": [21, 60, 162], "wore": 21, "nice": [21, 71, 72, 77, 121, 123, 161, 186, 194, 196], "useless": 21, "distract": 21, "reader": 21, "alreali": 21, "achiev": [21, 82, 85, 121, 168, 172, 187, 188], "handi": [21, 60, 96, 179], "finish": [21, 32, 36, 78, 86, 93, 94, 95, 96, 97, 98, 104, 112, 145, 146, 152, 153, 168, 185, 195], "criterion": [21, 30, 31, 32, 95, 168], "satisfi": [21, 66, 86, 93, 111, 197], "criteria": [21, 86, 134, 197], "parametr": 21, "elimin": 21, "met": [21, 196], "board": 21, "endless": 21, "benchmark": [21, 113, 139, 176, 190], "neglect": 21, "warrant": 21, "cannot": [21, 71, 72, 73, 84, 123, 135, 161, 162, 169, 170, 179, 185, 186], "ultim": [21, 66, 82, 126, 162], "qualit": [21, 31, 73, 94, 96, 104, 121, 134, 143, 178, 195], "upfront": 21, "amount": [21, 31, 67, 71, 78, 84, 85, 98, 113, 123, 135, 137, 145, 146, 160, 161, 168, 170, 171, 178, 179, 185, 194, 197], "w1d3": [21, 102, 118, 120, 192], "breadth": 21, "bic": 21, "aic": 21, "fair": 21, "respect": [21, 30, 68, 71, 73, 77, 78, 85, 86, 93, 94, 98, 104, 113, 120, 121, 122, 123, 134, 145, 146, 152, 153, 154, 161, 169, 171, 178, 188], "subsumpt": 21, "uncov": [21, 25, 32, 93, 122, 198], "falsifi": 21, "demonstr": [21, 22, 23, 66, 68, 120, 126, 154, 188], "appar": [21, 30, 113], "alon": [21, 171], "leverl": 21, "avenu": 21, "experiment": [21, 23, 25, 73, 82, 85, 91, 123, 145, 162, 168, 171, 174, 185, 190, 195, 197], "target": [21, 30, 32, 68, 104, 105, 114, 120, 123, 130, 161, 176, 179, 185, 187], "experimentalist": [21, 145, 162], "analog": [21, 170, 195], "famou": [21, 72, 187], "worth": [21, 121, 171, 174, 178], "1000": [21, 23, 71, 72, 73, 77, 78, 84, 85, 94, 98, 109, 111, 112, 122, 123, 135, 136, 143, 144, 145, 146, 152, 161, 162, 172, 186, 187, 188, 195], "parallel": [21, 25, 67, 128, 134, 185], "convinc": [21, 136, 137], "AND": [21, 67], "impact": [21, 73, 100, 144, 150, 169, 171, 186, 188, 197], "accept": [21, 30, 31, 32, 67, 78, 95, 123, 152, 153, 154, 179], "frget": 21, "spell": 21, "unreason": 21, "claim": [21, 168], "reject": [21, 95, 150, 197], "mesi": 21, "rightfulli": 21, "cleanli": 21, "comment": [21, 32, 62, 78, 84, 85, 86, 104, 113, 114, 135, 150, 162, 178, 186, 187, 188], "stereotyp": 21, "piec": [21, 30, 104, 123, 161], "condens": [21, 96, 171], "To": [21, 22, 23, 30, 32, 43, 68, 71, 72, 73, 77, 78, 84, 85, 86, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 122, 123, 134, 135, 136, 137, 143, 145, 146, 152, 154, 160, 161, 162, 168, 170, 171, 174, 178, 179, 185, 188, 194, 196], "summari": [21, 171], "summar": [21, 22, 23, 62, 67, 78, 98, 111, 134, 160, 169], "articul": [21, 22, 23], "tri": [21, 22, 23, 60, 93, 94, 105, 137, 160, 170, 187], "overview": [21, 22, 23, 111, 112, 113, 114, 134, 152, 190], "conclud": [21, 22, 23], "briefli": [21, 22, 23, 68, 109, 135, 171, 172], "argu": [21, 22, 23, 192], "plausibl": [21, 22, 23, 32, 73, 100, 118, 198], "instruct": [21, 30, 31, 32, 78, 93, 122, 178], "guidelin": [21, 22, 23], "effect": [21, 30, 31, 32, 62, 71, 73, 77, 78, 80, 85, 86, 91, 94, 96, 100, 107, 120, 121, 145, 148, 152, 162, 168, 169, 171, 185, 186, 188, 190, 192, 194, 195, 196, 197], "mensh": 21, "schedul": [21, 185], "schemat": [21, 105, 194], "necessarili": [21, 68, 97, 153, 161, 185], "upload": 21, "github": [21, 28, 32, 39, 89, 105, 107, 114, 116, 120, 134, 171], "forc": [21, 31, 66, 105, 120, 178, 194, 195], "succinctli": [21, 96], "commit": 21, "purpos": [21, 22, 23, 60, 67, 68, 71, 73, 78, 85, 93, 98, 104, 105, 120, 123, 137, 143, 162, 171], "walk": [21, 122, 134, 135, 137, 168, 171, 174], "biol": [21, 72, 73], "e1005619": 21, "1005619": 21, "disclaim": [22, 23, 67], "procedur": [22, 23, 89, 93, 95, 97, 105, 123, 144, 158, 197], "pip": [22, 23, 28, 31, 44, 71, 171, 197], "tqdm": 22, "quiet": [22, 23, 28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "matric": [22, 30, 66, 68, 91, 96, 97, 105, 113, 120, 122, 123, 134, 137, 169, 171, 179, 194, 195, 196, 197], "begin": [22, 23, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 174, 178, 179, 185, 186, 187, 194, 196, 197], "301": 22, "36": [22, 60, 77, 78, 95, 98, 104, 105, 111, 113, 120, 123, 130, 136, 146, 168, 170, 171, 172, 178, 188, 194, 195, 197], "7575": 22, "975": 22, "m_r": 22, "m_p": 22, "mathbb": [22, 67, 86, 97, 112, 143, 160, 161, 171, 185, 186, 194], "c_": [22, 23, 85, 104, 121, 197], "cdot": [22, 23, 66, 67, 71, 73, 77, 105, 111, 120, 122, 123, 144, 146, 152, 154, 161, 169, 172], "w1d4": [22, 192], "glm": [22, 82, 91, 102, 105, 118], "whiteboard": [22, 23], "convert": [22, 30, 31, 32, 86, 120, 121, 122, 123, 143, 144, 145, 168, 170, 172], "belong": [22, 84, 123], "half": [22, 31, 73, 95, 121, 136, 179], "halfwin": 22, "a_r": 22, "cross": [22, 30, 31, 32, 62, 73, 85, 89, 93, 94, 95, 96, 97, 102, 104, 122, 123, 134, 144, 152, 168], "getdesignmatrix": 22, "arg": [22, 23, 30, 31, 32, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 185, 186, 187, 188, 194, 195, 196, 197], "ndarrai": [22, 30, 31, 32, 66, 67, 68, 71, 77, 78, 84, 86, 93, 94, 95, 96, 97, 98, 114, 120, 122, 123, 134, 135, 136, 143, 160, 170, 171, 179, 185, 186, 187, 188, 194, 195, 196, 197], "length": [22, 31, 32, 66, 67, 68, 71, 84, 96, 105, 111, 120, 135, 137, 144, 145, 168, 169, 172, 178, 179, 194, 197], "float": [22, 30, 31, 32, 60, 62, 68, 77, 78, 84, 85, 93, 94, 95, 105, 111, 112, 113, 114, 120, 121, 122, 123, 134, 136, 137, 143, 146, 152, 161, 162, 168, 169, 172, 178, 179, 185, 186, 187, 188, 195, 196, 197], "extent": [22, 32, 66, 94, 113, 162], "1d": [22, 66, 84, 85, 93, 94, 96, 104, 105, 120, 122, 123, 152, 154, 168, 169, 170, 179], "movstim": 22, "win_idx": 22, "desmat": 22, "mov": [22, 23], "76": [22, 62, 143, 145, 168, 169, 188], "33475": 22, "77": [22, 62, 72, 78, 168, 188], "53275": 22, "78": [22, 62, 130, 168, 179, 190], "61975": 22, "calcul": [22, 30, 31, 32, 67, 68, 72, 73, 77, 78, 84, 93, 94, 95, 96, 97, 98, 111, 120, 122, 134, 135, 136, 143, 144, 145, 146, 153, 154, 161, 168, 169, 170, 172, 178, 179, 185, 186, 187, 195, 196, 197], "correctli": [22, 31, 78, 96, 168, 178, 179, 194, 197], "saw": [22, 30, 32, 66, 67, 68, 71, 73, 84, 85, 98, 105, 112, 113, 120, 122, 135, 143, 145, 154, 160, 161, 162, 169, 170, 185, 186, 195, 197], "cv": [22, 105, 143, 145], "dot": [22, 23, 60, 62, 67, 72, 73, 77, 85, 86, 97, 98, 104, 105, 111, 112, 134, 135, 136, 137, 145, 161, 162, 168, 194, 195, 196, 197], "graph": [22, 73, 97, 114, 123, 130, 135, 172, 179, 194, 195, 197], "56": [22, 104, 123, 130, 135, 143, 152, 153, 168, 187, 188, 194, 195], "72": [22, 25, 66, 78, 86, 120, 123, 130, 143, 148, 153, 154, 168, 169, 179, 188], "65": [22, 67, 78, 80, 123, 145, 146, 152, 154, 160, 161, 168, 178, 188], "median": [22, 95, 161, 162, 195], "accord": [22, 67, 71, 77, 82, 84, 94, 95, 96, 98, 111, 122, 146, 168, 170, 172, 178, 179, 185, 187, 194], "magnitud": [22, 105, 123, 134, 146, 170, 179, 195], "ignor": [22, 32, 78, 96, 104, 105, 114, 120, 122, 123, 153, 154, 160, 161, 162, 171, 192], "maximum": [22, 30, 31, 32, 68, 71, 77, 84, 93, 95, 96, 97, 98, 100, 102, 104, 105, 112, 122, 123, 145, 146, 152, 158, 160, 178, 179, 185, 186, 187, 188], "discrimin": [22, 113, 118, 120, 121], "classifymotionfromspik": 22, "750": [22, 98, 145], "int": [22, 23, 30, 31, 32, 60, 67, 68, 71, 77, 78, 84, 85, 95, 105, 113, 114, 120, 122, 123, 137, 143, 144, 145, 146, 152, 154, 168, 169, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "regular": [22, 60, 102, 120, 143, 145, 158, 188, 196], "intend": [22, 170, 195], "ye": [22, 23, 137, 143, 144, 178], "somewhat": [22, 78, 171], "contrast": [22, 71, 78, 96, 114, 169, 172, 176, 188, 198], "quit": [22, 93, 97, 104, 120, 162, 186, 188, 197], "presenc": [22, 152, 197], "runanalysi": 22, "050": 22, "class_set": 22, "empti": [22, 66, 68, 77, 104, 143, 169, 178], "halfwin_no": 22, "lty": 22, "leg_hw": 22, "classes_no": 22, "leg_class": 22, "color": [22, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 84, 85, 93, 94, 95, 96, 104, 105, 111, 112, 114, 121, 122, 123, 134, 136, 137, 143, 144, 145, 146, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 188, 194, 195, 196, 197, 198], "purpl": [22, 67], "motions_no": 22, "cond_acc": 22, "m_acc": 22, "simplifi": [22, 60, 71, 73, 78, 85, 94, 97, 141, 146, 172], "plotaccuraci": 22, "accuarci": 22, "xlim": [22, 30, 31, 32, 66, 67, 68, 71, 72, 73, 77, 84, 85, 86, 94, 95, 113, 120, 123, 135, 136, 144, 145, 146, 154, 160, 171, 172, 187, 188, 196, 197], "ylim": [22, 30, 31, 32, 66, 67, 68, 71, 72, 73, 77, 84, 85, 86, 94, 95, 112, 113, 120, 123, 136, 143, 144, 145, 146, 152, 154, 160, 171, 172, 186, 187, 188], "proport": [22, 23, 78, 93, 105, 113, 136, 144, 160, 161, 168, 169, 171, 194, 196, 197], "xtick": [22, 31, 32, 62, 66, 67, 68, 71, 104, 105, 112, 123, 137, 160, 186], "tick": [22, 30, 113, 114, 122, 185, 194, 195], "loc": [22, 66, 67, 68, 71, 73, 96, 104, 122, 136, 143, 144, 145, 146, 152, 153, 154, 161, 168, 169, 170, 178, 179, 187, 188], "job": [22, 104, 120, 137, 168, 187, 194, 196], "dash": [22, 72, 73, 143, 144, 145, 152, 161, 162, 168, 169, 179], "wors": [22, 122, 161, 195], "longer": [22, 31, 78, 145, 146, 161, 185, 186, 188], "harder": [22, 72, 123, 168, 190, 196], "clearer": [22, 62], "judgment": [22, 23, 116, 118, 164], "sensor": [22, 170, 171], "notion": [22, 71, 105, 150, 160], "Of": [22, 78, 160, 195], "contribut": [22, 60, 71, 85, 87, 94, 96, 174, 187, 190], "adjac": [22, 23, 66, 71, 84, 137, 144, 172], "unknown": [22, 23, 71, 73, 93, 160, 161, 186], "effort": [22, 93, 171, 178], "cumul": [22, 71, 113, 135, 136, 168, 185, 187], "instantan": [22, 144, 146, 178, 187], "world": [22, 30, 31, 66, 72, 78, 94, 121, 136, 158, 160, 161, 166, 168, 170, 176, 178, 183, 185, 187, 190, 196, 198], "scenario": [22, 30, 60, 86, 96, 146, 160, 179, 185, 186], "causal": [22, 36, 84, 102, 130, 141, 150, 190, 192, 198], "letter": [22, 23, 72], "paraphras": [22, 23], "extrem": [22, 23, 30, 68, 77, 78, 93, 104, 160, 178, 186], "artifici": [22, 23, 30, 80, 116, 118, 137, 145, 146, 162, 183, 185], "hopefulli": [22, 23, 30, 32, 60, 66, 77, 82, 121, 122, 136, 195], "hit": [22, 23, 143, 161, 187], "roadblock": [22, 23], "somewher": [22, 23, 104, 170, 178], "optim": [22, 30, 31, 32, 36, 71, 77, 82, 94, 95, 96, 97, 98, 102, 105, 113, 116, 118, 121, 122, 123, 130, 152, 153, 154, 158, 160, 161, 162, 166, 169, 172, 174, 176, 183, 185, 186, 187, 188, 198], "neuroscientist": [22, 77, 80, 109, 118, 152, 172], "weight": [22, 31, 32, 66, 67, 68, 73, 77, 86, 96, 97, 98, 104, 105, 112, 114, 120, 122, 141, 145, 152, 160, 161, 162, 170, 185, 194, 195, 196, 197], "role": [22, 30, 78, 100, 105, 111, 130, 144, 152, 185, 190], "demo": [23, 158, 162], "theta": [23, 30, 31, 32, 66, 71, 78, 93, 94, 95, 96, 97, 98, 104, 105, 111, 121, 122, 123, 143, 152, 153, 154, 171, 172, 178, 194, 195, 196, 197], "mathbf": [23, 66, 67, 68, 78, 93, 94, 95, 96, 104, 112, 120, 122, 123, 134, 135, 137], "sigma": [23, 30, 60, 62, 71, 77, 78, 94, 97, 98, 105, 111, 112, 121, 122, 123, 136, 137, 143, 161, 162, 168, 169, 170, 171, 194, 196, 197], "drift": [23, 72, 73, 137, 164, 179], "diffus": [23, 72, 73, 137, 145, 164, 169], "establish": [23, 137], "framework": [23, 68, 78, 100, 102, 104, 105, 116, 137, 141, 158, 183, 185, 188, 195], "frac": [23, 31, 60, 66, 71, 72, 73, 77, 78, 85, 86, 93, 94, 96, 98, 104, 105, 111, 112, 113, 120, 122, 123, 134, 136, 143, 144, 145, 146, 152, 160, 161, 168, 170, 171, 172, 178, 179, 186, 196], "de": [23, 86, 144, 153, 154, 174], "leakag": [23, 85], "instal": [23, 44, 75], "panda": [23, 170], "dark_background": 23, "vestibular_sign": 23, "sig": [23, 136, 137, 143, 144, 145, 152, 154], "scalar": [23, 66, 67, 68, 71, 77, 78, 85, 96, 97, 98, 104, 105, 111, 112, 113, 120, 122, 123, 134, 135, 136, 137, 160, 161, 162, 168, 170, 179, 197], "sd": [23, 104], "white": [23, 30, 84, 94, 104, 113, 121, 145, 170], "1m": 23, "linspac": [23, 30, 31, 32, 60, 62, 67, 77, 78, 84, 86, 93, 94, 96, 104, 105, 120, 121, 122, 123, 137, 143, 146, 152, 153, 154, 161, 162, 168, 169, 170, 172, 179, 187, 188, 194, 195, 196, 197], "14": [23, 25, 66, 71, 73, 77, 78, 84, 85, 93, 94, 95, 96, 97, 98, 100, 104, 105, 112, 116, 120, 121, 122, 123, 134, 136, 139, 144, 145, 146, 152, 153, 154, 162, 169, 171, 179, 185, 186, 187, 188, 194, 195, 197], "1001": 23, "exp": [23, 71, 72, 73, 77, 78, 84, 94, 104, 105, 121, 122, 123, 134, 152, 153, 154, 161, 162, 168, 170, 172, 194, 195, 196, 197], "diff": [23, 71, 84, 85, 86, 135, 143, 145, 172], "u": [23, 30, 31, 32, 60, 66, 68, 71, 77, 100, 111, 112, 116, 120, 145, 152, 153, 154, 156, 160, 170, 179, 187, 188, 190], "leaki": [23, 60, 85, 86, 130, 141, 144, 198], "append": [23, 30, 31, 32, 72, 73, 84, 85, 96, 98, 105, 120, 122, 123, 135, 143, 144, 145, 146, 152, 153, 154, 168, 169, 172, 178, 179, 197], "thr": [23, 145], "run_model": 23, "selfmot": 23, "aris": [23, 67, 122, 143, 150, 154, 162, 196], "fool": [23, 185], "conceptu": 23, "behav": [23, 85, 136, 145, 161, 170, 172, 185, 187, 197], "regim": [23, 120, 139, 143, 145, 148, 154], "itertool": [23, 67], "automat": [23, 30, 62, 116, 120, 123, 174], "param": [23, 31, 134, 137, 162, 170, 171, 178, 187, 188], "zip": [23, 30, 31, 32, 66, 68, 86, 93, 94, 105, 121, 122, 146, 160, 171, 172], "temp": 23, "hypothsi": 23, "pd": [23, 170], "df": [23, 71, 152, 153, 154, 170], "datafram": [23, 170], "column": [23, 30, 60, 67, 71, 78, 96, 97, 98, 104, 111, 112, 113, 120, 121, 122, 123, 160, 162, 196], "multi": [23, 122, 130, 148, 185], "panel": [23, 44, 72, 73, 105], "layout": [23, 31, 71, 72, 73, 77, 78, 143, 144, 145, 146, 160, 161, 169, 170, 172, 178], "constrained_layout": 23, "absent": 23, "present": [23, 25, 30, 32, 36, 78, 96, 104, 116, 118, 120, 121, 122, 135, 152, 162, 171, 185, 194], "mov_": 23, "uniqu": [23, 66, 73, 86, 104, 120, 122, 123, 135], "thr_": 23, "sig_": 23, "thr_n": 23, "c_n": [23, 66], "subdf0": 23, "groupbi": 23, "subdf1": 23, "im0": [23, 194], "im1": [23, 194], "4f": [23, 30, 31, 32, 78, 123, 137, 152, 185], "set_ylim": [23, 67, 68, 86, 123, 136, 146, 154, 160, 161, 168, 169, 170, 172, 178], "set_xlim": [23, 67, 68, 86, 123, 146, 160, 161, 170, 172, 178], "450": 23, "set_xlabel": [23, 71, 77, 78, 86, 104, 120, 121, 122, 123, 134, 146, 153, 154, 160, 161, 162, 168, 169, 170, 178, 179, 185, 194, 196, 197], "set_ylabel": [23, 66, 71, 77, 78, 86, 104, 120, 121, 122, 123, 134, 146, 153, 154, 160, 161, 162, 168, 169, 170, 172, 178, 179, 185, 194, 195, 196, 197], "set_facecolor": [23, 162], "grei": [23, 62, 67, 72, 73, 160, 161, 162, 169, 171], "redund": 23, "sensibl": [23, 136], "0004": 23, "d0": 23, "d1": 23, "detect": [23, 25, 171], "57": [23, 73, 80, 104, 123, 135, 143, 153, 154, 168, 187, 188, 197], "roughli": [23, 104, 114, 185, 195], "likelihood": [23, 77, 89, 91, 93, 95, 96, 97, 98, 100, 102, 104, 105, 122, 123, 158, 161, 166, 168, 169, 170, 172, 187], "201": 23, "monoton": [23, 71, 78, 84, 94, 123, 145, 152, 172], "satur": [23, 120, 152], "push": 23, "larger": [23, 71, 73, 104, 105, 112, 118, 120, 121, 123, 136, 137, 160, 185, 186, 192, 195, 196, 197], "linearli": [23, 66, 73, 136, 194], "error": [23, 30, 31, 32, 44, 66, 67, 84, 86, 89, 94, 95, 96, 98, 104, 105, 113, 120, 130, 136, 137, 152, 153, 154, 161, 168, 170, 171, 174, 179, 187, 188, 197], "construct": [23, 30, 84, 85, 86, 102, 104, 120, 122, 123, 136, 137, 162], "under": [23, 30, 31, 44, 67, 71, 98, 122, 123, 143, 144, 145, 153, 154, 164, 169, 178, 179, 185], "variat": [23, 73, 84, 85, 112, 135, 143, 185], "probabilist": [23, 77, 78, 100, 135, 160, 171, 190], "dokka": 23, "head": [23, 66, 67, 136, 186], "39": [25, 68, 78, 85, 104, 105, 111, 112, 120, 123, 136, 143, 145, 160, 168, 170, 172, 187, 188, 194, 195, 196, 197], "neuropixel": [25, 84, 105], "700": [25, 121], "superior": [25, 171], "colliculu": 25, "pathwai": [25, 130], "lfp": [25, 195], "waveform": 25, "zatka": 25, "haa": 25, "carandini": 25, "harri": [25, 130], "action": [25, 62, 82, 97, 141, 143, 146, 156, 160, 161, 162, 166, 172, 174, 176, 178, 183, 185, 187, 188, 198], "576": 25, "7786": 25, "266": [25, 66], "273": 25, "s41586": [25, 181], "019": [25, 116, 130, 181], "1787": 25, "neurostar": 25, "org": [25, 42, 66, 72, 73, 80, 89, 98, 100, 105, 107, 114, 116, 120, 121, 122, 123, 130, 148, 156, 174, 181, 190, 197], "14539": 25, "000": [25, 30, 60, 113, 114, 120, 121, 122, 123, 152, 162, 195], "grate": [25, 118, 120, 121, 122, 123], "whisk": 25, "snif": 25, "tast": [25, 62, 84], "orient": [25, 30, 32, 66, 77, 78, 96, 118, 120, 121, 123, 153, 161, 196], "reddi": 25, "multidimension": [25, 96], "364": 25, "6437": 25, "eaav7893": 25, "1126": [25, 80, 130, 139, 148, 174, 181], "aav7893": 25, "michaelo": [25, 116], "tsyboulski": [25, 116], "lindo": [25, 116], "184": [25, 116], "2767": [25, 116], "2778": [25, 116], "03": [25, 73, 89, 100, 116, 122, 139, 148, 154, 161, 174], "042": [25, 116, 152], "beginn": [25, 30, 62, 156], "mice": [25, 84, 105, 118, 120, 121, 122, 179], "novel": [25, 77, 78], "excitatori": [25, 73, 85, 86, 148, 150, 154], "vip": 25, "sst": 25, "lm": [25, 152], "dataload": 25, "sdk": 25, "atla": 25, "swdb": 25, "databook": 25, "marina": 25, "garret": 25, "iryna": 25, "yavorska": 25, "doug": 25, "ollerenshaw": 25, "garrett": 25, "2023": 25, "circuit": [25, 66, 100, 121, 145, 148], "www": [25, 66, 72, 73, 89, 107, 116, 120, 121, 122, 123, 130, 156, 174, 197], "1101": [25, 89, 116, 120, 121, 122, 123, 148, 181], "02": [25, 60, 62, 71, 73, 105, 122, 130, 135, 136, 137, 143, 145, 148, 152, 153, 154, 160, 161, 169, 172], "528085v2": 25, "bonu": [28, 32, 84, 109, 118, 137, 141, 153, 161, 166], "autoencod": [28, 109], "pip3": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "vibecheck": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "datatop": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "datatopscontentreviewcontain": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "content_review": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "notebook_sect": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "str": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "prompt": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "pmyvdlilci": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "api": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "east": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "amazonaw": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "klab": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "neuromatch_cn": [28, 29, 30, 31, 32, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "user_kei": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "y1x3mpx5": [28, 29, 30, 31, 32, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "feedback_prefix": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "bonus_autoencoders_intro": 28, "33m": 28, "deprec": [28, 136, 137], "legaci": 28, "setup": 28, "py": [28, 66, 78, 120, 123, 134, 136, 137, 152, 160, 195, 196], "bdist_wheel": 28, "enforc": [28, 30, 120, 123], "pep517": 28, "pyproject": 28, "toml": 28, "file": [28, 32, 66, 78, 104, 120, 123, 128, 134, 139, 152], "tree": [28, 181], "pypa": 28, "6334": 28, "0m": 28, "31merror": 28, "account": [28, 44, 72, 77, 78, 91, 98, 104, 136, 137, 146, 148, 160, 161, 164, 170, 171, 179], "packag": [28, 30, 60, 66, 78, 85, 120, 123, 134, 152, 171, 195, 196], "conflict": [28, 97], "jupyt": [28, 105, 114, 134], "client": 28, "incompat": 28, "31m": 28, "_video": [28, 29, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 126, 127, 132, 133, 141, 142, 150, 151, 158, 159, 166, 167, 176, 177, 183, 184, 192, 193], "bonus_autoencoders_outro": 29, "marco": [30, 31, 32, 60, 62], "brigham": [30, 31, 32, 60, 62], "ccnss": [30, 31, 32, 60, 62], "itzel": [30, 31, 32, 170, 178], "olivo": [30, 31, 32, 170, 178], "karen": [30, 31, 32], "schroeder": [30, 31, 32], "karolina": [30, 31, 32, 60, 62, 134, 135, 162, 178, 179], "stosio": [30, 31, 32, 60, 62, 134, 135, 162, 178, 179], "spiro": [30, 31, 32, 60, 62, 71, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 188, 194, 195, 196, 197], "chavli": [30, 31, 32, 60, 62, 71, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 188, 194, 195, 196, 197], "robust": [30, 31, 32, 80, 114], "famili": [30, 67, 84], "auxiliari": [30, 170], "primari": [30, 78, 120, 122, 130], "compress": [30, 31, 32, 109], "throw": 30, "awai": [30, 32, 68, 78, 85, 136, 145, 160, 161, 171, 187, 196], "fictiti": 30, "cognit": [30, 31, 32, 80, 89, 100, 107, 116, 136, 139, 148, 171], "bundl": 30, "elabor": 30, "guess": [30, 77, 78, 95, 104, 137, 146, 152, 161, 168, 170, 171, 185, 187], "occlud": [30, 32], "recov": [30, 32, 67, 78, 145, 154, 162, 170, 172, 179, 186, 195, 197], "handwritten": [30, 113], "digit": [30, 31, 71, 94, 113, 114, 120, 122, 123, 137], "bottleneck": [30, 31, 32], "layer": [30, 31, 32, 104, 105, 118, 120, 139], "fewer": [30, 98, 113, 120, 121, 168, 197], "enabl": [30, 31, 44, 62, 66, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 105, 111, 112, 113, 120, 123, 134, 135, 136, 143, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 178, 179, 185, 186, 194, 195, 196, 197], "roadmap": 30, "typic": [30, 31, 82, 84, 91, 120, 121, 123, 134, 143, 144, 145, 146, 160, 162, 171, 172, 185, 192], "architectur": [30, 32, 118, 120, 121, 122, 188], "extend": [30, 32, 68, 71, 72, 73, 96, 104, 120, 145, 150, 152, 153, 160, 161, 168, 179, 198], "acquaint": 30, "princip": [30, 109, 113, 114, 134], "non": [30, 31, 32, 67, 73, 84, 85, 86, 105, 109, 118, 120, 121, 122, 134, 145, 150, 152, 161, 170, 179, 190], "factor": [30, 68, 71, 72, 73, 84, 85, 86, 94, 107, 123, 130, 134, 144, 152, 161, 170, 187, 188], "hidden": [30, 31, 36, 62, 77, 78, 84, 100, 105, 120, 122, 123, 130, 158, 162, 166, 170, 171, 172, 176, 178, 183, 185, 196, 198], "inspect": [30, 31, 32, 44, 68, 96, 153, 178, 179, 196], "bonus_autoencoders_t1": 30, "torch": [30, 31, 32, 120, 121, 122, 123], "fetch_openml": [30, 31, 32, 113, 114], "log": [30, 31, 32, 44, 60, 62, 65, 67, 68, 71, 72, 73, 76, 77, 78, 84, 85, 86, 89, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "getlogg": [30, 31, 32, 60, 62, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "font_manag": [30, 31, 32, 60, 62, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "disabl": [30, 31, 32, 60, 62, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "config": [30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "inlinebackend": [30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "figure_format": [30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "retina": [30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "githubusercont": [30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "neuromatchacademi": [30, 31, 32, 39, 42, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "nma2020": [30, 31, 32, 162, 168, 169, 172], "mplstyle": [30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "fig_w": [30, 62, 71], "fig_h": [30, 62, 71], "rcparam": [30, 62, 67, 68, 71, 78], "downloadmnist": [30, 31, 32], "tensor": [30, 31, 32, 120, 121, 122, 123, 130, 172], "60000": [30, 31, 32], "28": [30, 31, 32, 60, 66, 68, 73, 86, 89, 93, 95, 104, 111, 113, 116, 120, 121, 122, 123, 134, 135, 136, 144, 145, 146, 152, 153, 154, 162, 168, 170, 171, 174, 178, 179, 185, 186, 188, 194, 195, 196, 197], "10000": [30, 31, 32, 62, 68, 84, 135, 136, 144, 178, 195, 196, 197], "mnist_784": [30, 31, 32, 113, 114], "return_x_i": [30, 31, 32], "as_fram": [30, 31, 32, 113, 114], "trunk": [30, 31, 32], "n_train": [30, 31, 32, 120, 122, 123], "n_test": [30, 31, 32, 123], "train_idx": [30, 31, 32], "test_idx": [30, 31, 32], "from_numpi": [30, 31, 32, 121, 122, 123], "astyp": [30, 31, 32, 68, 121, 122, 123, 143, 145, 146, 161, 178], "float32": [30, 31, 32, 84, 120, 121, 122, 123], "init_weights_kaiming_uniform": [30, 31, 32], "pytorch": [30, 31, 32, 118, 123], "kaim": [30, 31, 32], "uniform": [30, 31, 32, 60, 71, 78, 86, 93, 94, 95, 96, 97, 98, 113, 161, 171, 178, 185, 187, 188], "modul": [30, 31, 32, 33, 34, 35, 44, 62, 84, 98, 104, 111, 112, 113, 114, 120, 121, 122, 123, 137, 143, 144, 145, 146, 148, 152, 153, 154, 169, 195, 198], "noth": [30, 31, 32, 62, 77, 78, 111, 112, 113, 114, 120, 122, 123, 134, 145, 161, 179, 194, 195, 196, 197], "isinst": [30, 31, 32, 66, 152], "init": [30, 31, 32, 120, 123, 152, 153, 154, 179], "kaiming_uniform_": [30, 31, 32], "init_weights_kaiming_norm": [30, 31, 32], "kaiming_normal_": [30, 31, 32], "get_layer_weight": [30, 31, 32], "learnabl": [30, 31, 32], "item": [30, 31, 32, 84, 104, 105, 120, 122, 123, 146, 152, 172, 178], "detach": [30, 31, 32, 121, 122, 123], "eval_ms": [30, 31, 32], "y_pred": [30, 31, 32, 105, 123], "y_true": [30, 31, 32, 95], "squar": [30, 31, 32, 60, 66, 67, 77, 94, 95, 97, 98, 104, 111, 112, 114, 120, 123, 144, 160, 161, 171, 188], "mse": [30, 31, 32, 94, 95, 97, 98, 120, 123, 161, 171, 179], "no_grad": [30, 31, 32], "mseloss": [30, 31, 32, 120, 123], "eval_bc": [30, 31, 32], "entropi": [30, 31, 32, 122, 123], "bce": [30, 31, 32], "bceloss": [30, 31, 32, 122], "plot_weights_ab": 30, "encoder_w_a": 30, "encoder_w_b": 30, "decoder_w_a": 30, "decoder_w_b": 30, "label_a": 30, "label_b": 30, "bins_encod": 30, "bins_decod": 30, "row": [30, 31, 32, 60, 62, 67, 71, 78, 84, 96, 104, 113, 114, 120, 121, 122, 123, 136, 144, 145, 146, 160, 162, 169, 172, 178, 188, 196], "histogram": [30, 77, 78, 84, 85, 94, 136, 137, 143, 144, 146, 170, 178], "checkpoint": [30, 32], "string": [30, 31, 32, 104, 105, 122, 134, 162, 178, 185], "num": [30, 60, 187, 188], "32": [30, 31, 32, 62, 66, 84, 96, 97, 98, 104, 105, 113, 116, 120, 122, 123, 134, 145, 152, 153, 154, 160, 162, 168, 171, 172, 178, 185, 186, 187, 188, 194, 197], "221": [30, 145], "hist": [30, 62, 77, 78, 84, 86, 94, 95, 135, 136, 137, 143, 148, 170, 178], "flatten": [30, 96, 122, 123, 160, 169, 172, 194, 195, 196, 197], "222": [30, 154], "223": [30, 145], "224": [30, 145, 154], "tight_layout": [30, 31, 32, 62, 96, 104, 105, 113, 120, 122, 123, 143, 145, 146, 153, 154, 170, 178, 179, 185, 195, 196], "plot_row": [30, 31, 32], "show_n": [30, 31, 32], "image_shap": [30, 31, 32], "randomli": [30, 31, 32, 77, 78, 95, 104, 113, 120, 123, 136, 137, 169, 172, 185, 186, 187, 188, 192, 194], "tupl": [30, 31, 32, 84, 105, 122, 123, 134, 152, 162, 197], "items_idx": [30, 31, 32], "enumer": [30, 31, 32, 62, 66, 67, 72, 93, 94, 95, 98, 104, 121, 122, 123, 134, 136, 137, 168, 171, 172, 178, 186, 188, 195, 196, 197], "ndim": [30, 31, 32, 96, 97, 98, 121, 136, 137, 187, 188], "expand_dim": [30, 31, 32, 194, 195], "image_idx": [30, 31, 32], "imshow": [30, 31, 32, 62, 66, 78, 94, 105, 113, 120, 121, 122, 123, 162, 171, 185, 187, 188, 194, 195, 196, 197], "cmap": [30, 31, 32, 62, 66, 68, 71, 94, 96, 104, 113, 114, 120, 121, 122, 123, 134, 160, 161, 187, 188, 194, 195, 196, 197], "grai": [30, 31, 32, 121, 153, 154, 170, 179, 188], "vmin": [30, 31, 32, 66, 68, 94, 113, 120, 121, 122, 123, 160, 194, 195, 196, 197], "vmax": [30, 31, 32, 66, 68, 94, 113, 120, 121, 122, 123, 160, 194, 195, 196, 197], "xy_lim": [30, 31, 32], "minimum": [30, 31, 32, 66, 71, 84, 93, 104, 105, 120, 143, 152, 160, 179], "x_min": [30, 31, 32], "x_max": [30, 31, 32], "finfo": [30, 31, 32, 152, 162], "ep": [30, 31, 32, 78, 152, 162, 195, 196], "plot_gen": [30, 31, 32], "decoder_fn": [30, 31, 32], "n_row": [30, 31, 32], "16": [30, 31, 32, 60, 62, 66, 67, 71, 73, 77, 78, 84, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 116, 120, 121, 122, 123, 134, 135, 136, 144, 145, 146, 152, 153, 154, 160, 162, 168, 169, 171, 172, 178, 179, 185, 186, 187, 188, 190, 195, 197], "grid": [30, 31, 32, 62, 66, 67, 68, 71, 78, 93, 96, 105, 121, 122, 123, 134, 136, 143, 153, 187, 188], "coordin": [30, 31, 32, 38, 62, 66, 67, 77, 134, 153, 154, 161, 171], "dx": [30, 31, 32, 67, 71, 73, 134, 152, 153, 154, 161], "canva": [30, 31, 32, 66], "get_cmap": [30, 31, 32, 94, 96, 172], "latent_i": [30, 31, 32], "latent_x": [30, 31, 32], "dtype": [30, 31, 32, 78, 84, 105, 120, 121, 122, 123, 134, 152, 169, 172, 178], "x_decod": [30, 31, 32], "plot_lat": [30, 31, 32], "500": [30, 31, 32, 62, 77, 98, 123, 130, 135, 136, 137, 139, 143, 145, 168, 170, 187, 188], "fontdict": [30, 31, 32], "xy_label": [30, 31, 32], "bold": [30, 31, 32, 77, 91, 145, 146, 154, 194, 195, 196, 197], "tab10": [30, 31, 32, 114, 172], "my_x": [30, 31, 32], "my_i": [30, 31, 32], "horizontalalign": [30, 31, 32, 68, 145, 153, 154], "verticalalign": [30, 31, 32, 68, 145, 153, 154], "z_1": [30, 31, 32, 122], "z_2": [30, 31, 32, 122], "plot_latent_gen": [30, 31, 32], "horizont": [30, 31, 32, 67, 71, 73, 77, 78, 84, 105, 111, 121, 137], "fig": [30, 31, 32, 66, 67, 68, 71, 72, 73, 77, 78, 85, 86, 93, 94, 95, 96, 97, 105, 111, 112, 113, 120, 121, 122, 123, 134, 136, 137, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "suptitl": [30, 31, 32, 67, 77, 78, 120, 121, 122, 123, 134, 179, 194, 195, 196, 197], "add_subplot": [30, 31, 32, 66, 71, 111, 112, 162, 170], "121": [30, 31, 32, 93, 94, 95, 96, 100, 113, 123, 143, 145, 153, 154, 172], "122": [30, 31, 32, 113, 123, 143, 145, 146, 153, 154, 172], "plot_latent_ab": [30, 32], "x1": [30, 32, 71, 96, 134, 137], "x2": [30, 32, 96, 134, 137], "selected_idx": [30, 31, 32], "title_a": [30, 32], "title_b": [30, 32], "index": [30, 32, 78, 84, 86, 104, 112, 113, 121, 122, 123, 137, 172, 185, 188, 194, 195, 196, 197], "s2": [30, 31, 32], "boolean": [30, 31, 32, 104, 113, 120, 121, 122, 123, 134, 143, 144, 145, 146, 152, 154, 171, 185, 186], "3d": [30, 32, 66, 67, 68, 71, 96, 114, 172], "spheric": [30, 32], "phi": [30, 31, 32, 120, 121, 122, 123], "runsgd": [30, 31, 32], "net": [30, 31, 32, 102, 116, 120, 122, 123, 168], "input_train": [30, 31, 32], "input_test": [30, 31, 32], "n_epoch": [30, 31, 32, 120, 122, 123], "batch_siz": [30, 31, 32, 122], "verbos": [30, 31, 32, 168], "stochast": [30, 31, 32, 60, 91, 100, 122, 135, 143, 170, 171, 178, 179, 185, 186, 198], "gradient": [30, 31, 32, 78, 116, 121, 122, 123, 136], "descent": [30, 31, 32, 78, 97, 122, 123], "adam": [30, 31, 32, 130], "opoch": [30, 31, 32], "minibatch": [30, 31, 32, 122], "mini": [30, 31, 32, 120, 122], "batch": [30, 31, 32, 116, 120, 122, 123, 169, 171], "loss_fn": [30, 31, 32, 120, 122, 123], "elif": [30, 31, 32, 67, 68, 71, 78, 80, 89, 100, 104, 105, 120, 121, 122, 123, 130, 135, 143, 144, 145, 146, 148, 152, 161, 168, 171, 178, 179, 187, 188], "sgd": [30, 31, 32, 122, 123], "placehold": [30, 31, 32, 120, 122, 123], "track_loss": [30, 31, 32, 122], "epoch": [30, 31, 32, 120, 122, 123, 172], "shuffle_idx": [30, 31, 32], "permut": [30, 31, 32], "output_train": [30, 31, 32], "zero_grad": [30, 31, 32, 120, 122, 123], "backward": [30, 31, 32, 120, 122, 123, 171, 185], "loss_epoch": [30, 31, 32], "loss_train": [30, 31, 32], "output_test": [30, 31, 32], "loss_test": [30, 31, 32, 123], "loss_ms": [30, 31, 32], "nmse": [30, 31, 32], "loss_bc": [30, 31, 32], "ceil": [30, 31, 32, 67, 94, 172], "x_rang": [30, 31, 32, 86], "c0": [30, 31, 32, 60, 62, 78, 96, 185], "_intro_video": [30, 82, 91, 162], "_autoencoders_video": 30, "decompress": [30, 31, 32], "character": [30, 100, 152, 153, 178], "trigger": [30, 100, 102, 104], "backpropag": [30, 116, 120], "adjust": [30, 31, 32, 60, 62, 66, 68, 77, 84, 105, 134, 170, 178, 185, 197], "unseen": [30, 32, 105, 123], "fulli": [30, 31, 32, 66, 67, 78, 96, 100, 118, 121, 154, 160, 178, 188, 195], "aan": 30, "due": [30, 31, 62, 66, 72, 84, 85, 120, 130, 141, 145, 162, 171, 185, 186, 195, 197], "stretch": [30, 134], "28x28": [30, 113], "pixel": [30, 32, 66, 109, 113, 121, 122, 123, 171], "grayscal": [30, 113, 121, 122], "uncom": [30, 31, 32, 67, 78, 121, 137, 187], "255": [30, 31, 32, 113], "rescal": [30, 135, 171], "favor": [30, 168], "input_s": [30, 31, 32], "prod": [30, 31, 32, 122, 123], "test_selected_idx": [30, 31, 32], "train_selected_idx": [30, 31, 32], "bottom": [30, 32, 38, 66, 67, 68, 71, 72, 73, 78, 113, 121, 122, 145, 146, 153, 154, 160, 161, 168, 178, 179, 187, 188, 194, 195, 198], "w1d5": [30, 122, 192], "overlaid": [30, 171], "overlai": [30, 66, 171, 172], "pca1": 30, "pca2": 30, "Their": [30, 194], "usag": [30, 145, 195], "straightforward": [30, 137, 145], "shown": [30, 62, 71, 78, 104, 120, 121, 135, 143, 146, 154, 168, 178, 179, 185, 194, 195], "truncat": [30, 113, 114], "svd": [30, 194, 195, 196, 197], "truncatedsvd": 30, "n_compon": [30, 114, 122, 169, 172], "svd_latent_train": 30, "svd_latent_test": 30, "svd_reconstruction_train": 30, "inverse_transform": 30, "svd_reconstruction_test": 30, "obtain": [30, 32, 60, 71, 77, 84, 93, 96, 104, 105, 120, 143, 144, 145, 152, 154, 161, 171, 178, 179, 185, 187, 188, 194, 196, 197], "todo": [30, 31, 60, 62, 66, 68, 71, 73, 77, 78, 84, 93, 94, 95, 96, 97, 98, 105, 111, 112, 113, 114, 121, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 168, 171, 185, 186, 187, 188, 194, 195, 196, 197], "rais": [30, 31, 32, 60, 62, 66, 68, 71, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "notimplementederror": [30, 31, 32, 60, 62, 66, 68, 71, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "make_design_matrix": [30, 96, 97, 98, 104], "pca_latent_test": 30, "_visualize_pca_latent_space_exercis": 30, "similarli": [30, 32, 67, 71, 122, 145, 146, 154, 169, 179], "recogniz": 30, "components_": 30, "colormap": [30, 134, 162], "sign": [30, 44, 67, 71, 104, 112, 121, 137, 152, 154, 168], "thick": [30, 152], "thin": 30, "indistinguish": [30, 187], "confus": [30, 105, 145, 161, 171], "pca_compon": 30, "pca_output_test": 30, "shallow": [30, 31, 116, 120], "program": [30, 32, 174, 179, 185], "oop": [30, 32], "w3d4": [30, 32, 118, 141], "equival": [30, 60, 67, 71, 77, 84, 86, 104, 120, 160, 161, 162, 168], "deepnetrelu": [30, 120, 123], "sequenti": [30, 31, 32, 130, 187], "n_input": [30, 120, 123], "n_hidden": [30, 120, 123], "n_output": 30, "hyper": 30, "nielsen": [30, 116], "excel": [30, 112, 121], "ian": 30, "goodfellow": 30, "yoshua": 30, "bengio": [30, 116], "aaron": 30, "courvil": 30, "coverag": 30, "momentum": [30, 116, 120, 122, 123], "decai": [30, 68, 73, 84, 136, 145, 146, 152, 154, 185], "smith": [30, 174], "rectifi": [30, 120, 121, 152], "encoding_dim": 30, "sigmoid": [30, 31, 32, 71, 120, 122, 152, 153, 194, 195, 196, 197], "compat": 30, "Such": [30, 32, 71, 82, 121, 122, 134, 136, 145, 150, 154], "finit": [30, 71, 77, 84, 95, 179], "addition": [30, 111, 121, 123, 137, 144, 161, 194], "greater": [30, 68, 77, 120, 160], "input_shap": 30, "encoding_s": [30, 31, 32], "insert": [30, 62, 78, 85, 86, 114, 135, 136, 137, 162, 168, 169, 172, 179, 194, 195, 196, 197], "in_featur": 30, "784": [30, 31, 32, 113], "out_featur": 30, "bia": [30, 32, 78, 93, 94, 95, 96, 98, 104, 105, 120, 121, 122, 123], "_design_ann_autoencoder_exercis": 30, "hat": [30, 78, 93, 94, 95, 96, 97, 98, 104, 105, 112, 113, 161, 170, 171, 179, 197], "64": [30, 31, 60, 78, 86, 121, 122, 123, 130, 152, 174, 178, 179, 187, 188], "translat": [30, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 121, 130, 143, 161], "middl": [30, 32, 72, 73, 86, 121, 153, 160, 161, 188], "priorit": [30, 181], "penal": 30, "gentl": 30, "quadrat": [30, 93], "rise": [30, 78, 85, 86, 144], "dramat": [30, 154], "dark": [30, 78, 161], "wherea": [30, 105, 121, 137, 145, 146, 171], "verifi": [30, 32, 44, 86, 152, 154], "subtl": [30, 120, 178], "converg": [30, 105, 120, 136, 152, 153, 154, 170, 185, 196], "retrain": [30, 98, 105], "accentu": 30, "opt": [30, 66, 71, 78, 120, 123, 134, 152, 153, 154, 179, 195, 196], "prelu": [30, 31, 32], "wiggl": 30, "latent_test": [30, 31, 32], "wise": [30, 66, 84, 162, 172, 178, 194, 195, 196, 197], "capac": [30, 31], "oper": [30, 31, 67, 120, 121, 122, 123, 136, 137, 162, 178, 187, 190], "successfulli": [30, 31, 145, 172], "despit": [30, 68, 171, 186, 194], "charact": 30, "advantag": [30, 31, 78, 98, 121, 188], "pattern": [30, 31, 72, 85, 89, 91, 96, 97, 105, 116, 120, 130, 137, 141, 143, 145, 146, 148, 160, 168, 170, 171, 176, 186, 194], "richer": [30, 134, 196], "tackl": [30, 66, 102, 172, 187], "_wrapup_video": [30, 31, 32], "default": [30, 60, 67, 68, 77, 78, 84, 105, 120, 121, 122, 123, 143, 145, 152, 153, 154, 170, 171, 187, 188], "rng": [30, 60, 78], "manual_se": [30, 120, 122, 123], "afterward": [30, 60, 162, 185], "success": [30, 93, 172, 178, 185], "rai": 30, "recal": [30, 77, 78, 86, 94, 96, 105, 111, 113, 121, 123, 154, 168, 171, 185, 186, 187, 188, 194, 196], "sqrt": [30, 31, 32, 60, 66, 77, 94, 111, 112, 113, 122, 134, 143, 144, 145, 152, 154, 160, 161, 168, 169, 170, 179], "fan_in": 30, "increment": [30, 60, 62, 143, 144, 145, 146, 153, 154], "central": [30, 77, 139, 161, 192], "theorem": [30, 73, 77, 144, 168, 174], "clt": 30, "independ": [30, 71, 78, 85, 93, 94, 95, 96, 98, 105, 107, 121, 135, 136, 144, 145, 160, 161, 162, 168, 169, 171, 172], "inter": [30, 82, 85, 86, 135, 143, 144, 145, 185], "collaps": [30, 31, 84], "unchang": [30, 71, 111, 160], "bias": [30, 78, 98, 120, 122, 123, 168, 192], "torch_se": 30, "reset": [30, 32, 60, 62, 73, 85, 143, 144, 145, 146, 185], "encoder_w_init": 30, "encoder_b_init": 30, "decoder_w_init": 30, "decoder_b_init": 30, "encoder_w_train": 30, "encoder_b_train": 30, "decoder_w_train": 30, "decoder_b_train": 30, "popular": [30, 85, 105, 136, 186], "mathcal": [30, 60, 62, 71, 73, 77, 78, 94, 98, 105, 111, 123, 161, 168, 169, 170, 171, 194], "fan": 30, "_in": 30, "mu": [30, 62, 77, 78, 94, 122, 135, 136, 143, 145, 161, 162, 168, 169, 170, 171, 186], "backprop": 30, "feedforward": [30, 152, 174], "delv": [30, 68, 71, 72, 102], "surpass": 30, "imagenet": [30, 121], "_choosing_weight_initialization_bonus_exercis": 30, "proce": [30, 32, 185], "sk": 30, "furthest": 30, "apart": [30, 161], "shift": [30, 71, 116, 121, 122, 123, 137, 154, 170, 185], "nmf_latent_test": 30, "nmf_compon": 30, "nmf_output_test": 30, "sphere": [31, 32], "geometri": [31, 111, 112, 130], "degre": [31, 32, 66, 77, 78, 96, 97, 98, 111, 120, 121, 122, 123, 136, 137, 139, 144, 161], "freedom": 31, "plotli": 31, "bonus_autoencoders_t2": 31, "graph_object": 31, "print_parameter_count": 31, "params_n": 31, "layer_idx": 31, "params_layer_n": 31, "ntotal": 31, "sampl": [31, 32, 62, 71, 78, 85, 86, 93, 94, 95, 96, 97, 98, 113, 114, 120, 121, 122, 123, 136, 137, 144, 146, 152, 153, 154, 161, 162, 168, 169, 170, 172, 186, 187, 188, 190, 197], "loss": [31, 32, 67, 116, 122, 160], "to_s2": [31, 32], "pi": [31, 32, 60, 67, 71, 73, 77, 78, 94, 98, 111, 112, 113, 121, 122, 123, 161, 168, 170, 171, 179, 185, 186, 194, 195, 196, 197], "arcco": [31, 32, 112, 113], "arctan2": [31, 32], "to_u3": [31, 32], "sin": [31, 32, 60, 67, 71, 73, 121, 122, 123, 170, 179, 194, 195, 196, 197], "co": [31, 32, 66, 67, 71, 73, 104, 121, 122, 123, 194, 195, 196, 197], "varphi": [31, 32], "plot_latent_3d": 31, "show_text": 31, "marker": [31, 60, 62, 72, 73, 104, 105, 168, 170, 171, 172, 187, 188], "margin": [31, 67, 105, 111, 169, 172, 174], "scene": [31, 116, 120, 121, 123], "xaxi": [31, 66, 67, 160, 178, 185, 194, 195], "showspik": 31, "z1": 31, "yaxi": [31, 66, 67, 104, 160, 170, 194, 195], "z2": 31, "zaxi": 31, "z3": 31, "t10": 31, "idx": [31, 32, 84, 123, 143, 161, 162, 178, 188, 195, 196, 197], "trace": [31, 60, 71, 85, 168, 171], "scatter3d": 31, "textfont": 31, "hovermod": 31, "hoverinfo": 31, "opac": 31, "normalizelay": 31, "l2": [31, 32, 102, 105, 123], "inherit": [31, 32], "__init__": [31, 32, 62, 66, 78, 120, 121, 122, 123, 134, 178, 179, 185, 187, 188], "super": [31, 32, 66, 120, 121, 122, 123, 179, 185, 190], "dim": [31, 32, 122, 123, 171], "_extensions_video": 31, "leverag": [31, 44, 187, 197], "capabl": [31, 32, 77, 86, 120, 122, 136, 186], "layerwis": 31, "depthwis": 31, "392": 31, "aim": [31, 80, 93, 123, 186], "trainabl": 31, "doubl": [31, 62, 66, 84, 97], "halv": 31, "667k": 31, "333k": 31, "diminish": [31, 146, 185], "2x": [31, 71, 93], "3x": 31, "particularli": [31, 78, 102, 120, 121, 161], "drove": 31, "revolut": 31, "n_l": 31, "fill": [31, 32, 36, 60, 62, 66, 68, 77, 78, 84, 85, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 122, 123, 128, 134, 143, 144, 146, 152, 160, 162, 168, 170, 171, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "_build_deeper_autoencoder_exercis": 31, "128": [31, 32, 195], "skew": [31, 161], "lean": 31, "recogn": [31, 122], "spread": [31, 77, 95, 111, 136, 161], "z_3": 31, "indefinit": [31, 71], "eventu": [31, 86, 152, 153, 168, 179, 186], "divid": [31, 60, 66, 71, 73, 98, 120, 137, 143, 144, 145, 153, 160, 168, 179, 194, 195, 196, 197], "l_2": 31, "longmapsto": 31, "s_1": [31, 169], "s_3": 31, "_2": [31, 66, 68, 120, 134, 137], "radiu": 31, "custom": [31, 123, 197], "_deep_autoencoder_with_latent_spherical_space_exercis": 31, "arctan": 31, "angl": [31, 66, 67, 111, 120, 121, 122, 123, 153, 154], "un": [31, 86, 169], "unfold": 31, "rich": [31, 32, 153], "sophist": [31, 120, 186, 194, 196, 197], "8m": [31, 104], "equip": [32, 146], "encount": [32, 66, 67, 68, 71, 77, 96, 150, 158, 160, 172, 195, 196], "evolv": [32, 62, 68, 134, 136, 137, 146, 152, 153, 154, 169, 171, 179, 185], "bonus_autoencoders_t3": 32, "os": [32, 104, 105, 120, 121, 122, 123, 171], "ndimag": [32, 123], "s_2": 32, "out_train": 32, "out_test": [32, 123], "different_output": 32, "batches_out": 32, "batch_idx": 32, "image_occlus": 32, "quadrant": [32, 73, 112, 113], "image_rot": 32, "deg": [32, 136, 144], "my_deg": 32, "prefilt": 32, "autoencoderclass": 32, "activatino": 32, "enc1": 32, "enc1_f": 32, "enc2": 32, "enc2_f": 32, "enc3": 32, "enc3_f": 32, "dec1": 32, "dec1_f": 32, "dec2": 32, "dec2_f": 32, "dec3": 32, "dec3_f": 32, "pass": [32, 66, 71, 104, 105, 120, 122, 123, 143, 145, 152, 153, 154, 171, 172, 178, 179, 188, 194, 197], "save_checkpoint": 32, "filenam": [32, 66, 121, 123], "save": [32, 43, 85, 96, 104, 114, 120, 122, 123, 128, 172, 185, 188], "model_state_dict": 32, "state_dict": [32, 185], "optimizer_state_dict": 32, "pt": [32, 122, 136], "load_checkpoint": 32, "local": [32, 38, 43, 66, 71, 73, 78, 84, 85, 100, 104, 114, 120, 121, 122, 123, 130, 134, 148, 152, 153, 154, 186], "path": [32, 104, 105, 120, 121, 122, 123, 171, 190], "isfil": [32, 104, 105, 120, 121, 122, 123, 171], "wget": 32, "reset_checkpoint": 32, "load_state_dict": 32, "_applications_video": 32, "test_subset_idx": 32, "onto": [32, 67, 109, 113, 122, 123, 128, 135, 186], "lengthi": 32, "ident": [32, 67, 78, 113, 123, 145, 146, 154, 162, 168, 171, 185], "filename_path": 32, "eval": [32, 71, 105, 112, 113, 154], "repo": 32, "3rd": 32, "root": [32, 66, 71, 94, 144, 152, 153, 154, 198], "mpbrigham": 32, "colaboratori": 32, "master": [32, 60, 66, 181, 190, 194, 195, 196, 197], "ae_6h_prelu_bce_adam_25e_32b": 32, "_s2": 32, "abil": [32, 78, 86, 104, 118, 121, 169, 187, 188, 195], "invari": [32, 86, 121, 179, 190], "latent_test_ref": 32, "clean": [32, 60, 111, 171, 185], "noise_factor": 32, "input_train_noisi": 32, "input_test_noisi": 32, "output_test_noisi": 32, "latent_test_noisi": 32, "regener": 32, "denois": 32, "caus": [32, 67, 80, 105, 141, 145, 150, 162, 170, 179, 185, 190, 194, 196, 197], "compos": [32, 78, 84, 86, 152, 153, 185], "characterist": [32, 84], "adapt": [32, 89, 100, 120, 130, 174, 188], "partial": [32, 94, 120, 178], "input_train_mask": 32, "input_test_mask": 32, "output_test_mask": 32, "latent_test_mask": 32, "arguabl": [32, 91], "input_train_rot": 32, "90": [32, 62, 66, 72, 78, 111, 113, 121, 122, 148, 168, 170, 186, 188, 194, 195], "input_test_rot": 32, "output_test_rot": 32, "latent_test_rot": 32, "melt": 32, "my_input_train": 32, "my_input_test": 32, "my_y_test": 32, "my_latent_test": 32, "occupi": [32, 121, 122, 123], "Will": [32, 123, 144, 145, 152], "evenli": [32, 67, 86, 186, 195], "intersect": [32, 152, 153, 154], "cond_a": 32, "cond_b": 32, "missing_a": 32, "missing_b": 32, "47335": 32, "7885": 32, "_removing_the_most_dominant_class_exercis": 32, "asia": 32, "supposedli": 32, "revers": [32, 66, 71, 143, 144, 145, 146, 168, 171], "shuffle_image_idx": 32, "unshuffl": 32, "input_shuffl": 32, "shuffle_rev_image_idx": 32, "empty_lik": 32, "pos_idx": 32, "po": [32, 121, 168], "input_train_shuffl": 32, "input_test_shuffl": 32, "input_train_shuffle_noisi": 32, "input_test_shuffle_noisi": 32, "confirm": [32, 194], "latent_test_shuffle_noisi": 32, "output_test_shuffle_noisi": 32, "hoorai": [32, 137, 146], "hope": [32, 95, 186], "embed": [32, 33, 34, 35, 114, 171], "imprint": 32, "coin": [32, 136, 137, 186], "daniel": 32, "kahneman": 32, "psycholog": [32, 116, 130, 160, 183, 185], "replic": [32, 60, 121], "middlebrook": [33, 34, 35], "panelist": [33, 34, 35], "adrienn": 33, "fairhal": 33, "bing": [33, 134, 135, 136, 137], "kanaka": 33, "rajan": 33, "audio": [33, 34, 35, 72, 73, 78], "ifram": [33, 34, 35], "src": [33, 34, 35], "braininspir": [33, 34, 35], "casto": [33, 34, 35], "player": [33, 34, 35], "563932": 33, "height": [33, 34, 35, 62, 71, 121, 122, 123, 160, 161], "athena": [34, 174, 179], "akrami": 34, "demba": 34, "ba": 34, "kunlin": 34, "wei": [34, 89, 153, 154], "560014": 34, "yael": 35, "niv": [35, 181], "sam": 35, "gershman": 35, "tim": 35, "behren": 35, "569670": 35, "tuesdai": 36, "wednesdai": 36, "thursdai": 36, "fridai": 36, "reinforc": [36, 82, 91, 118, 158, 166, 176, 181, 183, 185, 186, 187, 198], "graduat": 36, "00": [36, 105, 107, 120, 137, 143, 196], "pod": 36, "ii": [36, 71, 73, 145, 153, 154, 188], "asynchron": [36, 198], "synchron": [36, 141], "info": [36, 73, 178], "farewel": 36, "ceremoni": 36, "certiic": 36, "cour": 36, "goodby": 36, "impos": [36, 179], "slot": [38, 186], "utc": 38, "zone": 38, "tz": 39, "launch": [41, 43, 44], "environ": [41, 43, 44, 60, 66, 77, 105, 114, 118, 178, 185, 186, 187, 188], "portal": 42, "violat": 42, "precours": [42, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 82], "exempt": 42, "shrubhlgswj8dua7": 42, "attend": 42, "waiver": 42, "bi_ssrrhyrfg_": 42, "button": [43, 44, 84, 178], "overwrit": [43, 78], "git": 43, "ipynb": 43, "china": 44, "substitut": [44, 66, 67, 68, 94, 168, 195], "regist": [44, 162], "asococi": 44, "workaround": 44, "user": [44, 78, 123, 171], "phone": 44, "gpu": [44, 120], "internet": 44, "sidebar": 44, "enter": [44, 84, 113, 137, 187], "credenti": 44, "kernel": [44, 121, 122, 123, 143, 145, 146], "restart": 44, "newli": [44, 95], "grant": [44, 120], "NOT": [44, 67, 162, 178], "comp": [44, 68, 198], "drop": [44, 71, 94, 98, 112, 144, 145, 178], "menu": [44, 71, 123], "artwork": [45, 46, 79, 129, 138, 147], "daniela": [45, 46, 79], "buchwald": [45, 46, 79], "arvind": [47, 57, 71, 72, 73, 143, 144, 145, 146, 152, 153, 154], "kumar": [47, 52, 57, 71, 72, 73, 130, 143, 144, 145, 146, 152, 153, 154], "caption": [47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], "ashish": [47, 54, 58], "sahoo": [47, 54, 58], "kushaan": [47, 54, 58], "gupta": [47, 54, 58, 164], "cynthia": 47, "castillo": [47, 170, 178], "shuze": [47, 49, 51, 52, 53, 54, 55, 56, 57, 58], "liu": [47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 194, 195, 196, 197], "8zxfvwxw": [47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78], "w0d0_t1": 47, "jen": 48, "kremkow": 48, "jiaxin": [48, 51, 55], "tu": [48, 51, 55], "pooya": [48, 52, 53, 66, 67, 77, 78], "pakarian": [48, 52, 53, 66, 67, 77, 78], "maryam": [48, 84, 85, 86, 143, 144, 145, 152, 153, 154], "ansari": 48, "antoni": 48, "puthusseri": 48, "w0d0_t10": 48, "emanuela": 49, "santini": 49, "ethan": [49, 50, 54, 77, 78, 135, 143], "cheng": [49, 50, 54, 77, 78, 135, 143, 185, 186, 187, 188], "anoop": [49, 50, 54, 58, 66, 67, 77, 78, 160, 161, 185, 186, 187, 188], "kulkarni": [49, 50, 54, 58, 66, 67, 77, 78, 100, 160, 161, 185, 186, 187, 188], "manisha": [49, 50, 51, 55, 57], "sinha": [49, 50, 51, 55, 57], "andrew": [49, 56, 57], "sun": [49, 56, 57, 116], "carolina": [49, 53, 54], "shimabukuro": [49, 54], "yihe": 49, "lu": 49, "w0d0_t11": 49, "christof": 50, "koch": [50, 164], "lili": [50, 185, 186, 187, 188], "ghinwa": [50, 56], "el": [50, 56, 60, 62], "masri": [50, 56], "w0d0_t12": 50, "jenni": 51, "zahra": [51, 56, 160, 161], "arjmandi": [51, 56, 160, 161], "lui": [51, 52, 55, 56, 57, 58], "alvarez": [51, 52, 55, 56, 57, 58], "tong": 51, "liang": 51, "w0d0_t2": 51, "swapnil": [52, 72, 73], "jeremi": [52, 53], "forest": [52, 53], "aditya": 52, "yang": [52, 54, 58], "lin": [52, 54, 58], "w0d0_t3": 52, "churchland": [53, 80, 130], "chaoqun": 53, "yin": 53, "alex": [53, 93, 94, 95, 96, 97, 98, 111, 112, 113, 114], "kostiuk": 53, "luka": 53, "oesch": 53, "ryan": 53, "ashlei": 53, "chen": [53, 130, 164], "joao": 53, "couto": 53, "oluwatomisin": [53, 58], "faniyan": [53, 58], "sirisha": [53, 55, 72], "sripada": [53, 55, 72], "shimabuku": 53, "w0d0_t4": 53, "thoma": [54, 130], "tago": 54, "w0d0_t5": 54, "gaut": 55, "einevol": 55, "richard": [55, 111, 112, 113, 114, 116, 134, 135, 136, 137, 141, 143, 144, 145, 146, 152, 153, 154, 156], "gao": [55, 111, 112, 113, 114, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 164], "zhanao": [55, 56], "fu": [55, 56], "w0d0_t6": 55, "nihan": 56, "alp": 56, "natali": [56, 77, 78, 111, 112, 113, 114], "schaworonkow": [56, 77, 78, 111, 112, 113, 114], "w0d0_t7": 56, "pedro": 57, "vald": 57, "sosa": 57, "benjamin": [57, 100, 104, 105, 194, 195, 196, 197], "becker": 57, "carlo": [57, 78], "lopez": 57, "liangyou": 57, "zhang": [57, 116], "w0d0_t8": 57, "yeka": 58, "apont": 58, "matt": [58, 71, 84, 85, 86, 87, 111, 112, 113, 114, 162, 168, 169, 171, 172, 178, 179, 185, 186, 187, 188], "mccann": [58, 71, 72, 73], "w0d0_t9": 58, "fun": [60, 78, 104, 134, 136, 152, 153, 185], "sneak": 60, "workhors": 60, "unlock": 60, "couldn": 60, "evolut": [60, 62, 68, 116, 152, 153], "w0d1_t1": 60, "_python_basics_and_the_lif_model_video": 60, "tau_m": [60, 72, 73, 143, 144, 145, 146], "e_": [60, 145, 146], "quad": [60, 62, 73, 85, 86, 93, 94, 95, 96, 104, 105, 111, 112, 113, 143, 144, 145, 152, 154, 186], "leq": [60, 105], "v_": [60, 62, 78, 85, 143, 185], "th": [60, 62, 72, 86, 96, 104, 112, 113, 120, 122, 143, 145, 146, 168], "leak": [60, 73, 143, 144, 145, 146, 154], "resist": [60, 72, 73, 85, 143], "voltag": [60, 62, 71, 72, 73, 85, 139, 143, 144, 145, 146, 169, 197], "v_m": [60, 62, 85], "conveni": [60, 66, 78, 85, 94, 113, 135, 146, 168, 171, 178], "charg": [60, 85], "ordinari": [60, 71, 97, 98, 104, 134, 145], "_nano_recap_of_comments_and_strings_video": 60, "modifi": [60, 111, 120, 122, 123, 136, 143, 146, 178, 197], "t_max": [60, 62, 170], "150e": [60, 62], "1e": [60, 62, 84, 120, 123, 146, 152, 153, 154, 169, 195, 196], "tau": [60, 62, 71, 143, 152, 170], "20e": [60, 62], "60e": [60, 62], "milivolt": [60, 62], "vr": [60, 62], "70e": [60, 62], "vth": [60, 62], "50e": [60, 62], "100e6": [60, 62], "ohm": [60, 62, 145], "i_mean": [60, 62, 71, 143], "25e": [60, 62], "amper": [60, 62], "07": [60, 105, 116, 148, 162, 172, 174], "100000000": 60, "5e": [60, 104, 123], "_defining_parameters_ecercis": 60, "notat": [60, 68, 77, 78, 134, 154, 161, 162, 170, 171, 179, 194, 197], "goe": [60, 71, 72, 77, 121, 134, 143, 146, 152, 160, 161, 168, 169, 187, 188], "sinusoid": [60, 73, 179], "i_": [60, 71, 72, 73, 85, 143, 145, 146, 152, 154], "01": [60, 62, 71, 72, 73, 78, 80, 84, 85, 95, 100, 105, 121, 122, 123, 130, 135, 136, 139, 143, 152, 153, 154, 160, 161, 162, 169, 170, 171, 178, 179, 186, 194, 195, 196, 197], "009": [60, 80, 130, 174, 197], "delta": [60, 73, 136, 143, 145, 153, 154, 168, 169, 170, 188], "block": [60, 72, 102, 118, 121, 122, 135, 141, 150, 160, 194], "syntax": [60, 120, 152], "sine": 60, "dagger": 60, "nameerror": [60, 73, 104, 111, 112, 113, 114, 122, 123, 136, 137, 146, 154, 162, 171, 172, 179, 185, 186, 187, 194, 197], "traceback": [60, 62, 66, 68, 71, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "recent": [60, 62, 66, 68, 71, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 134, 135, 136, 137, 141, 143, 144, 145, 146, 152, 153, 154, 160, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "969463130731183e": 60, "877641290737885e": 60, "9694631307311837e": 60, "5000000000000007e": 60, "0305368692688176e": 60, "2235870926211617e": 60, "223587092621159e": 60, "0305368692688186e": 60, "_simulating_an_input_current_ecercis": 60, "3f": [60, 120, 123, 134, 135, 137, 143, 144, 145, 146, 152, 153, 154, 171, 195, 196, 197], "decim": 60, "4e": 60, "exponenti": [60, 71, 72, 73, 82, 84, 85, 86, 94, 104, 134, 144, 145, 146, 152, 161, 170, 172, 185], "14159265e": 60, "314": 60, "1416e": 60, "step_end": [60, 62], "5000e": 60, "9695e": 60, "002": [60, 62, 100, 116, 123, 172], "8776e": 60, "003": [60, 130, 171, 181], "005": [60, 84, 107, 139, 148, 160, 171], "0305e": 60, "007": [60, 62, 72, 73, 139], "2236e": 60, "_printing_pretty_numbers_ecercis": 60, "_for_loops_and_discrete_time_integration_video": 60, "indent": [60, 71, 169, 170], "stepsiz": [60, 77, 78, 153], "_nano_recap_of_discrete_time_integration_video": 60, "qquad": [60, 72, 73, 145, 152, 153, 154], "manipul": [60, 72, 73, 85, 168, 169, 170, 178, 185], "euler": [60, 71, 82, 143, 145, 146, 152, 153, 154], "e_l": [60, 72, 73, 143, 145, 146], "reorgan": 60, "eq": [60, 145, 154, 179, 194], "v0": 60, "8750e": 60, "6828e": 60, "4548e": 60, "2381e": 60, "0778e": 60, "9989e": 60, "9974e": 60, "0414e": 60, "0832e": 60, "0775e": 60, "_simulating_membrane_potential_exercis": 60, "_intro_to_plotting_video": 60, "_nano_recap_of_plotting_video": 60, "024": [60, 146], "ko": [60, 152, 153, 154], "24": [60, 62, 66, 68, 72, 73, 77, 84, 85, 86, 94, 95, 96, 100, 104, 105, 111, 121, 123, 134, 135, 136, 137, 139, 144, 145, 146, 148, 153, 154, 162, 168, 170, 172, 174, 178, 179, 185, 187, 188, 194, 196, 197], "curent": 60, "_plotting_current_exercis": 60, "t_": [60, 62, 71, 72, 73, 134, 143, 145, 146, 172, 197], "nearest": [60, 122], "_plotting_membrane_potential_exercis": 60, "perspect": [60, 66, 67, 80, 116, 121, 130, 190], "xi": [60, 143, 152, 172], "sim": [60, 77, 85, 94, 111, 136, 152, 168, 169, 170, 171, 185, 194, 197], "pseudo": [60, 78, 95], "random_num": [60, 77], "_adding_randomness_exercis": 60, "_lists_": 60, "_ensemble_statistics_video": 60, "_nano_recap_of_ensemble_statistics_": 60, "_lists_video": 60, "impress": [60, 105], "autocovari": [60, 143], "v_n": [60, 62], "langl": 60, "rangl": 60, "sum_": [60, 62, 66, 78, 86, 93, 94, 96, 105, 112, 113, 120, 121, 122, 123, 144, 146, 160, 168, 171, 172, 179, 185, 194], "command": [60, 120], "symbol": [60, 71, 96], "beta": [60, 78, 85, 105, 161, 197], "tex": 60, "markup": 60, "intiati": 60, "xkcd": [60, 71, 72, 73, 78, 162, 172, 187], "transpar": 60, "34": [60, 71, 73, 77, 95, 96, 98, 104, 112, 114, 116, 120, 122, 123, 134, 136, 145, 152, 162, 171, 172, 174, 178, 185, 186, 194, 195, 197], "_storing_simulations_in_lists_exercis": 60, "v_mean": [60, 62], "_plotting_sample_mean_exercis": 60, "equiv": [60, 105, 152, 160, 179], "var": [60, 78, 97, 105, 111, 113, 122, 136, 144, 160, 169, 170, 172, 179, 197], "v_var": 60, "49": [60, 62, 73, 78, 98, 123, 143, 171, 185, 188, 197], "81": [60, 62, 78, 130, 179], "v_var_n": 60, "v_std": 60, "markers": [60, 71, 97, 123, 136, 170, 178], "c7": 60, "38": [60, 62, 72, 78, 84, 86, 95, 96, 104, 105, 111, 112, 120, 123, 136, 143, 145, 146, 168, 170, 172, 178, 186, 195, 196, 197], "_plotting_sample_standard_deviation_exercis": 60, "_using_numpy_video": 60, "updat": [60, 62, 66, 68, 71, 78, 85, 112, 120, 122, 123, 134, 136, 143, 144, 145, 146, 152, 153, 154, 158, 160, 168, 169, 170, 171, 172, 176, 178, 185, 187, 194, 196, 197], "significantli": [60, 121], "narr": [60, 62], "_nano_recap_of_using_numpy_video": 60, "t_rang": [60, 62], "endpoint": [60, 161, 194, 195, 196, 197], "44": [60, 62, 71, 73, 77, 123, 134, 153, 168, 170, 171, 174, 178, 179, 194, 195], "_rewriting_with_numpy_exercis": 60, "i_step": 60, "46": [60, 62, 123, 153, 162, 168, 170, 171, 185, 188, 194, 197], "_using_enumerate_and_indexing_exercis": 60, "_aggregation_video": 60, "_nano_recap_of_aggregation_video": 60, "transpos": [60, 96, 169, 194, 196, 197], "52": [60, 73, 93, 98, 123, 143, 153, 168, 171, 185, 188, 194, 197], "_using_2d_arrays_exercis": 60, "pm": [60, 168], "54": [60, 123, 135, 143, 144, 153, 168, 178, 188, 194, 197], "_plotting_sample_mean_and_standard_deviation_exercis": 60, "_overview_video": 60, "repeatedli": [62, 186, 188], "elsewher": [62, 161], "w0d2_t1": 62, "creation": [62, 67, 68, 71, 72, 73, 77, 78], "plot_al": 62, "spikes_mean": 62, "membran": [62, 71, 73, 85, 86, 130, 139, 143, 144, 146, 169], "ax1": [62, 71, 85, 94, 95, 111, 112, 120, 123, 146, 153, 154, 169, 171, 178, 179, 185, 186, 187], "c1": [62, 78, 84, 93, 95, 96, 185], "auto": [62, 94, 113, 114, 120, 122, 123, 130, 137, 160, 162, 171, 187, 188, 197], "sharex": [62, 104, 105, 153, 154, 160, 161, 179], "ones_lik": [62, 104, 137, 161, 195, 196], "hz": [62, 71, 72, 73, 144, 145, 146, 172], "_histograms_video": 62, "t_k": [62, 73, 145], "m_j": 62, "fall": [62, 66, 68, 84, 86, 95, 104, 120, 121, 122, 123, 141, 178], "nbin": 62, "histtyp": [62, 84, 94], "stepfil": [62, 84, 94], "patch": [62, 66, 121, 122, 123, 160, 169, 172, 197], "edg": [62, 84, 85, 86, 121, 123, 186, 187, 194], "_nano_recap_of_histograms_video": 62, "_plotting_a_histogram_exercis": 62, "_dictionaries_": 62, "_introducing_spikes_video": 62, "geq": [62, 104, 143, 185], "_nano_recap_of_dictionaries_video": 62, "spike_tim": [62, 72, 73, 85, 86, 143], "sharei": [62, 104, 105, 122, 153, 154, 160, 161, 179], "1st": [62, 134, 145, 178], "my_data_left": 62, "my_data_right": 62, "spikes_n": 62, "vm": 62, "22": [62, 66, 68, 73, 77, 78, 85, 86, 89, 94, 95, 96, 100, 104, 111, 112, 113, 116, 120, 121, 122, 123, 134, 135, 136, 137, 144, 146, 152, 153, 160, 162, 168, 169, 170, 172, 178, 179, 187, 188, 194, 195, 196, 197], "_adding_spiking_to_the_lif_neuron_exercis": 62, "_boolean_indexes_video": 62, "itself": [62, 66, 68, 71, 72, 84, 105, 120, 137, 146, 158, 171, 187], "_nano_recap_of_boolean_indexes_video": 62, "v_rest": 62, "__main__": [62, 68, 84, 98, 111, 112, 113, 114, 122, 137, 143, 144, 145, 146, 152, 153, 154, 169], "v_thr": 62, "_using_boolean_indexing_exercis": 62, "v_reset": [62, 72, 73, 143, 144, 145, 146], "_making_a_binary_raster_plot_exercis": 62, "_refractory_period_video": 62, "millisecond": [62, 85, 146], "synapt": [62, 68, 71, 100, 121, 141, 143, 144, 148, 152, 154], "2nd": [62, 67, 72, 73, 134, 178, 186], "biophys": [62, 139, 148, 153, 154], "_nano_recap_of_refractory_period_video": 62, "ref": [62, 143], "lambda": [62, 66, 67, 68, 73, 77, 85, 104, 136, 137, 144, 152, 169, 172], "clamp": [62, 71, 143, 176, 185, 194, 197], "t_ref": 62, "last_spik": 62, "_investigating_refractory_periods_exercis": 62, "random_ref_period": 62, "syn": [62, 144, 145], "_": [62, 66, 67, 68, 71, 72, 73, 77, 78, 85, 86, 93, 94, 97, 111, 112, 113, 120, 123, 134, 135, 143, 144, 145, 146, 152, 154, 162, 168, 170, 171, 172, 178, 179, 185, 188, 194, 195, 196, 197], "_random_refractory_period_interactive_demo": 62, "_functions_video": 62, "_nano_recap_of_functions_video": 62, "spike_clamp": 62, "ode_step": 62, "discret": [62, 73, 78, 84, 86, 130, 134, 136, 143, 144, 145, 146, 152, 153, 154, 161, 162, 164, 168, 169, 170, 171, 179], "delta_spik": 62, "87": [62, 136, 168, 174], "89": [62, 168, 188], "92": [62, 134, 139, 146, 172], "93": [62, 66, 100, 130, 134, 188], "27": [62, 66, 68, 73, 84, 86, 93, 94, 96, 98, 104, 105, 111, 113, 116, 120, 122, 123, 134, 135, 136, 144, 145, 146, 152, 153, 154, 162, 169, 170, 172, 178, 179, 186, 188, 196, 197], "41": [62, 67, 96, 104, 105, 112, 116, 123, 136, 143, 146, 153, 162, 168, 170, 178, 179, 188, 194, 195, 196, 197], "43": [62, 68, 78, 85, 93, 104, 105, 111, 112, 116, 123, 130, 136, 153, 160, 162, 168, 170, 171, 179, 188, 194, 195, 197], "47": [62, 73, 77, 100, 123, 134, 153, 170, 171, 188, 194, 197], "48": [62, 73, 77, 78, 98, 121, 122, 123, 134, 143, 162, 170, 171, 185, 197], "_rewriting_code_with_functions_exercis": 62, "_classes_video": 62, "reliabl": [62, 104, 144, 145, 160], "unimport": 62, "attribut": [62, 66, 84, 120, 121, 122, 123, 160, 185], "_nano_recap_of_classes_video": 62, "lifneuron": 62, "spike_and_clamp": 62, "t_ref_mu": 62, "t_ref_sigma": 62, "histori": [62, 68, 78, 100, 135, 137, 141, 145, 168, 171, 178, 188], "ran": [62, 168, 188], "74": [62, 66, 123, 168, 169, 179, 188], "_making_a_lif_class_exercis": 62, "_last_concepts_": 62, "_recap_video": 62, "butler": [64, 70, 71, 72, 73, 75, 81, 90, 101, 108, 117, 125, 131, 134, 135, 136, 137, 140, 149, 157, 165, 168, 169, 172, 175, 182, 191, 198], "w0d3_daysummari": 64, "_slide": [64, 70, 75], "patient": [65, 66, 68, 76, 170], "delai": [65, 76, 84, 137, 144, 185, 187], "redirect": [65, 76], "keith": [66, 67, 73, 77, 78, 168], "antwerp": [66, 67, 77, 78, 168], "siddharth": [66, 67, 111, 112, 113, 114, 152, 153, 154], "suresh": [66, 67, 111, 112, 113, 114, 152, 153, 154], "geometr": [66, 67, 96, 112], "w0d3_t1": 66, "fix": [66, 67, 77, 78, 86, 93, 94, 95, 96, 123, 143, 144, 145, 150, 153, 161, 169, 170, 171, 178, 179, 185, 186, 194, 195, 196, 198], "fancyarrowpatch": 66, "mpl_toolkit": [66, 67, 71, 104, 194, 197], "mplot3d": [66, 67, 71], "proj3d": 66, "visualize_vector": 66, "v_unit": 66, "aesthet": 66, "set_color": [66, 67, 68, 71, 105, 146], "set_posit": [66, 67, 68, 71, 178], "zorder": [66, 68, 104, 122, 123, 136, 144, 145, 146, 152, 154, 161, 171, 178], "v_arr": 66, "648fff": [66, 68], "length_includes_head": [66, 67, 68, 134, 194, 195, 196, 197], "v_unit_arr": 66, "dc267f": [66, 68], "leg": [66, 68], "tild": [66, 98, 120, 122, 123, 162], "handlelength": [66, 68, 153, 154], "fontsiz": [66, 67, 68, 71, 105, 136, 144, 145, 146, 152, 153, 169, 172, 178, 179, 194, 196], "upper": [66, 71, 73, 77, 84, 86, 104, 122, 123, 161, 168, 169, 170, 178, 179, 188, 194], "handl": [66, 68, 80, 85, 95, 98, 116, 172, 187, 188, 197], "legendhandl": [66, 68], "get_facecolor": [66, 68], "arrow3d": 66, "xs": [66, 84], "ys": [66, 84], "zs": 66, "kwarg": [66, 67, 85, 120, 123, 143, 144, 145, 146, 152, 153, 154], "_verts3d": 66, "xs3d": 66, "ys3d": 66, "zs3d": 66, "proj_transform": 66, "do_3d_project": 66, "_why_do_we_care_about_linear_algebra_video": 66, "_vector_definition_": 66, "_properties_video": 66, "bmatrix": [66, 67, 68, 96, 105, 120, 122, 123, 154, 169, 171, 194, 196], "_i": [66, 68, 78, 93, 96, 105, 112, 122, 144, 153, 154, 162], "x_1": [66, 67, 77, 78, 86, 94, 96, 111, 134, 136, 137, 194], "x_2": [66, 67, 77, 78, 86, 96, 111, 134, 137, 194], "x_3": [66, 67, 78, 86, 194], "normalize_vector": 66, "input_vector": 66, "n_dim": 66, "linalg": [66, 67, 68, 78, 96, 97, 98, 104, 112, 113, 134, 135, 137, 154, 194, 195, 196, 197], "vector_length": 66, "normalized_vector": 66, "33": [66, 77, 78, 84, 96, 97, 98, 100, 104, 111, 113, 114, 116, 120, 123, 134, 136, 144, 145, 152, 153, 154, 162, 168, 170, 171, 172, 178, 185, 186, 188, 194, 197], "_normalizing_vectors_exercis": 66, "_linear_combinations_of_vectors_video": 66, "180": [66, 111, 121, 122, 123, 143], "_1": [66, 68, 120, 134, 137, 168, 171, 196], "vdot": [66, 96, 122, 123], "_n": [66, 96], "stack": [66, 96, 97, 98, 111, 121, 122, 135, 169, 172, 187, 194], "tail": [66, 67, 186], "essenc": [66, 97, 161], "parallelogram": 66, "4th": [66, 67], "vertex": 66, "c_1": [66, 68], "c_2": [66, 68], "fraction": [66, 84, 113, 123, 135, 144, 145, 170, 196, 197], "slider": [66, 68, 71, 77, 78, 84, 85, 86, 111, 112, 113, 134, 153, 160, 168, 169, 170, 178, 179, 185, 196], "releas": [66, 68, 145], "desir": [66, 68, 77, 111, 112, 161, 168, 176, 188, 197], "plot_arrow": [66, 68], "a_times_x": [66, 68], "b_times_i": [66, 68], "set_aspect": [66, 67, 68, 120, 122, 123, 162, 170, 179, 194, 195, 196, 197], "xticklabel": [66, 68, 104, 160], "yticklabel": [66, 68, 160], "z_arr": [66, 68], "x_orig": [66, 68], "y_orig": [66, 68], "ax_arr": [66, 68], "by_arr": [66, 68], "bbox_to_anchor": [66, 68, 71, 122, 168, 169], "get_color": [66, 68], "floatslid": [66, 68, 72, 73, 77, 84, 93, 94, 111, 134, 143, 145, 146, 152, 153, 154, 160, 161, 168, 169, 170, 171, 178, 179, 185, 186], "plot_linear_combin": [66, 68], "_linear_combinations_of_vectors_interactive_demo": 66, "35": [66, 67, 78, 84, 85, 86, 96, 97, 98, 104, 105, 111, 113, 114, 116, 120, 122, 123, 134, 136, 144, 145, 146, 152, 153, 160, 161, 168, 169, 170, 171, 178, 186, 188, 194, 195, 196, 197], "_span_and_linear_independence_video": 66, "rm": [66, 143, 144, 145, 146, 152, 154, 169, 170, 171, 178], "111": [66, 71, 80, 116, 154, 162, 170, 187], "mutation_scal": 66, "lw": [66, 67, 84, 105, 143, 145, 146, 152, 154, 169, 170], "arrowstyl": [66, 134], "add_artist": 66, "785ef0": 66, "ffb000": 66, "zlim": 66, "zlabel": [66, 71, 96], "attributeerror": [66, 123], "callback": [66, 78, 152], "_draw_all_if_interact": 66, "0x7f17c86909d0": 66, "post_execut": 66, "typeerror": 66, "hostedtoolcach": [66, 78, 120, 123, 134, 152, 195, 196], "x64": [66, 78, 120, 123, 134, 152, 195, 196], "lib": [66, 78, 120, 123, 134, 152, 195, 196], "python3": [66, 78, 120, 123, 134, 152, 195, 196], "site": [66, 71, 78, 120, 123, 134, 152, 178, 195, 196], "268": 66, "267": 66, "is_interact": 66, "draw_al": 66, "_pylab_help": 66, "131": 66, "gcf": 66, "cl": 66, "129": [66, 174], "get_all_fig_manag": 66, "130": 66, "stale": 66, "draw_idl": 66, "backend_bas": 66, "1905": [66, 130], "figurecanvasbas": 66, "1903": 66, "_is_idle_draw": 66, "1904": 66, "_idle_draw_cntx": 66, "backend": [66, 67, 71], "backend_agg": 66, "387": [66, 100], "figurecanvasagg": 66, "384": 66, "lock": [66, 186], "cach": [66, 78, 104, 188], "385": 66, "toolbar": 66, "_wait_cursor_for_draw_cm": 66, "386": 66, "nullcontext": 66, "388": [66, 130], "gui": 66, "389": [66, 171], "superclass": 66, "390": 66, "artist": 66, "95": [66, 72, 95, 130, 134, 136, 139, 144, 162, 178, 179], "_finalize_raster": 66, "draw_wrapp": 66, "wrap": 66, "94": [66, 100, 134, 188], "96": [66, 134, 153, 154, 178, 188], "_raster": 66, "97": [66, 72, 73, 95, 100, 130, 134, 139, 188], "stop_raster": 66, "allow_raster": 66, "69": [66, 78, 120, 123, 168, 169, 179], "get_agg_filt": 66, "70": [66, 73, 78, 113, 120, 123, 143, 160, 169, 179, 185], "start_filt": 66, "73": [66, 78, 120, 123, 143, 168, 179, 188], "3162": 66, "3159": 66, "valueerror": 66, "resiz": 66, "3161": 66, "mimag": 66, "_draw_list_compositing_imag": 66, "3163": 66, "suppresscomposit": 66, "3165": 66, "close_group": 66, "3166": 66, "132": 66, "parent": [66, 120, 123], "suppress_composit": 66, "not_composit": 66, "has_imag": 66, "133": 66, "134": 66, "composit": [66, 86, 130], "135": 66, "image_group": 66, "axes3d": [66, 67, 71], "441": 66, "437": [66, 164], "zorder_offset": 66, "get_zord": 66, "438": 66, "_axis_map": 66, "439": 66, "collection_zord": 66, "patch_zord": 66, "collections_and_patch": 66, "442": 66, "443": 66, "444": 66, "mcoll": 66, "445": 66, "instanc": [66, 78, 98, 114, 120, 136, 143, 146, 154, 169, 171, 172, 185, 186, 188], "nonetyp": 66, "formatt": 66, "340": [66, 80, 130], "baseformatt": 66, "__call__": 66, "obj": 66, "338": [66, 100], "339": [66, 80, 130, 139], "printer": 66, "341": 66, "342": 66, "get_real_method": 66, "print_method": 66, "pylabtool": 66, "retina_figur": 66, "base64": 66, "160": [66, 188], "161": 66, "png": [66, 105], "162": [66, 78], "163": [66, 78], "byte": 66, "167": [66, 135], "168": [66, 78], "pngdata": 66, "print_figur": 66, "fmt": [66, 105], "170": 66, "171": 66, "172": 66, "152": [66, 134], "bbox_inch": 66, "149": [66, 139], "bytes_io": 66, "kw": [66, 104], "153": [66, 80, 134, 174], "getvalu": 66, "154": [66, 134], "svg": 66, "2175": 66, "dpi": [66, 67], "facecolor": [66, 67, 71, 95, 153, 154, 160, 169, 172, 179], "edgecolor": [66, 67, 71, 170], "pad_inch": 66, "bbox_extra_artist": 66, "2172": [66, 174], "draw_without_rend": 66, "2173": 66, "inject": [66, 71, 143, 144, 145, 152, 154, 194, 197], "2174": 66, "getattr": 66, "_draw_dis": 66, "2176": 66, "2177": 66, "tight": [66, 85, 192], "800x600": [66, 136, 152], "o\u011ful": 66, "yurdakul": 66, "geogebra": 66, "hherq78z": 66, "_determing_dependence_discuss": 66, "_basis_vectors_video": 66, "tradit": 66, "applic": [66, 72, 73, 95, 102, 107, 118, 121, 130, 137, 139, 153, 154, 168, 169, 170, 171, 176, 190, 194, 197], "unwieldi": 66, "though": [66, 67, 68, 84, 85, 86, 93, 97, 98, 105, 120, 123, 135, 145, 146, 158, 161, 168, 171, 185, 186, 195], "plane": [66, 67, 71, 96, 150, 152], "unusu": [66, 104], "tightli": 66, "subspac": 66, "r3": 66, "xx": [66, 94, 96, 104, 121, 122, 123, 137, 161], "yy": [66, 94, 96, 121, 122, 123, 137, 161], "meshgrid": [66, 67, 71, 121, 122, 123, 134, 153, 154, 160], "plot_surfac": [66, 71, 96], "invert_xaxi": 66, "_figuring_out_a_basis_discuss": 66, "hr": [66, 105, 120, 160], "_the_dot_product_video": 66, "retin": [66, 67, 68, 96, 100, 116], "synaps": [66, 130, 141, 144, 194], "dot_prod": 66, "r_1": [66, 67, 120], "r_2": [66, 67, 120], "w_1r_1": 66, "w_2r_2": 66, "heatmap": [66, 78, 104, 120, 123, 187, 188, 194, 195, 196], "combo": 66, "highest": [66, 78, 86, 96, 123, 160, 161, 186], "postsynapt": [66, 139, 143, 144, 145], "minim": [66, 67, 78, 93, 94, 95, 96, 104, 113, 120, 122, 123, 162, 178, 179], "x_vec": 66, "y_vec": 66, "n_pixel": 66, "coord1": 66, "coord2": 66, "circle_mask": 66, "coord_i": 66, "coord_j": 66, "mask": [66, 171], "plot_heatmap": 66, "masked_x": 66, "masked_i": 66, "outer": 66, "im": [66, 78, 94, 121, 123, 185, 187, 188, 194, 195, 196, 197], "bwr": [66, 121, 123], "cbar": [66, 78, 120, 122, 123, 162, 194, 195], "colorbar": [66, 68, 71, 78, 94, 104, 113, 114, 120, 121, 122, 123, 162, 185, 187, 188, 194, 195, 196, 197], "set_label": [66, 162], "rotat": [66, 67, 68, 72, 73, 78, 111, 122, 153, 154, 170, 194, 195], "270": 66, "labelpad": [66, 134, 135, 170, 194, 195], "set_label_coord": [66, 178], "fr_arr": 66, "40b0a6": 66, "we_arr": 66, "frameon": [66, 146, 161], "description_width": [66, 160], "neuron1_fir": 66, "neuron2_fir": 66, "firing_r": 66, "_lgn_firing_interactive_demo": 66, "_the_geometry_of_the_dot_product_video": 66, "largest": [66, 73, 96, 186, 194, 197], "smallest": [66, 96], "perpendicular": 66, "axiom": 66, "cd": 66, "mostli": [66, 78, 104, 105, 122, 145, 171, 190, 194, 196], "p_3": [66, 77], "c_o": 66, "c_1x": 66, "c_2x": 66, "c_3x": 66, "c_0": 66, "c_3": 66, "obei": [66, 135], "prove": [66, 97, 168], "law": [66, 145], "cosin": 66, "formula": [66, 67, 71, 73, 77, 78, 86, 98, 122, 123, 136, 144, 161, 168, 194], "subtract": [66, 71, 111, 112, 113, 120, 122], "aderogba": [67, 71], "bayo": [67, 71], "openedx": 67, "sea": [67, 174], "gwu": 67, "gw": 67, "engcomp4": 67, "plot_linear_transform": 67, "licens": 67, "bsd": 67, "claus": 67, "lorena": 67, "barba": 67, "tingyu": 67, "IS": 67, "BY": 67, "THE": 67, "copyright": 67, "holder": 67, "contributor": 67, "AS": 67, "warranti": 67, "TO": [67, 113, 114, 120, 122, 123, 169], "OF": [67, 72, 73], "merchant": 67, "FOR": 67, "IN": 67, "NO": 67, "shall": [67, 96, 154], "BE": 67, "liabl": 67, "indirect": [67, 161], "incident": 67, "exemplari": 67, "consequenti": 67, "damag": 67, "procur": 67, "servic": 67, "profit": 67, "interrupt": [67, 171], "ON": [67, 104], "liabil": 67, "contract": 67, "strict": 67, "tort": 67, "neglig": 67, "IF": 67, "advis": 67, "SUCH": 67, "w0d3_t2": 67, "inv": [67, 68, 96, 97, 98, 104], "eig": [67, 68, 134, 135, 152, 154], "ticker": [67, 185], "get_backend": 67, "rc": 67, "cycl": [67, 134, 172], "_int_backend": 67, "gtk3agg": 67, "gtk3cairo": 67, "macosx": 67, "nbagg": 67, "qt4agg": 67, "qt4cairo": 67, "qt5agg": 67, "qt5cairo": 67, "tkagg": 67, "tkcairo": 67, "webagg": 67, "wx": 67, "wxagg": 67, "wxcairo": 67, "_backend": 67, "shrink": [67, 105, 170, 194, 195], "fig_scal": 67, "808080": 67, "gold": [67, 80, 93, 160, 195], "cab18c": 67, "lightblu": 67, "0096d6": 67, "008367": 67, "red": [67, 71, 73, 77, 78, 85, 94, 111, 112, 113, 134, 145, 146, 152, 153, 160, 161, 168, 169, 170, 178, 188], "e31937": 67, "darkblu": 67, "004065": 67, "pink": [67, 120, 123], "yellow": [67, 71, 73, 170, 188], "brown": [67, 100, 130, 144, 156, 190], "ef7b9d": 67, "fbd349": 67, "ffa500": 67, "a35cff": 67, "731d1d": 67, "quiver_param": 67, "xy": [67, 153, 154, 160, 161], "scale_unit": [67, 153, 154], "grid_param": 67, "set_rc": 67, "func": [67, 152, 153, 154], "wrapper": [67, 195, 196, 197], "serif": 67, "axisbelow": 67, "titles": [67, 71], "plot_vector": 67, "assert": [67, 160, 161, 168, 169, 194, 195, 196, 197], "zeros_lik": [67, 77, 78, 134, 135, 136, 137, 152, 161, 162, 168, 171, 186], "tile": [67, 121, 162, 169, 172, 187, 188], "nvector": 67, "ntail": 67, "xlimit": [67, 113], "ylimit": 67, "hstack": [67, 78, 96, 97, 98, 172], "quiver": [67, 153, 154, 187, 188], "finer": [67, 68], "get_xtick": [67, 185], "get_ytick": 67, "dy": [67, 71, 73], "multipleloc": 67, "set_major_loc": [67, 104, 185], "hide": [67, 68], "plot_transformation_help": 67, "unit_vector": 67, "unit_circl": 67, "helper": [67, 78, 84, 94, 95, 104, 111, 134, 136, 143, 152, 169, 187, 194], "2x2": [67, 134, 154, 160], "bool": [67, 168, 169], "circl": [67, 73, 153, 154], "grid_rang": 67, "x_": [67, 73, 93, 95, 96, 97, 104, 134, 136, 137, 172, 194, 195, 196, 197], "y_": [67, 73, 93, 95, 97, 172, 197], "color_cycl": 67, "vector_": 67, "vstack": [67, 135, 137], "circle_tran": 67, "set_linewidth": [67, 105, 185], "axis1": 67, "axis2": 67, "plot_eig_vec_transform": 67, "vec_nam": 67, "vec": [67, 68, 154, 194, 195, 196, 197], "prop_cycl": [67, 68], "by_kei": [67, 68], "i_vec": 67, "head_width": [67, 134, 194, 195, 196, 197], "transformed_vec": 67, "matmul": [67, 112, 113], "_systems_of_equations_video": 67, "3x_1": 67, "2x_2": 67, "y_1": [67, 73, 94, 120, 161], "7x_1": 67, "2x_3": 67, "y_2": [67, 120, 161], "y_3": 67, "appeal": 67, "cast": 67, "lgn": [67, 68], "dictat": [67, 135], "g_": [67, 145, 146, 170, 179, 185], "p_1": [67, 73, 77, 123], "p_2": [67, 77, 123], "3r_2": 67, "2r_1": 67, "_p": [67, 120], "g_p": 67, "ellipsi": [67, 77], "q": [67, 139, 161, 171, 179, 186], "invert": [67, 78, 105, 196], "g_q": 67, "_understanding_neural_transformations_exercis": 67, "_linear_transformations_video": 67, "enact": 67, "manner": [67, 102, 143, 145], "straight": [67, 73], "flip": [67, 112, 113, 136, 137, 186], "bar": [67, 71, 78, 96, 97, 98, 112, 121, 122, 135, 144, 145, 146, 160, 170, 179, 186], "_creating_matrices_for_transformations_exercis": 67, "_rank_": 67, "_null_space_video": 67, "alter": [67, 86, 152, 185], "li": [67, 68, 96, 104, 116, 143, 144, 145, 146, 152, 153, 154, 172], "aren": [67, 120, 160, 161, 186], "intrins": [67, 113, 174], "_neural_coding_discuss": 67, "_eigenstuff_video": 67, "infinit": [67, 77, 105, 120, 161, 179], "jog": 67, "expans": 67, "vertic": [67, 71, 73, 78, 85, 121, 122, 123], "_identifying_transformations_from_eigenvectors_discuss": 67, "_matrix_multiplication_video": 67, "pen": [67, 160], "wr": 67, "matrix1": 67, "matrix2": 67, "_computation_corner_exercis": 67, "interconnect": [68, 194], "explod": [68, 152, 179], "w0d3_bonu": 68, "plot_circuit_respons": 68, "cs": [68, 181], "textz": 68, "tracker_text": 68, "transax": [68, 123], "eigval": 68, "eigvec": 68, "lc1": 68, "lc2": 68, "cm": [68, 120, 121, 122, 123, 134, 160, 162], "coolwarm": [68, 96, 104, 194, 195, 196, 197], "a_1": [68, 194, 197], "a_2": 68, "scalarmapp": 68, "get_eigval_specified_matrix": 68, "target_eig": 68, "unless": [68, 161], "distinct": [68, 161, 172, 179], "diag": [68, 152, 172], "bc": 68, "squeez": [68, 104, 105, 121, 123, 172], "_a_neural_circuit_video": 68, "subscript": [68, 94, 145], "a_": [68, 134, 146, 153, 154, 172, 178, 179, 185, 186, 187, 194], "w_": [68, 73, 123, 153, 154, 170], "chop": 68, "weird": 68, "faithfulli": 68, "symmetr": [68, 111, 112, 122, 161, 168], "mess": [68, 197], "luckili": [68, 71, 96, 98, 161, 196], "concern": [68, 71, 94, 144, 146], "quantiti": [68, 77, 120, 122, 123, 145, 146, 161, 171, 183, 185], "unsurprisingli": 68, "embrac": 68, "tomorrow": [68, 136, 160], "w2d2": [68, 72, 141, 150], "circuit_implement": 68, "_0": [68, 134, 171, 194, 196], "a0": 68, "i_t": [68, 194], "u0": [68, 145], "42": [68, 73, 77, 85, 104, 105, 111, 112, 123, 134, 136, 143, 160, 162, 168, 170, 172, 174, 178, 179, 188, 194, 195, 196, 197], "_implementing_the_circuit_exercis": 68, "infin": 68, "incred": 68, "115": [68, 71, 116, 174], "31": [68, 71, 73, 77, 98, 111, 113, 116, 120, 122, 123, 134, 136, 145, 146, 152, 154, 162, 168, 171, 178, 185, 186, 187, 188, 194, 197], "a_i": [68, 153, 154, 172], "ia_0": 68, "a_0": [68, 194, 195, 196, 197], "_looking_at_activity_along_an_eigenvector_video": 68, "rewrit": [68, 104, 113, 152, 153, 154, 168], "subsitut": 68, "subsequ": [68, 122], "lie": [68, 136], "plot_system": 68, "_changing_the_eigenvalue_interactive_demo": 68, "_understanding_general_dynamics_using_eigenstuff_video": 68, "lambda_1": 68, "lambda_2": 68, "a0_1": 68, "a0_2": 68, "eigenvalue1": 68, "eigenvalue2": 68, "lag": [68, 104, 144, 196, 197], "update_rang": 68, "_changing_both_eigenvalues_interactive_demo": 68, "until": [68, 85, 98, 121, 128, 136, 145, 168, 170, 171, 187], "proof": [68, 116, 187], "sustain": 68, "_t": [68, 170, 171, 178, 179, 194, 196, 197], "takeawai": [68, 195, 197], "whose": [68, 71, 77, 86, 112, 120, 122, 123, 136, 145, 170, 187], "w0d4_daysummari": 70, "tessi": [71, 72], "tom": [71, 72], "matthew": [71, 72, 73, 134, 135, 136, 137, 143, 144, 145, 146, 185, 186, 187, 188], "rusti": 71, "w0d4_t1": 71, "sp": [71, 77, 78, 143, 145], "toolbox": [71, 77, 89, 116], "rendr": 71, "my_layout": [71, 72, 73, 143, 144, 145, 146], "my_fonts": 71, "my_param": 71, "labels": [71, 178, 194, 195], "move_sympyplot_to_ax": 71, "process_seri": 71, "plot_funct": [71, 105, 170], "show_deriv": 71, "show_integr": 71, "2t": [71, 168], "parabol": 71, "diff_f": 71, "p1": [71, 168, 169], "line_color": 71, "int_f": 71, "plot_alpha_func": 71, "df_dt": 71, "au": 71, "plot_charge_transf": 71, "psp": [71, 145], "numerical_integr": 71, "_why_do_we_care_about_calculus_video": 71, "_a_geometrical_interpretation_of_differentiation_and_integration_video": 71, "eigenfunct": 71, "contin": 71, "slight": [71, 78, 186, 187], "distanc": [71, 77, 114, 161, 178], "travel": [71, 77], "vehicl": 71, "decreas": [71, 73, 84, 85, 86, 105, 111, 112, 113, 123, 143, 145, 146, 154, 172], "different": 71, "5t": 71, "4t": 71, "function_opt": 71, "dropdown": [71, 123, 134, 161], "checkbox": [71, 145, 160, 169, 170], "on_value_chang": 71, "eigenvector": [71, 113, 135], "imagin": [71, 77, 78, 96, 105, 111, 123, 145, 146, 161, 168, 169, 170, 186, 188, 194, 197], "_geometrical_understanding_interactive_demo": 71, "_differentiation_video": 71, "trusti": 71, "friend": 71, "wikipedia": 71, "nt": [71, 104], "me": 71, "3t": 71, "du": [71, 145], "dv": [71, 72, 73, 85, 143, 144, 145, 146], "u_t": 71, "v_t": [71, 179], "du_dt": 71, "dv_dt": 71, "_derivative_of_the_postsynaptic_potential_alpha_function_exercis": 71, "dr": [71, 102, 145, 152, 154, 171, 185], "da": [71, 172], "expon": [71, 86], "_chain_rule_math_exercis": 71, "hood": 71, "fd": 71, "rightarrow": [71, 73, 94, 105, 122, 135, 146, 153, 154, 169], "accur": [71, 73, 97, 109, 123, 130, 134, 137, 144, 160, 162, 170, 171, 178, 196], "numerical_derivative_demo": 71, "tx": 71, "sine_fun": 71, "diffrenti": 71, "cos_fun": 71, "n_tx": 71, "n_sine_fun": 71, "sine_diff": 71, "ncol": [71, 85, 86, 93, 94, 95, 104, 169, 170, 171, 186, 187, 188], "fancybox": 71, "_numerical_differentiation_of_the_sine_function_interactive_demo": 71, "dc": [71, 104, 145], "eta": [71, 136, 137, 143, 152, 171, 197], "visit": [71, 77], "timestep": [71, 73, 85, 134, 135, 171, 179, 185, 194, 195, 196, 197], "compute_rate_and_gain": 71, "current_timestep": 71, "plot_rate_and_gain": 71, "i_1": [71, 144], "rate_1": 71, "i_2": [71, 144], "rate_2": 71, "input_rang": 71, "output_rang": 71, "ital": 71, "bbox": [71, 169], "pad": [71, 104, 121, 122, 123, 160, 194, 196, 197], "_calculating_the_transfer_function_and_gain_of_a_neuron_interactive_demo": 71, "_functions_of_multiple_variables_video": 71, "inhibitori": [71, 73, 86, 148, 150, 154], "derriv": 71, "multivari": [71, 96, 113, 120, 197], "2xy": 71, "2y": 71, "curvi": 71, "f2d_string": 71, "plot_partial_deriv": 71, "f2d": 71, "f2d_dx": 71, "f2d_dy": 71, "plot3d": 71, "p2": 71, "p3": 71, "jacobian": [71, 153], "_visualize_partial_derivatives_interactive_demo": 71, "_numerical_integration_video": 71, "wish": [71, 93, 96, 145, 168, 197], "rectangl": [71, 172], "approcah": 71, "cut": 71, "stripe": 71, "downsid": 71, "underestim": 71, "overestim": 71, "riemann_sum_demo": 71, "step_siz": [71, 77], "min_val": [71, 172], "max_val": [71, 172], "ftn": 71, "int_ftn": 71, "r_tx": 71, "fun_valu": 71, "r_sum": 71, "cumsum": [71, 113, 135, 136, 161, 168, 172, 179], "lebesgu": 71, "rung": 71, "kutta": 71, "_riemann_sum_vs_analytical_integral_with_changing_step_size_interactive_demo": 71, "68": [71, 84, 145, 179], "incom": [71, 85, 145, 170], "elicit": [71, 145, 146], "tau_": [71, 73, 143, 145, 146, 152, 153, 154], "t_sp": [71, 144, 145, 146], "rectangle_area": 71, "_calculating_charge_transfer_with_excitatory_input_exercis": 71, "_filtering_operations_video": 71, "consequ": [71, 145, 160, 161, 170, 171, 179], "akin": 71, "shock": 71, "absorb": 71, "noise_sign": 71, "wave": 71, "x1_diff": 71, "x1_integr": 71, "sec": [71, 143, 144], "0x7f0cc2f42df0": 71, "amplifi": [71, 150], "suppress": [71, 148, 150], "smooth": [71, 84, 86, 96, 123, 185], "easili": [71, 78, 93, 96, 118, 120, 122, 128, 160, 169, 171, 186], "took": [71, 160, 162, 170, 186, 187], "tradeoff": [71, 98, 105, 186], "trough": 71, "smoothen": 71, "enhanc": 71, "inhibit": [71, 73, 82, 145, 150, 153], "sigmoid_funct": 71, "exc_input": 71, "inh_input": 71, "exc_a": 71, "exc_theta": 71, "inh_a": 71, "inh_theta": 71, "jj": 71, "lg_txt": 71, "ax2": [71, 85, 94, 95, 111, 112, 120, 123, 146, 153, 154, 169, 170, 171, 178, 185, 186, 187], "ax3": [71, 111, 112, 186], "surf": 71, "rstride": 71, "cstride": 71, "viridi": 71, "set_zlabel": 71, "expectedli": 71, "downward": 71, "tediou": [71, 104, 134], "plot_2d_neuron_transfer_funct": 71, "rate_d": 71, "rate_di": 71, "surf1": 71, "exc": [71, 85, 145, 154], "inh": [71, 85, 145], "view_init": 71, "xde": 71, "yde": 71, "surf2": 71, "wrt": 71, "xdi": 71, "ydi": 71, "surf3": 71, "_numerical_partial_derivatives_bonus_discuss": 71, "rebecca": 72, "bradi": 72, "gate": 72, "blood": 72, "nobel": 72, "prize": 72, "hodgkin": [72, 130], "huxlei": [72, 130], "axon": [72, 139], "paradox": [72, 148], "mc": [72, 73], "escher": 72, "paint": 72, "motiv": [72, 73, 84, 102, 198], "raster": [72, 73, 144, 146, 172], "breakdown": 72, "w0d4_t2": 72, "ipd": [72, 73], "gridspec": [72, 73, 160, 179], "plot_dpdt": 72, "birth": [72, 73, 197], "gs": [72, 73, 111, 112, 160, 179], "dpdt": 72, "fucntion": 72, "plot_v_no_input": 72, "v_rang": 72, "dvdt": 72, "hline": [72, 73, 78, 161], "linestyl": [72, 73, 85, 104, 105, 146, 161, 168, 169, 170, 179, 187, 188], "vline": [72, 73, 85, 93, 94, 161, 178], "mv": [72, 73, 143, 144, 145, 146], "plot_if": [72, 73], "height_ratio": [72, 73, 185], "na": [72, 73, 196], "plot_dvdt": 72, "85": [72, 148, 168, 172, 179, 188], "g_l": [72, 143, 144, 145], "exact_integrate_and_fir": 72, "v_exact": 72, "t_isi": [72, 73], "v_th": [72, 73, 143, 144, 145, 146], "_why_do_we_care_about_differential_equations_video": 72, "_population_differential_equation_video": 72, "_interpretating_the_behavior_of_a_linear_population_equation_discuss": 72, "obscur": 72, "p_0": [72, 73], "grow": [72, 118, 134, 136, 152, 154], "declin": 72, "asid": [72, 122], "mathematician": 72, "taunt": 72, "3p": 72, "generaliz": 72, "countri": 72, "transit": [72, 78, 134, 150, 169, 171, 172, 179, 185, 187, 188], "450px": [72, 73, 143, 145], "pop_widget": [72, 73], "_parameter_change_interactive_demo": 72, "simplif": [72, 85], "pronounc": 72, "growth": [72, 73, 84], "extern": [72, 73, 102, 123, 143, 144, 145, 146, 148, 153, 154], "weather": 72, "predat": [72, 123], "prei": [72, 170], "_the_leaky_integrate_and_fire_model_video": 72, "loui": [72, 143], "\u00e9douard": [72, 143], "lapicqu": [72, 73, 139, 143], "1907": [72, 73, 139, 143], "subthreshold": [72, 143], "r_mi": [72, 73], "r_m": [72, 73, 85], "minu": [72, 104, 122, 123, 161], "arrang": [72, 73, 122], "_effect_of_membrane_potential_interactive_demo": 72, "91": [72, 188], "61": [72, 123, 148, 152, 168, 187, 188, 195], "v_reset_widget": 72, "_initial_condition_vreset_interactive_demo": 72, "_the_impact_of_input_interactive_demo": 72, "t_rest": 72, "_adding_firing_to_the_lif_video": 72, "plateau": 72, "isi": [72, 82, 85, 145], "\ud835\udc46\ud835\udc5d\ud835\udc56\ud835\udc58\ud835\udc52": 72, "discontinu": [72, 73], "eleg": [72, 73, 102], "electrophysiologist": [72, 73], "_input_on_spikes_interactive_demo": 72, "exectur": 72, "fi": 72, "i_rang": 72, "spike_r": [72, 145], "weak": [72, 78, 161, 168, 186], "_summary_video": [72, 73, 78, 194, 195, 197], "lotka": [72, 73], "1920": [72, 73], "rhythmic": [72, 73], "inorgan": [72, 73], "410": [72, 73], "415": [72, 73, 148], "brunel": [72, 73, 139, 148, 150], "rossum": [72, 73, 139], "frog": [72, 73, 139], "cybern": [72, 73], "dec": [72, 73], "337": [72, 73, 130, 139], "1007": [72, 73, 80, 100, 130, 139, 174, 190], "s00422": [72, 73, 130, 139], "0190": [72, 73, 139], "epub": [72, 73], "oct": [72, 73], "pmid": [72, 73], "17968583": [72, 73], "2001": [72, 73, 82, 116, 130, 174], "strogatz": [72, 73], "chao": [72, 73, 148], "chemistri": [72, 73], "westview": [72, 73], "press": [72, 73, 80, 84, 89, 100, 116, 130, 139, 148, 156, 174, 181, 185, 190], "lindsai": [72, 73, 116, 148], "bloomsburi": [72, 73], "2004": [72, 73, 89, 100, 104, 139, 145], "sync": [72, 73, 169, 170], "emerg": [72, 73, 80, 116, 130, 144, 187, 192], "penguin": [72, 73], "uk": [72, 73, 89, 100, 116, 156], "joi": [72, 73], "quantamagazin": [72, 73], "tag": [72, 73, 168, 169, 179], "quanta": [72, 73], "magazin": [72, 73], "harvei": [73, 100], "mccone": 73, "odd": [73, 77, 121, 122, 169], "mysteri": 73, "w0d4_t3": 73, "plot_slop": 73, "og": 73, "plot_stepeul": 73, "bo": [73, 143, 144, 146, 152, 153], "t_1": [73, 134], "e_1": 73, "visualize_population_approx": 73, "e_k": 73, "plot_reri": 73, "r_e": [73, 145, 152], "r_i": [73, 122, 154], "plot_reri_simpl": 73, "plot_reri_matrix": 73, "null_r": 73, "null_ri": 73, "_intro_to_numerical_methods_for_differential_equations_video": 73, "leonhard": 73, "1707": 73, "1783": 73, "t_0": [73, 134, 135], "y_0": [73, 171], "_slope_of_a_line_interactive_demo": 73, "p_0e": 73, "rearrang": [73, 111], "henc": [73, 77, 78, 146, 168, 194], "_euler_error_of_single_step_interactive_demo": 73, "_taking_more_steps_video": 73, "segment": [73, 93], "t_2": [73, 134], "t_3": 73, "t_4": 73, "times1": 73, "_step_step_step_exercis": 73, "_leaky_integrate_and_fire_video": 73, "v_k": 73, "euler_integrate_and_fir": 73, "esitm": 73, "53": [73, 98, 104, 105, 107, 135, 143, 144, 153, 162, 168, 171, 187, 188, 197], "_lif_and_euler_exercis": 73, "_systems_of_differential_equations_video": 73, "grip": 73, "regul": [73, 174, 195], "dr_e": [73, 145, 154], "ee": [73, 153, 154], "ei": [73, 153, 154], "tau_i": [73, 153, 154], "dr_i": [73, 154], "ie": [73, 104, 145, 152, 153, 154, 179, 197], "timescal": [73, 130, 134, 146, 152, 153, 154, 170, 194, 195, 196, 197], "120": [73, 104, 146, 153], "100m": 73, "120m": 73, "01m": 73, "r_": [73, 85, 144, 152, 185, 186], "euler_simple_linear_system": 73, "_euler_on_a_simple_system_exercis": 73, "_simple_euler_solution_to_the_wilson_cowan_model_discuss": 73, "stabl": [73, 98, 134, 148, 154, 179, 197], "orbit": 73, "_discuss_the_plots_discuss": 73, "re_": 73, "re_k": 73, "ri_k": 73, "ri_": 73, "re_0": 73, "ri_0": 73, "willson": 73, "euler_linear_system_matrix": 73, "w_ee": 73, "n_er": 73, "dre": [73, 152, 153, 154], "n_ir": 73, "dri": [73, 153, 154], "w_ei": 73, "w_ie": 73, "w_ii": 73, "_oscillations_discuss": 73, "62": [73, 78, 123, 148, 152, 168, 187, 188, 195], "maintain": [73, 85, 136, 171, 179], "_small_change_changes_everything_interactive_demo": 73, "k_1": 73, "y_k": 73, "k_2": 73, "k_3": 73, "k_4": 73, "tk_3": 73, "2k_2": 73, "2k_3": 73, "p_": [73, 78, 162, 168, 169, 172, 178], "rk4": 73, "t_fine": 73, "prk4": 73, "dp": [73, 172], "k1": [73, 113], "k2": [73, 113], "k3": 73, "k4": 73, "ro": [73, 77, 146, 153], "entre": 73, "constitut": [73, 192], "essai": [73, 80], "dowl": 73, "florencia": 73, "assaneo": 73, "omega": 73, "x_k": [73, 136, 137], "x_0": [73, 104, 134, 136, 137, 194], "plot_stuart_landa": 73, "width_ratio": [73, 104, 179], "euler_stuart_landau": 73, "lamba": 73, "doell": 73, "perfectli": [73, 122], "lamda": 73, "_oscillator_bonus_interactive_demo": 73, "4hz": 73, "freq": 73, "flash": 73, "50hz": 73, "_stuart_landau_system_bonus_interactive_demo": 73, "e3001234": 73, "pbio": 73, "3001234": 73, "gadget": 75, "w0d5_daysummari": 75, "ulrik": [77, 78], "beierholm": [77, 78], "hyosub": [77, 78, 160, 161], "kim": [77, 78, 130, 160, 161], "previous": [77, 78, 86, 95, 104, 105, 114, 145, 154, 176, 178, 188], "w0d5_t1": 77, "hbox": [77, 78, 160, 161, 169, 170, 172], "vbox": [77, 78, 160, 161, 169, 170, 172], "interact_manu": [77, 78, 186], "plot_random_sampl": 77, "figtitl": [77, 78, 134], "datax": 77, "datai": 77, "plot_random_walk": 77, "plot_hist": [77, 78], "num_bin": [77, 78], "my_plot_singl": 77, "px": [77, 78, 160], "c2": [77, 78, 84, 185], "plot_gaussian_samples_tru": [77, 78], "xspace": [77, 78], "num_sampl": [77, 78, 168], "densiti": [77, 78, 94, 134, 161, 162, 170], "_stochastic_world_video": 77, "bound": [77, 78, 86, 136, 146, 171], "generate_random_sampl": 77, "num_point": [77, 78, 169], "uniformli": [77, 86, 96, 134, 135, 144, 145, 146, 172, 178], "_create_randomness_exercis": 77, "although": [77, 104, 135, 136, 145], "smoothli": [77, 84, 86], "increasingli": [77, 121, 198], "gen_and_plot_random_sampl": 77, "selectionslid": 77, "_random_sample_generation_from_uniform_distribution_interactive_demo": 77, "_random_walk_video": 77, "rat": [77, 78, 130, 168], "generate_random_walk": 77, "enclos": 77, "num_step": 77, "random_x_step": 77, "random_y_step": 77, "restrict": [77, 84, 120, 144, 179], "_modeling_a_random_walk_exercis": 77, "arena": 77, "intslid": [77, 78, 85, 86, 105, 153, 169, 170, 171, 185, 186, 196], "gen_and_plot_random_walk": 77, "_varying_parameters_of_a_random_walk_interactive_demo": 77, "nevertheless": 77, "preview": [77, 78], "_binomial_distribution_video": 77, "bernoulli": [77, 105, 122, 137, 197], "thankfulli": 77, "maze": [77, 78, 187], "food": [77, 78, 123, 136, 178, 185], "mutual": [77, 161], "exclus": [77, 194], "binom": 77, "coeffici": [77, 96, 105, 111, 120, 122, 123, 137, 143, 144, 161, 171, 194, 195, 196, 197], "mass": 77, "sum_k": [77, 145], "n_sampl": [77, 78, 93, 94, 95, 96, 97, 98, 105, 114], "visualis": 77, "left_turn_samples_1000": 77, "_binomial_distribution_sampling_discuss": 77, "p_4": 77, "sum_i": [77, 78, 86, 98, 105, 160, 162, 172], "p_i": [77, 78, 86, 123, 146], "multinomi": 77, "markov": [77, 130, 166, 170, 171, 172, 176, 178, 183, 185], "chain": [77, 93, 120, 154, 169, 171, 172], "_poisson_distribution_video": 77, "encapsul": [77, 78], "sampled_spike_count": 77, "drawn": [77, 78, 94, 120, 123, 136, 169, 179, 186], "_poisson_distribution_sampling_exercis": 77, "asymmetr": [77, 161], "lambda_valu": 77, "gen_and_plot_possion_sampl": 77, "_varying_parameters_of_poisson_distribution_interactive_demo": 77, "typo": [77, 78], "vido": 77, "mu_1": [77, 161], "sigma_1": [77, 111, 161], "mu_2": [77, 161], "sigma_2": [77, 111, 161], "_continuous_distributions_video": 77, "ourselv": [77, 78, 105, 120, 134, 136, 179, 196], "000120141": 77, "believ": [77, 93, 105, 137, 161], "int_": [77, 162, 171], "int_a": 77, "infti": [77, 105, 136, 137, 161, 179, 185], "permit": [77, 161], "particip": [77, 78, 91, 162], "portion": [77, 188, 197], "my_gaussian": [77, 78, 162], "therefor": [77, 84, 93, 95, 104, 118, 120, 121, 122, 123, 135, 144, 145, 146, 152, 153, 154, 160, 162, 187, 188, 196], "x_point": [77, 78, 162], "normalis": [77, 78], "_gaussian_distribution_exercis": 77, "standard_dev": 77, "gen_and_plot_normal_sampl": 77, "distriut": 77, "everywher": [77, 91, 161, 192, 194], "_sampling_from_a_gaussian_distribution_interactive_demo": 77, "gotten": [77, 137], "textbook": [77, 170], "summaris": 78, "maximis": 78, "w0d5_t2": 78, "default_rng": 78, "plot_likelihood": 78, "mean_val": 78, "variance_v": 78, "va": [78, 105, 160, 194, 195], "set_xtick": [78, 113, 120, 121, 122, 123, 160, 169, 172, 178, 187, 188, 194, 195, 197], "set_ytick": [78, 113, 120, 121, 122, 123, 160, 161, 169, 170, 178, 187, 188], "set_xticklabel": [78, 111, 160, 172, 185, 187, 188, 194, 195, 197], "set_yticklabel": [78, 123, 160, 169, 170, 178, 187, 188], "posterior_plot": 78, "posterior_pointwis": 78, "auditori": 78, "plot_classical_vs_bayesian_norm": 78, "mu_class": 78, "var_class": 78, "mu_bay": 78, "var_bay": 78, "_basic_probability_video": 78, "marginalis": 78, "cap": 78, "summat": [78, 145], "b0": 78, "db": [78, 170], "hubel": [78, 121], "wiesel": [78, 121], "1959": 78, "fiction": 78, "inact": 78, "h_": [78, 121, 122, 171], "h_0": [78, 197], "v_0": 78, "percent": [78, 185, 196], "horizon": [78, 178, 179, 187], "lastli": [78, 192], "latter": 78, "_probability_example_main_exercis": 78, "_markov_chains_video": 78, "memoryless": 78, "bright": 78, "state_i": 78, "state_": 78, "determinist": [78, 86, 135, 170, 185, 188], "tt": 78, "jth": 78, "transition_matrix": [78, 179], "p0": [78, 168, 169], "matrix_pow": 78, "p4": 78, "4311": 78, "spent": [78, 135, 136], "implicit": 78, "ergod": 78, "p_random": 78, "p_average_time_sp": 78, "4473": 78, "4211": 78, "1316": 78, "_markov_chains_exercis": 78, "satiat": 78, "tire": 78, "mont": 78, "_statistical_inference_and_likelihood_video": 78, "x_i": [78, 86, 93, 94, 96, 105, 111, 112, 162, 172], "unbias": [78, 192], "x_n": [78, 86, 94], "prod_": [78, 94, 168], "emphas": [78, 143, 160], "logarithm": [78, 86, 94, 123], "compute_likelihood_norm": 78, "standard_dev_v": 78, "p_data": 78, "true_mean": 78, "true_standard_dev": 78, "guess_mean": 78, "guess_standard_dev": 78, "92904": 78, "meaningless": 78, "ry": 78, "initialis": 78, "gvien": 78, "idxmean": 78, "idxvar": 78, "_computing_likelihood_exercis": 78, "_maximum_likelihood_video": 78, "implicitli": [78, 91], "underset": [78, 94, 123, 186], "operatornam": [78, 94, 97, 186], "argmax": [78, 94, 105, 123, 161, 162, 172, 178, 186, 187, 188], "gave": 78, "manual": [78, 123], "bunch": [78, 135, 168], "val": [78, 98, 105], "plotfnc": 78, "loglikelihood": [78, 162], "_maximum_likelihood_inference_interactive_demo": 78, "machin": [78, 89, 97, 100, 102, 105, 109, 113, 116, 120, 121, 123, 130, 137, 170, 171, 174, 186, 188, 192, 196, 198], "minimis": 78, "optimis": 78, "hundr": [78, 84, 120], "negloglik": 78, "bnd": 78, "optimal_paramet": 78, "_minim": 78, "713": 78, "x0": [78, 84, 96, 104, 134, 135, 136, 137, 152, 154], "jac": [78, 152], "hess": 78, "hessp": 78, "tol": [78, 104, 152], "710": 78, "_minimize_newtoncg": 78, "711": 78, "712": 78, "meth": [78, 152], "bfg": 78, "_minimize_lbfgsb": 78, "714": 78, "715": 78, "tnc": 78, "716": 78, "_minimize_tnc": 78, "717": 78, "_lbfgsb_py": 78, "347": [78, 190], "disp": 78, "maxcor": 78, "ftol": 78, "gtol": 78, "maxfun": 78, "maxit": 78, "iprint": 78, "maxl": 78, "finite_diff_rel_step": 78, "unknown_opt": [78, 152], "344": 78, "346": [78, 116], "_prepare_scalar_funct": 78, "sf": [78, 121, 122, 123], "epsilon": [78, 94, 96, 152, 168, 187, 188, 194, 195, 196, 197], "348": 78, "349": 78, "351": 78, "func_and_grad": 78, "fun_and_grad": 78, "353": 78, "fortran_int": 78, "_lbfgsb": 78, "intvar": 78, "_optim": 78, "288": 78, "284": 78, "inf": [78, 152, 172], "286": 78, "scalarfunct": 78, "grad": [78, 120], "287": 78, "289": 78, "291": [78, 116], "_differentiable_funct": 78, "166": 78, "finite_diff_bound": 78, "fun_wrap": [78, 134], "165": 78, "_update_fun_impl": 78, "update_fun": 78, "_update_fun": 78, "callabl": [78, 105], "262": 78, "260": 78, "261": 78, "f_updat": 78, "145": 78, "141": [78, 80, 144], "nfev": [78, 134], "142": 78, "send": [78, 161], "143": [78, 144], "undefin": [78, 86], "144": [78, 123, 162], "fx": 78, "146": 78, "147": 78, "isscalar": 78, "280": 78, "148": 78, "_maximum_likelihood_estimation_exercis": 78, "9547432925098045": 78, "9870331586690259": 78, "theseparamet": 78, "mle": [78, 104, 160], "wiki": 78, "_analytical_solution_exercis": 78, "_bayesian_inference_with_gaussian_distribution_video": 78, "denomin": [78, 98, 195, 196], "classic_vs_bayesian_norm": 78, "mean_class": 78, "mean_bay": 78, "ndata": 78, "random_num_gener": 78, "xsupp": 78, "compris": [78, 120, 121, 122, 123], "benefici": [78, 86, 171], "_bayesian_inference_with_gaussian_distribution_discuss": 78, "_conjugate_priors_video": 78, "binomi": [78, 100, 178], "mathrm": [78, 85, 94, 96, 97, 98, 104, 143, 146, 152, 154], "priorl": 78, "priorr": 78, "numl": 78, "numr": 78, "betapdf": 78, "betaprior": 78, "datapoint": [78, 105], "stabilis": 78, "fluctuat": [78, 139, 143, 145, 146, 154], "willing": 78, "peaki": 78, "conid": 78, "regularis": [78, 196], "badli": 78, "benefit": [78, 178, 188, 197], "_conjugate_priors_interactive_demo": 78, "skeleton": [78, 120], "pointwis": [78, 162], "predefin": 78, "compute_posterior_pointwis": 78, "localization_simul": 78, "mu_auditori": 78, "sigma_auditori": 78, "mu_visu": 78, "sigma_visu": 78, "82": [78, 179, 188], "79": [78, 89, 168], "71": [78, 123, 169, 179, 188], "66": [78, 130, 178, 179, 188], "devot": 78, "_finding_the_posterior_computationally_bonus_exercis": 78, "belief": [78, 158, 170, 186, 187], "frequentist": 78, "paradigm": [78, 185], "aka": [78, 82, 104, 123, 185, 187], "hous": 78, "unreli": [78, 161, 170], "sprinkler": 78, "water": 78, "grass": 78, "rain": 78, "wet": 78, "obvious": [78, 188], "999": [78, 100, 130, 139, 171], "99": [78, 120, 122, 123, 160, 161, 172, 188, 195], "home": 78, "eqnarrai": [78, 134, 143, 145, 146, 161, 162, 171, 172, 179], "pw1r1s1": 78, "pw1r1s0": 78, "pw1r0s1": 78, "pw1r0s0": 78, "ps": [78, 160], "7522": 78, "neighbour": 78, "_bayes_net_bonus_exercis": 78, "stuctur": 78, "_causality_in_the_brain_bonus_discuss": 78, "bassett": 80, "zurn": 80, "566": 80, "578": [80, 148], "s41583": [80, 116], "018": [80, 107, 116, 130, 181, 190], "0038": 80, "postprint": [80, 100, 107, 116, 130, 139, 148, 174, 181, 190], "europepmc": [80, 100, 107, 116, 130, 148, 174, 181], "pmc6466618": 80, "bennett": 80, "hacker": 80, "2003": [80, 89, 139, 148, 156], "philosoph": 80, "foundat": [80, 109, 136, 158, 166, 171, 178, 190, 198], "wilei": 80, "blackwel": 80, "1998": [80, 139, 170, 171], "occam": [80, 89], "razor": [80, 89], "philosophi": 80, "pp": [80, 116, 130, 190], "195": [80, 130], "clarendon": 80, "oxford": [80, 156], "chandrasekhar": 80, "chicago": 80, "chater": 80, "oaksford": 80, "1999": [80, 100], "ration": 80, "trend": [80, 89, 178], "s1364": 80, "6613": 80, "98": [80, 105, 130, 134, 148, 174, 185, 188], "01273": 80, "sejnowski": [80, 148], "1990": 80, "343": 80, "382": [80, 139, 148], "2307": 80, "2214198": 80, "cnl": 80, "salk": 80, "20represent": 80, "20and": 80, "20neural": 80, "20comput": 80, "201990": 80, "3325": 80, "1988": [80, 144], "242": 80, "4879": 80, "741": 80, "745": [80, 171], "3055294": 80, "cichi": [80, 116], "kaiser": 80, "305": 80, "317": 80, "tic": [80, 89], "2005": [80, 100, 139, 168, 181], "feldman": 80, "interdisciplinari": 80, "330": 80, "1002": 80, "wc": 80, "1406": 80, "pmc5125387": 80, "gillett": 80, "cambridg": [80, 89, 139, 148, 156, 190], "goldstein": [80, 116], "e40018": 80, "7554": [80, 89, 100, 130, 148], "40018": 80, "jona": [80, 190], "microprocessor": 80, "e1005268": 80, "1005268": 80, "josephson": 80, "ed": [80, 100, 156], "1996": [80, 130, 139, 148, 156], "abduct": 80, "infer": [80, 84, 89, 93, 94, 95, 96, 97, 98, 100, 113, 114, 118, 130, 156, 158, 160, 166, 168, 170, 171, 172, 176, 178, 183, 190, 194, 198], "technolog": 80, "kaplan": 80, "2011": [80, 100, 156, 164], "synthes": [80, 170], "183": [80, 148, 190], "373": 80, "s11229": 80, "011": [80, 89, 100, 116], "9970": 80, "31219": 80, "3vy69": 80, "lee": 80, "criss": 80, "devez": 80, "donkin": 80, "etz": 80, "leit": 80, "vandekerckhov": 80, "31234": 80, "dmfhk": 80, "lombrozo": 80, "1093": 80, "oxfordhb": 80, "9780199734689": 80, "013": 80, "0014": 80, "marr": 80, "poggio": 80, "1976": [80, 174], "circuitri": 80, "intellig": [80, 116, 183, 185], "laboratori": 80, "memo": 80, "massachusett": 80, "institut": 80, "357": 80, "dspace": [80, 190], "1721": [80, 190], "5782": 80, "parker": 80, "metasci": 80, "vol": [80, 89, 156, 179, 190], "s11016": 80, "9567": 80, "pearl": [80, 190, 192], "mackenzi": [80, 190], "russel": 80, "1917": 80, "mystic": 80, "5962": 80, "bhl": 80, "19230": 80, "archiv": 80, "download": [80, 84, 104, 105, 120, 121, 122, 123, 171], "mysticismlogicot00russiala": 80, "mysticismlogicot00russiala_bw": 80, "simon": 80, "1969": 80, "ma": [80, 89, 156, 174, 179], "trappenberg": 80, "oup": 80, "collin": [80, 89, 130], "e49547": [80, 89], "49547": [80, 89], "w1d1_daysummari": 81, "_day_summari": [81, 90, 101, 108, 117, 125, 131, 140, 175, 182], "meta": [82, 181], "remaind": 82, "compactli": 82, "quantifi": [82, 86, 95, 113, 120, 122, 136, 143, 160, 168, 178, 179, 194, 195, 197], "bay": [82, 102, 156, 158, 166, 168, 176], "quest": 82, "t1": [82, 91, 102, 161], "t3": 82, "w1d1_intro": 82, "w1d1_outro": 83, "_outro_video": [83, 92, 162], "laport": [84, 85, 86, 87], "byron": [84, 85, 86, 87, 93, 94, 95, 96, 107, 109, 168, 171, 185, 186, 187, 188], "galbraith": [84, 85, 86, 87, 93, 94, 95, 96, 168, 171, 185, 186, 187, 188], "dalin": [84, 85, 86], "guo": [84, 85, 86], "aishwarya": [84, 85, 86], "balwani": [84, 85, 86], "madineh": [84, 85, 86, 94, 120, 121, 122, 123, 194, 195, 196, 197], "sarvestani": [84, 85, 86, 94, 120, 121, 122, 123, 194, 195, 196, 197], "vaziri": [84, 85, 86, 143, 144, 145, 152, 153, 154], "pashkam": [84, 85, 86, 143, 144, 145, 152, 153, 154], "gagana": [84, 85, 86, 87, 111, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 185, 186, 188, 194, 195, 196, 197], "acknowledg": [84, 86, 93, 104, 105, 171, 172], "flavor": [84, 85, 86, 105], "w1d1_t1": 84, "script": [84, 162], "corner": [84, 188, 195], "keyboard": 84, "shortcut": [84, 188], "cmd": 84, "mac": 84, "ctrl": 84, "bracket": 84, "inlin": [84, 85, 86, 104, 105, 121, 122, 128, 161, 162, 179], "plot_isi": 84, "single_neuron_isi": 84, "axvlin": [84, 85, 93, 94, 95, 122, 146, 153, 161, 162, 179, 188], "durat": [84, 104, 134, 135, 136, 143, 144, 145, 146, 152, 153, 154, 170, 172], "request": [84, 86, 104, 105, 120, 121, 122, 123, 171], "sy5xt": [84, 86], "status_cod": [84, 86, 104, 105, 120, 121, 122, 123, 171], "bytesio": [84, 86, 171], "allow_pickl": [84, 86, 171], "_what_models_video": [84, 134], "probe": [84, 105], "implant": 84, "electr": [84, 85, 145, 164], "electrod": [84, 85], "nearbi": 84, "preced": [84, 104, 162, 168, 185], "incomplet": [84, 162, 168, 169], "partli": 84, "undocu": 84, "circumst": [84, 194], "unfamiliar": 84, "ahead": [84, 169], "734": 84, "sep": [84, 86], "826": 84, "321": [84, 146], "9723": 84, "i_neuron": 84, "i_print": 84, "slice": [84, 194, 195, 196, 197], "8149": 84, "822467": 84, "9646": 84, "1436": 84, "8709": 84, "0698667": 84, "1536334": 84, "2403667": 84, "7072": 84, "799": 84, "n_neuron": [84, 105, 120, 121, 122, 123, 194, 195, 196, 197], "total_spikes_per_neuron": 84, "spike_times_i": 84, "five": [84, 95, 146, 169, 171], "2818": 84, "3953": [84, 130], "646": 84, "1115": [84, 130], "_exploring_the_dataset_video": 84, "loud": [84, 161, 162], "percentag": [84, 137, 186], "mean_spike_count": 84, "frac_below_mean": 84, "major": [84, 178, 187, 188], "exception": 84, "median_spike_count": 84, "limegreen": [84, 170, 171], "50th": 84, "percentil": [84, 95, 120, 123], "interquartil": 84, "_comparing_mean_and_median_neurons_exercis": 84, "restrict_spike_tim": 84, "inner": 84, "interval_spike_tim": 84, "interval_mask": 84, "t_interv": 84, "original_count": 84, "interval_count": 84, "frac_interval_spik": 84, "ptp": 84, "spike_times_flat": 84, "experiment_dur": 84, "interval_dur": 84, "frac_interval_tim": 84, "neuron_idx": [84, 86, 194, 195, 196, 197], "51": [84, 123, 130, 135, 143, 144, 161, 171, 185, 188, 197], "5th": 84, "_visualizing_activity_video": 84, "energi": [84, 85, 86, 174], "cellular": 84, "machineri": 84, "refractori": [84, 143, 144, 145, 146, 194], "metabol": 84, "longest": 84, "interspik": [84, 86, 143, 146], "compute_single_neuron_isi": 84, "single_neuron_spik": 84, "283": [84, 86, 174], "predomin": 84, "rapidli": [84, 85, 104, 154, 170, 188], "absenc": [84, 136], "agre": [84, 122, 137], "domin": [84, 144, 145], "_isis_and_their_distributions_exercis": 84, "_isi_distribution_video": 84, "maxima": [84, 186], "parameter": [84, 94, 120, 152, 178], "offset": [84, 96, 104, 161, 168, 169, 178, 196, 197], "y0": [84, 134], "single_neuron_idx": 84, "c4": 84, "exp_scal": 84, "20000": [84, 104, 185, 197], "250": [84, 98, 113, 136, 143, 178, 196], "exp_rat": 84, "exp_x0": 84, "inv_scal": 84, "3e2": 84, "inv_x0": 84, "lin_slop": 84, "1e5": 84, "6e5": 84, "lin_y0": 84, "4e4": 84, "fit_plot": 84, "2000": [84, 85, 95, 107, 114, 139, 148, 174, 190, 195, 197], "func_param": 84, "fill_between": [84, 85, 86, 161, 168, 170, 178, 179, 195, 196, 197], "_isi_functions_explorer_interactive_demo_and_discuss": 84, "_fitting_models_by_hand_video": 84, "_reflecting_on_what_models_discuss": 84, "poke": 84, "realist": [85, 143, 152, 179, 185, 187], "w1d1_t2": 85, "ax_arg": 85, "duplic": 85, "shade": [85, 86], "drawstyl": [85, 86], "heurist": [85, 102], "ymin": [85, 93, 94, 169], "ymax": [85, 86, 93, 94, 169, 172], "yscale": 85, "autoscal": 85, "plot_neuron_stat": 85, "n_bin": [85, 86, 121, 123], "xmax": [85, 94], "_how_models_video": 85, "discharg": [85, 148], "preserv": [85, 86, 94], "presynapt": [85, 145], "ge": [85, 145, 146], "suitabl": [85, 86, 93], "lif_neuron": 85, "alia": 85, "n_step": [85, 185, 186], "precomput": [85, 105, 114, 171], "_compute_dvm_exercis": 85, "_lif_neuron": 85, "floatlogslid": [85, 171, 186], "plot_lif_neuron": 85, "_linear_if_neuron_interactive_demo_and_discuss": 85, "_linear_if_models_video": 85, "empir": [85, 95, 98, 100, 135, 161, 172], "upon": [85, 122, 170, 176, 185, 186, 188, 194, 198], "tendenc": [85, 136, 197], "steadi": [85, 152, 153, 154], "lambda_": [85, 172], "lif_neuron_inh": 85, "exc_rat": [85, 145], "inh_rat": [85, 145], "_compute_dvm_with_inhibitory_signals_exercis": 85, "_lif_neuron_inh": 85, "_lif_and_inhibition_neuron_interactive_demo_and_discuss": 85, "_lif_and_inhibition_video": 85, "_reflecting_on_how_models_discuss": 85, "c_m": [85, 143], "capacit": [85, 143], "ion": [85, 135, 145, 169], "revert": 85, "insul": 85, "capacitor": 85, "resistor": 85, "millivolt": 85, "megaohm": 85, "w1d1_t3": 86, "plot_pmf": 86, "isi_rang": 86, "pmf_": 86, "steinmetz_spik": 86, "_why_models_video": 86, "consum": [86, 145], "deplet": 86, "replenish": 86, "downstream": [86, 130, 144], "shannon": 86, "h_b": 86, "log_b": [86, 172], "nat": 86, "subdivid": 86, "concentr": [86, 194], "log2": [86, 195], "nan": [86, 123, 143, 188], "convent": [86, 122, 171], "exclud": [86, 98], "2f": [86, 93, 94, 95, 96, 120, 123, 134, 136, 137, 143, 144, 160, 178, 179, 186, 195, 196, 197], "_optimization_and_information_exercis": 86, "log_2": 86, "regardless": [86, 121, 160, 187], "likewis": [86, 135], "taller": 86, "certainti": [86, 185], "h_2": 86, "_entropy_of_different_distributions_video": 86, "nervou": 86, "budget": 86, "expenditur": 86, "mean_isi": 86, "025": [86, 100, 123, 146], "mean_idx": 86, "searchsort": 86, "pmf_singl": 86, "pmf_uniform": 86, "pmf_exp": 86, "dist": 86, "_probabilities_from_histogram_video": 86, "n_i": 86, "nolimits_": 86, "taken": [86, 120, 122, 144, 152, 171, 178, 179, 183, 186, 187, 188], "pmf_from_count": 86, "_probability_mass_function_exercis": 86, "_calculating_entropy_from_pmf_video": 86, "_pmf_from_count": 86, "_entropi": 86, "steinmetz_pmf": 86, "_entropy_of_neurons_interactive_demo": 86, "_reflecting_on_why_models_discuss": 86, "_summary_of_model_types_video": 86, "congratul": [86, 143, 145, 153, 162, 185], "discov": [86, 116, 121, 123, 171, 178], "closest": [86, 102, 122, 162], "exhibit": [86, 153], "1948": 86, "claud": 86, "began": 86, "subdivis": 86, "i_b": 86, "unsurpris": 86, "prefer": [87, 98, 105, 123, 186], "w1d1_t4": 87, "favorit": [87, 102, 111], "_model_discussions_discuss": 87, "palminteri": 89, "wyart": 89, "koechlin": 89, "falsif": 89, "425": 89, "433": 89, "079798": 89, "bishop": [89, 170, 171], "nasrabadi": 89, "738": 89, "york": [89, 156, 171, 190], "springer": [89, 156, 190], "microsoft": 89, "en": 89, "cmbishop": 89, "mackai": [89, 156], "itprnn": [89, 156], "arlot": 89, "celiss": 89, "1214": 89, "ss054": 89, "acerbi": 89, "lacerbi": 89, "boyd": [89, 96, 104, 179], "vandenbergh": [89, 96, 104], "convex": [89, 93, 94, 102, 104, 120, 172], "stanford": [89, 104, 185], "cvxbook": 89, "motor": [89, 130, 162, 174, 176], "101": [89, 130, 169, 172], "655": 89, "664": 89, "90545": 89, "w1d2_daysummari": 90, "confront": 91, "systemat": [91, 126, 130, 137, 144, 195], "bread": 91, "butter": 91, "zoo": 91, "embodi": [91, 162], "assess": [91, 95, 98, 109, 116, 139], "t2": [91, 102], "w1d2_intro": 91, "w1d2_outro": 92, "pierr": [93, 94, 95, 96, 97, 98, 104, 105], "\u00e9tienn": [93, 94, 95, 96, 97, 98], "fiquet": [93, 94, 95, 96, 97, 98, 104, 105], "anqi": [93, 94, 95, 96, 97, 98, 102], "wu": [93, 94, 95, 96, 97, 98, 164, 178, 179], "hyafil": [93, 94, 95, 96, 97, 98], "lina": [93, 94, 95, 96, 97, 98], "teichmann": [93, 94, 95, 96, 97, 98], "saeed": [93, 95, 96, 160, 161, 162, 178, 179], "salehi": [93, 95, 96, 160, 161, 162, 178, 179], "patrick": [93, 94, 95, 96, 97, 98], "mineault": [93, 94, 95, 96, 97, 98], "bootstrap": [93, 94, 96, 97, 98], "polynomi": [93, 94, 95, 97, 98], "trade": [93, 94, 95, 96, 98, 116, 168, 171, 187], "thank": [93, 96, 104], "eero": 93, "simoncelli": [93, 100, 130], "mathtool": 93, "w1d2_t1": 93, "plot_observed_vs_predict": 93, "y_hat": [93, 95, 96, 97, 98], "theta_hat": [93, 94, 95, 96, 97, 98], "residu": [93, 96, 97, 98, 116, 120], "_mean_squared_error_video": 93, "old": [93, 102, 137], "ls": [93, 143, 145, 146, 153, 161, 162, 168, 178], "suppos": [93, 172, 179, 196, 197], "explanatori": 93, "corrupt": [93, 104, 105, 113, 120, 121, 122, 123, 171], "epsilon_": 93, "synthet": [93, 95, 137, 162], "luxuri": [93, 95], "psuedorandom": [93, 94, 95, 96], "randn": [93, 94, 95, 96, 97, 98, 143, 144, 145, 152, 154, 170, 179, 194], "_compute_mse_exercis": 93, "lowest": [93, 98], "plot_data_estim": 93, "_mse_explorer_interactive_demo_discuss": 93, "landscap": [93, 116, 120], "textrm": [93, 94, 104, 105, 160, 161, 168], "theta_hat_grid": 93, "best_error": 93, "argmin": [93, 122, 161, 162, 179], "theta_": [93, 153, 154], "candid": [93, 168, 171, 178, 188], "solve_normal_eqn": [93, 95], "_solve_for_the_optimal_estimator_exercis": 93, "y_i": [93, 94, 95, 96, 98, 105], "2x_i": [93, 95], "waskomli": 94, "incorpor": [94, 96, 98, 120, 122, 123, 130, 135, 137, 145, 169, 186, 188], "w1d2_t2": 94, "plot_density_imag": 94, "xmin": 94, "wistia": [94, 160], "_maximum_likelihood_estimation_video": 94, "treat": [94, 118, 122, 123, 152, 197], "nuisanc": 94, "plot_normal_dist": 94, "_gaussian_distribution_explorer_interactive_demo_and_discuss": 94, "pair": [94, 102, 107, 114, 120, 122, 123, 137, 144, 146, 153, 154, 160, 161, 185, 187, 188, 194, 197], "invok": [94, 95, 96, 105, 120, 123, 194, 195], "get_ylim": [94, 95, 123, 169, 170, 172], "inher": [94, 171], "11344443599846923": 94, "_likelihood_function_exercis": 94, "joint": [94, 111, 112, 145, 160, 161, 172], "y_n": 94, "arithmet": 94, "underflow": 94, "circumv": 94, "routin": [94, 96, 150, 188], "likelihhood": 94, "remark": [94, 113], "theta_hat_ml": 94, "gaug": 95, "w1d2_t3": 95, "plot_original_and_resampl": 95, "get_xlim": [95, 123, 172], "haven": [95, 98], "_confidence_intervals_and_bootstrapping_video": 95, "bradlei": 95, "efron": 95, "epsilon_i": 95, "resample_with_replac": 95, "sample_idx": 95, "_resample_dataset_with_replacement_exercis": 95, "thata_hat": 95, "bootstrap_estim": 95, "123": [95, 153, 174], "27550888": 95, "17317819": 95, "18198819": 95, "25329255": 95, "20714664": 95, "_bootsrap_estimates_exercis": 95, "get_legend_handles_label": 95, "set_alpha": 95, "uncertain": 95, "ci": 95, "reassur": 95, "ag": 95, "trevor": 95, "hasti": [95, 97, 168], "w1d2_t4": 96, "evaluate_fit": 96, "order_list": [96, 98], "mse_list": 96, "plot_fitted_polynomi": 96, "x_grid": 96, "max_ord": [96, 97, 98], "x_design": [96, 97, 98], "univari": 96, "regressor": [96, 104, 196, 197], "theta_0": 96, "theta_1": 96, "theta_2": 96, "theta_d": 96, "x_d": 96, "boldsymbol": [96, 104], "ol": 96, "_multiple_linear_regression_and_polynomial_regression_video": 96, "ganglion": [96, 100, 116], "light": [96, 120, 122, 162, 171, 188], "1234": 96, "n_regressor": [96, 97, 98], "ordinary_least_squar": [96, 97, 98], "13861386": 96, "09395731": 96, "16370742": 96, "_ordinary_least_squares_estimator_exercis": 96, "mgrid": [96, 161], "50j": 96, "y_hat_grid": 96, "theta_3": 96, "theta_4": 96, "output_nois": 96, "input_nois": 96, "ldot": [96, 120, 122, 123], "_m": 96, "broadcast": [96, 97, 98], "design_matrix": [96, 97, 98], "51194917": 96, "35259945": 96, "solve_poly_reg": [96, 97, 98], "this_theta": [96, 97, 98], "lapack": 96, "stephen": [96, 104, 130, 179], "lieven": [96, 104], "w1d2_t5": 97, "plot_mse_poly_fit": 97, "mse_train": 97, "mse_test": 97, "held": [97, 98, 120], "_bias_variance_tradeoff_video": 97, "n_train_sampl": [97, 98], "n_test_sampl": [97, 98], "overli": [97, 190], "underfit": [97, 98], "overfit": [97, 98, 102, 120, 123, 137], "fortmann": 97, "roe": 97, "biasvari": 97, "metric": [97, 114, 122, 190, 194], "t4": 97, "port": 97, "evaluate_poly_reg": [97, 98], "evalute_poly_reg": 97, "compute_ms": 97, "_compute_train_vs_test_error_exercis": 97, "strike": 97, "modern": 97, "tibshirani": 97, "friedman": [97, 194, 195, 196, 197], "_proof_bias_variance_for_mse_bonus_exercis": 97, "w1d2_t6": 98, "kfold": 98, "plot_cross_validate_ms": 98, "mse_al": 98, "k_fold": 98, "n_split": 98, "plot_aic": 98, "aic_list": 98, "_crossvalidation_video": 98, "commonli": [98, 105, 120, 122, 123, 136, 161], "hasn": [98, 105, 186], "reassign": 98, "fold": [98, 105, 116], "divis": [98, 122], "sacrif": 98, "preciou": 98, "consensu": 98, "former": 98, "cross_valid": 98, "wrongli": 98, "kfold_iter": 98, "i_split": 98, "train_indic": 98, "val_indic": 98, "x_cv_train": 98, "y_cv_train": 98, "x_cv_val": 98, "y_cv_val": 98, "mse_this_split": 98, "_implement_cross_validation_exercis": 98, "strive": 98, "2k": 98, "plug": [98, 105, 120, 152], "cancel": [98, 144, 168], "sse": 98, "this_aic": 98, "_compute_aic_bonus_exercis": 98, "gerwinn": 100, "bethg": [100, 116], "mack": [100, 104, 105], "seeger": 100, "neurip": 100, "cc": [100, 116, 144, 164], "hash": [100, 116, 164], "46ba9f2a6976570b0353203ec4474217": 100, "glaser": 100, "farhoodi": [100, 120, 121, 122, 123, 178, 179], "supervis": [100, 104, 105, 116], "neurobiolog": [100, 107, 139, 181], "175": 100, "126": 100, "137": [100, 144], "pneurobio": 100, "pmc8454059": 100, "chowdhuri": 100, "perich": 100, "miller": [100, 130, 139, 148, 150], "0506": 100, "hardcastl": 100, "maheswaranathan": [100, 116], "ganguli": [100, 116, 130], "giocomo": 100, "multiplex": 100, "heterogen": 100, "medial": 100, "entorhin": 100, "375": 100, "latim": [100, 164], "riek": 100, "pillow": [100, 104, 130, 164], "e47012": 100, "47012": 100, "bues": 100, "cunningham": [100, 107, 130], "yu": [100, 107, 109, 130], "shenoi": [100, 130], "sahani": [100, 130], "nip": [100, 116, 164], "7143d7fbadfa4693b9eec507d9d37443": 100, "kastner": 100, "baccu": [100, 116], "multilay": [100, 116], "e1006291": 100, "1006291": 100, "mccullagh": 100, "nelder": 100, "1989": [100, 168, 185, 187], "chapman": [100, 156], "hall": [100, 156], "london": 100, "mcfarland": 100, "cui": 100, "butt": 100, "e1003143": 100, "1003143": 100, "paninski": [100, 116, 130, 139, 148], "cascad": 100, "243": 100, "0954": 100, "898x": 100, "panzeri": 100, "piasini": 100, "latham": 100, "fellin": 100, "crack": 100, "intervent": [100, 190, 195, 197], "491": [100, 156, 190], "507": 100, "036": 100, "park": [100, 102], "covari": [100, 102, 111, 113, 116, 144, 170, 171, 179, 196, 197], "6395ebd0f4b478145ecfbaf939454fa4": 100, "e1002219": 100, "1002219": 100, "meister": 100, "huk": [100, 164, 168], "pariet": 100, "sensorimotor": [100, 107], "1395": 100, "1403": 100, "3800": 100, "pmc4176983": 100, "uzzel": [100, 104], "chichilniski": [100, 104, 130], "11003": 100, "11013": 100, "jneurosci": [100, 116, 139, 144, 148, 174], "3305": 100, "shlen": [100, 107, 130], "sher": [100, 116, 130], "litk": [100, 116, 130], "spatio": [100, 116, 130], "454": [100, 130], "7207": [100, 130], "995": [100, 130], "nature07140": [100, 130], "pmc2684455": [100, 130], "b55ec28c52d5f6205684a473a2193564": 100, "1404": [100, 107], "schwartz": 100, "327": 100, "gazzaniga": 100, "iii": 100, "stevenson": 100, "obi": [100, 107], "sach": 100, "reimer": 100, "englitz": 100, "e1002775": 100, "1002775": 100, "truccolo": 100, "eden": [100, 156, 190], "fellow": 100, "donoghu": [100, 164], "extrins": [100, 113], "1074": 100, "1089": [100, 174], "00697": 100, "vidn": 100, "ahmadian": [100, 148], "s10827": 100, "0376": 100, "pmc3560841": 100, "weber": 100, "repertoir": [100, 141], "3260": 100, "3289": 100, "1162": [100, 116, 148], "neco_a_01021": 100, "1602": 100, "07389": 100, "zhao": 100, "iyengar": 100, "nonconverg": 100, "1231": 100, "1244": 100, "neco": 100, "982": 100, "w1d3_daysummari": 101, "unifi": [102, 139, 148, 170, 171], "swiss": 102, "armi": 102, "knife": 102, "intent": 102, "spot": [102, 137, 194], "protect": 102, "l1": [102, 105, 123], "reverend": 102, "christina": 102, "savin": [102, 171], "canon": [102, 185], "she": [102, 141, 145, 150], "qu": 102, "assist": 102, "prof": 102, "georgia": 102, "tech": 102, "mem": [102, 145], "cat": [102, 121, 176, 179], "he": [102, 109, 116, 128, 137, 141, 150], "danger": [102, 161, 178, 179, 188], "touch": [102, 120], "readout": [102, 144], "w1d3_intro": 102, "_day_intro": 102, "w1d3_outro": 103, "_day_outro": 103, "etienn": [104, 105], "ari": [104, 105, 194, 195, 196, 197], "jakob": [104, 105], "david": [104, 105, 156], "valeriani": [104, 105], "alish": [104, 105], "dipani": [104, 105], "ej": 104, "permiss": 104, "jonathan": 104, "w1d3_t1": 104, "loadmat": 104, "plot_stim_and_spik": 104, "stim": [104, 171], "intens": 104, "ax_stim": 104, "ax_spik": 104, "nrow": [104, 185, 187, 188], "plot_glm_matric": 104, "boundarynorm": 104, "axes_grid1": [104, 194, 197], "make_axes_locat": [104, 194, 197], "skinni": 104, "ax_x": [104, 160, 161], "ax_i": [104, 160, 161], "gridspec_kw": [104, 185], "imx": 104, "pcolormesh": 104, "setp": 104, "visibl": [104, 145, 156], "divx": 104, "caxx": 104, "append_ax": [104, 194, 197], "cbarx": 104, "cax": [104, 120, 121, 123, 194, 197], "set_tick": 104, "set_ticklabel": 104, "imi": 104, "magma": 104, "invert_yaxi": [104, 162], "divi": 104, "caxi": 104, "cbari": 104, "plot_spike_filt": 104, "gca": [104, 121, 122, 123, 172, 194, 195, 196], "axhlin": [104, 105, 143, 145, 162, 185], "plot_spikes_with_predict": 104, "predicted_spik": 104, "t0": [104, 134], "stem": [104, 105, 185], "set_zord": [104, 123], "setdefault": [104, 152], "yhat": 104, "maxnloc": 104, "hashlib": [104, 105, 120, 121, 122, 123, 171], "fname": [104, 105, 120, 121, 122, 123, 171], "rgcdata": 104, "mat": [104, 105], "mzuj": 104, "expected_md5": [104, 105, 120, 121, 122, 123, 171], "1b2977453020bce5319f2608c94d38d0": 104, "connectionerror": [104, 105, 120, 121, 122, 123, 171], "md5": [104, 105, 120, 121, 122, 123, 171], "hexdigest": [104, 105, 120, 121, 122, 123, 171], "wb": [104, 105, 120, 121, 122, 123, 171], "fid": [104, 105, 120, 121, 122, 123, 171], "_linear_gaussian_model_video": 104, "lumin": 104, "rgc": 104, "flicker": 104, "120hz": 104, "144051": 104, "spcount": 104, "dtstim": 104, "dt_stim": 104, "cellnum": 104, "keep_timepoint": 104, "ij": [104, 112, 121, 122, 123, 144, 169, 172, 194], "onset": 104, "padded_stim": 104, "_create_design_matrix_exercis": 104, "augment": 104, "column_stack": [104, 111, 112], "lg": 104, "theta_lg": 104, "predict_spike_counts_lg": 104, "predicted_count": 104, "_predict_counts_with_linear_gaussian_model_exercis": 104, "bump": [104, 161], "troublingli": 104, "failur": [104, 196], "subcas": 104, "sta": 104, "statement": [104, 178, 194, 197], "_bonus_challenge_act": 104, "_generalized_linear_model_video": 104, "unfortun": [104, 160, 197], "stuck": [104, 186], "chord": 104, "4g": 104, "566e": 104, "88846e": 104, "bear": 104, "emphasi": 104, "moment": [104, 130, 135, 145, 185, 188], "start_point": 104, "mew": 104, "lnp": 104, "mid": [104, 162, 169, 194, 196], "sum_t": [104, 178], "y_t": [104, 171, 172, 197], "x_t": [104, 169, 172, 194, 195], "lambda_t": 104, "neg_log_lik_lnp": 104, "loglik": 104, "log_lik": 104, "fit_lnp": 104, "theta_lnp": 104, "59": [104, 123, 168, 187, 188, 195], "_fitting_the_poisson_glm_exercis": 104, "broadli": [104, 183, 185], "predict_spike_counts_lnp": 104, "_predict_spike_counts_exercis": 104, "_predict_spike_counts_bonu": 104, "oftentim": 105, "awak": [105, 118], "asleep": 105, "car": 105, "bu": 105, "mous": [105, 109, 120, 121, 122, 123, 130, 161, 179], "choi": 105, "hyperparamet": [105, 120, 185, 196, 197], "w1d3_t2": 105, "plot_weight": [105, 121, 123], "atleast_1d": [105, 152], "set_mark": 105, "c3": 105, "plot_model_select": 105, "c_valu": 105, "set_xscal": 105, "best_c": 105, "1g": 105, "plot_non_zero_coef": 105, "non_zero_l1": 105, "n_voxel": 105, "r9gh8": 105, "w1d4_steinmetz_data": 105, "npz": [105, 120, 121, 122, 123, 171], "d19716354fed0981267456b80db07ea8": 105, "load_steinmetz_data": 105, "data_fnam": [105, 171], "dobj": [105, 120, 121, 122, 123, 171], "_logistic_regression_video": 105, "coinflip": 105, "squash": [105, 122, 194], "Its": [105, 122, 161], "_implement_the_sigmoid_function_exercis": 105, "wheel": 105, "gabor": [105, 121, 122, 123], "kordinglab": 105, "nogo": 105, "n_trial": [105, 144, 172, 185, 186, 195, 196, 197], "0s": [105, 194], "1s": [105, 194], "276": 105, "691": 105, "n_featur": [105, 114], "log_reg": 105, "rerun": [105, 114, 123], "trust": [105, 114], "unabl": [105, 114, 154, 196], "nbviewer": [105, 114], "logisticregressionifittedlogisticregress": 105, "score": [105, 112, 113, 114, 116, 120, 121, 123, 128], "compute_accuraci": 105, "train_accuraci": 105, "_classifier_accuracy_video": 105, "idiosyncrat": 105, "justcv": 105, "brief": [105, 154, 195, 198], "tini": 105, "_regularization_video": [105, 123], "priori": 105, "idiosyncrasi": 105, "ridg": 105, "beta2": 105, "theta_i": [105, 153, 154], "unregular": 105, "log_reg_l2": 105, "log_c_step": 105, "penalized_model": 105, "log_c": 105, "max_it": [105, 196, 197], "5000": [105, 135, 136, 185, 194, 195, 196, 197], "plot_observ": [105, 196, 197], "frac1": 105, "lasso": [105, 197], "log_reg_l1": 105, "ugli": [105, 181], "warn": [105, 123, 160, 161, 178, 185], "spars": [105, 114, 148, 194, 195, 196, 197], "unpack": 105, "dens": 105, "m_spars": 105, "text_kw": 105, "iter_part": 105, "1f": [105, 111, 112, 136, 137, 143, 146, 152, 154], "count_non_zero_coef": 105, "non_zero_coef": 105, "coef": 105, "non_zero": 105, "logspac": [105, 168], "_effect_of_l1_on_sparsity_exercis": 105, "bigger": [105, 120, 195], "sparser": [105, 123], "thalamu": 105, "carri": [105, 112, 120, 185], "scheme": [105, 122, 134, 143, 146], "acc": 105, "_model_selection_exercis": 105, "poorli": [105, 114, 120, 197], "risk": [105, 116, 160, 186, 188], "ny_i": 105, "fresh": [105, 170], "proper": [105, 154, 198], "1708": 105, "00909": 105, "1100": 107, "hyvarinen": 107, "oja": 107, "411": 107, "430": [107, 148], "s0893": 107, "6080": 107, "00026": 107, "cse": 107, "msu": 107, "cse902": 107, "s03": 107, "icasurvei": 107, "gilli": 107, "nonneg": 107, "1401": 107, "5226": 107, "coenen": 107, "pearc": 107, "wattenberg": [107, 114], "viega": 107, "johnson": [107, 130], "distil": [107, 114, 116], "23915": [107, 116], "00002": 107, "1500": 107, "1509": 107, "3776": 107, "pmc4433019": 107, "golub": [107, 130], "chase": [107, 161], "batista": 107, "dissect": [107, 116], "opinion": [107, 139, 181], "58": [107, 123, 143, 187, 195, 197], "conb": [107, 139, 181], "sadtler": 107, "ryu": [107, 130], "tyler": 107, "kabara": 107, "reassoci": 107, "607": 107, "s41593": [107, 116, 181], "0095": 107, "pmc5876156": 107, "512": 107, "7515": 107, "423": 107, "426": 107, "nature13665": 107, "pmc4393644": 107, "w1d4_daysummari": 108, "orthonorm": [109, 112, 113], "constantli": [109, 152, 179], "w1d4_intro": 109, "_intro": [109, 118], "w1d4_outro": 110, "_outro": 110, "cayco": [111, 112, 113, 114], "gajic": [111, 112, 113, 114], "roozbeh": [111, 112, 113, 114, 120, 121, 122, 123, 178, 179], "farhoudi": [111, 112, 113, 114], "kraus": [111, 112, 113, 114, 134, 135, 136, 137, 143, 144, 145, 146, 162, 168, 169, 171, 172, 178, 179, 185, 186, 187, 188], "w1d4_t1": 111, "plot_data": [111, 112], "bivari": [111, 112, 197], "add_gridspec": [111, 112], "markerfacecolor": [111, 112], "markeredgewidth": [111, 112, 144, 145, 146], "corr": [111, 112, 144, 160, 161, 194, 195, 196, 197], "corrcoef": [111, 112, 122, 194, 195, 196, 197], "plot_basis_vector": [111, 112], "plot_data_new_basi": [111, 112], "ascend": [111, 112], "_geometric_view_of_data_video": 111, "mu_i": [111, 144, 161], "sigma_i": [111, 144, 161], "rho": [111, 160, 161, 179], "cov": [111, 112, 122, 144, 160, 170, 171, 179, 197], "bf": [111, 112, 113, 134, 179], "pmatrix": [111, 169], "diagon": [111, 122, 172], "_multivariate_data_video": 111, "get_data": [111, 112, 120, 123], "cov_matrix": [111, 112, 113], "multivariate_norm": [111, 112, 161, 171, 194, 195, 196, 197], "indices_for_sort": [111, 112], "argsort": [111, 112, 113, 123], "calculate_cov_matrix": [111, 112], "var_1": [111, 112], "var_2": [111, 112], "corr_coef": [111, 112, 122], "variance_1": [111, 112], "variance_2": [111, 112], "_draw_samples_from_a_distribution_exercis": 111, "cloud": 111, "_calculate_cov_matrix": 111, "visualize_correlated_data": 111, "_correlation_effect_on_data_interactive_demo_and_discuss": 111, "_orthonormal_bases_video": 111, "u_1": 111, "u_2": 111, "w_2": 111, "orthogon": [111, 112, 113], "define_orthonormal_basi": [111, 112], "orthonom": 111, "_find_an_orthonormal_basis_exercis": 111, "_change_of_basis_video": 111, "change_of_basi": [111, 112, 113], "_change_to_orthonormal_basis_exercis": 111, "uncorrel": [111, 112, 146, 197], "tan": 111, "_play_with_basis_vectors_interactive_demo_and_discuss": 111, "mixtur": [111, 145], "decorrel": 111, "beautifulli": [112, 190], "w1d4_t2": 112, "plot_eigenvalu": [112, 113], "scree": 112, "sort_evals_descend": [112, 113], "evector": [112, 113], "_pca_video": 112, "sigma_": [112, 143, 144, 152, 160, 161, 162, 170], "x_j": 112, "n_": 112, "_j": 112, "get_sample_cov_matrix": [112, 113], "sample_cov_matrix": 112, "99315313": 112, "82347589": 112, "01281397": 112, "_calculate_the_covariance_matrix_exercis": 112, "eigh": [112, 113], "descend": [112, 120], "_eigenvectors_of_the_covariance_matrix_exercis": 112, "_pca_implementation_exercis": 112, "_exploration_of_the_correlation_coefficient_interactive_demo_and_discuss": 112, "lose": [112, 160], "_properties_of_pca_bonus_video": 112, "w1d4_t3": 113, "plot_variance_explain": 113, "variance_explain": 113, "plot_mnist_reconstruct": 113, "x_reconstruct": 113, "keep_dim": 113, "tick_param": [113, 170, 172, 178, 194, 195], "labelbottom": 113, "clim": [113, 114], "plot_mnist_sampl": 113, "plot_mnist_weight": 113, "seismic": 113, "add_nois": 113, "frac_noisy_pixel": 113, "x_noisi": 113, "n_noise_ix": 113, "noise_ix": 113, "_pca_for_dimensionality_reduction_video": 113, "unravel": 113, "nine": 113, "parser": [113, 114], "elbow": 113, "_scree_plot_of_mnist_exercis": 113, "lambda_i": [113, 172], "get_variance_explain": 113, "csum": 113, "_plot_the_explained_variance_exercis": 113, "_data_reconstruction_video": 113, "reconstruct_data": 113, "x_mean": 113, "_data_reconstruction_exercis": 113, "_reconstruct_the_data_matrix_using_different_numbers_of_pcs_interactive_demo_and_discuss": 113, "100th": 113, "500th": 113, "700th": 113, "_visualization_of_the_weights_exercis": 113, "inflat": 113, "implic": [113, 145], "salt": 113, "pepper": 113, "score_noisi": 113, "evectors_noisi": 113, "evals_noisi": 113, "variance_explained_noisi": 113, "_add_noise_to_the_data_bonus_exercis": 113, "x_noisy_mean": 113, "projx_noisi": 113, "_denoising_bonus_exercis": 113, "w1d4_t4": 114, "visualize_compon": 114, "component1": 114, "component2": 114, "_pca_applications_video": 114, "reload": 114, "x_all": 114, "labels_al": 114, "pca_model": 114, "pcaifittedpca": 114, "_base": 114, "_pca": 114, "x_new": 114, "_visualization_of_mnist_in_2d_using_pca_exercis": 114, "overlap": [114, 122, 186, 190], "_pca_visualization_discuss": 114, "_nonlinear_methods_video": 114, "manifold": [114, 122], "tsne_model": 114, "fit_transform": [114, 122], "_t_sne": 114, "csr": 114, "csc": 114, "coo": 114, "barnes_hut": 114, "emb": 114, "_apply_tsne_on_mnist_exercis": 114, "explore_perplex": 114, "perp": 114, "redefin": 114, "_run_tsne_with_different_perplexities_exercis": 114, "_tsne_visualization_discuss": 114, "openreview": 116, "id": [116, 144, 146, 171], "bjjsrmfcz": 116, "lillicrap": 116, "beaudoin": 116, "bogacz": 116, "christensen": 116, "1761": [116, 120, 123], "1770": 116, "0520": 116, "ncbi": [116, 130, 174], "nlm": [116, 130, 174], "nih": [116, 130, 174], "gov": [116, 130, 174], "pmc": [116, 130, 174], "pmc7115933": 116, "convolut": [116, 118], "2031": 116, "jocn_a_01544": 116, "07092": 116, "dnn": 116, "khosla": [116, 169, 172], "torralba": 116, "hierarch": [116, 121], "srep27755": 116, "hasson": 116, "nastas": 116, "evolutionari": 116, "105": [116, 130, 153], "416": 116, "434": 116, "heuer": 116, "gulban": 116, "bazin": 116, "osoianu": 116, "valabregu": 116, "santin": 116, "toro": 116, "neocort": [116, 139, 143, 145], "phylogenet": 116, "primat": [116, 121, 130], "speci": [116, 168], "04": [116, 148, 164, 196, 197], "zhou": 116, "lapedriza": 116, "detector": 116, "cnn": 116, "iclr": 116, "san": 116, "diego": 116, "ca": 116, "usa": 116, "1412": 116, "6856": 116, "bau": 116, "ieee": [116, 130, 174], "transact": [116, 130, 174], "2131": 116, "2145": 116, "1109": [116, 130, 174], "tpami": 116, "2858759": 116, "stringer": [116, 120, 121, 122, 123], "e15": 116, "679324": 116, "merel": 116, "brackbil": 116, "heitman": 116, "recurr": [116, 130, 154], "toulon": 116, "franc": 116, "hkei22jeg": 116, "cadena": 116, "denfield": 116, "walker": [116, 187], "gati": 116, "tolia": 116, "ecker": 116, "macaqu": 116, "e1006897": 116, "1006897": 116, "mcintosh": 116, "nayebi": 116, "a1d33d0dfec820b41b54430b50e96b5c": 116, "sinz": 116, "cobo": 116, "muhammad": 116, "froudaraki": 116, "fahei": 116, "incept": 116, "2060": 116, "2065": 116, "0517": 116, "guclu": 116, "gerven": 116, "stream": [116, 166, 171, 186], "10005": 116, "10014": 116, "5023": 116, "khaligh": 116, "razavi": 116, "unsupervis": [116, 130, 144, 146], "IT": [116, 121], "e1003915": 116, "1003915": 116, "mohsenzadeh": [116, 122], "mullin": 116, "lahner": 116, "peripheri": 116, "s41598": 116, "020": 116, "61409": 116, "yamin": 116, "hong": 116, "cadieu": 116, "solomon": 116, "seibert": 116, "dicarlo": 116, "8619": 116, "8624": 116, "1403112111": 116, "pmc4060707": 116, "goh": 116, "e6": 116, "00006": 116, "ren": 116, "770": 116, "778": 116, "ieeexplor": 116, "stamp": 116, "jsp": 116, "arnumb": 116, "7780459": 116, "ioff": 116, "szegedi": 116, "448": [116, 144], "456": 116, "pmlr": 116, "mlr": 116, "v37": 116, "ioffe15": 116, "xu": [116, 174], "taylor": 116, "studer": 116, "a41b3bb3e6b050b6c9067c67f663b915": 116, "neuralnetworksanddeeplearn": 116, "chap4": 116, "olah": 116, "conv": [116, 121, 122, 123, 187, 188], "modular": 116, "colah": 116, "jozwik": 116, "storr": 116, "outperform": 116, "1726": [116, 148], "fpsyg": 116, "01726": 116, "dougla": 116, "1148": 116, "1160": 116, "0210": 116, "pmc6706072": 116, "kietzmann": 116, "spoerer": 116, "s\u00f6rensen": 116, "hauk": 116, "116": [116, 130, 139], "21854": 116, "21863": 116, "1905544116": 116, "kubiliu": 116, "schrimpf": 116, "kar": 116, "rajalingham": 116, "majaj": 116, "nips2019": 116, "santoro": 116, "marri": 116, "akerman": 116, "hinton": 116, "335": 116, "0277": 116, "ora": 116, "ox": 116, "ac": 116, "uuid": 116, "862189c1": 116, "0088": 116, "4f78": 116, "b17a": 116, "2748c2019209": 116, "download_fil": 116, "safe_filenam": 116, "lillicrap_v6_2020": 116, "file_format": 116, "type_of_work": 116, "nili": 116, "wingfield": 116, "walther": 116, "su": 116, "marslen": 116, "e1003553": 116, "1003553": 116, "issa": 116, "407007": 116, "mehrer": 116, "charest": 116, "e1008215": 116, "1008215": 116, "inferior": 116, "2044": 116, "2064": 116, "jocn_a_01755": 116, "ubn": 116, "ru": 116, "nl": 116, "bitstream": [116, 190], "2066": 116, "237374": 116, "tang": 116, "lotter": 116, "moerman": 116, "pared": 116, "caro": 116, "kreiman": 116, "8835": 116, "8840": 116, "1719397115": 116, "chamber": 116, "seethapathi": 116, "saluja": 116, "loeb": 116, "pierc": 116, "bogen": 116, "infant": [116, 118, 197], "neuromotor": 116, "rehabilit": 116, "2431": 116, "2442": 116, "tnsre": 116, "3029121": 116, "pmc8011647": 116, "w1d5_daysummari": 117, "aud": [118, 121], "propag": [118, 120, 141, 169, 171], "caveat": 118, "taskonomi": 118, "reward": [118, 181, 183, 187, 188], "w1d5_intro": 118, "w1d5_outro": 119, "_outro_video1": 119, "_outro_video2": 119, "jorg": [120, 121, 122, 123], "menendez": [120, 121, 122, 123], "carsen": [120, 121, 122, 123], "thrive": 120, "w1d5_t1": 120, "mpl": [120, 121, 122, 123, 162], "plot_data_matrix": [120, 123], "plot_train_loss": 120, "train_loss": [120, 123], "load_data": [120, 122, 123], "data_nam": [120, 121, 122, 123], "bin_width": [120, 122, 123], "679324v2": [120, 121, 122, 123], "calcium": [120, 121, 122, 123, 145, 172], "smoother": [120, 122, 123, 143, 171], "resp": [120, 122, 123], "n_stimuli": [120, 121, 122, 123], "mention": [120, 121, 122, 123, 143, 144, 145, 171, 172], "360": [120, 122, 123], "stimuli_bin": [120, 122, 123], "resp_bin": [120, 122, 123], "resp_tensor": [120, 122, 123], "stimuli_tensor": [120, 121, 122, 123], "unsqueez": [120, 121, 122, 123], "singleton": [120, 122, 123, 172], "n_stim": [120, 123], "train_data": [120, 122, 123], "train_label": [120, 122, 123], "radian": [120, 121, 122, 123], "istim": [120, 123], "ori": [120, 121, 122, 123], "w3d4_stringer_oribinned1": [120, 122, 123], "683xc": [120, 122, 123], "436599dfd8ebe6019f066c38aed20580": [120, 122, 123], "_decoding_from_neural_data_video": 120, "front": 120, "photon": 120, "thousand": 120, "24000": 120, "circ": [120, 123], "resp_al": [120, 123], "stimuli_al": [120, 123], "ineuron": [120, 122, 123], "stimuli_train": [120, 123], "resp_train": [120, 121, 123], "stimuli_test": [120, 123], "resp_test": [120, 121, 123], "ishuffl": [120, 122, 123], "randperm": [120, 122, 123], "itrain": [120, 123], "itest": [120, 123], "entail": 120, "r_n": 120, "infrastructur": 120, "deepnet": 120, "declar": [120, 121], "in_lay": [120, 123], "out_lay": [120, 123], "sent": [120, 187], "_nonlinear_activation_functions_video": 120, "relu": [120, 121, 122, 123, 152], "sole": 120, "tanh": [120, 152], "rectif": 120, "ctifi": 120, "inear": 120, "nit": 120, "nonsens": 120, "1751": [120, 123], "_wrapped_call_impl": [120, 123], "1749": [120, 123], "_compiled_call_impl": [120, 123], "misc": [120, 123], "1750": [120, 123], "_call_impl": [120, 123], "1762": [120, 123], "1757": [120, 123], "hook": [120, 122, 123], "1758": [120, 123], "1759": [120, 123], "_backward_hook": [120, 123], "_backward_pre_hook": [120, 123], "_forward_hook": [120, 123], "_forward_pre_hook": [120, 123], "1760": [120, 123], "_global_backward_pre_hook": [120, 123], "_global_backward_hook": [120, 123], "_global_forward_hook": [120, 123], "_global_forward_pre_hook": [120, 123], "forward_cal": [120, 123], "1764": [120, 123], "1765": [120, 123], "called_always_called_hook": [120, 123], "139": 120, "_nonlinear_activations_exercis": 120, "_loss_functions_and_gradient_descent_video": 120, "nowher": 120, "shortli": [120, 121, 146, 185], "y_p": 120, "42949": 120, "dw": [120, 146], "accordingli": [120, 123, 136, 145, 154], "realiti": 120, "rocki": 120, "gif": [120, 121], "blob": 120, "grad_desc": 120, "lr": [120, 122, 123], "blank": 120, "learning_r": [120, 122, 123], "67": [120, 123, 169, 178, 179, 188], "_gradient_descent_in_pytorch_exercis": 120, "wrote": [120, 122, 123, 195], "monkei": [120, 168, 172], "xor": [120, 178], "drastic": 120, "neat": 120, "truli": [120, 137, 187], "said": [120, 121, 135], "prone": 120, "rescu": 120, "leftarrow": [120, 185, 186, 187, 197], "minima": [120, 162, 186], "odot": [120, 162], "prime": 120, "hadamard": [120, 162], "elementwis": [120, 169], "infeas": [120, 172, 197], "bypass": 120, "demand": 120, "subsampl": [120, 196], "induc": [120, 145, 146, 195], "whatev": 120, "suffic": 120, "w1d5_t2": 121, "show_stimulu": [121, 122], "img": [121, 122, 171], "conv_channel": [121, 123], "wmax": [121, 123], "cb_ax": 121, "add_ax": [121, 123, 160, 161], "plot_example_activ": 121, "load_data_split": [121, 123], "imaging": [121, 122, 123], "resp_train_tensor": [121, 123], "resp_test_tensor": [121, 123], "out_channel": [121, 122, 123], "wide_gaussian": [121, 122, 123], "center_surround": [121, 122, 123], "lam": [121, 122, 123, 134, 135, 136, 137], "newaxi": [121, 122, 123, 137, 172, 187, 188], "640": [121, 122, 123], "480": [121, 122, 123], "deg2rad": [121, 122, 123], "wpix": [121, 122, 123], "hpix": [121, 122, 123], "xcent": [121, 122, 123], "ycent": [121, 122, 123], "xxc": [121, 122, 123], "yyc": [121, 122, 123], "icirc": [121, 122, 123], "w3d4_stringer_oribinned6_split": [121, 123], "p3aeb": [121, 123], "b3f7245c6221234a676b71a1f43c3bb5": [121, 123], "slid": 121, "k_x": 121, "k_y": 121, "miro": 121, "medium": 121, "5bwzuqaqffp5f3wkyq6wjg": 121, "_2d_convolutions_video": 121, "revolution": 121, "alexnet": 121, "depict": 121, "downsampl": 121, "attach": [121, 122, 123, 170], "proxim": 121, "stride": [121, 123], "convolutionallay": 121, "conv2d": [121, 122, 123], "barrel": 121, "whisker": 121, "unsolv": 121, "advent": 121, "790": 121, "1okwhewf5kctipafib4xaa": 121, "counterpart": [121, 188], "substanti": [121, 154, 162, 171, 172], "versu": [121, 137, 169, 170, 172, 194], "n_col": [121, 122], "0f": [121, 122, 123], "c_in": [121, 122, 123, 144], "c_out": [121, 122, 123], "kernel_s": [121, 122, 123], "predesign": 121, "example_filt": [121, 123], "convout": 121, "in_channel": 121, "convlay": [121, 123], "h_in": [121, 122], "w_in": [121, 122, 123], "_2d_convolution_in_pytorch_exercis": 121, "_output_and_weight_shapes_conv_layer_discuss": 121, "vocabulari": 121, "teas": 121, "wherebi": [121, 122], "union": 121, "firstli": [121, 122], "mammalian": [121, 122], "mammal": 121, "secondli": [121, 122], "_visualizing_convolutional_filter_weights_bonus_exercis": 121, "_complex_cell_bonus_discuss": 121, "yalda": 122, "shed": 122, "rsa": 122, "w1d5_t3": 122, "zscore": 122, "plot_corr_matrix": 122, "plot_multiple_rdm": 122, "rdm_dict": 122, "resp_dict": 122, "plot_rdm_rdm_correl": 122, "rdm_sim": 122, "nwith": [122, 154], "plot_rdm_row": 122, "ori_list": 122, "rdm_ori": 122, "ori_plot": 122, "iori": 122, "nto": 122, "tilt": 122, "maxpool2d": 122, "fc": 122, "convolv": [122, 187, 188], "kpool": 122, "10d": 122, "0005": 122, "cf": 122, "appendix": [122, 171, 194], "minibatch_data": 122, "minibatch_label": 122, "2e": [122, 143], "get_hidden_act": 122, "layer_label": 122, "hidden_act": 122, "module_label": 122, "_modul": 122, "argwher": [122, 194], "register_forward_hook": 122, "children": 122, "pred": [122, 171], "_deep_convolutional_network_for_orientation_discrimination_video": 122, "conceiv": 122, "courtesi": 122, "10e": 122, "17e": 122, "32e": 122, "29e": 122, "08e": 122, "resp_v1": 122, "resp_model": 122, "aggreg": 122, "_quantitative_comparisons_of_cnns_and_neural_activity_video": 122, "zz": [122, 161], "zresp": 122, "dictcomp": 122, "_compute_rdms_exercis": 122, "_solution_discussion_video": 122, "m_": [122, 168, 169, 170, 171, 178], "ss": 122, "overcount": 122, "moreov": [122, 141, 150, 179], "correlate_rdm": 122, "rdm1": 122, "rdm2": 122, "ioffdiag": 122, "triu_indic": 122, "rdm1_offdiag": 122, "rdm2_offdiag": 122, "rdm_model": 122, "rdm_v1": 122, "pop": 122, "_correlate_rdms_exercis": 122, "55": [122, 143, 144, 145, 146, 160, 161, 168, 187, 188, 194, 197], "plot_resp_lowd": 122, "resp_lowd": 122, "twilight": 122, "_vizualizing_reduced_dimensionality_representations_discuss": 122, "fourier": 122, "convfc": [122, 123], "lfloor": 122, "rfloor": 122, "convpoolfc": 122, "neighbor": 122, "leftrightarrow": [122, 194], "gd": [122, 123], "gather": [122, 135, 178], "z_i": 122, "z_n": 122, "ddot": 122, "w1d5_t4_bonu": 123, "plot_decoded_result": 123, "test_loss": 123, "test_label": 123, "predicted_test_label": 123, "n_class": 123, "class_bin": 123, "visualize_weight": 123, "w_in_sort": 123, "w_out": 123, "visualize_hidden_unit": 123, "plot_tun": 123, "respi_train": 123, "respi_test": 123, "neuron_index": 123, "plot_predict": 123, "plot_training_curv": 123, "identitylin": 123, "lim": [123, 194, 195, 196], "minval": 123, "maxval": 123, "equal_lim": 123, "stimulus_class": 123, "accommod": 123, "regularized_mse_loss": 123, "l2_penalti": 123, "l1_penalti": 123, "scala": 123, "penalti": [123, 161], "cuda": 123, "is_avail": 123, "runtim": 123, "hardwar": 123, "12219": 123, "759": 123, "1672": 123, "731": 123, "548": 123, "097": 123, "235": [123, 152, 178], "619": [123, 134], "jump": [123, 134, 169, 187, 195], "obstacl": [123, 187], "23589": 123, "gaussian_filter1d": 123, "resp_smooth": 123, "preferred_orient": 123, "resort": 123, "isort": 123, "_visualizing_weights_exercis": 123, "b_in": 123, "_interpreting_weights_discuss": 123, "weren": 123, "axtick": 123, "_delving_into_error_problems_discuss": 123, "359": [123, 130], "2b": [123, 135, 170], "3b": 123, "p_c": 123, "softmax": 123, "troubl": 123, "logsoftmax": 123, "l_i": 123, "deepnetsoftmax": 123, "logprob": 123, "logp": 123, "nllloss": 123, "test_data": 123, "n_iter": [123, 179], "decode_orient": 123, "train_binned_label": 123, "test_binned_label": 123, "out_label": 123, "frac_correct": 123, "_a_new_loss_function_exercis": 123, "regularized_loss": 123, "_add_regularization_to_training_exercis": 123, "_convolutional_encoding_model_video": 123, "grating_stimuli": 123, "neuronsto": 123, "tmp": [123, 136, 137, 172], "ipykernel_6048": 123, "554819614": 123, "deprecationwarn": [123, 136, 137], "__array__": 123, "_number_of_units_and_weights_discuss": 123, "custom_loss": 123, "param_group": 123, "conv1d": 123, "normal_": 123, "_add_linear_layer_exercis": 123, "ineur": 123, "runtimeerror": 123, "125": [123, 153, 196], "124": [123, 153], "mat1": 123, "mat2": 123, "720x16": 123, "23589x20": 123, "1940": 123, "__getattr__": 123, "1938": 123, "1939": 123, "1941": 123, "__name__": 123, "1942": 123, "w2d1_daysummari": 125, "w2d1_intro": 126, "w2d1_outro": 127, "w2d1_t1": 128, "_introduction_to_tutorial_video": 128, "_asking_a_question_video": 128, "buili": 128, "_asking_your_own_question_discuss": 128, "_literature_review_and_background_knowledge_video": 128, "_literature_review_discuss": 128, "_submit_your_feedback_video": 128, "_determine_your_basic_ingredients_discuss": 128, "_formulating_your_hypothesis_video": 128, "_formulating_your_hypothesis_discuss": 128, "persist": 128, "solid": [128, 168, 198], "2002": [128, 148, 164], "03211v1": 128, "ekaterina": [129, 138, 147], "morozova": [129, 138, 147], "costa": 130, "aham": 130, "1501": [130, 190], "1510": 130, "1813476116": 130, "billeh": 130, "cai": 130, "gratii": 130, "iyer": 130, "gouwen": 130, "arkhipov": 130, "106": [130, 153, 169, 174], "403": [130, 174], "040": 130, "botvinick": [130, 181], "brodi": 130, "6128": 130, "1233912": 130, "kutz": 130, "258": 130, "010": [130, 185], "gilson": 130, "burkitt": 130, "grayden": 130, "hemmen": 130, "plastic": [130, 141], "cybernet": [130, 139], "102": [130, 164, 169, 174], "0319": 130, "aravkin": 130, "autoregress": [130, 197], "siam": 130, "2335": 130, "2358": 130, "1137": 130, "20m1338058": 130, "08389": 130, "1952": [130, 139], "nerv": [130, 139], "117": [130, 139, 153], "544": [130, 174], "1113": [130, 139], "jphysiol": [130, 139], "sp004764": [130, 139], "hu": 130, "cain": 130, "mihala": 130, "shea": [130, 144], "motif": [130, 148], "062312": 130, "1103": [130, 190], "physrev": 130, "izhikevich": [130, 139], "burst": [130, 172], "blei": 130, "1610": 130, "08466": 130, "mant": 130, "sussillo": 130, "newsom": [130, 168], "prefront": [130, 181], "503": 130, "7474": 130, "nature12742": 130, "pmc4121670": 130, "morrison": 130, "curto": 130, "combinatori": 130, "241": 130, "277": [130, 174], "academ": [130, 156], "b978": 130, "814066": 130, "00008": 130, "1804": 130, "01487": 130, "ocker": 130, "litwin": 130, "doiron": [130, 144], "microcircuit": 130, "e1004458": 130, "1004458": 130, "josi\u0107": [130, 144], "buic": 130, "e1005583": 130, "1005583": 130, "seung": 130, "13339": 130, "13344": 130, "usher": 130, "mcclelland": [130, 185], "compet": 130, "108": [130, 153, 187], "550": 130, "1037": 130, "0033": 130, "295x": 130, "s41467": 130, "10772": 130, "kaufman": 130, "foster": 130, "nuyujukian": 130, "487": 130, "7405": 130, "nature11129": 130, "pmc3393826": 130, "gilja": 130, "pandarinath": 130, "blabe": 130, "simer": 130, "sarma": 130, "henderson": 130, "prosthesi": 130, "medicin": 130, "1142": 130, "1145": [130, 190], "nm": 130, "pmc4805425": 130, "kao": 130, "ncomms8759": 130, "935": 130, "945": 130, "tbme": 130, "2582691": 130, "nonhuman": 130, "jproc": 130, "2586967": 130, "pmc7970827": 130, "albit": 130, "sanabria": 130, "saab": 130, "jarosiewicz": 130, "tablet": 130, "paralysi": 130, "e0204566": 130, "pone": [130, 164], "0204566": 130, "jozefowicz": 130, "staviski": 130, "805": 130, "815": 130, "s41592": 130, "0109": 130, "pmc6380887": 130, "soric": 130, "willett": 130, "intracort": 130, "e18554": 130, "18554": 130, "santhanam": 130, "afshar": 130, "prosthes": 130, "1315": 130, "1330": 130, "00097": 130, "annual": [130, 190], "062111": 130, "150509": 130, "visuomotor": 130, "null": [130, 197], "208": [130, 148], "023": 130, "murphi": [130, 148], "rezaii": 130, "avansino": 130, "dorsal": 130, "speech": 130, "e46015": 130, "46015": 130, "trautmann": 130, "lahiri": 130, "103": [130, 169], "292": [130, 171], "308": 130, "vya": 130, "1177": 130, "1186": 130, "249": [130, 178], "092619": 130, "094115": 130, "pmc7402639": 130, "329": 130, "deo": 130, "hochberg": 130, "knob": 130, "premotor": 130, "bodi": 130, "181": 130, "396": 130, "409": 130, "043": 130, "william": [130, 185, 186, 187, 188], "discoveri": [130, 190], "demix": 130, "1099": 130, "015": 130, "nips2008": 130, "w2d2_daysummari": 131, "w2d2_intro": 132, "w2d2_outro": 133, "wen": [134, 135, 136, 137], "alic": [134, 136], "schwarz": [134, 136], "norma": [134, 135, 136, 137], "kuhn": [134, 135, 136, 137, 139, 145], "w2d2_t1": 134, "solve_ivp": 134, "plot_trajectori": 134, "initial_condit": 134, "portrait": 134, "figtitlt": 134, "t_span": 134, "t_eval": 134, "dense_output": 134, "timecolor": 134, "ah1": [134, 136], "ah2": [134, 136], "ah3": 134, "set_size_inch": 134, "bx": 134, "subplots_adjust": 134, "wspace": 134, "plot_streamplot": 134, "x1dot": 134, "x2dot": 134, "log1p": 134, "sca": 134, "streamplot": 134, "cividi": 134, "arrows": 134, "eigenvector1": [134, 135], "eigenvector2": [134, 135], "plot_specific_example_stream_plot": 134, "a_opt": 134, "eigstr": 134, "y_label": [134, 161], "righthand": 134, "hspace": [134, 146], "_linear_dynamical_systems_video": [134, 171], "serv": [134, 135, 136], "govern": [134, 135, 136, 152, 188], "t_i": [134, 172], "sudden": 134, "fine": 134, "1b": 134, "integrate_exponenti": 134, "xdot": 134, "_forward_euler_integration_exercis": 134, "\u03b1": [134, 161, 186], "readout_format": [134, 185], "plot_euler_integr": 134, "clunki": 134, "259": 134, "_forward_euler_integration_interactive_demo_discuss": 134, "imaginari": 134, "oscil": [134, 148, 150, 153], "hertz": 134, "0001": [134, 152, 185], "_oscillatory_dynamics_interactive_demo_discuss": 134, "_multidimensional_dynamics_video": 134, "bigg": [134, 153, 161], "1c": 134, "\ud835\udc651": 134, "\ud835\udc652": 134, "a00": 134, "a01": 134, "a10": 134, "a11": 134, "xdot1": 134, "xdot2": 134, "_ivp": 134, "ivp": 134, "621": 134, "618": 134, "tf": 134, "623": 134, "624": 134, "ts": [134, 172], "rk": 134, "rungekutta": 134, "t_bound": 134, "max_step": [134, 187, 188], "rtol": 134, "atol": 134, "first_step": 134, "extran": 134, "validate_max_step": 134, "validate_tol": 134, "h_ab": 134, "select_initial_step": 134, "error_estimator_ord": 134, "odesolv": 134, "fun_singl": 134, "check_argu": 134, "asarrai": [134, 160, 169, 178, 196], "593": 134, "592": [134, 148], "_sample_trajectories_in_2_dimensions_exercis": 134, "a_option_1": 134, "a_option_2": 134, "a_option_3": 134, "a_option_4": 134, "_varying_a_interactive_demo_discuss": 134, "x0_option_1": 134, "x0_option_2": 134, "x0_option_3": 134, "_varying_initial_conditions_interactive_demo_discuss": 134, "fortun": [134, 171, 179], "1_0": 134, "2_0": 134, "shrunk": 134, "_interpreting_eigenvalues_and_eigenvectors_discuss": 134, "elli": 135, "stradquist": 135, "markovian": [135, 185], "w2d2_t2": 135, "plot_switch_simul": 135, "plot_interswitch_interval_histogram": 135, "inter_switch_interv": 135, "plot_state_prob": 135, "prob": [135, 160, 169, 172, 178], "_markov_process_video": 135, "mu_": [135, 144, 161, 168, 169, 170], "c2o": 135, "o2c": 135, "req": [135, 143, 144, 153, 160, 161, 169, 198], "ion_channel_open": 135, "switch_tim": 135, "uniti": 135, "myrand": 135, "random_sampl": 135, "2a": [135, 170], "_computing_intervals_between_switches_exercis": 135, "return_count": 135, "undergon": 135, "adopt": 135, "plot_inter_switch_interv": 135, "_varying_transition_probability_values_and_t_interactive_demo_and_discuss": 135, "_k": 135, "x_kp1": 135, "plu": [135, 136, 160, 168, 197], "simulate_prob_prop": 135, "latest": [135, 170], "_probability_propagation_exercis": 135, "settl": [135, 136, 186], "relax": 135, "_continuous_vs_discrete_time_fromulation_video": 135, "eigendecomposit": 135, "988": 135, "98058068": 135, "19611614": 135, "70710678": 135, "_finding_a_stable_state_discuss": 135, "biraj": [136, 137], "pandei": [136, 137], "neither": 136, "face": [136, 161, 171, 186, 197], "w2d2_t3": 136, "plot_random_walk_sim": 136, "nsim": 136, "3a": 136, "plot_mean_var_by_timestep": 136, "plot_ddm": 136, "xinfti": [136, 137], "var_comparison_plot": 136, "plot_dynam": [136, 178], "_ecoli_and_random_walks_video": 136, "gander": 136, "wander": 136, "aimlessli": 136, "live": [136, 172], "bacterium": 136, "odor": 136, "substrat": [136, 181], "seek": [136, 178, 187], "dog": 136, "blindfold": 136, "flail": 136, "brownian": 136, "terminolog": 136, "microscop": 136, "protein": 136, "mintag": 136, "this_step": 136, "random_walk_simul": 136, "nxt": 136, "random_walk_simulator_funct": 136, "_random_walk_simulation_exercis": 136, "bacteria": 136, "2500": 136, "sig2": 136, "mytitl": [136, 137], "sharpli": 136, "_random_walk_and_variance_exercis": 136, "plot_gaussian": [136, 161], "_influence_of_parameter_choice_interactive_demo_and_discuss": 136, "_combining_deterministic_and_stochastic_processes_video": 136, "ddm": [136, 137], "hang": [136, 161], "imperfectli": 136, "land": [136, 187, 188], "simulate_ddm": 136, "_driftdiffusion_model_exercis": 136, "stimul": [136, 145, 152, 192], "_driftdiffusion_simulation_observations_discuss": 136, "_balance_of_variances_video": 136, "pull": [136, 171, 186], "restor": 136, "standard_norm": [136, 137], "ddm_eq_var": 136, "hack": 136, "sweep": 136, "empirical_vari": 136, "analytical_vari": 136, "ipykernel_6497": 136, "1365116358": 136, "convers": [136, 137], "_computing_the_variances_empirically_exercis": 136, "interplai": [136, 145], "w2d2_t4": 137, "plot_residual_histogram": 137, "4a": 137, "stdev": 137, "plot_training_fit": 137, "4b": 137, "build_time_delay_matric": 137, "xprime": 137, "roll": 137, "ar_predict": 137, "ar_model": 137, "error_r": 137, "mismatch": [137, 171], "count_nonzero": 137, "_autoregressive_models_video": 137, "ipykernel_6546": 137, "4059738216": 137, "bird": [137, 174], "reformul": 137, "rnk": 137, "lstsq": 137, "rcond": 137, "lam_hat": 137, "_residuals_of_the_autoregressive_model_exercis": 137, "_monkey_at_a_typewriter_video": 137, "alpha_0": 137, "alpha_1": 137, "alpha_2": 137, "alpha_3": 137, "alpha_": [137, 154], "jot": 137, "monkey_at_typewrit": 137, "1010101010101010101010101010101010101010101010101": 137, "100100100100100100100100100100100100100": 137, "char": 137, "char2arrai": 137, "_understanding_autoregressive_parameters_discuss": 137, "notori": 137, "terribl": 137, "yr": 137, "laptop": 137, "jab": 137, "10010101001101000111001010110001100101000101101001010010101010001101101001101000011110100011011010010011001101000011101001110000011111011101000011110000111101001010101000111100000011111000001010100110101001011010010100101101000110010001100011100011100011100010110010111000101": 137, "test_monkei": 137, "00100101100001101001100111100101011100101011101001010101000010110101001010100011110": 137, "randint": 137, "unpredict": 137, "jitter": 137, "_fitting_ar_models_exercis": 137, "x1_test": 137, "x2_test": 137, "err": 137, "rr": 137, "test_error": 137, "sweet": 137, "6th": 137, "gerstner": [139, 148], "kistler": [139, 148], "naud": [139, 141, 143, 144, 145, 146, 148], "katz": 139, "giant": 139, "loligo": 139, "424": 139, "sp004716": 139, "fitzhugh": 139, "nagumo": 139, "scholarpedia": 139, "1349": 139, "4249": 139, "1955": 139, "bulletin": 139, "257": 139, "278": [139, 171], "bf02477753": 139, "hakim": 139, "richardson": 139, "155": 139, "326": [139, 146], "5951": 139, "379": 139, "380": 139, "1181936": 139, "infosci": 139, "epfl": [139, 148], "142067": 139, "naud09": 139, "jolivet": 139, "kobayashi": 139, "rauch": 139, "shinomoto": 139, "417": [139, 148], "118680": 139, "jolivet08": 139, "lewi": 139, "959": 139, "976": 139, "00190": 139, "larkum": 139, "nevian": 139, "sandler": 139, "polski": 139, "schiller": 139, "tuft": 139, "dendrit": [139, 141], "pyramid": 139, "325": [139, 146], "5941": 139, "756": [139, 174], "760": 139, "1171958": 139, "poirazi": [139, 141], "brannon": 139, "mel": 139, "989": [139, 171], "s0896": 139, "6273": 139, "00149": 139, "aertsen": [139, 144, 145], "rotter": [139, 145], "2345": 139, "2356": 139, "3349": 139, "markram": 139, "tsodyk": [139, 148], "redistribut": 139, "efficaci": [139, 143, 145], "6594": 139, "807": 139, "810": 139, "382807a0": 139, "5323": 139, "5328": 139, "steven": 139, "1995": [139, 156, 174, 179], "depress": [139, 146], "795": 139, "802": [139, 144], "0896": 139, "90223": 139, "nelson": [139, 181], "tame": 139, "beast": 139, "1178": 139, "1183": 139, "81453": 139, "bi": [139, 144, 161], "poo": 139, "modif": [139, 146], "cultur": 139, "hippocamp": [139, 181], "10464": 139, "10472": 139, "song": 139, "competit": [139, 181], "hebbian": 139, "919": 139, "926": 139, "78829": 139, "w2d3_daysummari": 140, "upi": 141, "bhalla": 141, "irregular": [141, 144, 145, 148], "synchroni": 141, "yiota": 141, "morpholog": 141, "w3d5": [141, 150], "dysfunct": [141, 174], "w2d3_intro": 141, "w2d3_outro": 142, "qinglong": [143, 144, 145, 146, 152, 153, 154], "gu": [143, 144, 145, 146, 152, 153, 154], "songtin": [143, 144, 145, 146, 152, 153, 154], "lorenzo": [143, 144, 145, 146, 152, 153, 154], "fontolan": [143, 144, 145, 146, 152, 153, 154], "w2d3_t1": 143, "plot_volt_trac": [143, 145], "par": [143, 144, 145, 146, 152, 153, 154], "trajetori": [143, 145], "volt": [143, 145], "range_t": [143, 144, 145, 146, 152, 153, 154], "sp_num": [143, 145, 146], "nicer": [143, 145], "npotenti": 143, "plot_gwn": 143, "i_gwn": [143, 144, 145], "pa": [143, 144, 145], "my_hist": 143, "isi1": 143, "isi2": 143, "cv1": 143, "cv2": 143, "sigma1": [143, 161], "sigma2": [143, 161], "my_bin": [143, 144], "_lif_model_video": 143, "laurenc": 143, "eqn": 143, "mimick": [143, 144], "exceed": 143, "default_par": [143, 144, 145, 153, 154], "simulation_tim": 143, "time_step": [143, 152, 153, 154], "new_param": 143, "ns": [143, 144, 145], "v_init": [143, 144, 145, 146], "tref": [143, 144, 145, 146], "000e": 143, "997e": 143, "998e": [143, 196], "999e": 143, "run_lif": [143, 144], "iinj": [143, 144, 145], "puls": 143, "rec_v": [143, 144, 145, 146], "rec_sp": 143, "lt": [143, 144, 145, 146, 152, 153, 154, 179], "rec_spik": [143, 144, 145, 146], "tr": [143, 144, 145, 146], "counter": [143, 144], "_lif_model_exercis": 143, "_response_lif_model_video": 143, "cosmet": 143, "rheobas": 143, "i_dc": 143, "diff_dc": 143, "_parameter_exploration_of_dc_input_amplitude_interactive_demo_and_discuss": 143, "vivo": [143, 145, 185, 197], "mimic": 143, "my_gwn": [143, 144, 145], "myse": [143, 144, 145, 146, 152, 154], "amplitut": [143, 144, 145, 146, 152, 154], "mu_gwn": 143, "diff_gwn_to_lif": 143, "_gaussian_white_noise_interactive_demo_and_discuss": 143, "clock": [143, 144], "_analyzing_gwn_effects_on_spiking_discuss": 143, "textbf": 143, "clocklik": 143, "diff_std_affect_fi": 143, "spk_count": 143, "spk_count_dc": 143, "v_dc": 143, "rec_sp_dc": 143, "_f_i_explorer_interactive_demo_and_discuss": 143, "isi_cv_lif": 143, "spike_train": [143, 144, 146], "sig_gwn1": 143, "sig_gwn2": 143, "i_gwn1": 143, "sp1": [143, 144], "i_gwn2": 143, "sp2": [143, 144], "_compute_cv_isi_exercis": 143, "cv_isi": [143, 145], "_spike_irregularity_interactive_demo_and_discuss": 143, "shot": [143, 144], "my_ou": [143, 152, 154], "i_ou": [143, 152, 154], "tau_ou": [143, 152, 154], "sig_ou": [143, 152, 154], "mu_ou": 143, "190": 143, "220": 143, "lif_with_": 143, "_lif_explorer_with_ou_input_bonus_interactive_demo_and_discuss": 143, "_extension_to_integrate_and_fire_bonus_video": 143, "lif": [144, 152], "w2d3_t2": 144, "example_plot_mycc": 144, "50000": 144, "r12": 144, "i1gl": 144, "i2gl": 144, "correlate_input": 144, "my_cc": 144, "my_raster_poisson": 144, "ffunction": 144, "exce": [144, 146, 154], "rater": 144, "plot_c_r_lif": 144, "mycolor": [144, 153, 154], "mylabel": [144, 153, 154], "polyfit": 144, "c_rang": 144, "v_l": [144, 145, 146], "mebran": [144, 145, 146], "lif_output_cc": 144, "bin_siz": 144, "coe": 144, "sp_rate": 144, "i_trial": 144, "sp1_count": 144, "sp2_count": 144, "poisson_gener": [144, 145, 146], "coincid": 144, "uni": 144, "direction": 144, "gap": [144, 196], "junction": 144, "stronger": [144, 197], "forthcom": 144, "impair": 144, "_input_and_output_correlations_video": 144, "unconnect": 144, "i_i": [144, 154], "xi_i": 144, "xi_c": 144, "le": 144, "le1": 144, "whute": 144, "xi_1": 144, "xi_2": 144, "i_j": 144, "pearson": [144, 195], "rodger": 144, "nicewand": 144, "rij": 144, "rxy": 144, "tip1": 144, "a1": 144, "a2": 144, "a3": 144, "b1": 144, "b2": 144, "b3": 144, "tip2": 144, "tip3": 144, "var_i": 144, "var_j": 144, "_compute_the_correlation_exercis": 144, "\ud835\udc36\ud835\udc49isi": 144, "pre_spike_train": [144, 145, 146], "ith": [144, 145, 146], "u_rand": [144, 145, 146], "poisson_train": [144, 145, 146], "generate_corr_poisson": 144, "poi_rat": 144, "mother_r": 144, "mother_spike_train": 144, "sp_mother": 144, "l_sp_mother": 144, "sp_mother_id": 144, "l_sp_corr": 144, "corr_coeff_pair": 144, "r_12": 144, "diff_trial": 144, "simu": 144, "197": 144, "_measure_the_correlation_between_spike_trains_exercis": 144, "aforement": [144, 145], "gwn_mean": 144, "gwn_std": 144, "80000": 144, "starttim": [144, 146], "perf_count": [144, 146], "r12_ss": 144, "sp_ss": 144, "endtim": [144, 146], "timecost": [144, 146], "8000": 144, "140": 144, "138": 144, "ic": 144, "_input_output_correlation_discuss": 144, "r12_l": 144, "r12_sl": 144, "sp_l": 144, "sp_sl": 144, "_gwn_and_the_correlation_transfer_function_discuss": 144, "campbel": 144, "unphysiolog": 144, "ou": [144, 152, 154], "la": [144, 174], "rocha": 144, "rey": 144, "806": 144, "nature06028": 144, "bujan": 144, "af": 144, "evok": 144, "neocortex": 144, "8611": 144, "4536": 144, "_correlations_and_network_activity_discuss": 144, "correlogram": 144, "response_of_ensemble_of_neurons_to_time_varying_input_bonus_video": 144, "chemic": 145, "neurotransmitt": 145, "cleft": 145, "permeabl": 145, "partner": 145, "undergo": [145, 185], "w2d3_t3": 145, "my_illus_lifsyn": 145, "v_fmp": 145, "illustart": 145, "fmp": 145, "alongsid": 145, "pot": 145, "my_illus_std": 145, "tau_d": 145, "tau_f": 145, "plot_out": 145, "constantr": 145, "ot": 145, "t_simu": 145, "isi_num": 145, "1e3": 145, "dynamic_syn": 145, "g_bar": 145, "tau_syn": 145, "spt": [145, 146], "gwn": 145, "poissonian": 145, "_static_and_dynamic_synapses_video": 145, "depolar": 145, "hyperpolar": 145, "transient": [145, 154], "dg_": 145, "g_e": [145, 146], "g_i": [145, 146, 154], "e_i": 145, "inj": 145, "bombard": 145, "run_lif_cond": 145, "i_inj": 145, "pre_spike_train_ex": [145, 146], "pre_spike_train_in": 145, "gi": 145, "ge_bar": [145, 146], "gi_bar": 145, "vi": 145, "tau_syn_": [145, 146], "tau_syn_i": 145, "pre_spike_train_ex_tot": 145, "pre_spike_train_in_tot": 145, "cv_": 145, "descriptor": 145, "_measure_the_mean_free_membrane_potential_exercis": 145, "ei_isi_regular": 145, "lip": [145, 164], "211": [145, 146, 153, 154], "fontweight": [145, 146, 154], "spk": 145, "_lif_explorer_interactive_demo_and_discuss": 145, "_excitatory_inhibitory_balance_discuss": 145, "vesicl": 145, "termin": [145, 185], "fashion": 145, "influx": 145, "du_e": 145, "u_": 145, "u_0": 145, "5mm": [145, 146], "dg_e": 145, "_e": [145, 153, 154], "spiketim": 145, "ur": 145, "gg": 145, "incur": [145, 187, 188], "phenomenolog": [145, 146], "kinet": 145, "dg": [145, 154], "regularli": 145, "uncheck": 145, "my_std_diff_r": 145, "_std_explorer_with_input_rate_interactive_demo_and_discuss": 145, "her": [145, 197], "10th": 145, "input_r": 145, "g_1": 145, "g_2": 145, "st": 145, "_stf_explorer_with_input_rate_interactive_demo_and_discuss": 145, "therebi": [145, 188], "imping": 145, "run_lif_cond_stp": 145, "u0_": 145, "tau_d_": 145, "tau_f_": 145, "u0i": 145, "tau_di": 145, "tau_fi": 145, "u0_i": 145, "tau_d_i": 145, "tau_f_i": 145, "ne": 145, "ni": 145, "ue": 145, "ge_tot": 145, "ui": 145, "ri": [145, 153, 154], "gi_tot": 145, "tau_ratio": 145, "lif_stp": 145, "t_plot_rang": 145, "400m": 145, "onward": 145, "_lif_with_stp_bonus_interactive_demo": 145, "w2d3_t4_bonu": 146, "my_raster_plot": 146, "raster_plot": 146, "my_example_p": 146, "ltp": 146, "rastert": 146, "color_set": 146, "cyan": 146, "212": [146, 153, 154], "mystdp_plot": 146, "a_plu": 146, "a_minu": 146, "tau_stdp": 146, "time_diff": 146, "biphas": 146, "default_pars_stdp": 146, "ltd": 146, "_stdp_video": 146, "weaken": 146, "latenc": 146, "delta_w": 146, "pre_spik": 146, "post_spik": 146, "_compute_stdp_changes_exercis": 146, "dm": 146, "displaystyl": [146, 152], "sp_or_not": 146, "generate_p": 146, "_compute_dp_exercis": 146, "foral": 146, "run_lif_cond_stdp": 146, "ge_init": 146, "ge_bar_upd": 146, "id_temp": 146, "epsp": 146, "322": 146, "323": 146, "324": 146, "_analyzing_synaptic_strength_discuss": 146, "depotenti": 146, "example_lif_stdp": 146, "inputr": 146, "tsim": 146, "120000": 146, "intputr": 146, "014": 146, "gbar_norm": 146, "620px": 146, "sample_tim": 146, "my_visual_stdp_distribut": 146, "g_di": 146, "_lif_and_stdp_interactive_demo_and_discuss": 146, "example_lif_stdp_corrinput": 146, "i_pr": 146, "figtemp": 146, "iput": 146, "get_text": [146, 178], "legend_handl": 146, "g_dis_cc": 146, "g_dis_dp": 146, "unaffect": [146, 197], "_lif_plasticity_correlated_inputs_interactive_demo_and_discuss": 146, "loooong": 146, "neuronaldynam": 148, "ch4": 148, "cowan": [148, 150], "1972": [148, 153, 154], "s0006": [148, 153, 154], "3495": [148, 153, 154], "86068": [148, 153, 154], "635": 148, "648": 148, "ozeki": 148, "finn": 148, "schaffer": 148, "ferster": 148, "028": 148, "sanzeni": 148, "akitak": 148, "goldbach": 148, "leedi": 148, "widespread": 148, "e54875": 148, "54875": 148, "skagg": 148, "mcnaughton": 148, "1997": [148, 181], "interneuron": 148, "4388": 148, "04382": 148, "rubin": [148, 156, 190, 194], "1994": 148, "2037": 148, "neco_a_00472": 148, "pmc4026108": 148, "1202": 148, "6670": 148, "cerebr": 148, "109": 148, "3373": 148, "3391": 148, "031": [148, 164], "1908": 148, "10101": 148, "hennequin": 148, "lengyel": 148, "attractor": [148, 150], "846": 148, "860": [148, 181], "017": 148, "875534": 148, "hooser": 148, "402": 148, "026": [148, 171], "vreeswijk": 148, "sompolinski": 148, "274": 148, "5293": 148, "1724": 148, "1023": 148, "1008925309027": 148, "01095": 148, "w2d4_daysummari": 149, "_daysummari": [149, 157, 165, 171, 191], "nicola": 150, "juliana": 150, "georgieva": 150, "ken": 150, "expos": [150, 198], "amplif": 150, "supra": 150, "w2d3": 150, "manifest": 150, "oscillatori": [150, 153, 154, 171], "w2d4_intro": 150, "w2d4_outro": 151, "julijana": [152, 153, 154], "gjorgjieva": [152, 153, 154], "mainli": 152, "signatur": [152, 171, 188], "diseas": [152, 174], "epilepsi": 152, "parkinson": 152, "homogen": 152, "w2d4_t1": 152, "plot_fi": 152, "plot_dr_r": 152, "drdt": 152, "x_fp": [152, 153, 154], "plot_dfdt": 152, "dfdt": 152, "_dynamic_networks_video": 152, "feed": 152, "ext": [152, 153, 154], "default_pars_singl": 152, "i_ext": 152, "r_init": 152, "t_sim": [152, 153, 154], "new_para": [152, 153, 154], "my_func": 152, "hyperbol": 152, "tangent": [152, 153], "_implement_fi_curve_exercis": 152, "interactive_plot_fi": 152, "expecxt": 152, "_parameter_exploration_of_fi_curve_interactive_demo_and_discuss": 152, "simulate_singl": 152, "ana": 152, "myplot_e_diffi_difftau": 152, "r_ana": 152, "_parameter_exploration_of_single_population_dynamics_interactive_demo_and_discuss": 152, "_finite_activities_discuss": 152, "_finding_fixed_points_video": 152, "deduc": 152, "compute_drdt": 152, "other_par": [152, 153, 154], "unus": 152, "_visualization_of_the_fixed_points_exercis": 152, "my_fp_singl": 152, "r_guess": 152, "check_fp_singl": 152, "fp": [152, 154], "my_fp_find": 152, "r_guess_vector": 152, "my_wcr": [152, 154], "mytol": [152, 154], "toler": [152, 154, 196], "correct_fp": 152, "student_exercis": 152, "_numerical_calculation_of_fixed_points_exercis": 152, "plot_intersection_singl": 152, "r_init_vector": 152, "_fixed_points_inputs_interactive_demo_and_discuss": 152, "_root": 152, "236": 152, "233": 152, "fatol": 152, "hybr": 152, "sol": 152, "_root_hybr": 152, "237": [152, 178], "238": [152, 178], "_root_leastsq": 152, "_minpack_pi": 152, "232": 152, "col_deriv": 152, "xtol": 152, "maxfev": 152, "230": 152, "231": 152, "_check_func": 152, "fsolv": [152, 160], "epsfcn": 152, "234": [152, 178], "checker": 152, "argnam": 152, "thefunc": 152, "numinput": 152, "output_shap": 152, "plot_single_diffeinit": 152, "_dynamics_initial_value_interactive_demo_and_discuss": 152, "800x500": 152, "_stable_vs_unstable_fixed_points_discuss": 152, "_inhibitory_populations_discuss": 152, "_stability_of_fixed_points_bonus_video": 152, "perturb": [152, 154, 192, 195, 196, 197], "wf": 152, "dfdx": [152, 153, 154], "eig_singl": 152, "r_fp": 152, "eig_fp": 152, "point1": [152, 153, 154], "583": 152, "point2": 152, "447": 152, "498": 152, "point3": 152, "900": 152, "626": 152, "_compute_eigenvalues_bonus_exercis": 152, "ornstein": [152, 154], "uhlenbeck": [152, 154], "uhlenback": 152, "becam": 153, "w2d4_t2": 153, "plot_fi_invers": [153, 154], "f_inv": [153, 154], "plot_fi_ei": [153, 154], "fi_exc": [153, 154], "fi_inh": [153, 154], "my_test_plot": [153, 154], "re1": [153, 154], "ri1": [153, 154], "re2": [153, 154], "ri2": [153, 154], "plot_nullclin": [153, 154], "exc_null_r": [153, 154], "exc_null_ri": [153, 154], "inh_null_r": [153, 154], "inh_null_ri": [153, 154], "my_plot_nullclin": [153, 154], "get_e_nullclin": [153, 154], "get_i_nullclin": [153, 154], "my_plot_vector": [153, 154], "my_n_skip": [153, 154], "myscal": [153, 154], "ei_grid": [153, 154], "dredt": [153, 154], "dridt": [153, 154], "eideriv": [153, 154], "n_skip": [153, 154], "my_plot_trajectori": [153, 154], "x_init": [153, 154], "re_init": [153, 154], "ri_init": [153, 154], "re_tj": [153, 154], "ri_tj": [153, 154], "simulate_wc": [153, 154], "e_grid": [153, 154], "trjectori": [153, 154], "plot_complete_analysi": [153, 154], "nfor": [153, 154], "nlow": [153, 154], "nhigh": [153, 154], "plot_fp": [153, 154], "wee": 153, "wie": [153, 154], "wii": [153, 154], "i_ext_": [153, 154], "i_ext_i": [153, 154], "_phase_analysis_video": 153, "subtyp": 153, "f_e": [153, 154], "f_i": [153, 154], "ae": 153, "ai": 153, "_plot_fi_exercis": 153, "_numerical_integration_of_we_model_exercis": 153, "plot_ei_diffiniti": 153, "_population_trajectories_with_different_initial_values_interactive_demo_and_discuss": 153, "_nullclines_and_vector_fields_video": 153, "n_t": [153, 186], "plot_activity_phas": 153, "_time_plane_to_phase_plane_interactive_demo_and_discuss": 153, "1mm": [153, 154], "shere": 153, "ln": [153, 154], "f_invers": [153, 154], "finvers": [153, 154], "_compute_the_nullclines_we_exercis": 153, "travers": 153, "119": [153, 174], "104": [153, 169], "770x600": 153, "_compute_the_vector_field_exercis": 153, "_analyzing_the_vector_field_discuss": 153, "w2d4_t3_bonu": 154, "_fixed_points_and_stability_video": 154, "my_fp": 154, "check_fp": 154, "vicin": 154, "x_fp_1": 154, "x_fp_2": 154, "x_fp_3": 154, "_find_the_fixed_points_of_we_exercis": 154, "attract": 154, "yield": 154, "get_eig_jacobian": 154, "eig_1": 154, "eig_2": 154, "eig_3": 154, "_compute_the_jacobian_exercis": 154, "pitchfork": 154, "bifurc": 154, "plot_nullcline_diffwe": 154, "clip_on": 154, "_effect_of_wee_interactive_demo_and_discuss": 154, "time_constant_effect": 154, "ei_grid_": 154, "ei_grid_i": 154, "_limit_cycle_and_oscillations_interactive_demo": 154, "subpopul": 154, "alpha_i": 154, "noninhibit": 154, "get_dgd": 154, "dgde": 154, "dgdre": 154, "dgdre1": 154, "dgdre2": 154, "dgdre3": 154, "fp1": 154, "fp2": 154, "fp3": 154, "x_fp_lc": 154, "dgdre_lc": 154, "fp_lc": 154, "650": 154, "519": [154, 197], "706": 154, "837": 154, "_compute_dgdre_exercis": 154, "iff": 154, "det": 154, "fw": 154, "steeper": 154, "isn_i_perturb": 154, "_nullclines_of_isn_and_nonisn_interactive_demo_and_discuss": 154, "20201": 154, "20202": 154, "se": [154, 197], "outlast": 154, "my_inject": 154, "t_start": 154, "t_lag": 154, "n_start": 154, "n_lag": 154, "i_puls": 154, "l_puls": 154, "wc_with_puls": 154, "2022": [154, 156, 190], "_persistent_activity_interactive_demo_and_discuss": 154, "treatment": [156, 190, 192, 196, 197], "goldreich": 156, "cn": 156, "nyu": 156, "malab": 156, "bayesianbook": 156, "gelman": 156, "carlin": 156, "stern": 156, "crc": 156, "mcelreath": 156, "rethink": 156, "stan": 156, "stuff": 156, "downei": 156, "reilli": 156, "media": 156, "inc": 156, "kruschk": 156, "jag": 156, "knill": 156, "propel": 156, "welchman": 156, "trommershaus": 156, "landi": 156, "cue": [156, 185], "kass": [156, 190], "w3d1_daysummari": 157, "fish": [158, 161, 166, 168, 169, 176], "astrocat": [158, 166, 176, 179], "rl": [158, 183, 185], "w3d1_intro": 158, "w3d1_outro": 159, "xaq": [160, 161, 168, 169, 170, 171, 178, 179], "pitkow": [160, 161, 168, 169, 170, 171, 178, 179], "w3d1_t1": 160, "namedtupl": [160, 169, 170, 172, 179], "gridspeclayout": 160, "togglebutton": [160, 178], "interactive_output": [160, 161], "clear_output": [160, 161], "filterwarn": [160, 161], "plot_joint_prob": 160, "marginal_i": 160, "marginal_x": 160, "joint_prob": 160, "rect_histx": 160, "rect_histi": 160, "rect_x_cmap": 160, "rect_y_cmap": 160, "matshow": 160, "barh": 160, "ind": 160, "tick_bottom": 160, "tick_left": 160, "silver": [160, 181], "plot_prior_likelihood_posterior": 160, "small_width": 160, "left_spac": 160, "added_spac": 160, "rect_prior": 160, "rect_likelihood": 160, "rect_posterior": 160, "ax_prior": 160, "ax_likelihood": 160, "ax_posterior": 160, "rect_colormap": 160, "tick_right": 160, "set_ticks_posit": 160, "plot_prior_likelihood": 160, "p_a_s1": 160, "p_a_s0": 160, "small_pad": 160, "prior_colormap": 160, "posterior_colormap": 160, "plot_util": 160, "rect_util": 160, "rect_expect": 160, "ax_util": 160, "ax_expect": 160, "plot_prior_likelihood_util": 160, "expected_colormap": 160, "compute_margin": 160, "cor": 160, "p11": 160, "p01": 160, "p10": 160, "p00": 160, "compute_cor_rang": 160, "cmax": 160, "cmin": 160, "_introduction_to_bayesian_statistics_and_decisions_video": 160, "_gone_fishin_video": 160, "losss": 160, "_utility_video": 160, "submarin": 160, "sunburn": 160, "afternoon": 160, "dock": 160, "weigh": [160, 161], "correspondingli": [160, 171], "ps_widget": 160, "make_utility_plot": 160, "_exploring_the_decision_interactive_demo_and_discuss": 160, "_utility_demo_discussion_video": 160, "_likelihood_video": 160, "fisher": 160, "_guessing_the_location_of_the_fish_discuss": 160, "knew": [160, 168], "_correlation_and_marginalization_video": [160, 161], "golden": 160, "cor_widget": 160, "\u03c1": [160, 161, 179], "px_widget": 160, "py_widget": 160, "make_corr_plot": 160, "_covarying_probability_distributions_discuss": 160, "journei": 160, "irrelev": 160, "njoint": 160, "n1": 160, "n2": 160, "n3": 160, "_computing_marginal_probabilities_math_exercis": 160, "caught": [160, 169, 178], "nprior": 160, "nlikelihood": 160, "_computing_marginal_likelihood_math_exercis": 160, "_posterior_beliefs_video": [160, 161], "propto": [160, 161, 162, 169], "intract": 160, "whfere": 160, "bother": 160, "unnorm": 160, "_calculating_a_posterior_probability_math_exercis": 160, "compute_posterior": 160, "p_m": 160, "_computing_posteriors_exercis": 160, "incorrect": [160, 168], "exert": 160, "p_a_s1_widget": 160, "370px": 160, "p_a_s0_widget": 160, "observed_widget": 160, "button_styl": [160, 178], "flex": [160, 161], "widget_ui": [160, 161], "widget_out": [160, 161], "_what_affects_the_posterior_interactive_demo_and_discuss": 160, "_posterior_beliefs_exercises_discussion_video": 160, "_bayesian_decisions_video": [160, 161], "econom": [160, 174, 183, 185], "ecolog": 160, "300px": 160, "_probabilities_vs_utilities_interactive_demo_and_discuss": 160, "_bayesian_decisions_demo_discussion_video": 160, "rho_": [160, 161], "w3d1_t2": 161, "gamma_distribut": 161, "affine2d": 161, "plot_mixture_prior": 161, "gaussian1": 161, "gaussian2": 161, "plot_loss": 161, "mse_loss": 161, "abs_loss": 161, "zero_one_loss": 161, "ax_gau": 161, "ax_error": 161, "gaussian_mixtur": 161, "mu1": [161, 168], "mu2": 161, "deepskyblu": 161, "aquamarin": 161, "plot_utility_mixture_dist": 161, "mu_g": 161, "sigma_g": 161, "mu_loc": 161, "mu_dist": 161, "plot_utility_row": 161, "mu_post": 161, "sigma_post": 161, "product_guassian": 161, "sigma_mix": 161, "mu_mix1": 161, "mu_mix2": 161, "gaus_mix1": 161, "gaus_mix2": 161, "plot_bayes_utility_row": 161, "plot_bayes_row": 161, "plot_mvn2d": 161, "cov12": 161, "mvn2d": 161, "contourf": 161, "plot_margin": 161, "c_x": 161, "c_y": 161, "p_x": 161, "p_y": 161, "mu_x_i": 161, "mu_y_x": 161, "sigma_x_i": 161, "sigma_y_x": 161, "p_x_y": 161, "p_y_x": 161, "p_c_y": 161, "p_c_x": 161, "rect_z": 161, "rect_x": 161, "rect_i": 161, "ax_z": 161, "set_axis_off": 161, "plot_bay": 161, "plot_inform": 161, "mu3": 161, "sigma3": 161, "satellit": 161, "plot_information_glob": 161, "reverse_product": 161, "plot_loss_utility_gaussian": 161, "loss_f": 161, "mu_tru": 161, "plot_loss_util": 161, "plot_loss_utility_mixtur": 161, "calc_mean_mode_median": 161, "calc_loss_func": 161, "calc_expected_loss": 161, "min_expected_loss": 161, "dashdot": 161, "plot_loss_utility_bay": 161, "plot_simple_utility_gaussian": 161, "mu_c": 161, "sigma_c": 161, "plot_utility_gaussian": 161, "plot_utility_mixtur": 161, "mu_m1": 161, "mu_m2": 161, "sigma_m1": 161, "sigma_m2": 161, "plot_utility_uniform": 161, "plot_utility_gamma": 161, "gamma_pdf": 161, "max_util": 161, "plot_bayes_loss_utility_gaussian": 161, "plot_bayes_loss_util": 161, "plot_bayes_loss_utility_uniform": 161, "plot_bayes_loss_utility_gamma": 161, "plot_bayes_loss_utility_mixtur": 161, "expected_loss": 161, "global_loss_plot_switch": 161, "loss_plot_switch": 161, "what_to_plot": 161, "loss_f_opt": 161, "mu_slid": 161, "\u00b5_estim": 161, "continuous_upd": [161, 196], "sigma_slid": 161, "\u03c3_estim": 161, "mu_true_slid": 161, "\u00b5_true": 161, "mu1_slid": 161, "\u00b5_est_p": 161, "mu2_slid": 161, "\u00b5_est_q": 161, "sigma1_slid": 161, "\u03c3_est_p": 161, "sigma2_slid": 161, "\u03c3_est_q": 161, "factor_slid": 161, "\u03c0": 161, "global_plot_prior_switch": 161, "plot_prior_switch": 161, "\u00b5_prior": 161, "\u00b5_likelihood": 161, "\u03c3_prior": 161, "\u03c3_likelihood": 161, "alpha_slid": 161, "\u03b1_prior": 161, "beta_slid": 161, "\u03b2_prior": 161, "offset_slid": 161, "gaus_label": 161, "justify_cont": 161, "gamma_label": 161, "mu_m1_slid": 161, "\u00b5_mix_p": 161, "mu_m2_slid": 161, "\u00b5_mix_q": 161, "sigma_m1_slid": 161, "\u03c3_mix_p": 161, "sigma_m2_slid": 161, "\u03c3_mix_q": 161, "global_plot_bayes_loss_utility_switch": 161, "plot_bayes_loss_utility_switch": 161, "empty_label": 161, "\u03bc": 161, "\u03b2": 161, "mvn": 161, "dstack": 161, "j_1": 161, "j_2": 161, "j_3": 161, "mu_prod": 161, "sigma_prod": 161, "calc": [161, 162], "cdf": 161, "_introduction_video": [161, 169, 171, 172, 185], "astronaut": 161, "jetpack": [161, 176, 179], "thumb": 161, "jet": [161, 179], "pack": [161, 179], "earth": [161, 179], "glimps": 161, "_astrocat_video": 161, "remot": 161, "tenni": 161, "_the_gaussian_distribution_video": 161, "ormal": 161, "clarif": 161, "\u00b5": 161, "_exploring_gaussian_parameters_interactive_demo_and_discuss": 161, "mu_3": 161, "sigma_3": 161, "_multiplying_gaussians_video": 161, "\u00b5_1": 161, "\u00b5_2": 161, "\u03c3_1": 161, "\u03c3_2": 161, "distro_1_label": 161, "distro_2_label": 161, "_multiplying_gaussians_interactive_demo_and_discuss": 161, "multimod": 161, "_mixtures_of_gaussians_video": 161, "\u00b5_p": 161, "\u00b5_q": 161, "\u03c3_p": 161, "\u03c3_q": 161, "mixture_label": 161, "_exploring_gaussian_mixtures_interactive_demo_and_discuss": 161, "_utility_loss_estimators_video": 161, "_exploring_loss_with_different_distributions_interactive_demo_and_discuss": 161, "fairli": [161, 197], "safe": [161, 186], "eu": 161, "mu_g_slid": 161, "\u00b5_gain": 161, "mu_c_slid": 161, "\u00b5_cost": 161, "sigma_g_slid": 161, "\u03c3_gain": 161, "sigma_c_slid": 161, "\u03c3_cost": 161, "distro_label": 161, "gain_label": 161, "loss_label": 161, "_complicated_cat_costs_interactive_demo_and_discuss": 161, "mu_x": 161, "sigma_x": 161, "anticorrel": 161, "\u00b5_x": 161, "\u00b5_y": 161, "\u03c3_x": 161, "\u03c3_y": 161, "corr_slid": 161, "distro1_label": 161, "distro2_label": 161, "corr_label": 161, "_covarying_2d_gaussian_interactive_demo_and_discuss": 161, "c_x_slider": 161, "cx": 161, "c_y_slid": 161, "cy": 161, "_marginalization_and_information_interactive_demo_and_discuss": 161, "2_": [161, 169], "_prior_exploration_interactive_demo_and_discuss": 161, "modal": 161, "_standard_loss_functions_with_various_priors_interactive_demo_and_discuss": 161, "dist_label": 161, "\u00b51_c": 161, "\u00b52_c": 161, "loc_label": 161, "mu_dist_slid": 161, "mu_loc_slid": 161, "_complicated_cat_costs_with_various_priors_interactive_demo_and_discuss": 161, "vincent": 162, "valton": 162, "jess": [162, 168, 169, 171, 172], "livezei": [162, 168, 169, 171, 172], "revis": [162, 171, 172], "outdat": 162, "w3d1_t3_bonu": 162, "plot_myarrai": 162, "plot_my_bayes_model": 162, "ex": 162, "alpha_tri": 162, "nll": 162, "i_tri": 162, "p_independ": 162, "ix": 162, "plot_simulated_behavior": 162, "true_stim": 162, "moments_myfunc": 162, "cdf_function": 162, "noisili": 162, "puppet": 162, "curtain": 162, "speaker": 162, "distant": 162, "hypothetical_stim": 162, "compute_likelihood_arrai": 162, "stim_arrai": 162, "likelihood_arrai": 162, "_auditory_likelihood_exercis": 162, "_prior_array_video": 162, "peakier": 162, "calculate_prior_arrai": 162, "p_indep": 162, "prior_mean_common": 162, "prior_sigma_common": 162, "prior_mean_indep": 162, "prior_sigma_indep": 162, "indep": 162, "prior_common": 162, "prior_indep": 162, "prior_mix": 162, "prior_arrai": 162, "fcn": 162, "_implement_prior_array_exercis": 162, "_posterior_array_video": 162, "calculate_posterior_arrai": 162, "posterior_arrai": 162, "_calculate_posterior_exercis": 162, "_binary_decision_matrix_video": 162, "unobserv": [162, 169, 172, 196, 197], "scan": [162, 171], "x_column": 162, "calculate_binary_decision_arrai": 162, "binary_decision_arrai": 162, "docstr": [162, 178], "_calculate_estimated_response_exercis": 162, "_input_array_video": 162, "generate_input_arrai": 162, "input_arrai": 162, "_generate_input_array_exercis": 162, "_marginalization_video": 162, "snippet": 162, "artifact": 162, "my_margin": 162, "marginalization_arrai": 162, "_implement_marginalization_matrix_exercis": 162, "recoveri": 162, "gone": 162, "x_stim": 162, "x_hat": [162, 197], "prior_mean": [162, 170], "prior_sigma1": 162, "prior_sigma2": 162, "prior1": 162, "prior2": 162, "prior_combin": 162, "i_stim": 162, "likelihood_mean": 162, "likelihood_sigma": 162, "_loglikelihood_video": 162, "my_bayes_model_ms": 162, "recomput": [162, 186], "trial_ll": 162, "marginal_nonzero": 162, "neg_ll": 162, "_fitting_a_model_to_generated_data_exercis": 162, "went": [162, 187, 188], "katahira": 164, "suzuki": 164, "okanoya": 164, "okada": 164, "birdsong": 164, "e24516": 164, "0024516": 164, "hmm": [164, 166, 170, 171, 178], "serruya": 164, "shaikhouni": 164, "bienenstock": 164, "cursor": 164, "169779d3852b32ce8b1a1724dbf5217d": 164, "kf": [164, 171, 179], "mormann": 164, "malmaud": 164, "huth": 164, "rangel": 164, "pressur": 164, "449": 164, "2139": 164, "ssrn": 164, "1901533": 164, "zoltowski": 164, "yate": 164, "1249": 164, "1258": 164, "demystifi": 164, "vannevar": 164, "ec": 164, "uw": 164, "techsit": 164, "uweetr": 164, "0002": 164, "w3d2_daysummari": 165, "recreat": [166, 185], "plenti": 166, "lesson": [166, 170, 176, 178], "pervas": 166, "fluoresc": 166, "w3d2_intro": 166, "w3d2_outro": 167, "yicheng": [168, 169, 172], "fei": [168, 169, 172], "melvin": 168, "selim": 168, "atai": 168, "posterior": [168, 169, 170, 171, 176, 178, 179], "w3d2_t1": 168, "erf": 168, "plot_accuracy_vs_stoptim": 168, "stop_time_list": 168, "accuracy_analytical_list": 168, "accuracy_list": 168, "stop_time_list_plot": 168, "sigma_st_max": 168, "stop_tim": 168, "ins": 168, "inset_ax": 168, "mu_st": 168, "sigma_st": 168, "lbl": [168, 169], "crimson": [168, 169, 170, 178], "domain0": 168, "simulate_and_plot_sprt_fixedtim": 168, "evidence_history_list": 168, "ttotal_evid": 168, "tdecis": 168, "evidence_histori": 168, "mvec": 168, "simulate_sprt_fixedtim": 168, "maxlen_evid": 168, "simulate_and_plot_sprt_fixedthreshold": 168, "threshold_from_errorr": 168, "ttime": 168, "taccumul": 168, "simulate_sprt_threshold": 168, "simulate_and_plot_accuracy_vs_threshold": 168, "threshold_list": 168, "alpha_list": 168, "decision_spe": 168, "simulate_accuracy_vs_threshold": 168, "amin": 168, "amax": 168, "_overview_of_tutorials_video": 168, "iid": 168, "l_t": [168, 179], "m_t": [168, 169, 170, 171, 179], "tp": 168, "delta_t": 168, "l_": 168, "epsilon_t": [168, 194, 196, 197], "_sequential_probability_ratio_test_video": 168, "m_i": 168, "rewritten": [168, 171], "bt": 168, "log_likelihood_ratio": 168, "logpdf": 168, "llvec": 168, "true_dist": 168, "mu_po": 168, "mu_neg": 168, "p_po": 168, "p_neg": 168, "ll_ratio_vec": 168, "total_evid": 168, "_simulating_an_sprt_model_exercis": 168, "_trajectories_under_the_fixed_time_stop": 168, "rule_interactive_demo_and_discuss": 168, "_section_1_exercises_discussion_video": [168, 169], "_speed_vs_accuracy_tradeoff_video": 168, "buri": 168, "simulate_accuracy_vs_stoptim": 168, "no_numer": 168, "stop_list_list": 168, "flag": [168, 171], "decisions_list": 168, "tracker": [168, 171], "accuracies_analyt": 168, "i_stop_tim": 168, "sigma_sum_gaussian": 168, "_speed_vs_accuracy_tradeoff_exercis": 168, "inset": 168, "_speed_vs_accuracy_tradeoff_interactive_demo_and_discuss": 168, "_section_2_exercises_discussion_video": 168, "kinematogram": 168, "britten": 168, "movshon": 168, "rightward": 168, "leftward": 168, "shadlen": 168, "pamela": 168, "reinagl": 168, "youtu": [168, 171, 172], "odxcytn": 168, "0o": 168, "learnt": 168, "_fixed_threshold_on_confidence_bonus_video": 168, "variant": [168, 170], "th_1": 168, "th_0": 168, "th_": 168, "pl": 168, "mul": 168, "has_enough_data": 168, "data_histori": 168, "current_evid": 168, "ll_ratio": 168, "chunk": 168, "log10_alpha": 168, "log10": 168, "_simulating_the_ddm_with_fixed_confidence_thresholds_bonus_exercis": 168, "_ddm_with_fixed_confidence_threshold_bonus_interactive_demo": 168, "ant": 168, "bee": 168, "rodent": 168, "incentiv": 168, "suppli": 168, "decision_speed_list": 168, "decision_time_list": 168, "decision_list": 168, "decision_tim": 168, "decision_length": 168, "decision_accuraci": 168, "86": [168, 188], "_speed_vs_accuracy_tradeoff_revisited_bonus_exercis": 168, "_speed_vs_accuracy_with_a_threshold_rule_bonus_interactive_demo": 168, "meenakshi": [169, 172], "sleep": [169, 196], "wake": 169, "indirectli": 169, "s_t": [169, 170, 171, 178, 179, 185, 187], "emiss": [169, 172], "w3d2_t2": 169, "linear_sum_assign": [169, 172], "plot_hmm1": 169, "flag_m": [169, 170], "hmmlearn": 169, "nstep": [169, 185], "aspect_ratio": 169, "states_forplot": 169, "twinx": [169, 170, 178], "maroon": 169, "fill_betweenx": [169, 170], "plot_marginal_seq": 169, "predictive_prob": 169, "switch_prob": 169, "prob_neg": 169, "p_vec": 169, "prob_po": 169, "boxstyl": 169, "wheat": 169, "plot_evidence_vs_noevid": 169, "posterior_matrix": 169, "nsampl": 169, "posterior_mean": [169, 170], "plot_forward_infer": 169, "states_inf": 169, "posterior_prob": 169, "flag_d": 169, "flag_pr": 169, "flag_lik": 169, "flag_post": 169, "gaussianhmm": 169, "states_interpol": 169, "borderaxespad": 169, "bar_scal": 169, "dodgerblu": [169, 170], "keepdim": 169, "wholli": 169, "s_": [169, 170, 171, 179, 185, 187], "d_": 169, "p_t": [169, 171], "_binary_hmm_with_gaussian_measurements_video": 169, "noise_level": 169, "create_hmm": 169, "transmat_": 169, "gaussianhmm1d": [169, 172], "startprob": [169, 172], "startprob_vec": 169, "transmat": [169, 172], "transmat_mat": 169, "means_vec": 169, "vars_vec": 169, "transition_vector": 169, "09355908": 169, "58552915": 169, "93502804": 169, "98819072": 169, "32506947": 169, "_simulating_binary_hmm_with_gaussian_measurements_exercis": 169, "plot_samples_widget": 169, "log10_noise_level": 169, "_binary_hmm_interactive_demo_and_discuss": 169, "_forgetting_in_a_changing_world_video": 169, "s_0": [169, 171], "simulate_prediction_onli": 169, "prob_switch": 169, "entropy_list": 169, "_forgetting_in_a_changing_world_interactive_demo_and_discuss": 169, "_section_2_exercise_discussion_video": 169, "_forward_inference_in_an_hmm_video": 169, "markov_forward": 169, "one_step_upd": 169, "compute_likelihood": 169, "simulate_forward_infer": 169, "rv0": 169, "rv1": 169, "predictive_state1": 169, "posterior_state1": 169, "hte": 169, "posterior_tm1": 169, "posterior_t": 169, "_forward_inference_of_hmm_exercis": 169, "log_10_noise_level": 169, "plot_forward_inference_widget": 169, "_forward_inference_of_hmm_interactive_demo": 169, "_section_3_exercise_discussion_video": 169, "rowei": [170, 171], "ghahramani": [170, 171], "mission": [170, 179], "w3d2_t3": 170, "visualize_astrocat": 170, "plot_measur": [170, 178], "y1": 170, "y2": 170, "y3": 170, "y4": 170, "y5": 170, "y6": 170, "process_nois": 170, "measurement_nois": 170, "todays_prior": 170, "info_prior": 170, "info_likelihood": 170, "info_posterior": 170, "prior_weight": 170, "likelihood_weight": 170, "posterior_cov": 170, "todays_posterior": 170, "predicted_estim": [170, 179], "predicted_covari": [170, 179], "innovation_estim": [170, 179], "innovation_covari": [170, 179], "updated_mean": [170, 179], "updated_cov": [170, 179], "paintmyfilt": 170, "initial_guess": 170, "cov_": 170, "filter_s_": 170, "filter_cov_": 170, "process_noise_std": 170, "measurement_noise_std": 170, "smin": 170, "smax": 170, "pscale": 170, "lightgrai": 170, "_astrocat_through_time_video": 170, "_quantifying_astrocat_dynamics_video": 170, "ds_": [170, 171], "w_t": [170, 171, 179], "sigma_p": 170, "actuat": 170, "propuls": 170, "tau_min": 170, "tau_max": 170, "process_noise_min": 170, "process_noise_max": 170, "measurement_noise_min": 170, "measurement_noise_max": 170, "unit_process_nois": 170, "unit_measurement_nois": 170, "s0": 170, "_simulating_astrocats_movements_exercis": 170, "_playing_with_astrocat_movement_interactive_demo_and_discuss": 170, "_exercise_1": 170, "1_discussion_video": 170, "_measuring_astrocats_movements_video": 170, "sigma_measur": 170, "read_collar": 170, "_reading_measurements_from_astrocats_collar_exercis": 170, "_comparing_true_states_to_measured_states_video": 170, "catastroph": 170, "sbound": 170, "_compare_true_states_to_measured_states_exercis": 170, "2_discussion_video": 170, "_the_kalman_filter_video": 170, "15ex": [170, 178, 179], "flag_": 170, "flag_s_": 170, "flag_err_": 170, "stochastic_system": 170, "process_noise_cov": 170, "measurement_noise_cov": 170, "prior_cov": 170, "captured_prior": 170, "captured_likelihood": 170, "captured_posterior": 170, "onfilt": 170, "show_pdf": 170, "pdf_likelihood": 170, "pdf_post": 170, "pdf_prior": 170, "_the_kalman_filter_in_action_interactive_demo": 170, "_interactive_demo_2": 170, "_implementing_a_kalman_filter_video": 170, "recip": 170, "broaden": 170, "sigma_w": 170, "sigma_m": 170, "textit": 170, "congrat": 170, "partwai": 170, "_implement_your_own_kalman_filter_exercis": 170, "_exercise_2": 170, "_compare_states_estimates_and_measurements_video": 170, "errorbar": 170, "yerr": 170, "mfc": 170, "mec": 170, "axhist": 170, "pdf_g": 170, "_compare_states_estimates_and_measurements_interactive_demo": 170, "_how_long_does_it_take_to_find_astrocat_video": 170, "hone": 170, "snr": 170, "decibel": 170, "equilibr": 170, "snrdb": 170, "pcov": 170, "equilibrium_posterior_var": 170, "equilibrium_process_var": 170, "labelcolor": 170, "set_major_formatt": 170, "funcformatt": 170, "format_func": 170, "nprocess": 170, "_how_long_does_it_take_to_find_astrocat_interactive_demo": 170, "3_discussion_video": 170, "carolin": 171, "haimerl": 171, "cristina": 171, "w3d2_t4_bonu": 171, "sy": 171, "set_printopt": [171, 186], "plot_kalman": 171, "plot_gaze_data": 171, "plot_kf_stat": 171, "mu_0": 171, "n_dim_stat": 171, "initial_state_mean": [171, 179], "w2d3_mit_eyetracking_2009": 171, "jfk8w": 171, "20c7bc4a6f61f49450997e381cf5e0dd": 171, "load_eyetracking_data": 171, "imread": 171, "jpg": 171, "6f_51l3i5aq": 171, "2swh639ygeg": 171, "condition": 171, "hs_": 171, "eta_t": 171, "sigma_0": 171, "tractabl": 171, "apolog": 171, "timecours": 171, "n_dim_ob": 171, "sample_ld": 171, "n_timestep": 171, "ob": 171, "_sampling_from_a_linear_dynamical_system_exercis": 171, "explore_dynam": 171, "_adjusting_system_dynamics_interactive_demo": 171, "vbozov9qmoi": 171, "_kalman_filtering_video": 171, "m_1": 171, "sigma_t": 171, "mathsf": 171, "newest": 171, "k_t": 171, "k_th": 171, "hdz_": 171, "kalman_filt": 171, "mu_pr": 171, "sigma_pr": 171, "filtered_state_mean": 171, "filtered_state_covari": 171, "_implement_kalman_filtering_exercis": 171, "m7ouxmvwhgi": 171, "_fitting_eye_gaze_data_video": 171, "devic": 171, "calibr": 171, "ambient": 171, "eyetrack": 171, "databas": 171, "judd": 171, "fixat": 171, "subject_id": 171, "image_id": 171, "plot_subject_trac": 171, "_tracking_eye_gaze_interactive_demo": 171, "influenti": 171, "texttt": 171, "transition_matric": 171, "transition_covari": [171, 179], "observation_matric": 171, "observation_covari": [171, 179], "initial_state_covari": [171, 179], "kalmanfilt": [171, 179], "em_var": 171, "016": 171, "219": 171, "774": 171, "596": 171, "magenta": 171, "triangl": 171, "plot_smoothed_trac": 171, "decent": 171, "nonetheless": 171, "kf_state": 171, "kf_data": 171, "environment": [171, 174, 188], "mitig": 171, "delet": 171, "arbitrarili": 171, "cb": 171, "4ar2myz1nm": 171, "_kalman_smoothing_and_the_em_algorithm_bonus_video": 171, "j_t": 171, "z_t": 171, "kalman_smooth": 171, "mu_hat": 171, "sigma_hat": 171, "smoothed_state_mean": 171, "smoothed_state_covari": 171, "_implement_kalman_smoothing_bonus_exercis": 171, "dz": 171, "kl": 171, "kept": 171, "s_ts_": 171, "j_": [171, 179, 194], "q_0": 171, "s_0s_0": 171, "s_ts_t": 171, "ny_ty_t": 171, "sean": 172, "escola": 172, "w3d2_t5_bonu": 172, "plot_spike_train": 172, "hot": 172, "trial_t": 172, "rect": 172, "add_patch": 172, "plot_ll": 172, "plot_lls_ecl": 172, "plot_epoch": 172, "save_v": 172, "minll": 172, "maxll": 172, "bs": 172, "lls_for_plot": 172, "eclls_for_plot": 172, "ecll": 172, "framealpha": 172, "plot_learnt_vs_tru": 172, "l_true": 172, "a_tru": 172, "run_em": 172, "psi": 172, "flot": 172, "e_step": 172, "print_everi": 172, "psi_new": 172, "a_new": 172, "l_new": 172, "m_step": 172, "interpol": [172, 187, 188], "extrapol": 172, "b_min": 172, "b_max": 172, "b_lim": 172, "num_plot_v": 172, "logpmf": 172, "diff_ll": 172, "ceqxn0ouafo": 172, "wb8mf5chmyi": 172, "_hmm_for_poisson_spiking_neurons_video": 172, "thalam": 172, "relai": 172, "tonic": 172, "rapid": 172, "receptor": 172, "molecular": 172, "n_frozen_tri": 172, "max_firing_r": 172, "max_transition_r": 172, "expens": 172, "craft": 172, "psi_tru": 172, "xf": 172, "yf": 172, "one_hot": 172, "umu4wuwlkvg": 172, "_em_tutorial_video": 172, "b_i": 172, "pairwis": 172, "gamma_": 172, "xi_": 172, "sum_j": 172, "ji": 172, "a_j": 172, "b_j": 172, "b_": 172, "psi_i": 172, "gamma_i": 172, "compact": 172, "o_j": 172, "o_": 172, "lj": 172, "l1j": 172, "node": [172, 195], "log_a": 172, "log_ob": 172, "maxtmp": 172, "h4ggtg_9bae": 172, "_implement_the_m_step_video": 172, "swapax": 172, "_implement_m_step_exercis": 172, "6utsxxe3hg0": 172, "_running_and_plotting_em_video": 172, "\ud835\udf03": [172, 178], "8684143040628": 172, "481": [172, 174], "5065734432824": 172, "cost_mat": 172, "true_ind": 172, "est_ind": 172, "bertseka": [174, 179], "bellman": 174, "1966": 174, "3731": 174, "charnov": 174, "forag": 174, "136": 174, "doyl": 174, "1978": 174, "lqg": 174, "757": 174, "tac": 174, "1101812": 174, "kalman": 174, "1960": 174, "boletin": 174, "sociedad": 174, "matematica": 174, "mexicana": 174, "kappen": 174, "g\u00f3mez": 174, "opper": 174, "159": 174, "182": 174, "s10994": 174, "5278": 174, "todorov": 174, "11478": 174, "11483": 174, "0710743106": 174, "pmc2705278": 174, "castro": 174, "hadjiosif": 174, "hemphil": 174, "1050": 174, "1061": 174, "cub": 174, "049": 174, "brandt": 174, "shadmehr": 174, "disord": 174, "huntington": 174, "6769": 174, "549": 174, "35000576": 174, "harvard": 174, "motorlab": 174, "reprint": 174, "nature00": 174, "sing": 174, "joiner": 174, "nanayakkara": 174, "brayanov": 174, "primit": 174, "575": 174, "589": 174, "wagner": 174, "10663": 174, "10673": 174, "5479": 174, "bautista": 174, "tinbergen": 174, "kacelnik": 174, "fly": 174, "1094": 174, "pmc14713": 174, "ralston": 174, "1958": 174, "international": 174, "zeitschrift": 174, "f\u00fcr": 174, "angewandt": 174, "physiologi": 174, "einschliesslich": 174, "arbeitsphysiologi": 174, "bf00698754": 174, "ahm": 174, "vigor": 174, "neuroeconom": 174, "zee": 174, "saccad": 174, "196": [174, 181], "475": 174, "s00221": 174, "1879": 174, "pmc2771693": 174, "yoon": 174, "geari": 174, "e10476": 174, "e10485": 174, "1812979115": 174, "pmc6217431": 174, "jaleel": 174, "2161": 174, "00700": 174, "w3d3_daysummari": 175, "w3d3_intro": 176, "w3d3_outro": 177, "zhengwei": [178, 179], "shreya": [178, 179], "saxena": [178, 179], "melisa": 178, "maidana": 178, "capitan": 178, "pomdp": 178, "agent": [178, 183, 185, 186, 187, 188], "greatest": 178, "w3d3_t1": 178, "isclos": [178, 179], "plot_fish": 178, "fish_stat": 178, "cornflowerblu": 178, "rel_po": 178, "red_i": 178, "blue_i": 178, "royalblu": 178, "plot_act_loc": 178, "ax_loc": 178, "act_down": 178, "act_up": 178, "plot_belief": 178, "choose_polici": 178, "midnightblu": 178, "get_yticklabel": 178, "time_rang": 178, "mea": 178, "ax0": [178, 179], "ax_bel": 178, "belief_histogram": 178, "plot_value_threshold": 178, "threshold_arrai": 178, "value_arrai": 178, "yrang": 178, "star_loc": 178, "fig_": 178, "cost_sw": 178, "fist": 178, "init_t": 178, "rnd_tele": 178, "rnd_high_rwd": 178, "rnd_low_rwd": 178, "get_random": 178, "binomial_tel": 178, "getrandom": 178, "excerciseerror": 178, "assertionerror": [178, 179], "binaryhmm": 178, "fish_initi": 178, "loc_initi": 178, "fish_dynam": 178, "telegraph": 178, "p_stai": 178, "tele_oper": 178, "generate_process_lazi": 178, "rwd": 178, "p_low_rwd": 178, "p_high_rwd": 178, "p_rwd_vector": 178, "binaryhmm_belief": 178, "generate_process": 178, "low_rew_p": 178, "high_rew_p": 178, "rew_prob": 178, "belief_0": 178, "belief_upd": 178, "lazi": 178, "policy_threshold": 178, "policy_lazi": 178, "belief_past": 178, "rew_prob_matrix": 178, "belief_1": 178, "test_policy_threshold": 178, "well_don": 178, "test_value_funct": 178, "get_valu": 178, "value_funct": 178, "_gone_fishing_video": 178, "secretli": 178, "sw": 178, "q_": [178, 186], "price": 178, "prescrib": 178, "b_t": 178, "stay_prob": 178, "update_ex_1": 178, "swim": 178, "binaryhmm_test": 178, "_examining_fish_dynamics_interactive_demo_and_discuss": 178, "_catch_some_fish_video": 178, "seren": 178, "high_rew_prob": 178, "low_rew_prob": 178, "radiobutton": [178, 179], "update_ex_2": 178, "agent_initi": 178, "_examining_the_reward_function_interactive_demo_and_discuss": 178, "_where_are_the_fish_video": 178, "_examining_the_beliefs_interactive_demo_and_discuss": 178, "_how_should_you_act_video": 178, "239": 178, "_dynamics_threshold_based_policy_exercis": 178, "new_se": 178, "update_ex_4": 178, "_dynamics_with_different_thresholds_interactive_demo_and_discuss": 178, "_evaluate_policy_video": 178, "a_t": [178, 179, 187], "paid": 178, "actions_int": 178, "247": 178, "248": 178, "251": 178, "252": 178, "_implementing_a_value_function_exercis": 178, "brute": 178, "get_optimal_threshold": 178, "large_time_horizon": 178, "run_polici": 178, "_run_the_policy_exercise_and_discuss": 178, "mdp": 178, "illumin": 178, "_from_discrete_to_continuous_control_video": 178, "_sensitivity_of_optimal_policy_bonus_video": 178, "high_rwd": 178, "low_rwd": 178, "rarer": 178, "coars": 178, "update_ex_bonu": 178, "_explore_task_parameters_bonus_interactive_demo_and_discuss": 178, "w3d3_t2": 179, "plot_vs_tim": 179, "slabel": 179, "plot_kf_state_vs_tim": 179, "latent_st": 179, "standard_normal_nois": 179, "standard_normal_noise_mea": 179, "exerciseerror": 179, "test_lds_class": 179, "lds_class": 179, "ldsy": 179, "ini_st": 179, "noise_var": 179, "dynamics_openloop": 179, "dynamics_closedloop": 179, "test_lqr_class": 179, "lqr_class": 179, "lqreg": 179, "calculate_j_st": 179, "calculate_j_control": 179, "_flying_through_space_video": 179, "corros": 179, "unintend": 179, "ba_t": 179, "ds_t": 179, "neq": [179, 195, 196], "polici": [179, 185, 186, 188], "static_nois": 179, "_implement_state_evolution_equations_exercis": 179, "fare": 179, "simulate_ld": 179, "s_no_control": 179, "s_open_loop": 179, "s_closed_loop": 179, "a_closed_loop": 179, "_no_control_closed_lopp_open_loop_interactive_demo_and_discuss": 179, "optimum": 179, "ls_t": 179, "bl": 179, "calculate_plot_ms": 179, "num_iter": 179, "num_candid": 179, "control_gain_arrai": 179, "mse_arrai": 179, "ambiti": 179, "051": 179, "simulate_l": 179, "s_closed_loop_choic": 179, "l_theori": 179, "s_closed_loop_theoret": 179, "_closed_loop_exploration_interactive_demo_and_discuss": 179, "_lqr_video": 179, "fuel": 179, "certainli": 179, "riccati": 179, "dimitri": 179, "belmont": 179, "control_gain_lqr": 179, "p_t_1": 179, "j_state": 179, "j_control": 179, "_implement_the_cost_function_exercis": 179, "simulate_rho": 179, "s_lqr": 179, "a_lqr": 179, "_lqr_to_the_origin_interactive_demo_and_discuss": 179, "calculate_plot_cost": 179, "rho_arrai": 179, "_tracking_a_moving_goal_video": 179, "bounc": 179, "g_t": 179, "lqr_track": 179, "dynamics_track": 179, "a_bar": 179, "react": 179, "goal_func": 179, "simulate_track": 179, "lqr_time": 179, "s_lqr_time": 179, "a_lqr_tim": 179, "a_bar_lqr_tim": 179, "lqr_control_to_desired_time_varying_goal_interactive_demo_and_discuss": 179, "_lqg_video": 179, "radar": 179, "proc_nois": 179, "meas_nois": 179, "get_estim": 179, "observation_matrix": 179, "innov": 179, "ntrial": 179, "get_control_gain_infinit": 179, "control_policy_lqg": 179, "control_gain": 179, "estimated_st": 179, "current_act": [179, 195], "simulate_kf_no_control": 179, "ini_state_mean": 179, "ini_state_cov": 179, "_lqg_control_interactive_demo_and_discuss": 179, "simulate_kf_with_control": 179, "_lqc_controller_varying_gains_interactive_demo": 179, "simulate_kf_with_lqg": 179, "_lqc_controller_varying_weight_interactive_demo": 179, "lqg_slider": 179, "_process_noise_measurements_noise_interactive_demo": 179, "transit_matrix_slid": 179, "n_op": 179, "process_noise_var": 179, "measurement_noise_var": 179, "mse_array_n_mea": 179, "mse_array_n_proc": 179, "jcontrol_array_n_mea": 179, "jcontrol_array_n_proc": 179, "meas_noise_arrai": 179, "proc_noise_arrai": 179, "proc": 179, "mse_array_proc": 179, "jcontrol_array_proc": 179, "control_gain_lqg": 179, "filtered_state_means_impl": 179, "filtered_state_covariances_impl": 179, "action_cost": 179, "state_cost": 179, "mse_array_mea": 179, "jcontrol_array_mea": 179, "mse_array_proc_mean": 179, "mse_array_proc_std": 179, "mse_array_meas_mean": 179, "mse_array_meas_std": 179, "jcontrol_array_proc_mean": 179, "jcontrol_array_proc_std": 179, "jcontrol_array_meas_mean": 179, "jcontrol_array_meas_std": 179, "quantif": 179, "_noise_effects_on_the_lqg_discuss": 179, "sutton": 181, "barto": 181, "schultz": 181, "montagu": 181, "5306": 181, "1593": 181, "1599": 181, "utexa": 181, "dana": 181, "daw": 181, "dorsolater": 181, "striatal": 181, "1704": 181, "1711": 181, "nn1560": 181, "185": 181, "kurth": 181, "kumaran": 181, "tirumala": 181, "soyer": 181, "leibo": 181, "868": 181, "0147": 181, "295964": 181, "mattar": [181, 185, 186, 187, 188], "replai": 181, "1609": 181, "1617": 181, "0232": 181, "pmc6203620": 181, "dabnei": 181, "uchida": 181, "starkweath": 181, "hassabi": 181, "muno": 181, "dopamin": [181, 185], "577": 181, "7792": 181, "671": 181, "675": 181, "1924": 181, "pmc7476215": 181, "mnih": 181, "kavukcuoglu": 181, "rusu": 181, "veness": 181, "bellemar": 181, "518": 181, "7540": 181, "529": 181, "533": 181, "nature14236": 181, "huang": 181, "maddison": 181, "guez": 181, "sifr": 181, "driessch": 181, "game": 181, "7587": 181, "484": 181, "489": 181, "nature16961": 181, "w3d4_daysummari": 182, "exploit": [183, 186, 187], "dilemma": [183, 186], "w3d4_intro": 183, "w3d4_outro": 184, "marcelo": [185, 186, 187, 188], "sargent": [185, 186, 187, 188], "sowmya": [185, 186, 187, 188], "parthiban": [185, 186, 187, 188], "feryal": [185, 186, 187, 188], "behbahani": [185, 186, 187, 188], "jane": [185, 186, 187, 188], "ezekiel": [185, 186, 187, 188], "mehul": [185, 186, 187, 188], "rastogi": [185, 186, 187, 188], "roberto": [185, 186, 187, 188], "guidotti": [185, 186, 187, 188], "arush": [185, 186, 187, 188], "tagad": [185, 186, 187, 188], "kelson": [185, 186, 187, 188], "shill": [185, 186, 187, 188], "scrivo": [185, 186, 187, 188], "uncondit": 185, "conting": 185, "rpe": 185, "tap": 185, "w3d4_t1": 185, "plot_value_funct": 185, "plot_tde_trac": 185, "tde": 185, "fixedloc": 185, "learning_summary_plot": 185, "ex1": 185, "reward_guesser_title_hint": 185, "r1": 185, "r2": 185, "mildli": 185, "obfusc": 185, "spoil": 185, "classicalcondit": 185, "reward_magnitud": 185, "reward_tim": 185, "n_action": [185, 187, 188], "cs_time": 185, "reward_st": 185, "reward_prob": 185, "set_reward": 185, "_create_state_dictionari": 185, "get_outcom": [185, 187, 188], "current_st": 185, "next_stat": [185, 187, 188], "episod": [185, 186, 187, 188], "is_delai": 185, "t_in_delai": 185, "multirewardcc": 185, "deliv": 185, "probabilisticcc": 185, "p_reward": 185, "iti": 185, "quarter": 185, "rumelhart": 185, "pdplab": 185, "pdphandbook": 185, "handbookch10": 185, "limits_": 185, "sum_a": 185, "proxi": [185, 192], "delta_": [185, 194], "discrep": 185, "tl": 185, "td_learner": 185, "env": [185, 187, 188], "_td_learning_exercis": 185, "saliv": 185, "smell": 185, "tasti": 185, "pavlov": 185, "ring": 185, "inconsist": 185, "plot_tde_by_tri": 185, "basefmt": 185, "linefmt": 185, "markerfmt": 185, "c1d": 185, "c0o": 185, "_us_to_cs_transfer_interactive_demo": 185, "plot_summary_alpha_gamma": 185, "980": 185, "\u03b3": 185, "v_param": 185, "tde_param": 185, "_learning_rates_and_discount_factors_interactive_demo_and_discuss": 185, "learner": 185, "dispens": 185, "rng_state": 185, "get_stat": 185, "v_multi": 185, "tde_multi": 185, "reward_guesser_interact": 185, "inttext": 185, "env2": 185, "v_guess": 185, "yo": 185, "set_markers": 185, "set_markerfacecolor": 185, "rx": 185, "_examining_the_td_error_discuss": 185, "intermitt": 185, "set_stat": 185, "resynchron": 185, "v_stochast": 185, "tde_stochast": 185, "_probabilistic_rewards_discuss": 185, "bewar": 185, "_removing_the_cs_bonus_discuss": 185, "w3d4_t2": 186, "plot_choic": 186, "choice_fn": 186, "rng_seed": 186, "plot_multi_armed_bandit_result": 186, "qs": 186, "plot_parameter_perform": 186, "trial_reward": 186, "trial_optim": 186, "_multiarmed_bandits_video": 186, "colloqui": 186, "lever": 186, "rig": 186, "monei": 186, "payout": 186, "r_t": [186, 187], "fatal": 186, "flaw": 186, "trap": 186, "bet": 186, "regret": 186, "stumbl": 186, "epsilon_greedi": [186, 187, 188], "be_greedi": [186, 188], "_implement_epsilon_greedy_exercis": 186, "amongst": 186, "\u03b5": 186, "explore_epilson_valu": 186, "_changing_epsilon_interactive_demo_and_discuss": 186, "q_t": 186, "update_action_valu": 186, "_updating_action_values_exercis": 186, "multi_armed_bandit": 186, "n_arm": 186, "all_reward": 186, "optimal_act": 186, "alright": 186, "explore_bandit_paramet": 186, "worst": 186, "_changing_epsilon_and_alpha_interactive_demo": 186, "bandit": [187, 188], "w3d4_t3": 187, "plot_state_action_valu": [187, 188], "n_state": [187, 188], "plot_quiver_max_act": [187, 188], "cheese_world": [187, 188], "dim_x": [187, 188], "dim_i": [187, 188], "which_max": [187, 188], "minor": [187, 188], "plot_heatmap_max_v": [187, 188], "value_max": [187, 188], "afmhot": [187, 188], "windy_cliff_grid": [187, 188], "plot_reward": [187, 188], "n_episod": [187, 188], "average_rang": [187, 188], "smoothed_reward": [187, 188], "plot_perform": [187, 188], "reward_sum": [187, 188], "_mdps_and_q_learning_video": 187, "overcom": 187, "cliff": [187, 188], "4x10": 187, "td": 187, "watkin": 187, "max_": [187, 188], "discount": [187, 188], "greedi": [187, 188], "learn_environ": [187, 188], "lifecycl": 187, "cliffworld": 187, "border": [187, 188], "cliff_world": 187, "init_st": [187, 188], "get_all_outcom": [187, 188], "learning_rul": 187, "q_learn": [187, 188], "max_next_q": 187, "td_error": 187, "value_qlearn": 187, "reward_sums_qlearn": 187, "110": 187, "113": 187, "_implement_q_learning_algorithm_exercis": 187, "notabl": 187, "steadili": 187, "policy_next_q": 187, "policy_act": 187, "value_sarsa": 187, "reward_sums_sarsa": 187, "_implement_the_sarsa_algorithm_bonus_exercis": 187, "skittish": 187, "standpoint": 187, "skirt": 187, "wall": [187, 188], "rout": 187, "w3d4_t4": 188, "prev_valu": 188, "isnan": [188, 195, 196], "max_valu": 188, "model_updat": 188, "shortcut_episod": 188, "episode_step": 188, "toggle_shortcut": 188, "quentinsworld": 188, "quentin": 188, "shortcut_st": 188, "_modelbased_rl_video": 188, "costli": 188, "fuller": 188, "assimil": 188, "10x10": 188, "trivial": 188, "tabular": 188, "forev": 188, "nontermin": 188, "dyna_q_model_upd": 188, "_dynaq_model_update_exercis": 188, "dyna_q_plan": 188, "nx2": 188, "_dynaq_planning_exercis": 188, "n_experi": 188, "planning_step": 188, "steps_per_episod": 188, "warm": 188, "upward": 188, "consolid": 188, "hernan": [190, 194], "robin": 190, "readabl": 190, "charit": 190, "dag": 190, "angrist": [190, 194], "pischk": [190, 194], "princeton": 190, "harmless": [190, 194], "imben": [190, 194], "aschengrau": 190, "seag": 190, "health": 190, "jone": 190, "bartlett": 190, "dominik": 190, "bernhard": 190, "cooper": 190, "herskovit": 190, "1992": 190, "induct": 190, "309": 190, "bf00994110": 190, "amari": 190, "arai": 190, "diekman": 190, "diesmann": 190, "kramer": 190, "041715": 190, "033733": 190, "126718": 190, "annrev2017fin": 190, "marinescu": 190, "lawlor": 190, "quasi": 190, "891": 190, "898": 190, "s41562": 190, "0466": 190, "econ": 190, "quasiexperiment": 190, "mooij": 190, "janz": 190, "zscheischler": 190, "sch\u00f6lkopf": 190, "1204": 190, "acm": 190, "5555": 190, "2946645": 190, "2946677": 190, "b\u00fchlmann": 190, "meinshausen": 190, "identif": 190, "royal": 190, "947": 190, "1012": 190, "1111": 190, "rssb": 190, "12167": 190, "01332": 190, "scholkopf": 190, "judea": [190, 192], "765": 190, "804": 190, "3501714": 190, "3501755": 190, "1911": 190, "10500": 190, "shimizu": 190, "hoyer": 190, "hyv\u00e4rinen": 190, "kerminen": 190, "jordan": 190, "acycl": 190, "jmlr": 190, "v7": 190, "shimizu06a": 190, "spirt": 190, "glymour": 190, "schein": 190, "heckerman": 190, "causat": [190, 196, 197], "triantafil": 190, "tsamardino": 190, "2147": 190, "2205": 190, "v16": 190, "triantafillou15a": 190, "w3d5_daysummari": 191, "drug": [192, 194], "mislead": 192, "unmeasur": 192, "unavoid": 192, "w3d1": 192, "bedrock": 192, "heart": 192, "w3d5_intro": 192, "w3d5_outro": 193, "toni": [194, 195, 196, 197], "mike": [194, 195, 196, 197], "cohen": [194, 195, 196, 197], "yoni": [194, 195, 196, 197], "pproduct": 194, "w3d5_t1": 194, "see_neuron": [194, 195, 196, 197], "renorm": 194, "plot_connectivity_matrix": [194, 195, 196], "set_siz": [194, 195], "plot_connectivity_graph_matrix": 194, "plot_neural_act": [194, 197], "cax1": [194, 197], "plot_true_vs_estimated_connect": [194, 195], "estimated_connect": [194, 195, 196, 197], "true_connect": [194, 195], "selected_neuron": [194, 195, 197], "_defining_causality_video": 194, "rct": 194, "placebo": 194, "neuron_b": 194, "activity_of_a": 194, "diff_in_mean": 194, "9907195190159408": 194, "_randomized_controlled_trial_for_two_neurons_exercis": 194, "_simulated_neural_system_model_video": 194, "nonlinearli": 194, "i_n": 194, "create_connect": [194, 195, 196, 197], "nxn": [194, 195, 196, 197], "s_val": [194, 195, 196, 197], "s_val_test": [194, 197], "singular": [194, 197], "simulate_neuron": [194, 195, 196, 197], "timetep": [194, 195, 196, 197], "___t____t": 194, "1___": 194, "___1____0_____": 194, "_system_simulation_exercis": 194, "_perturbing_systems_video": 194, "frac1n": 194, "substack": 194, "interven": 194, "simulate_neurons_perturb": 194, "seriou": 194, "huh": 194, "x_perturb": 194, "boilerpl": 194, "cax0": 194, "_calculating_causality_video": 194, "start_index": 194, "end_index": 194, "count_bi": 194, "get_perturbed_connectivity_from_single_neuron": 194, "perturbed_x": 194, "neuron_perturb": 194, "all_neuron_output": 194, "this_neuron_output": 194, "one_idx": 194, "zero_idx": 194, "get_perturbed_connectivity_single_neuron": 194, "difference_in_mean": 194, "_perturbed_dynamics_to_recover_connectivity_exercis": 194, "strictli": [194, 195], "get_perturbed_connectivity_all_neuron": 194, "2n": 194, "987593404378358": 194, "econometr": 194, "proportion": 194, "w3d5_t2": 195, "plot_estimation_quality_vs_n_neuron": 195, "number_of_neuron": 195, "corr_func": 195, "corr_data": [195, 196, 197], "get_sys_corr": [195, 196, 197], "corr_mean": [195, 196, 197], "corr_std": [195, 196, 197], "correlation_for_all_neuron": [195, 196, 197], "_correlation_vs_causation_video": 195, "compute_connectivity_from_single_neuron": 195, "next_act": 195, "this_output_act": 195, "_approximate_causation_with_correlation_exercis": 195, "5f": 195, "95967": 195, "_correlation_causation_for_small_systems_video": 195, "_correlation_causation_in_large_systems_video": 195, "plot_corr": 195, "_function_base_impl": [195, 196], "2922": [195, 196], "runtimewarn": [195, 196], "invalid": [195, 196], "stddev": [195, 196], "2923": [195, 196], "_connectivity_estimation_as_a_function_of_number_of_neurons_interactive_demo": 195, "rightli": 195, "wonder": [195, 196, 197], "_connectivity_estimation_as_a_function_of_the_sparsity_a_interactive_demo": 195, "phrase": 195, "filler": 195, "mediat": 195, "promot": 195, "_reflecting_on_causality_discuss": 195, "spearman": 195, "dichotom": 195, "concord": 195, "kappa": 195, "braini": 195, "coarse_x": 195, "get_coarse_corr": 195, "n_group": 195, "coarse_a": 195, "_compute_average_activity_bonus_exercis": 195, "neffect": 195, "controversi": 196, "w3d5_t3": 196, "multioutput": [196, 197], "multioutputregressor": [196, 197], "ratio_observ": 196, "_regression_approach_video": 196, "confound": [196, 197], "homework": 196, "grade": 196, "confond": 196, "collid": 196, "counterintuit": 196, "_fitting_a_glm_video": 196, "logit": [196, 197], "l_1": 196, "fit_intercept": [196, 197], "get_regression_estim": [196, 197], "865": 196, "703": 196, "_linear_regression_with_lasso_to_estimate_causal_connectivities_exercis": 196, "_omitted_variable_bias_video": 196, "sel_idx": [196, 197], "set_text": [196, 197], "046": [196, 197], "get_regression_estimate_full_connect": [196, 197], "get_regression_corr_full_connect": [196, 197], "reg": [196, 197], "n_job": [196, 197], "estimators_": [196, 197], "observed_ratio": [196, 197], "regression_arg": [196, 197], "sel_x": [196, 197], "sel_a": [196, 197], "sel_v": [196, 197], "4000": 196, "reg_arg": [196, 197], "n_observ": [196, 197], "to_neuron": 196, "big_r": [196, 197], "nanmean": 196, "nanstd": 196, "_coordinate_desc": 196, "695": 196, "convergencewarn": 196, "dualiti": 196, "194e": 196, "991e": 196, "cd_fast": 196, "enet_coordinate_desc": 196, "035e": 196, "170e": 196, "444e": 196, "037e": 196, "527e": 196, "297e": 196, "612e": 196, "502e": 196, "267e": 196, "659e": 196, "571e": 196, "069e": 196, "205e": 196, "716e": 196, "784e": 196, "325e": 196, "105e": 196, "815e": 196, "791e": 196, "903e": 196, "111e": 196, "913e": 196, "089e": 196, "599e": 196, "078e": 196, "658e": 196, "302e": 196, "114e": 196, "171e": 196, "299e": 196, "018e": 196, "731e": 196, "472e": 196, "109e": 196, "060e": 196, "243e": 196, "636e": 196, "693e": 196, "154e": 196, "479e": 196, "440e": 196, "260e": 196, "467e": 196, "721e": 196, "617e": 196, "637e": 196, "640e": 196, "633e": 196, "605e": 196, "259e": 196, "183e": 196, "204e": 196, "021e": 196, "172e": 196, "223e": 196, "555e": 196, "058e": 196, "163e": 196, "365e": 196, "059e": 196, "291e": 196, "818e": 196, "122e": 196, "352e": 196, "162e": 196, "268e": 196, "813e": 196, "262e": 196, "152e": 196, "390e": 196, "719e": 196, "202e": 196, "340e": 196, "522e": 196, "547e": 196, "700e": 196, "904e": 196, "419e": 196, "428e": 196, "013e": 196, "687e": 196, "523e": 196, "683e": 196, "665e": 196, "632e": 196, "236e": 196, "873e": 196, "514e": 196, "023e": 196, "741e": 196, "361e": 196, "002e": 196, "649e": 196, "238e": 196, "406e": 196, "129e": 196, "778e": 196, "656e": 196, "394e": 196, "720e": 196, "902e": 196, "908e": 196, "739e": 196, "495e": 196, "708e": 196, "896e": 196, "932e": 196, "575e": 196, "446e": 196, "790e": 196, "209e": 196, "333e": 196, "165e": 196, "312e": 196, "862e": 196, "702e": 196, "094e": 196, "758e": 196, "478e": 196, "846e": 196, "533e": 196, "073e": 196, "124e": 196, "149e": 196, "776e": 196, "977e": 196, "159e": 196, "217e": 196, "102e": 196, "001e": 196, "723e": 196, "556e": 196, "173e": 196, "232e": 196, "535e": 196, "413e": 196, "339e": 196, "226e": 196, "151e": 196, "598e": 196, "910e": 196, "253e": 196, "940e": 196, "304e": 196, "768e": 196, "679e": 196, "676e": 196, "265e": 196, "043e": 196, "539e": 196, "512e": 196, "272e": 196, "578e": 196, "448e": 196, "497e": 196, "507e": 196, "355e": 196, "344e": 196, "328e": 196, "221e": 196, "883e": 196, "905e": 196, "096e": 196, "189e": 196, "865e": 196, "500e": 196, "317e": 196, "462e": 196, "751e": 196, "015e": 196, "284e": 196, "263e": 196, "797e": 196, "577e": 196, "916e": 196, "120e": 196, "435e": 196, "973e": 196, "764e": 196, "278e": 196, "878e": 196, "432e": 196, "042e": 196, "395e": 196, "468e": 196, "049e": 196, "178e": 196, "255e": 196, "364e": 196, "252e": 196, "674e": 196, "965e": 196, "029e": 196, "834e": 196, "714e": 196, "032e": 196, "837e": 196, "713e": 196, "367e": 196, "303e": 196, "863e": 196, "476e": 196, "466e": 196, "737e": 196, "684e": 196, "224e": 196, "130e": 196, "415e": 196, "_regression_performance_as_a_function_of_the_number_of_observed_neurons_interactive_demo": 196, "_summari": 196, "w3d5_t4": 197, "linearregress": 197, "compare_granger_connect": 197, "reject_nul": 197, "selecte_neuron": 197, "plot_performance_vs_eta": 197, "matri": 197, "print_corr": 197, "idx_dict": 197, "text_dict": 197, "tax": 197, "cigarett": 197, "statu": 197, "get_regression_corr": 197, "_instrumental_variables_video": 197, "wild": 197, "smoke": 197, "pregnant": 197, "wealth": 197, "tobacco": 197, "consumpt": 197, "z_": 197, "socioeconom": 197, "wealthier": 197, "birthweight": 197, "child": 197, "gram": 197, "3000": 197, "2t_": 197, "mother": 197, "babi": 197, "lighter": 197, "covar": 197, "483": 197, "740": 197, "unconfound": 197, "_stage_1_video": 197, "fit_first_stag": 197, "t_hat": 197, "stage1": 197, "t_c_corr": 197, "t_hat_c_corr": 197, "_compute_regression_stage_1_exercis": 197, "_stage_2_video": 197, "fit_second_stag": 197, "stage2": 197, "984": 197, "_compute_the_iv_estimate_exercis": 197, "ivs_in_simulated_neural_systems_video": 197, "wire": 197, "radio": 197, "simulate_neurons_iv": 197, "iv_on_this_timestep": 197, "_simulate_a_system_with_iv_exercis": 197, "get_iv_estimate_network": 197, "x_hati": 197, "corr_": 197, "_ivs_and_omitted_variable_bias_video": 197, "sel_z": 197, "iv_corr": 197, "big_v": 197, "reg_corr": 197, "compare_iv_estimate_to_regress": 197, "sel_reg_v": 197, "sel_iv_v": 197, "ncorrel": 197, "_estimating_connectivity_with_iv_vs_regression_interactive_demo": 197, "threat": 197, "discussion_questions_discuss": 197, "instrument_strength_effect": 197, "iv_v": 197, "_exploring_instrument_strength_bonus_exercis": 197, "h_a": 197, "retain": 197, "b_1": 197, "statsmodel": 197, "tsa": 197, "stattool": 197, "grangercausalitytest": 197, "get_granger_caus": 197, "bonferroni": 197, "p_val": 197, "max_lag": 197, "target_neuron": 197, "ts_data": 197, "pval": 197, "lrtest": 197, "_evaluate_granger_causality_bonus_exercis": 197, "advic": 198, "isabel": 198, "brush": 198}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"prerequisit": [0, 82, 91, 102, 158, 166], "preparatori": 0, "materi": 0, "nma": [0, 128], "comput": [0, 67, 72, 73, 78, 85, 86, 93, 96, 97, 98, 107, 122, 135, 136, 143, 144, 146, 152, 153, 154, 160, 194, 195, 197], "neurosci": [0, 72, 73, 89, 107, 130, 181], "prepar": [0, 30, 31, 32], "yourself": 0, "cours": [0, 18, 36], "program": 0, "math": [0, 60, 71, 72, 78, 160], "skill": 0, "overview": [1, 5, 19, 26, 28, 36, 60, 82, 91, 102, 109, 118, 126, 132, 141, 150, 158, 166, 168, 174, 176, 181, 183, 192, 198], "video": [1, 5, 19, 20, 21, 26, 28, 29, 30, 31, 32, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 82, 83, 84, 85, 86, 91, 92, 93, 94, 95, 96, 97, 98, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 118, 119, 120, 121, 122, 123, 127, 128, 132, 133, 134, 135, 136, 137, 141, 142, 143, 144, 145, 146, 150, 151, 152, 153, 154, 158, 159, 160, 161, 162, 166, 167, 168, 169, 170, 171, 172, 176, 177, 178, 179, 183, 184, 185, 186, 187, 188, 192, 193, 194, 195, 196, 197, 198], "ted": 1, "talk": 1, "kai": [1, 2, 15, 18, 19], "miller": [1, 2], "watch": 1, "until": 1, "15": [1, 170], "45": 1, "guid": [2, 4, 12, 18, 24, 25], "choos": [2, 4, 18, 25, 30, 105, 186], "an": [2, 18, 60, 68, 73, 84, 111, 143, 146, 162, 168, 169, 179, 186, 197], "eeg": [2, 14, 56], "ecog": [2, 6], "lfp": [2, 55], "dataset": [2, 4, 8, 15, 18, 19, 25, 26, 30, 31, 32, 84, 95, 116], "explor": [2, 84, 93, 94, 112, 143, 145, 152, 160, 161, 178, 179, 197], "ajile12": 2, "refer": [2, 18, 25, 72, 73], "face": 2, "hous": 2, "fingerflex": 2, "joystick": 2, "track": [2, 146, 171, 179], "memori": [2, 4, 154], "nback": 2, "direct": [2, 143], "see": [2, 36], "motor": [2, 4], "imageri": 2, "project": [2, 3, 4, 8, 11, 12, 15, 20, 22, 23, 25, 36, 111, 112, 128], "templat": [2, 4, 8, 12, 25], "doe": [2, 170, 178, 179], "neural": [2, 4, 66, 67, 68, 71, 73, 105, 120, 121, 122, 123, 152, 156, 194, 197], "activ": [2, 30, 54, 68, 73, 84, 104, 120, 121, 122, 144, 152, 153, 154, 195], "reflect": [2, 84, 85, 86, 195], "percept": 2, "behavior": [4, 5, 7, 13, 25, 52, 72], "And": 4, "theori": [4, 7, 17, 78], "caltech": [4, 5], "ibl": [4, 5], "laquitain": 4, "gardner": 4, "neuron": [4, 10, 16, 25, 50, 60, 62, 71, 84, 85, 86, 138, 139, 143, 144, 145, 146, 148, 152, 172, 194, 195, 196, 197], "2017": 4, "work": [4, 36, 107, 154, 197], "rnn": 4, "databas": 4, "model": [4, 12, 20, 21, 22, 23, 24, 32, 36, 60, 66, 72, 73, 77, 79, 84, 85, 86, 87, 88, 89, 94, 96, 97, 98, 99, 104, 105, 116, 122, 123, 124, 130, 136, 137, 138, 139, 143, 145, 146, 148, 152, 153, 154, 156, 162, 164, 168, 169, 172, 188, 194, 196], "addit": 4, "resourc": 4, "The": [4, 30, 60, 66, 72, 73, 85, 86, 105, 128, 136, 143, 161, 168, 170, 171, 179], "structur": [4, 96], "mous": [4, 5, 25], "social": [4, 5], "state": [4, 20, 25, 128, 135, 152, 160, 161, 170, 178, 179, 181], "depend": [4, 22, 31, 66, 71, 139, 146, 171, 178], "decis": [4, 23, 155, 160, 161, 162, 164, 187], "make": [4, 62, 160, 164], "mice": 4, "perform": [4, 112, 113, 123, 196], "2afc": 4, "task": [4, 12, 18, 19, 25, 120, 122, 178], "probe": 4, "dynam": [4, 33, 68, 130, 134, 139, 145, 147, 152, 163, 168, 170, 171, 178, 179, 194], "human": [4, 15, 51], "estim": [4, 78, 93, 94, 95, 96, 161, 162, 170, 194, 195, 196, 197], "error": [4, 73, 93, 97, 123, 185], "bayesian": [4, 78, 155, 160, 161], "framework": 4, "capac": 4, "recurr": [4, 152], "network": [4, 116, 120, 121, 122, 123, 144, 147, 148, 152, 154, 172, 189, 195], "attractor": 4, "link": [4, 12, 42, 72, 73, 181], "function": [4, 20, 22, 30, 31, 32, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "dure": [4, 25, 172], "learn": [4, 34, 105, 115, 116, 121, 172, 180, 185, 186, 187, 188, 190], "bay": [5, 78, 160, 161, 162], "heurist": 5, "fmri": [9, 15, 18, 19, 57], "2020": 11, "daili": [12, 36, 65, 76], "summari": [12, 20, 22, 23, 30, 31, 32, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 84, 85, 86, 90, 93, 94, 95, 96, 97, 98, 101, 104, 105, 108, 111, 112, 113, 114, 117, 120, 121, 122, 125, 128, 131, 134, 135, 136, 137, 140, 143, 144, 145, 146, 149, 152, 153, 157, 160, 161, 162, 165, 168, 169, 170, 175, 178, 179, 182, 185, 186, 187, 188, 191, 194, 195, 196, 197], "submiss": 12, "ta": 12, "mentor": 12, "week": 12, "1": [12, 20, 23, 30, 31, 32, 59, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 116, 119, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "get": [12, 84], "start": [12, 73], "w1d1": 12, "w1d2": 12, "w1d3": 12, "w1d5": 12, "look": [12, 32, 68], "ahead": 12, "first": 12, "dai": [12, 36, 64, 70, 72, 73, 75, 81, 90, 101, 108, 117, 125, 131, 140, 149, 157, 165, 175, 182, 191], "w2d1": [12, 36], "2": [12, 20, 23, 30, 31, 32, 60, 61, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 104, 105, 111, 112, 113, 114, 116, 119, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "read": [12, 20, 21, 25, 72, 73, 80, 89, 100, 107, 116, 128, 130, 139, 148, 156, 164, 170, 174, 181, 190], "write": [12, 21, 36], "data": [12, 20, 22, 84, 86, 97, 104, 105, 111, 112, 113, 120, 121, 122, 123, 128, 137, 156, 162, 171, 172], "analysi": [12, 30, 107, 112, 148, 152, 153, 154, 156], "half": [12, 36], "tutori": [12, 20, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 116, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "block": 12, "w2d2": 12, "w2d5": [12, 36], "abstract": [12, 21, 23, 36], "WITH": 12, "your": [12, 20, 28, 29, 30, 31, 32, 36, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "group": [12, 195], "pod": 12, "back": 12, "IN": 12, "bonu": [12, 30, 31, 66, 68, 71, 73, 78, 85, 86, 93, 94, 97, 98, 104, 105, 112, 113, 120, 121, 122, 123, 143, 144, 145, 146, 152, 154, 160, 162, 168, 171, 172, 178, 185, 187, 194, 195, 197], "w3": 12, "time": [12, 36, 60, 135, 139, 143, 144, 146, 153, 168, 170, 179], "w3d5": [12, 36], "final": [12, 22, 23, 36], "present": 12, "schedul": [12, 36, 37], "logist": [12, 105], "content": 12, "question": [12, 20, 22, 23, 128, 171, 197], "connectom": 15, "stringer": [16, 25, 26], "steinmetz": [16, 25, 26, 84], "hcp": [18, 19], "fsl": 18, "retinotopi": [18, 19], "natur": 18, "imag": [18, 32, 58], "bonner": [18, 19], "algonaut": [18, 19], "cichi": [18, 19], "gallant": 19, "2021": 19, "fslcours": 19, "step": [20, 21, 24, 44, 71, 73, 128, 171, 172], "4": [20, 30, 31, 32, 60, 62, 66, 67, 71, 72, 73, 77, 78, 84, 86, 87, 94, 96, 105, 111, 113, 114, 128, 134, 137, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 186, 188, 194, 195, 196, 197], "object": [20, 21, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "demo": [20, 62, 66, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 105, 111, 112, 113, 128, 134, 135, 136, 143, 145, 146, 152, 153, 154, 160, 161, 168, 169, 170, 171, 178, 179, 185, 186, 195, 196, 197], "introduct": [20, 30, 31, 32, 66, 71, 72, 95, 120, 121, 128, 160, 161, 162, 169, 171, 172, 185, 198], "setup": [20, 22, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "plot": [20, 22, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "gener": [20, 23, 36, 68, 77, 78, 89, 99, 104, 111, 123, 128, 139, 143, 162, 172], "find": [20, 78, 94, 111, 128, 135, 152, 154, 170], "phenomenon": [20, 22, 23, 128], "ask": [20, 128], "about": [20, 25, 66, 71, 72, 105, 128, 197], "exampl": [20, 22, 23, 66, 72, 78, 89, 128, 146, 154, 161, 197], "think": [20, 66, 67, 72, 73, 77, 78, 84, 85, 86, 87, 114, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 160, 185, 195, 197], "own": [20, 170], "understand": [20, 67, 68, 71, 73, 121, 122, 128, 137], "art": [20, 128, 181], "background": [20, 22, 23, 128], "3": [20, 23, 30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 94, 95, 96, 105, 111, 113, 120, 121, 122, 123, 128, 134, 135, 136, 143, 144, 145, 146, 152, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "literatur": [20, 128], "review": [20, 116, 128, 171], "knowledg": [20, 82, 91, 102, 128], "determin": [20, 122, 128, 136], "basic": [20, 60, 78, 128], "ingredi": [20, 22, 23, 128], "formul": [20, 128, 135], "specif": [20, 36, 128], "mathemat": [20, 112, 128, 153], "defin": [20, 60, 66, 68, 111, 128, 172, 194], "hypothes": [20, 22, 23, 128], "5": [20, 21, 31, 60, 62, 66, 67, 71, 72, 73, 77, 78, 84, 86, 97, 105, 128, 160, 161, 162, 168, 169, 170, 171, 172, 178, 194, 197], "hypothesi": [20, 128], "next": 20, "10": [21, 60, 62, 160, 170], "select": [21, 22, 23, 89, 97, 98, 105], "toolkit": [21, 22, 23], "6": [21, 32, 60, 62, 66, 71, 73, 78, 98, 128, 160, 161, 162, 168, 169, 170, 178, 197], "plan": [21, 188], "draft": [21, 22, 23], "7": [21, 60, 62, 66, 78, 160, 161, 162, 169, 170, 178], "implement": [21, 22, 23, 68, 98, 105, 112, 146, 152, 162, 170, 171, 172, 178, 179, 186, 187], "8": [21, 60, 62, 160, 161, 162, 170], "complet": [21, 22, 23], "9": [21, 60, 62, 160, 161, 170], "test": [21, 22, 23, 97, 123, 168], "evalu": [21, 22, 23, 96, 105, 122, 123, 178, 197], "publish": 21, "11": [21, 60, 62, 170], "paper": [21, 116, 190], "guidanc": 21, "suggest": [21, 80, 89, 100, 107, 116, 130, 139, 148, 156, 164, 174, 181, 190, 197], "train": [22, 23, 30, 31, 32, 84, 97, 105, 123, 144, 172], "illus": [22, 23], "instal": [22, 28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "helper": [22, 30, 31, 32, 62, 68, 72, 73, 97, 98, 105, 112, 113, 120, 121, 122, 123, 137, 144, 145, 146, 153, 154, 160, 161, 162, 168, 170, 172, 178, 179, 185, 188, 195, 196, 197], "thought": [22, 23], "vestibular": 23, "signal": [23, 54, 55, 56, 57, 58, 85], "integr": [23, 60, 71, 72, 73, 85, 134, 143, 153], "ddm": [23, 168], "mechan": 23, "threshold": [23, 168, 178], "assembl": 23, "allen": [25, 26], "institut": [25, 26], "you": [25, 178], "can": [25, 105], "more": [25, 73, 105, 160, 161], "scientif": 25, "discoveri": 25, "relat": 25, "thi": [25, 162], "our": [25, 36, 194, 197], "preprint": 25, "flow": 25, "inform": [25, 86, 98, 161], "through": [25, 66, 170, 179, 194], "brain": [25, 54, 55, 56, 57, 58, 73, 78, 107, 116], "sensorimotor": 25, "effect": [25, 72, 105, 111, 143, 144, 146, 154, 179], "stimulu": [25, 48, 162], "context": 25, "visual": [25, 30, 31, 71, 84, 113, 114, 120, 121, 122, 123, 146, 152], "represent": [25, 30, 48, 122], "cortex": 25, "autoencod": [27, 30, 31, 32], "intro": [28, 30, 47, 60, 66, 67, 73, 77, 82, 91, 102, 109, 112, 113, 114, 116, 118, 126, 132, 141, 150, 158, 162, 166, 174, 176, 183, 192], "import": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "feedback": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "gadget": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "slide": [28, 29, 82, 83, 91, 92, 102, 103, 109, 110, 118, 119, 132, 133, 141, 142, 150, 151, 158, 159, 166, 167, 176, 177, 182, 183, 184, 192, 193], "submit": [28, 29, 30, 31, 32, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 62, 64, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 81, 82, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137, 140, 141, 142, 143, 144, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 175, 176, 177, 178, 179, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 194, 195, 196, 197], "outro": [29, 65, 76, 83, 89, 92, 103, 107, 110, 116, 119, 127, 130, 133, 142, 151, 159, 162, 167, 174, 177, 184, 193], "intern": [30, 73], "figur": [30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "set": [30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 128, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "section": [30, 31, 32, 60, 62, 66, 67, 68, 71, 72, 73, 77, 78, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 161, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "0": [30, 31, 32, 66, 71, 72, 112, 113, 114, 120, 128, 145, 160, 161, 168, 169, 171, 172], "mnist": [30, 31, 32, 113, 114], "download": [30, 31, 32, 86], "sampl": [30, 60, 77, 105, 111, 112, 134, 171, 195], "latent": [30, 31, 32, 171], "space": [30, 31, 32, 66, 67, 179], "pca": [30, 107, 112, 113, 114], "code": [30, 31, 32, 60, 62, 66, 67, 68, 71, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "exercis": [30, 31, 32, 60, 62, 66, 67, 68, 71, 73, 77, 78, 84, 85, 86, 93, 94, 95, 96, 97, 98, 104, 105, 111, 112, 113, 114, 120, 121, 122, 123, 134, 135, 136, 137, 143, 144, 145, 146, 152, 153, 154, 160, 162, 168, 169, 170, 171, 172, 178, 179, 185, 186, 187, 188, 194, 195, 196, 197], "2d": [30, 31, 60, 71, 114, 121, 161], "qualit": [30, 122], "ann": [30, 32], "design": [30, 96, 104, 179], "32d": 30, "loss": [30, 120, 123, 161], "express": [30, 120], "power": 30, "wrap": [30, 31, 32, 33, 34, 35], "up": [30, 31, 32, 33, 34, 35, 84, 105, 122, 179], "failur": [30, 195], "mode": 30, "relu": 30, "unit": [30, 123], "weight": [30, 113, 121, 123, 146, 179], "initi": [30, 68, 72, 134, 152, 153, 172], "nmf": 30, "extens": [31, 143], "architectur": 31, "deeper": [31, 123], "build": [31, 122], "spheric": 31, "3d": 31, "deep": [31, 115, 116, 120, 121, 122], "surfac": 31, "s_2": 31, "thick": 31, "applic": [32, 71, 114, 146], "pre": [32, 146], "nois": [32, 94, 113, 143, 144, 179], "reconstruct": [32, 113], "befor": 32, "fine": 32, "tune": [32, 122, 123], "noisi": [32, 143, 152], "global": 32, "shift": 32, "occlus": 32, "after": [32, 36], "rotat": 32, "what": [32, 66, 71, 73, 84, 105, 121, 139, 144, 160], "would": 32, "digit": 32, "like": 32, "we": [32, 66, 71, 72, 105], "had": 32, "never": 32, "seen": 32, "remov": [32, 185], "most": 32, "domin": 32, "class": [32, 62, 185], "same": 32, "differ": [32, 86, 96, 105, 113, 114, 143, 145, 153, 161, 178, 185], "system": [33, 67, 68, 73, 107, 129, 130, 134, 152, 154, 171, 179, 194, 195, 196, 197], "podcast": [33, 34, 35, 72, 73], "panel": [33, 34, 35], "discuss": [33, 34, 35, 73, 87, 122, 160, 168, 169, 170, 171, 197], "machin": [34, 190], "stochast": [35, 77, 120, 136], "process": [35, 135, 136, 137, 143, 172, 179, 187], "For": [36, 60], "updat": [36, 186, 188], "annual": 36, "date": 36, "pleas": 36, "websit": 36, "coursework": 36, "slot": 36, "widget": [36, 39], "full": [36, 105], "convert": 36, "local": 36, "zone": 36, "chang": [36, 68, 71, 72, 73, 111, 146, 154, 169, 186, 188], "2025": 36, "all": [36, 73], "come": 36, "practic": [36, 124], "propos": 36, "share": 38, "calendar": 38, "timezon": 39, "us": [40, 41, 43, 44, 60, 62, 66, 68, 71, 73, 105, 113, 114, 116, 120, 170, 179, 185, 194, 196, 197], "discord": 40, "jupyterbook": 41, "quick": 42, "polici": [42, 178, 187], "googl": 43, "colab": 43, "advic": 43, "kaggl": 44, "technic": [45, 164], "help": 45, "neuro": [46, 197], "seri": 46, "neurotransmitt": 49, "conscious": 50, "psychophys": 51, "readout": 52, "live": 53, "lab": 53, "spike": [54, 60, 62, 72, 84, 85, 86, 104, 139, 143, 144, 146, 148, 172], "meg": 56, "calcium": 58, "python": [59, 60, 61, 71, 143], "workshop": [59, 61], "lif": [60, 62, 72, 73, 85, 143, 145, 146], "part": [60, 62, 73, 171], "i": [60, 143, 145, 152, 153, 154], "comment": 60, "nano": [60, 62], "recap": [60, 62], "string": 60, "paramet": [60, 72, 77, 78, 105, 136, 137, 143, 152, 154, 161, 172, 178], "oper": [60, 66, 71], "simul": [60, 136, 143, 145, 146, 152, 153, 168, 169, 170, 172, 194, 195, 197], "input": [60, 71, 72, 85, 143, 144, 145, 146, 152, 162, 179], "current": [60, 143], "print": 60, "format": [60, 105], "pretti": 60, "number": [60, 113, 123, 195, 196], "loop": [60, 179], "discret": [60, 68, 77, 135, 178], "membran": [60, 72, 145], "potenti": [60, 71, 72, 145], "random": [60, 62, 77, 136, 194], "synapt": [60, 139, 145, 146], "ad": [60, 62, 72, 73, 123], "list": [60, 72, 73], "ensembl": [60, 144], "statist": [60, 74, 78, 156, 160, 190], "store": 60, "mean": [60, 84, 93, 136, 144, 145], "standard": [60, 144, 161], "deviat": [60, 144], "numpi": 60, "rewrit": [60, 62], "12": [60, 62, 170], "enumer": 60, "index": [60, 62], "aggreg": 60, "13": [60, 62, 170], "arrai": [60, 162], "14": [60, 170], "ii": 62, "histogram": [62, 86], "dictionari": 62, "introduc": [62, 179], "boolean": 62, "binari": [62, 122, 148, 160, 162, 169], "raster": [62, 84], "refractori": 62, "period": 62, "investig": [62, 123, 144], "refactori": 62, "interact": [62, 66, 68, 71, 72, 73, 77, 78, 84, 85, 86, 93, 94, 105, 111, 112, 113, 134, 135, 136, 143, 145, 146, 152, 153, 154, 160, 161, 168, 169, 170, 171, 178, 179, 185, 186, 195, 196, 197], "last": 62, "concept": [62, 198], "linear": [63, 66, 67, 72, 85, 89, 93, 94, 96, 99, 104, 107, 123, 129, 130, 134, 152, 171, 179, 196], "algebra": [63, 66], "survei": [65, 76], "vector": [66, 111, 153], "why": [66, 71, 72, 85, 86, 105, 121], "do": [66, 71, 72, 85, 105, 144], "care": [66, 71, 72], "definit": [66, 171], "properti": [66, 112], "normal": [66, 162], "combin": [66, 136], "span": 66, "independ": 66, "determ": 66, "basi": [66, 111, 112], "out": [66, 153], "dot": 66, "product": [66, 71, 78], "lgn": 66, "fire": [66, 68, 72, 73, 85, 143, 146, 148], "geometri": 66, "polynomi": [66, 96], "proof": [66, 97], "equival": 66, "matric": 67, "solv": [67, 93, 179, 186], "equat": [67, 72, 73, 120, 134, 153, 179], "transform": [67, 146], "creat": [67, 77, 104, 123], "rank": 67, "null": 67, "eigenvalu": [67, 68, 134, 152, 154], "eigenvector": [67, 68, 112, 134], "eigenstuff": [67, 68], "identifi": 67, "from": [67, 77, 86, 111, 120, 121, 130, 153, 170, 171, 178, 186, 194], "matrix": [67, 96, 104, 112, 113, 122, 154, 162, 194], "multipl": [67, 71, 96], "corner": 67, "circuit": 68, "A": [68, 71, 73, 78, 122, 123, 134, 161, 190, 195, 197], "rate": [68, 72, 143, 145, 146, 148, 152, 185], "along": 68, "both": 68, "complex": [68, 121, 161, 195], "calculu": [69, 71], "differenti": [71, 72, 73, 134], "geometr": [71, 111], "interpret": [71, 72, 123, 134], "analyt": [71, 78], "numer": [71, 73, 152, 153], "rule": [71, 160, 162, 168], "deriv": [71, 73, 93], "postsynapt": [71, 146], "alpha": [71, 186], "chain": [71, 78], "sympi": 71, "sine": 71, "transfer": [71, 144, 185], "gain": [71, 179], "calcul": [71, 86, 112, 113, 152, 160, 162, 194], "variabl": [71, 196, 197], "partial": [71, 154, 179, 196], "demonstr": 71, "riemann": 71, "sum": 71, "vs": [71, 97, 120, 135, 145, 152, 168, 172, 179, 187, 195, 197], "size": [71, 105, 195], "charg": 71, "excitatori": [71, 145, 146, 152, 153], "filter": [71, 121, 164, 170, 171, 179], "popul": [72, 73, 152, 153], "exact": 72, "solut": [72, 73, 78, 122, 134], "condit": [72, 78, 134, 171], "leaki": [72, 73, 143], "without": 72, "v": 72, "v_": 72, "reset": 72, "impact": 72, "one": 72, "thing": 72, "matter": 72, "neuromatch": [72, 73], "bibliographi": [72, 73], "supplement": [72, 73], "popular": [72, 73], "method": [73, 89, 114], "euler": [73, 134], "slope": 73, "line": 73, "approxim": [73, 195], "singl": [73, 84, 152], "take": [73, 170], "simpl": 73, "wilson": [73, 153, 154], "cowan": [73, 153, 154], "phase": [73, 148, 153, 154], "plane": [73, 148, 153, 154], "nullclin": [73, 153, 154], "connect": [73, 122, 123, 146, 194, 195, 196, 197], "oscil": [73, 154], "small": [73, 195, 197], "everyth": 73, "4th": 73, "order": [73, 96, 137], "rung": 73, "kutta": 73, "ar": [73, 137, 178], "toward": 73, "rather": 73, "than": [73, 105], "end": 73, "Not": 73, "alik": 73, "stuart": 73, "landau": 73, "probabl": [77, 78, 86, 135, 160, 161, 162, 168], "distribut": [77, 78, 84, 86, 94, 111, 135, 146, 160, 161, 162, 171, 178], "world": [77, 169, 188], "uniform": 77, "walk": [77, 136], "vari": [77, 105, 134, 135, 144, 179, 185], "binomi": 77, "poisson": [77, 104, 172], "continu": [77, 135, 161, 178, 179], "gaussian": [77, 78, 94, 104, 143, 144, 161, 162, 169, 171, 179], "1a": [77, 136, 144, 146], "infer": [78, 161, 169, 174], "b": 78, "joint": [78, 171], "c": [78, 105], "d": 78, "margin": [78, 160, 161, 162, 171], "markov": [78, 135, 164, 169, 187], "likelihood": [78, 94, 160, 162], "maximum": [78, 94], "search": [78, 170], "best": 78, "optim": [78, 86, 89, 93, 104, 120, 173, 178, 179], "conjug": 78, "prior": [78, 161, 162], "posterior": [78, 160, 161, 162], "computation": 78, "net": 78, "causal": [78, 162, 189, 194, 195, 196, 197], "type": [79, 86, 143], "further": [80, 89, 100, 107, 116, 122, 130, 139, 148, 156, 164, 174, 179, 181, 190], "retriev": [84, 104, 105, 120, 121, 122, 123, 171], "warm": 84, "spike_tim": 84, "warmer": 84, "count": [84, 104], "total": 84, "compar": [84, 96, 97, 116, 170, 195], "median": 84, "subset": [84, 197], "inter": 84, "interv": [84, 95, 135], "isi": [84, 86, 143], "form": 84, "fit": [84, 88, 89, 96, 104, 105, 137, 162, 171, 196], "hand": 84, "how": [85, 139, 144, 170, 178, 179, 188, 197], "dv_m": 85, "IF": 85, "inhibitori": [85, 145, 152, 153], "inhibit": [85, 148, 154], "notat": [85, 86, 93, 94, 95, 96, 104, 105, 111, 112, 113], "entropi": 86, "mass": 86, "pmf": 86, "foundat": [86, 174], "tip": 89, "On": [89, 187], "regress": [89, 93, 94, 96, 104, 105, 196, 197], "llh": 89, "maxim": [89, 171, 172], "mse": [89, 93, 96], "minim": 89, "research": 89, "develop": 89, "squar": [93, 96, 197], "least": [93, 96, 197], "mle": 94, "probabilist": [94, 185], "confid": [95, 168], "bootstrap": 95, "resampl": 95, "replac": 95, "ordinari": 96, "qualiti": 96, "bia": [97, 196, 197], "varianc": [97, 113, 136], "trade": 97, "off": [97, 187], "tradeoff": [97, 168, 179], "decomposit": 97, "cross": [98, 105], "valid": [98, 105], "akaik": 98, "s": [98, 121, 122, 170], "criterion": 98, "aic": 98, "glm": [104, 196], "encod": [104, 116, 122, 123, 162], "load": [104, 105, 120, 121, 122, 123, 171], "retin": 104, "ganglion": 104, "cell": [104, 121, 162], "predict": [104, 169, 185], "challeng": 104, "nonlinear": [104, 107, 114, 120], "scipi": 104, "classifi": 105, "regular": [105, 123], "sigmoid": 105, "scikit": 105, "decod": [105, 120, 123], "accuraci": [105, 168, 170], "featur": 105, "lead": 105, "overfit": 105, "l_2": 105, "l_1": 105, "kei": 105, "between": [105, 135, 144, 152, 179], "sparsiti": [105, 195], "penalti": 105, "detail": 105, "dimension": [106, 107, 113, 114, 122, 134], "reduct": [106, 107, 113, 114, 122], "princip": [107, 112], "compon": [107, 112, 113], "other": 107, "interfac": 107, "shown": 107, "view": 111, "correl": [111, 112, 122, 144, 146, 160, 161, 195], "multivari": 111, "draw": 111, "new": [111, 123], "orthonorm": 111, "base": [111, 145, 148, 178, 188], "onto": [111, 112], "plai": [111, 170], "covari": [112, 160, 161], "coeffici": 112, "scree": 113, "explain": 113, "pc": 113, "examin": [113, 178, 185], "denois": 113, "add": [113, 123], "t": [114, 135], "sne": 114, "appli": 114, "run": [114, 162, 172, 178], "perplex": 114, "pytorch": [116, 120, 121, 122], "recommend": 116, "respons": [120, 143, 144, 162], "feed": 120, "forward": [120, 134, 169, 172], "split": 120, "gradient": 120, "descent": 120, "depth": 120, "width": 120, "sgd": 120, "gd": 120, "convolut": [121, 122, 123], "output": [121, 144, 179], "shape": 121, "layer": [121, 122, 123], "cnn": [121, 122], "norm": [122, 156], "orient": [122, 198], "discrimin": 122, "quantit": 122, "comparison": 122, "dissimilar": 122, "rdm": 122, "similar": [122, 195], "curv": [122, 123, 152, 153], "reduc": [122, 143], "fulli": [122, 123], "max": 122, "pool": 122, "classif": 122, "problem": [122, 123, 178], "z": 122, "score": 122, "explan": 122, "dive": 123, "devic": 123, "gpu": 123, "cpu": 123, "execut": 123, "set_devic": 123, "peer": 123, "insid": 123, "improv": 123, "critic": 123, "delv": 123, "frame": 128, "planner": 128, "lectur": 130, "One": 134, "oscillatori": 134, "determinist": [134, 136], "two": [134, 152, 194, 197], "dimens": 134, "multi": [134, 186], "trajectori": [134, 152, 153, 168], "3a": [134, 143], "3b": [134, 143], "stream": 134, "telegraph": 135, "switch": 135, "transit": [135, 152], "valu": [135, 143, 152, 153, 154, 178, 185, 186], "perspect": 135, "propag": 135, "equilibrium": 135, "stabl": [135, 152], "e": [136, 145, 152, 153, 154, 172], "coli": 136, "1b": [136, 144, 146], "influenc": [136, 179], "choic": 136, "ornstein": [136, 143], "uhlenbeck": [136, 143], "ou": [136, 137, 143], "drift": [136, 168], "diffus": [136, 168], "observ": [136, 179, 196, 197], "balanc": [136, 145, 148], "empir": 136, "autoregress": 137, "residu": 137, "higher": 137, "monkei": 137, "typewrit": 137, "biolog": 138, "text": 139, "book": 139, "hodgkin": 139, "huxlei": 139, "But": 139, "point": [139, 152, 154], "extend": [139, 154], "simplifi": 139, "synaps": [139, 145, 146], "short": [139, 145, 154], "term": [139, 145], "plastic": [139, 145, 146], "dc": 143, "amplitud": 143, "white": [143, 144], "gwn": [143, 144], "analyz": [143, 146, 153, 168, 178], "irregular": 143, "f": [143, 152, 153], "sig_gwn": 143, "cv_": 143, "synchroni": 144, "origin": [144, 179], "synchron": 144, "implic": 144, "measur": [144, 145, 169, 170, 179], "affect": [144, 160], "rational": 144, "behind": 144, "mu": 144, "sigma": 144, "transmiss": 145, "static": 145, "conduct": [145, 146], "free": 145, "depress": 145, "std": 145, "facilit": 145, "stf": 145, "stp": 145, "stdp": 146, "delta": 146, "w": 146, "keep": 146, "p": 146, "dp": 146, "show": 146, "evolut": [146, 179], "2a": 146, "strength": [146, 197], "2b": 146, "increas": 146, "presynapt": 146, "receiv": 146, "amplif": 148, "stabil": [148, 152, 154], "supralinear": 148, "scheme": [152, 153], "finit": 152, "fix": [152, 154, 168], "extern": 152, "relationship": 152, "unstabl": 152, "via": 152, "drive": 152, "descript": 153, "wc": 153, "field": 153, "r_i": 153, "r_e": [153, 154], "displaystyl": [153, 154], "big": 153, "frac": [153, 154], "dr_e": 153, "dt": 153, "dr_i": 153, "limit": 154, "cycl": 154, "jacobian": 154, "wee": 154, "posit": [154, 162], "isn": 154, "g_e": 154, "non": [154, 197], "puls": 154, "induc": 154, "persist": 154, "hidden": [160, 161, 163, 164, 168, 169], "gone": [160, 178], "fishin": 160, "decid": 160, "where": [160, 178], "fish": [160, 178], "util": [160, 161], "being": 160, "either": 160, "side": 160, "guess": 160, "locat": [160, 161], "belief": [160, 161, 178], "formula": 160, "astrocat": [161, 170], "multipli": 161, "mixtur": [161, 162], "complic": 161, "cat": 161, "cost": [161, 179], "theorem": 161, "variou": 161, "auditori": 162, "true": [162, 170, 172], "hypothet": 162, "x": 162, "hat": 162, "stimuli": 162, "expect": [162, 171, 172], "some": [162, 178], "generate_data": 162, "log": 162, "kalman": [164, 170, 171, 179], "aspect": 164, "sequenti": 168, "ratio": 168, "sprt": 168, "under": 168, "stop": 168, "speed": 168, "versu": 168, "revisit": 168, "hmm": [169, 172], "futur": 169, "forget": 169, "quantifi": 170, "movement": 170, "collar": 170, "action": [170, 179, 186], "long": 170, "ld": [171, 179], "adjust": 171, "ey": 171, "gaze": 171, "pykalman": 171, "handl": 171, "blink": 171, "smooth": 171, "em": [171, 172], "algorithm": [171, 172, 187], "m": [171, 172], "case": 172, "studi": 172, "frozen": 172, "sequenc": 172, "backward": 172, "learnt": 172, "progress": 172, "control": [173, 174, 178, 179, 194], "catch": 178, "reward": [178, 185, 186], "should": 178, "act": [178, 186, 187], "follow": 178, "sensit": 178, "open": 179, "close": 179, "fly": 179, "quadrat": 179, "regul": 179, "lqr": 179, "constraint": 179, "goal": 179, "move": 179, "desir": 179, "lqg": 179, "conjunct": 179, "effort": 179, "reinforc": [180, 188], "tempor": 185, "td": 185, "guarante": 185, "cs": 185, "discount": 185, "factor": 185, "magnitud": 185, "match": 185, "arm": 186, "bandit": 186, "epsilon": 186, "greedi": 186, "q": [187, 188], "mdp": 187, "sarsa": 187, "rl": 188, "dyna": 188, "much": 188, "when": 188, "econometr": 190, "epidemiolog": 190, "broad": 190, "rang": 190, "relev": 190, "intervent": 194, "trial": 194, "recov": [194, 196], "perturb": 194, "causat": 195, "try": 195, "larg": [195, 197], "metric": 195, "low": 195, "resolut": 195, "coars": 195, "averag": 195, "across": 195, "result": 195, "truth": 195, "simultan": 196, "approach": 196, "plu": 196, "lasso": 196, "omit": [196, 197], "instrument": 197, "iv": 197, "high": 197, "level": 197, "stage": 197, "granger": 197, "map": 198, "curriculum": 198}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx": 56}})