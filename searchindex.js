Search.setIndex({"docnames": ["prereqs/ComputationalNeuroscience", "projects/ECoG/ECoG_videos", "projects/ECoG/README", "projects/README", "projects/behavior_and_theory/README", "projects/behavior_and_theory/behavior_and_theory_videos", "projects/docs/ECoG", "projects/docs/behavior_and_theory", "projects/docs/datasets_overview", "projects/docs/fMRI", "projects/docs/neurons", "projects/docs/project_2020_highlights", "projects/docs/project_guidance", "projects/docs/project_templates", "projects/docs/projects_2020/behavior", "projects/docs/projects_2020/eeg", "projects/docs/projects_2020/fMRI", "projects/docs/projects_2020/neurons", "projects/docs/projects_2020/theory", "projects/fMRI/README", "projects/fMRI/fMRI_videos", "projects/modelingsteps/ModelingSteps_1through4", "projects/modelingsteps/ModelingSteps_5through10", "projects/modelingsteps/TrainIllusionDataProject", "projects/modelingsteps/TrainIllusionModel", "projects/modelingsteps/intro", "projects/neurons/README", "projects/neurons/neurons_videos", "tutorials/Bonus_Autoencoders/chapter_title", "tutorials/Bonus_Autoencoders/student/Bonus_Intro", "tutorials/Bonus_Autoencoders/student/Bonus_Outro", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial1", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial2", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial3", "tutorials/Module_WrapUps/DynamicalSystems", "tutorials/Module_WrapUps/MachineLearning", "tutorials/Module_WrapUps/StochasticProcesses", "tutorials/Schedule/daily_schedules", "tutorials/Schedule/schedule_intro", "tutorials/Schedule/shared_calendars", "tutorials/Schedule/timezone_widget", "tutorials/TechnicalHelp/Discord", "tutorials/TechnicalHelp/Jupyterbook", "tutorials/TechnicalHelp/Links_Policy", "tutorials/TechnicalHelp/Tutorial_colab", "tutorials/TechnicalHelp/Tutorial_kaggle", "tutorials/TechnicalHelp/tech_intro", "tutorials/W0D0_NeuroVideoSeries/chapter_title", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial1", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial10", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial11", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial12", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial2", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial3", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial4", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial5", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial6", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial7", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial8", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial9", "tutorials/W0D1_PythonWorkshop1/chapter_title", "tutorials/W0D1_PythonWorkshop1/student/W0D1_Tutorial1", "tutorials/W0D2_PythonWorkshop2/chapter_title", "tutorials/W0D2_PythonWorkshop2/student/W0D2_Tutorial1", "tutorials/W0D3_LinearAlgebra/chapter_title", "tutorials/W0D3_LinearAlgebra/student/W0D3_DaySummary", "tutorials/W0D3_LinearAlgebra/student/W0D3_Outro", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial1", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial2", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial3", "tutorials/W0D4_Calculus/chapter_title", "tutorials/W0D4_Calculus/student/W0D4_DaySummary", "tutorials/W0D4_Calculus/student/W0D4_Tutorial1", "tutorials/W0D4_Calculus/student/W0D4_Tutorial2", "tutorials/W0D4_Calculus/student/W0D4_Tutorial3", "tutorials/W0D5_Statistics/chapter_title", "tutorials/W0D5_Statistics/student/W0D5_DaySummary", "tutorials/W0D5_Statistics/student/W0D5_Outro", "tutorials/W0D5_Statistics/student/W0D5_Tutorial1", "tutorials/W0D5_Statistics/student/W0D5_Tutorial2", "tutorials/W1D1_ModelTypes/chapter_title", "tutorials/W1D1_ModelTypes/further_reading", "tutorials/W1D1_ModelTypes/student/W1D1_DaySummary", "tutorials/W1D1_ModelTypes/student/W1D1_Intro", "tutorials/W1D1_ModelTypes/student/W1D1_Outro", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial1", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial2", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial3", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial4", "tutorials/W1D2_ModelFitting/chapter_title", "tutorials/W1D2_ModelFitting/further_reading", "tutorials/W1D2_ModelFitting/student/W1D2_DaySummary", "tutorials/W1D2_ModelFitting/student/W1D2_Intro", "tutorials/W1D2_ModelFitting/student/W1D2_Outro", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial1", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial2", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial3", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial4", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial5", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial6", "tutorials/W1D3_GeneralizedLinearModels/chapter_title", "tutorials/W1D3_GeneralizedLinearModels/further_reading", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_DaySummary", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Intro", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Outro", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Tutorial1", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Tutorial2", "tutorials/W1D4_DimensionalityReduction/chapter_title", "tutorials/W1D4_DimensionalityReduction/further_reading", "tutorials/W1D4_DimensionalityReduction/student/W1D4_DaySummary", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Intro", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Outro", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial1", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial2", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial3", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial4", "tutorials/W1D5_DeepLearning/chapter_title", "tutorials/W1D5_DeepLearning/further_reading", "tutorials/W1D5_DeepLearning/student/W1D5_DaySummary", "tutorials/W1D5_DeepLearning/student/W1D5_Intro", "tutorials/W1D5_DeepLearning/student/W1D5_Outro", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial1", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial2", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial3", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial4", "tutorials/W2D1_ModelingPractice/chapter_title", "tutorials/W2D1_ModelingPractice/student/W2D1_DaySummary", "tutorials/W2D1_ModelingPractice/student/W2D1_Intro", "tutorials/W2D1_ModelingPractice/student/W2D1_Outro", "tutorials/W2D1_ModelingPractice/student/W2D1_Tutorial1", "tutorials/W2D2_LinearSystems/chapter_title", "tutorials/W2D2_LinearSystems/further_reading", "tutorials/W2D2_LinearSystems/student/W2D2_DaySummary", "tutorials/W2D2_LinearSystems/student/W2D2_Intro", "tutorials/W2D2_LinearSystems/student/W2D2_Outro", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial1", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial2", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial3", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial4", "tutorials/W2D3_BiologicalNeuronModels/chapter_title", "tutorials/W2D3_BiologicalNeuronModels/further_reading", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_DaySummary", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Intro", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Outro", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial1", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial2", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial3", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial4", "tutorials/W2D4_DynamicNetworks/chapter_title", "tutorials/W2D4_DynamicNetworks/further_reading", "tutorials/W2D4_DynamicNetworks/student/W2D4_DaySummary", "tutorials/W2D4_DynamicNetworks/student/W2D4_Intro", "tutorials/W2D4_DynamicNetworks/student/W2D4_Outro", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial1", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial2", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial3", "tutorials/W3D1_BayesianDecisions/chapter_title", "tutorials/W3D1_BayesianDecisions/further_reading", "tutorials/W3D1_BayesianDecisions/student/W3D1_DaySummary", "tutorials/W3D1_BayesianDecisions/student/W3D1_Intro", "tutorials/W3D1_BayesianDecisions/student/W3D1_Outro", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial1", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial2", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial3", "tutorials/W3D2_HiddenDynamics/chapter_title", "tutorials/W3D2_HiddenDynamics/further_reading", "tutorials/W3D2_HiddenDynamics/student/W3D2_DaySummary", "tutorials/W3D2_HiddenDynamics/student/W3D2_Intro", "tutorials/W3D2_HiddenDynamics/student/W3D2_Outro", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial1", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial2", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial3", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial4", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial5", "tutorials/W3D3_OptimalControl/chapter_title", "tutorials/W3D3_OptimalControl/further_reading", "tutorials/W3D3_OptimalControl/student/W3D3_DaySummary", "tutorials/W3D3_OptimalControl/student/W3D3_Intro", "tutorials/W3D3_OptimalControl/student/W3D3_Outro", "tutorials/W3D3_OptimalControl/student/W3D3_Tutorial1", "tutorials/W3D3_OptimalControl/student/W3D3_Tutorial2", "tutorials/W3D4_ReinforcementLearning/chapter_title", "tutorials/W3D4_ReinforcementLearning/further_reading", "tutorials/W3D4_ReinforcementLearning/student/W3D4_DaySummary", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Intro", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Outro", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial1", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial2", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial3", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial4", "tutorials/W3D5_NetworkCausality/chapter_title", "tutorials/W3D5_NetworkCausality/further_reading", "tutorials/W3D5_NetworkCausality/student/W3D5_DaySummary", "tutorials/W3D5_NetworkCausality/student/W3D5_Intro", "tutorials/W3D5_NetworkCausality/student/W3D5_Outro", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial1", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial2", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial3", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial4", "tutorials/intro"], "filenames": ["prereqs/ComputationalNeuroscience.md", "projects/ECoG/ECoG_videos.ipynb", "projects/ECoG/README.md", "projects/README.md", "projects/behavior_and_theory/README.md", "projects/behavior_and_theory/behavior_and_theory_videos.ipynb", "projects/docs/ECoG.md", "projects/docs/behavior_and_theory.md", "projects/docs/datasets_overview.md", "projects/docs/fMRI.md", "projects/docs/neurons.md", "projects/docs/project_2020_highlights.md", "projects/docs/project_guidance.md", "projects/docs/project_templates.md", "projects/docs/projects_2020/behavior.md", "projects/docs/projects_2020/eeg.md", "projects/docs/projects_2020/fMRI.md", "projects/docs/projects_2020/neurons.md", "projects/docs/projects_2020/theory.md", "projects/fMRI/README.md", "projects/fMRI/fMRI_videos.ipynb", "projects/modelingsteps/ModelingSteps_1through4.ipynb", "projects/modelingsteps/ModelingSteps_5through10.ipynb", "projects/modelingsteps/TrainIllusionDataProject.ipynb", "projects/modelingsteps/TrainIllusionModel.ipynb", "projects/modelingsteps/intro.md", "projects/neurons/README.md", "projects/neurons/neurons_videos.ipynb", "tutorials/Bonus_Autoencoders/chapter_title.md", "tutorials/Bonus_Autoencoders/student/Bonus_Intro.ipynb", "tutorials/Bonus_Autoencoders/student/Bonus_Outro.ipynb", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial1.ipynb", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial2.ipynb", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial3.ipynb", "tutorials/Module_WrapUps/DynamicalSystems.ipynb", "tutorials/Module_WrapUps/MachineLearning.ipynb", "tutorials/Module_WrapUps/StochasticProcesses.ipynb", "tutorials/Schedule/daily_schedules.md", "tutorials/Schedule/schedule_intro.md", "tutorials/Schedule/shared_calendars.md", "tutorials/Schedule/timezone_widget.md", "tutorials/TechnicalHelp/Discord.md", "tutorials/TechnicalHelp/Jupyterbook.md", "tutorials/TechnicalHelp/Links_Policy.md", "tutorials/TechnicalHelp/Tutorial_colab.md", "tutorials/TechnicalHelp/Tutorial_kaggle.md", "tutorials/TechnicalHelp/tech_intro.md", "tutorials/W0D0_NeuroVideoSeries/chapter_title.md", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial1.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial10.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial11.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial12.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial2.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial3.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial4.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial5.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial6.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial7.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial8.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial9.ipynb", "tutorials/W0D1_PythonWorkshop1/chapter_title.md", "tutorials/W0D1_PythonWorkshop1/student/W0D1_Tutorial1.ipynb", "tutorials/W0D2_PythonWorkshop2/chapter_title.md", "tutorials/W0D2_PythonWorkshop2/student/W0D2_Tutorial1.ipynb", "tutorials/W0D3_LinearAlgebra/chapter_title.md", "tutorials/W0D3_LinearAlgebra/student/W0D3_DaySummary.ipynb", "tutorials/W0D3_LinearAlgebra/student/W0D3_Outro.ipynb", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial1.ipynb", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial2.ipynb", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial3.ipynb", "tutorials/W0D4_Calculus/chapter_title.md", "tutorials/W0D4_Calculus/student/W0D4_DaySummary.ipynb", "tutorials/W0D4_Calculus/student/W0D4_Tutorial1.ipynb", "tutorials/W0D4_Calculus/student/W0D4_Tutorial2.ipynb", "tutorials/W0D4_Calculus/student/W0D4_Tutorial3.ipynb", "tutorials/W0D5_Statistics/chapter_title.md", "tutorials/W0D5_Statistics/student/W0D5_DaySummary.ipynb", "tutorials/W0D5_Statistics/student/W0D5_Outro.ipynb", "tutorials/W0D5_Statistics/student/W0D5_Tutorial1.ipynb", "tutorials/W0D5_Statistics/student/W0D5_Tutorial2.ipynb", "tutorials/W1D1_ModelTypes/chapter_title.md", "tutorials/W1D1_ModelTypes/further_reading.md", "tutorials/W1D1_ModelTypes/student/W1D1_DaySummary.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Intro.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Outro.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial1.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial2.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial3.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial4.ipynb", "tutorials/W1D2_ModelFitting/chapter_title.md", "tutorials/W1D2_ModelFitting/further_reading.md", "tutorials/W1D2_ModelFitting/student/W1D2_DaySummary.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Intro.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Outro.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial1.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial2.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial3.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial4.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial5.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial6.ipynb", "tutorials/W1D3_GeneralizedLinearModels/chapter_title.md", "tutorials/W1D3_GeneralizedLinearModels/further_reading.md", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_DaySummary.ipynb", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Intro.ipynb", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Outro.ipynb", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Tutorial1.ipynb", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Tutorial2.ipynb", "tutorials/W1D4_DimensionalityReduction/chapter_title.md", "tutorials/W1D4_DimensionalityReduction/further_reading.md", "tutorials/W1D4_DimensionalityReduction/student/W1D4_DaySummary.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Intro.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Outro.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial1.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial2.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial3.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial4.ipynb", "tutorials/W1D5_DeepLearning/chapter_title.md", "tutorials/W1D5_DeepLearning/further_reading.md", "tutorials/W1D5_DeepLearning/student/W1D5_DaySummary.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Intro.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Outro.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial1.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial2.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial3.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial4.ipynb", "tutorials/W2D1_ModelingPractice/chapter_title.md", "tutorials/W2D1_ModelingPractice/student/W2D1_DaySummary.ipynb", "tutorials/W2D1_ModelingPractice/student/W2D1_Intro.ipynb", "tutorials/W2D1_ModelingPractice/student/W2D1_Outro.ipynb", "tutorials/W2D1_ModelingPractice/student/W2D1_Tutorial1.ipynb", "tutorials/W2D2_LinearSystems/chapter_title.md", "tutorials/W2D2_LinearSystems/further_reading.md", "tutorials/W2D2_LinearSystems/student/W2D2_DaySummary.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Intro.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Outro.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial1.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial2.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial3.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial4.ipynb", "tutorials/W2D3_BiologicalNeuronModels/chapter_title.md", "tutorials/W2D3_BiologicalNeuronModels/further_reading.md", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_DaySummary.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Intro.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Outro.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial1.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial2.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial3.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial4.ipynb", "tutorials/W2D4_DynamicNetworks/chapter_title.md", "tutorials/W2D4_DynamicNetworks/further_reading.md", "tutorials/W2D4_DynamicNetworks/student/W2D4_DaySummary.ipynb", "tutorials/W2D4_DynamicNetworks/student/W2D4_Intro.ipynb", "tutorials/W2D4_DynamicNetworks/student/W2D4_Outro.ipynb", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial1.ipynb", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial2.ipynb", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial3.ipynb", "tutorials/W3D1_BayesianDecisions/chapter_title.md", "tutorials/W3D1_BayesianDecisions/further_reading.md", "tutorials/W3D1_BayesianDecisions/student/W3D1_DaySummary.ipynb", "tutorials/W3D1_BayesianDecisions/student/W3D1_Intro.ipynb", "tutorials/W3D1_BayesianDecisions/student/W3D1_Outro.ipynb", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial1.ipynb", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial2.ipynb", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial3.ipynb", "tutorials/W3D2_HiddenDynamics/chapter_title.md", "tutorials/W3D2_HiddenDynamics/further_reading.md", "tutorials/W3D2_HiddenDynamics/student/W3D2_DaySummary.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Intro.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Outro.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial1.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial2.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial3.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial4.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial5.ipynb", "tutorials/W3D3_OptimalControl/chapter_title.md", "tutorials/W3D3_OptimalControl/further_reading.md", "tutorials/W3D3_OptimalControl/student/W3D3_DaySummary.ipynb", "tutorials/W3D3_OptimalControl/student/W3D3_Intro.ipynb", "tutorials/W3D3_OptimalControl/student/W3D3_Outro.ipynb", "tutorials/W3D3_OptimalControl/student/W3D3_Tutorial1.ipynb", "tutorials/W3D3_OptimalControl/student/W3D3_Tutorial2.ipynb", "tutorials/W3D4_ReinforcementLearning/chapter_title.md", "tutorials/W3D4_ReinforcementLearning/further_reading.md", "tutorials/W3D4_ReinforcementLearning/student/W3D4_DaySummary.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Intro.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Outro.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial1.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial2.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial3.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial4.ipynb", "tutorials/W3D5_NetworkCausality/chapter_title.md", "tutorials/W3D5_NetworkCausality/further_reading.md", "tutorials/W3D5_NetworkCausality/student/W3D5_DaySummary.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Intro.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Outro.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial1.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial2.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial3.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial4.ipynb", "tutorials/intro.ipynb"], "titles": ["Prerequisites and preparatory materials for NMA Computational Neuroscience", "Overview videos", "Guide to choosing an EEG/ECoG/LFP dataset", "Projects", "Guide to choosing a Behavior dataset", "Overview videos", "ECoG", "Behavior and Theory", "Datasets", "fMRI", "Neurons", "Projects 2020", "Daily guide for projects", "Project Templates", "Behavior", "EEG", "fMRI", "Neurons", "Theory", "Guide to choosing an FMRI dataset", "Overview videos", "Modeling Steps 1 - 4", "Modeling Steps 5 - 10", "Example Data Project: the Train Illusion", "Example Model Project: the Train Illusion", "Modeling Step-by-Step Guide", "Guide to choosing a Neurons dataset", "Overview videos", "Autoencoders", "Intro", "Outro", "Tutorial 1: Intro to Autoencoders", "Tutorial 2: Autoencoder extensions", "Tutorial 3: Autoencoders applications", "Dynamical Systems Wrap-Up", "Machine Learning Wrap-Up", "Stochastic Processes Wrap-Up", "General schedule", "Schedule", "Shared calendars", "Timezone widget", "Using discord", "Using jupyterbook", "Quick links and policies", "Using Google Colab", "Using Kaggle", "Technical Help", "Neuro Video Series", "Intro", "Stimulus Representation", "Neurotransmitters", "Neurons to Consciousness", "Human Psychophysics", "Behavioral Readout", "Live in Lab", "Brain Signals: Spiking Activity", "Brain Signals: LFP", "Brain Signals: EEG &amp; MEG", "Brain Signals: fMRI", "Brain Signals: Calcium Imaging", "Python Workshop 1", "Tutorial: LIF Neuron Part I", "Python Workshop 2", "Tutorial 1: LIF Neuron Part II", "Linear Algebra", "Day Summary", "Outro", "Tutorial 1: Vectors", "Tutorial 2: Matrices", "Bonus Tutorial: Discrete Dynamical Systems", "Calculus", "Day Summary", "Tutorial 1: Differentiation and Integration", "Tutorial 2: Differential Equations", "Tutorial 3: Numerical Methods", "Statistics", "Day Summary", "Outro", "Tutorial 1: Probability Distributions", "Tutorial 2: Statistical Inference", "Model Types", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: \u201cWhat\u201d models", "Tutorial 2: \u201cHow\u201d models", "Tutorial 3: \u201cWhy\u201d models", "Tutorial 4: Model Discussions", "Model Fitting", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Linear regression with MSE", "Tutorial 2: Linear regression with MLE", "Tutorial 3: Confidence intervals and bootstrapping", "Tutorial 4: Multiple linear regression and polynomial regression", "Tutorial 5: Model Selection: Bias-variance trade-off", "Tutorial 6: Model Selection: Cross-validation", "Generalized Linear Models", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: GLMs for Encoding", "Tutorial 2: Classifiers and regularizers", "Dimensionality Reduction", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Geometric view of data", "Tutorial 2: Principal Component Analysis", "Tutorial 3: Dimensionality Reduction &amp; Reconstruction", "Tutorial 4:  Nonlinear Dimensionality Reduction", "Deep Learning", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Decoding Neural Responses", "Tutorial 2: Convolutional Neural Networks", "Tutorial 3: Building and Evaluating Normative Encoding Models", "Bonus Tutorial: Diving Deeper into Decoding &amp; Encoding", "Modeling Practice", "Day Summary", "Intro", "Outro", "Tutorial 1: Framing the Question", "Linear Systems", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Linear dynamical systems", "Tutorial 2: Markov Processes", "Tutorial 3: Combining determinism and stochasticity", "Tutorial 4: Autoregressive models", "Biological Neuron Models", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model", "Tutorial 2: Effects of Input Correlation", "Tutorial 3: Synaptic transmission - Models of static and dynamic synapses", "Bonus Tutorial: Spike-timing dependent plasticity (STDP)", "Dynamic Networks", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Neural Rate Models", "Tutorial 2: Wilson-Cowan Model", "Bonus Tutorial: Extending the Wilson-Cowan Model", "Bayesian Decisions", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Bayes with a binary hidden state", "Tutorial 2: Bayesian inference and decisions with continuous hidden state", "Bonus Tutorial: Fitting to data", "Hidden Dynamics", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Sequential Probability Ratio Test", "Tutorial 2: Hidden Markov Model", "Tutorial 3: The Kalman Filter", "Bonus Tutorial 4: The Kalman Filter, part 2", "Bonus Tutorial 5: Expectation Maximization for spiking neurons", "Optimal Control", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Optimal Control for Discrete States", "Tutorial 2: Optimal Control for Continuous State", "Reinforcement Learning", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Learning to Predict", "Tutorial 2: Learning to Act: Multi-Armed Bandits", "Tutorial 3: Learning to Act: Q-Learning", "Tutorial 4: Model-Based Reinforcement Learning", "Network Causality", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Interventions", "Tutorial 2: Correlations", "Tutorial 3: Simultaneous fitting/regression", "Tutorial 4: Instrumental Variables", "Introduction"], "terms": {"welcom": [0, 103, 199], "neuromatch": [0, 12, 21, 31, 32, 33, 34, 35, 36, 43, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 76, 78, 79, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 103, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198, 199], "academi": [0, 2, 19, 21, 31, 32, 33, 34, 35, 36, 43, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 117, 121, 122, 123, 124, 129, 131, 135, 136, 137, 138, 140, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 175, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "we": [0, 2, 4, 12, 21, 22, 23, 24, 31, 32, 37, 39, 45, 61, 63, 68, 69, 74, 78, 79, 83, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 103, 105, 110, 112, 113, 114, 115, 119, 121, 122, 123, 124, 127, 129, 133, 135, 136, 137, 138, 142, 144, 145, 146, 147, 151, 153, 154, 155, 159, 161, 162, 163, 167, 169, 170, 171, 172, 173, 177, 179, 180, 184, 186, 187, 188, 189, 191, 193, 195, 196, 197, 198, 199], "re": [0, 12, 21, 22, 24, 33, 45, 61, 63, 67, 68, 72, 73, 74, 79, 85, 92, 97, 99, 105, 106, 110, 112, 113, 115, 121, 122, 123, 124, 129, 136, 138, 146, 153, 154, 155, 162, 170, 171, 173, 179, 186, 195, 196, 198], "realli": [0, 12, 21, 22, 24, 67, 79, 92, 96, 103, 106, 117, 121, 123, 129, 138, 161, 162, 165, 199], "excit": [0, 12, 26, 67, 72, 74, 83, 86, 117, 131, 135, 140, 146, 149, 155, 189], "bring": [0, 4, 23, 161, 184, 186], "wide": [0, 2, 78, 96, 103, 119, 121, 159, 169, 173, 184], "vari": [0, 4, 24, 67, 79, 85, 86, 87, 92, 95, 97, 98, 112, 121, 131, 144, 146, 147, 153, 155, 161, 163, 169, 172, 187, 196], "audienc": [0, 12, 22], "an": [0, 4, 12, 21, 22, 23, 24, 31, 33, 42, 44, 45, 63, 67, 68, 72, 73, 78, 79, 83, 86, 87, 92, 94, 95, 96, 97, 98, 99, 103, 105, 106, 110, 113, 114, 115, 117, 119, 121, 122, 123, 124, 127, 129, 131, 135, 136, 137, 138, 142, 145, 146, 151, 153, 154, 155, 161, 162, 165, 167, 171, 172, 173, 177, 179, 182, 184, 186, 188, 189, 193, 195, 196, 197, 199], "amaz": 0, "set": [0, 2, 4, 12, 21, 22, 23, 24, 29, 45, 110, 167, 191], "lectur": [0, 37, 113, 114, 124, 136, 142, 144, 145, 151, 157, 173, 180], "tutori": [0, 37, 40, 45, 83, 92, 103, 108, 110, 119, 127, 142, 151, 157, 159, 165, 167, 177, 184, 193], "you": [0, 2, 4, 12, 21, 22, 23, 24, 29, 31, 32, 33, 37, 39, 42, 44, 45, 61, 63, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 83, 85, 86, 87, 88, 92, 94, 95, 96, 97, 98, 99, 103, 105, 106, 110, 112, 113, 114, 115, 119, 121, 122, 123, 124, 127, 129, 135, 136, 137, 138, 142, 144, 145, 146, 147, 151, 153, 154, 155, 159, 161, 162, 163, 167, 169, 170, 171, 172, 173, 177, 180, 184, 186, 187, 188, 189, 195, 196, 197, 198, 199], "peopl": [0, 12, 21, 23, 24, 90, 99, 129, 131, 186, 195, 197], "ar": [0, 2, 4, 11, 12, 19, 21, 22, 23, 24, 26, 29, 31, 32, 33, 37, 45, 61, 63, 67, 68, 69, 72, 73, 78, 79, 81, 83, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 103, 105, 106, 112, 113, 114, 115, 119, 121, 122, 123, 124, 129, 135, 136, 137, 140, 142, 144, 145, 146, 147, 151, 153, 154, 155, 157, 159, 161, 162, 163, 165, 169, 170, 171, 172, 173, 177, 180, 186, 187, 188, 189, 191, 193, 195, 196, 197, 198, 199], "come": [0, 12, 21, 22, 23, 26, 61, 68, 72, 74, 78, 79, 85, 97, 99, 106, 121, 129, 146, 157, 161, 162, 163, 169, 170, 173, 186, 187, 188, 189, 193], "thi": [0, 2, 4, 11, 12, 19, 21, 22, 23, 24, 29, 31, 32, 33, 34, 35, 36, 37, 40, 42, 44, 45, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 83, 85, 86, 87, 88, 92, 94, 95, 96, 97, 98, 99, 103, 105, 106, 110, 112, 113, 114, 115, 119, 121, 122, 123, 124, 129, 135, 136, 137, 138, 142, 144, 145, 146, 147, 151, 153, 154, 155, 157, 159, 161, 162, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 191, 193, 195, 196, 197, 198, 199], "from": [0, 2, 4, 11, 12, 19, 21, 22, 23, 24, 26, 29, 30, 31, 32, 33, 34, 35, 36, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 69, 71, 72, 73, 74, 76, 79, 81, 82, 83, 84, 85, 86, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 109, 110, 111, 113, 114, 115, 117, 118, 119, 120, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 155, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 173, 176, 177, 178, 180, 183, 184, 185, 186, 188, 189, 191, 192, 193, 194, 196, 197, 198, 199], "rang": [0, 12, 21, 22, 23, 24, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 94, 96, 97, 98, 99, 103, 105, 106, 112, 114, 115, 119, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "disciplin": [0, 31], "level": [0, 2, 12, 19, 21, 22, 24, 31, 32, 73, 79, 85, 106, 119, 121, 122, 123, 124, 144, 153, 169, 170, 171, 175, 180, 182, 187, 196, 197], "background": [0, 12, 19, 22], "want": [0, 4, 12, 21, 22, 23, 24, 44, 45, 61, 68, 73, 74, 78, 79, 83, 85, 95, 97, 98, 99, 103, 105, 106, 121, 122, 124, 129, 135, 136, 144, 145, 146, 153, 159, 161, 162, 163, 169, 172, 173, 180, 187, 189, 195, 196, 197, 198], "make": [0, 4, 12, 19, 21, 22, 23, 24, 31, 44, 45, 61, 67, 69, 72, 73, 74, 78, 79, 83, 85, 86, 87, 94, 95, 97, 98, 99, 101, 103, 105, 106, 112, 113, 114, 115, 119, 121, 122, 123, 124, 127, 129, 131, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 159, 162, 163, 169, 170, 171, 172, 173, 175, 179, 180, 184, 186, 187, 188, 189, 193, 195, 196, 197, 198, 199], "sure": [0, 12, 21, 22, 24, 45, 67, 69, 73, 74, 78, 79, 85, 87, 94, 95, 105, 112, 113, 114, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 169, 170, 172, 173, 179, 180, 186, 187, 196, 198], "everybodi": 0, "abl": [0, 12, 24, 67, 68, 72, 73, 78, 79, 85, 86, 92, 112, 114, 115, 121, 138, 151, 161, 162, 163, 169, 170, 172, 180, 187, 189, 193, 198], "follow": [0, 12, 21, 22, 23, 24, 29, 31, 32, 33, 37, 45, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 88, 95, 97, 98, 99, 103, 105, 106, 112, 113, 114, 115, 121, 122, 123, 127, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 180, 184, 186, 187, 188, 189, 195, 196, 197, 198], "enjoi": [0, 21, 33, 103, 129, 145], "school": [0, 12, 129, 161, 170, 179, 197], "dai": [0, 21, 23, 29, 31, 32, 33, 61, 63, 67, 68, 69, 72, 78, 79, 83, 85, 86, 87, 88, 92, 94, 95, 96, 97, 98, 99, 103, 105, 106, 110, 112, 113, 114, 115, 119, 121, 122, 123, 124, 127, 129, 131, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 159, 161, 162, 163, 167, 169, 170, 171, 172, 173, 177, 179, 180, 186, 187, 188, 189, 193, 195, 196, 197, 198, 199], "1": [0, 2, 4, 22, 23, 29, 30, 37, 39, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 65, 71, 76, 81, 82, 83, 84, 90, 91, 92, 93, 101, 102, 103, 104, 109, 110, 111, 118, 119, 126, 127, 128, 131, 132, 133, 134, 140, 141, 142, 143, 149, 150, 151, 152, 158, 159, 160, 166, 167, 168, 175, 176, 177, 178, 183, 184, 185, 191, 192, 193, 194], "mean": [0, 12, 21, 22, 23, 24, 31, 32, 33, 37, 63, 67, 69, 72, 73, 74, 78, 79, 86, 87, 95, 96, 97, 98, 99, 103, 105, 106, 110, 112, 113, 114, 119, 121, 122, 123, 124, 127, 129, 135, 136, 138, 142, 144, 147, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 187, 189, 195, 196, 197, 198], "need": [0, 12, 21, 22, 23, 24, 45, 61, 63, 67, 68, 72, 73, 78, 79, 85, 86, 87, 92, 96, 97, 98, 99, 103, 105, 106, 110, 112, 114, 115, 119, 121, 122, 123, 124, 127, 129, 135, 136, 137, 144, 145, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 193, 197, 198, 199], "know": [0, 12, 21, 22, 31, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 96, 99, 103, 105, 106, 122, 123, 129, 135, 137, 144, 146, 147, 161, 162, 163, 170, 172, 173, 177, 180, 184, 187, 188, 195, 196], "basic": [0, 12, 22, 23, 31, 44, 63, 67, 68, 69, 72, 78, 81, 83, 85, 86, 92, 97, 103, 106, 119, 122, 137, 144, 161, 162, 188, 191, 193, 199], "python": [0, 12, 21, 23, 63, 67, 68, 73, 74, 78, 79, 85, 103, 105, 121, 123, 124, 129, 135, 137, 153, 157, 196, 197, 199], "some": [0, 12, 21, 22, 23, 24, 31, 33, 67, 68, 69, 72, 73, 78, 79, 83, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 103, 105, 106, 114, 115, 117, 119, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 154, 155, 161, 162, 169, 171, 172, 180, 184, 186, 187, 188, 189, 195, 196, 197, 198], "core": [0, 21, 67, 110, 129, 161, 167, 171, 177, 179, 184], "concept": [0, 4, 12, 21, 22, 33, 61, 69, 72, 74, 78, 87, 92, 98, 103, 106, 112, 113, 138, 142, 145, 146, 147, 153, 154, 159, 161, 162, 167, 179, 180, 184, 186, 188, 193], "exposur": [0, 79], "below": [0, 12, 13, 22, 23, 31, 32, 33, 34, 35, 36, 39, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 95, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 136, 137, 138, 144, 145, 146, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 179, 180, 186, 187, 189, 195, 196, 197, 198], "provid": [0, 2, 4, 12, 21, 22, 26, 31, 33, 61, 63, 67, 68, 79, 83, 86, 87, 90, 92, 95, 103, 105, 112, 113, 121, 122, 123, 124, 127, 137, 142, 145, 146, 151, 153, 155, 159, 162, 163, 167, 169, 170, 171, 172, 173, 177, 179, 180, 184, 186, 195, 196, 197, 198], "more": [0, 2, 4, 12, 21, 22, 23, 24, 31, 32, 33, 37, 61, 63, 67, 68, 69, 72, 73, 78, 79, 83, 85, 86, 87, 92, 94, 96, 97, 98, 99, 103, 105, 110, 113, 114, 115, 119, 121, 122, 123, 124, 129, 135, 138, 142, 144, 146, 153, 154, 159, 163, 165, 169, 170, 171, 172, 173, 179, 180, 184, 186, 187, 188, 189, 195, 196, 197, 198, 199], "detail": [0, 12, 21, 22, 23, 31, 61, 63, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 103, 121, 122, 123, 127, 129, 140, 144, 161, 171, 180, 189], "run": [0, 2, 4, 12, 19, 21, 22, 23, 24, 26, 31, 33, 42, 44, 45, 61, 63, 68, 69, 72, 74, 78, 85, 86, 87, 96, 103, 105, 106, 112, 113, 114, 121, 122, 123, 124, 129, 135, 136, 137, 144, 145, 146, 147, 153, 167, 169, 172, 177, 180, 186, 187, 188, 189, 193, 195, 196, 197, 198], "us": [0, 2, 4, 11, 12, 19, 21, 22, 23, 24, 26, 29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 65, 68, 71, 73, 76, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 172, 173, 176, 177, 178, 179, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 196, 199], "If": [0, 4, 12, 21, 22, 23, 24, 33, 39, 44, 45, 61, 67, 68, 69, 72, 73, 78, 79, 85, 86, 87, 94, 97, 99, 106, 112, 113, 115, 121, 122, 123, 124, 129, 135, 136, 138, 144, 145, 146, 147, 153, 154, 161, 162, 169, 170, 172, 179, 187, 188, 189, 191, 195, 196, 197, 198], "ve": [0, 12, 22, 33, 63, 67, 69, 79, 85, 87, 106, 110, 113, 114, 115, 123, 124, 136, 137, 138, 144, 146, 147, 153, 155, 161, 163, 167, 169, 172, 179, 187, 189, 196, 197, 198], "never": [0, 12, 19, 22, 105, 106, 121, 138, 147, 154, 172, 186, 187, 196], "now": [0, 12, 21, 22, 23, 24, 32, 33, 63, 67, 69, 72, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 103, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 177, 179, 180, 187, 188, 189, 195, 196, 197, 198, 199], "good": [0, 12, 21, 22, 23, 24, 31, 61, 68, 73, 79, 87, 94, 95, 96, 98, 99, 103, 105, 106, 113, 121, 123, 124, 127, 129, 137, 138, 140, 151, 157, 162, 169, 172, 173, 177, 179, 180, 182, 186, 187, 193, 195, 196, 198], "time": [0, 2, 4, 19, 21, 22, 23, 24, 31, 32, 39, 40, 45, 63, 67, 68, 69, 72, 73, 74, 78, 79, 83, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 105, 106, 110, 112, 113, 114, 115, 121, 122, 123, 124, 129, 131, 135, 137, 138, 142, 146, 153, 155, 161, 162, 163, 165, 167, 170, 172, 173, 179, 186, 187, 188, 189, 193, 195, 196, 197, 198, 199], "start": [0, 21, 22, 23, 31, 32, 33, 37, 45, 61, 63, 67, 68, 69, 72, 73, 78, 79, 83, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 119, 121, 122, 123, 129, 135, 136, 137, 138, 142, 144, 145, 146, 151, 153, 154, 155, 157, 161, 162, 167, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198, 199], "practic": [0, 12, 23, 31, 61, 63, 72, 78, 79, 90, 94, 95, 96, 97, 105, 106, 121, 123, 124, 129, 161, 173, 180, 187, 189, 191, 197, 198, 199], "expect": [0, 12, 21, 22, 23, 24, 33, 63, 72, 74, 78, 79, 85, 87, 105, 106, 121, 122, 123, 124, 129, 137, 138, 144, 145, 147, 153, 154, 155, 161, 162, 165, 177, 179, 186, 187, 188, 189, 195, 196, 197], "student": [0, 2, 4, 11, 12, 31, 32, 37, 43, 61, 63, 67, 69, 72, 74, 78, 79, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 106, 112, 113, 114, 115, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 163, 169, 171, 172, 179, 186, 187, 188, 189, 195, 196, 198], "familiar": [0, 2, 12, 26, 72, 79, 137, 154, 197], "variabl": [0, 2, 4, 12, 21, 22, 23, 26, 31, 32, 33, 61, 63, 74, 78, 79, 85, 86, 87, 92, 94, 95, 96, 97, 98, 105, 106, 112, 113, 114, 119, 121, 122, 123, 124, 129, 135, 136, 137, 138, 145, 146, 147, 149, 154, 155, 161, 162, 163, 167, 169, 170, 171, 172, 173, 177, 179, 180, 186, 187, 191, 193, 195, 196], "list": [0, 4, 12, 21, 23, 24, 31, 32, 33, 63, 67, 68, 69, 72, 79, 85, 97, 98, 99, 106, 115, 117, 121, 123, 124, 129, 135, 136, 163, 169, 170, 173, 186, 195, 196, 198], "dict": [0, 24, 85, 97, 98, 99, 105, 106, 121, 122, 123, 124, 170, 172, 187, 188, 189, 197, 198], "numpi": [0, 21, 23, 24, 31, 32, 33, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "scipi": [0, 21, 23, 24, 33, 72, 78, 79, 86, 87, 95, 123, 124, 129, 135, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 188, 189], "librari": [0, 12, 21, 72, 85, 103, 106, 117, 121, 129, 147, 172, 198], "well": [0, 2, 4, 12, 21, 22, 23, 24, 26, 31, 32, 33, 63, 73, 74, 78, 79, 85, 86, 87, 96, 97, 98, 99, 106, 112, 113, 117, 121, 122, 123, 124, 129, 135, 137, 138, 146, 159, 161, 162, 163, 171, 172, 179, 180, 186, 187, 188, 189, 197, 198], "plot": [0, 12, 24, 31, 32, 33], "matplotlib": [0, 21, 23, 24, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "littl": [0, 12, 23, 24, 26, 31, 33, 67, 69, 72, 78, 79, 85, 124, 137, 138, 161, 169, 171, 180, 186, 196], "bit": [0, 21, 23, 31, 72, 73, 74, 78, 79, 85, 86, 87, 105, 124, 135, 161, 162, 187, 189, 196], "everi": [0, 4, 12, 22, 45, 67, 68, 72, 78, 79, 83, 85, 87, 88, 105, 106, 121, 122, 136, 137, 138, 144, 146, 157, 163, 173, 179, 186, 187, 188, 195, 196, 197], "ll": [0, 12, 21, 22, 23, 31, 32, 61, 63, 67, 68, 69, 72, 73, 78, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 110, 112, 113, 114, 115, 121, 122, 123, 124, 133, 146, 153, 155, 161, 162, 163, 167, 169, 170, 173, 177, 179, 186, 195, 196, 197, 198, 199], "great": [0, 12, 19, 22, 26, 31, 73, 74, 79, 83, 86, 95, 103, 105, 157, 187], "shape": [0, 21, 23, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 83, 85, 86, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 123, 124, 129, 136, 142, 145, 146, 147, 151, 153, 154, 155, 162, 163, 169, 170, 172, 173, 179, 180, 186, 188, 189, 195, 196, 197, 198], "class": [0, 23, 31, 32, 67, 68, 85, 86, 94, 105, 106, 121, 122, 123, 124, 172, 179, 180, 188, 189], "have": [0, 2, 4, 12, 21, 22, 23, 24, 26, 29, 31, 32, 33, 37, 39, 42, 44, 45, 61, 67, 68, 69, 72, 73, 74, 78, 79, 83, 85, 86, 87, 94, 95, 96, 97, 98, 99, 103, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 127, 129, 135, 136, 137, 138, 142, 144, 145, 146, 147, 151, 153, 154, 155, 159, 161, 162, 163, 165, 169, 170, 172, 173, 177, 179, 180, 184, 186, 187, 188, 189, 195, 196, 197, 198, 199], "workshop": [0, 12, 37, 61, 63], "w0d1": [0, 73], "w0d2": [0, 73], "here": [0, 4, 12, 21, 22, 23, 24, 31, 33, 34, 35, 36, 37, 41, 43, 45, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 83, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 167, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "should": [0, 2, 4, 12, 21, 22, 23, 24, 26, 39, 45, 61, 63, 68, 69, 72, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 99, 105, 106, 112, 113, 114, 121, 123, 124, 127, 129, 135, 136, 137, 138, 142, 144, 145, 146, 147, 151, 159, 161, 162, 167, 169, 170, 172, 177, 180, 186, 187, 188, 189, 193, 195, 196, 197, 198, 199], "go": [0, 4, 12, 19, 21, 22, 23, 24, 32, 45, 68, 72, 74, 78, 79, 85, 94, 97, 98, 103, 105, 106, 121, 122, 124, 127, 137, 138, 144, 145, 153, 161, 162, 172, 173, 179, 182, 187, 188, 189, 195, 196, 199], "through": [0, 12, 21, 22, 23, 24, 31, 68, 69, 72, 79, 83, 85, 97, 98, 99, 103, 106, 110, 121, 122, 123, 124, 127, 129, 131, 135, 136, 137, 138, 140, 153, 159, 161, 162, 163, 167, 169, 170, 173, 182, 186, 187, 188, 196, 198, 199], "made": [0, 12, 22, 85, 95, 121, 122, 124, 162, 163, 169, 172, 188, 198, 199], "content": [0, 2, 21, 22, 26, 31, 32, 33, 34, 35, 36, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 83, 85, 86, 87, 88, 92, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 117, 121, 122, 123, 124, 129, 135, 136, 137, 138, 142, 144, 145, 146, 147, 151, 153, 154, 155, 159, 161, 162, 163, 167, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "your": [0, 4, 22, 23, 24, 39, 40, 44, 45, 66, 77, 199], "own": [0, 12, 22, 23, 24, 78, 83, 106, 122, 127, 129, 145, 146, 147, 162, 173, 189, 197, 199], "pace": 0, "befor": [0, 12, 21, 22, 23, 31, 37, 61, 63, 66, 68, 69, 72, 74, 77, 78, 79, 83, 85, 86, 87, 94, 95, 98, 99, 105, 106, 113, 115, 121, 124, 129, 137, 138, 144, 146, 147, 153, 154, 161, 169, 171, 172, 173, 177, 179, 180, 186, 187, 188, 189, 197], "besid": [0, 31, 171], "recommend": [0, 12, 45, 115, 124, 161, 191], "softwar": [0, 4, 68, 105], "carpentri": 0, "free": [0, 4, 12, 21, 24, 33, 78, 115, 121, 123, 157, 161, 171, 179, 186, 188, 189], "edx": 0, "research": [0, 2, 4, 12, 21, 22, 23, 24, 31, 33, 44, 83, 92, 119, 121, 129, 175, 189, 191, 196], "For": [0, 2, 12, 21, 22, 24, 26, 31, 32, 33, 63, 67, 68, 69, 72, 74, 78, 79, 86, 87, 88, 94, 96, 97, 99, 105, 106, 110, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 142, 144, 145, 146, 147, 153, 155, 161, 162, 163, 167, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 193, 198], "depth": [0, 31, 32, 90, 113, 123, 157, 162], "intro": [0, 12, 21, 22, 24, 37, 44, 122, 170, 173, 191, 199], "see": [0, 3, 12, 13, 21, 22, 23, 24, 31, 33, 39, 42, 43, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 83, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 105, 106, 110, 112, 113, 114, 115, 121, 122, 123, 124, 127, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 155, 161, 162, 163, 167, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 193, 195, 196, 197, 198], "note": [0, 12, 21, 22, 23, 24, 37, 44, 45, 61, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 101, 105, 106, 112, 113, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 157, 161, 162, 163, 169, 170, 171, 172, 173, 175, 179, 180, 186, 191, 195, 196, 197, 198], "final": [0, 22, 31, 32, 33, 45, 67, 79, 83, 94, 96, 97, 99, 103, 105, 106, 110, 112, 113, 119, 123, 142, 145, 146, 147, 151, 154, 161, 162, 169, 172, 173, 179, 180, 184, 186, 189, 198, 199], "can": [0, 2, 4, 12, 19, 21, 22, 23, 24, 29, 31, 32, 33, 37, 42, 44, 45, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 83, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 103, 105, 110, 112, 113, 114, 115, 117, 119, 121, 122, 123, 124, 127, 129, 131, 135, 136, 137, 138, 142, 144, 145, 146, 147, 151, 153, 154, 155, 161, 162, 163, 165, 169, 170, 171, 172, 173, 179, 180, 184, 186, 187, 188, 189, 191, 193, 195, 196, 197, 198, 199], "data": [0, 2, 4, 19, 22, 24, 26, 31, 32, 33, 61, 63, 67, 68, 72, 78, 79, 81, 83, 86, 90, 92, 94, 95, 96, 97, 99, 103, 110, 115, 119, 131, 137, 145, 151, 161, 167, 169, 170, 171, 191, 193, 195, 196, 197, 198, 199], "scienc": [0, 2, 12, 19, 21, 22, 23, 26, 73, 74, 81, 90, 94, 96, 117, 129, 131, 140, 149, 171, 172, 175, 182, 184, 186, 191, 193, 195, 199], "handbook": [0, 81, 186], "which": [0, 2, 4, 12, 19, 21, 22, 23, 24, 26, 29, 31, 32, 33, 37, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 83, 85, 86, 87, 88, 92, 94, 95, 96, 97, 99, 103, 105, 106, 112, 113, 114, 115, 117, 119, 121, 122, 123, 124, 127, 129, 135, 136, 137, 142, 144, 145, 146, 147, 153, 154, 155, 157, 159, 161, 162, 163, 167, 169, 170, 171, 172, 173, 177, 179, 180, 184, 186, 187, 188, 189, 195, 196, 197, 198, 199], "also": [0, 2, 11, 12, 21, 22, 23, 24, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 83, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 103, 105, 106, 110, 112, 113, 114, 115, 121, 122, 123, 124, 127, 129, 136, 137, 138, 142, 144, 145, 146, 147, 151, 153, 154, 155, 157, 161, 162, 163, 167, 169, 170, 171, 172, 173, 177, 179, 180, 186, 187, 188, 189, 193, 196, 197, 198], "ha": [0, 2, 4, 12, 19, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 44, 45, 67, 69, 72, 73, 74, 78, 79, 83, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 170, 171, 172, 173, 179, 180, 184, 186, 187, 188, 189, 195, 196, 197, 198], "print": [0, 21, 23, 24, 31, 32, 33, 63, 68, 72, 78, 79, 85, 87, 94, 95, 96, 97, 105, 106, 113, 121, 122, 123, 124, 129, 136, 138, 144, 145, 146, 147, 153, 154, 155, 163, 169, 170, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "edit": [0, 12, 37, 44, 73, 74, 163], "matlab": [0, 90, 105], "quickli": [0, 12, 31, 85, 86, 94, 113, 146, 153, 170, 180, 186, 187, 189], "get": [0, 11, 21, 22, 23, 24, 31, 45, 61, 67, 68, 69, 72, 73, 74, 78, 79, 86, 87, 94, 95, 96, 97, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 137, 138, 144, 145, 146, 147, 153, 154, 155, 157, 161, 162, 163, 169, 170, 171, 172, 173, 177, 179, 180, 186, 187, 188, 189, 191, 195, 196, 197, 198], "up": [0, 4, 12, 21, 22, 23, 24, 61, 67, 68, 69, 72, 73, 74, 78, 79, 87, 95, 96, 97, 99, 105, 110, 112, 114, 121, 122, 124, 129, 138, 144, 146, 153, 161, 162, 163, 167, 169, 170, 171, 172, 179, 186, 187, 188, 189, 195, 196, 197, 198, 199], "speed": [0, 23, 61, 86, 105, 117, 124, 171, 175, 186, 187, 189], "cheatsheet": 0, "mai": [0, 12, 22, 23, 24, 31, 32, 33, 45, 61, 63, 67, 68, 72, 73, 74, 78, 79, 85, 86, 87, 96, 97, 99, 106, 114, 115, 117, 121, 122, 123, 124, 129, 135, 136, 137, 142, 144, 145, 146, 147, 151, 161, 162, 163, 169, 170, 172, 179, 180, 186, 187, 188, 189, 193, 196, 197, 198], "paperback": 0, "neural": [0, 2, 4, 12, 19, 23, 29, 31, 73, 78, 79, 81, 85, 86, 87, 90, 92, 101, 103, 105, 108, 110, 114, 117, 119, 129, 131, 140, 142, 145, 146, 149, 159, 165, 167, 169, 170, 171, 173, 175, 182, 191, 196, 199], "both": [0, 12, 21, 23, 24, 31, 32, 33, 37, 67, 72, 73, 78, 79, 86, 97, 98, 99, 106, 112, 113, 114, 122, 124, 135, 136, 137, 142, 144, 145, 146, 154, 155, 161, 162, 167, 170, 172, 179, 180, 186, 187, 188, 195, 197, 198, 199], "version": [0, 12, 13, 29, 31, 32, 33, 44, 61, 67, 74, 79, 105, 110, 112, 123, 137, 163, 167, 171, 173, 193], "analysi": [0, 2, 19, 21, 22, 23, 72, 79, 81, 83, 92, 96, 101, 103, 105, 110, 117, 119, 121, 123, 129, 131, 136, 151, 163, 167, 171, 191, 196, 198], "reli": [0, 12, 22, 23, 24, 92, 94, 96, 161, 162, 172, 197], "linear": [0, 12, 21, 23, 24, 31, 32, 33, 37, 69, 72, 74, 78, 79, 83, 85, 87, 92, 96, 98, 99, 101, 103, 106, 110, 115, 119, 121, 122, 123, 133, 136, 137, 138, 142, 144, 145, 151, 154, 155, 167, 170, 171, 179, 191, 198, 199], "algebra": [0, 61, 68, 69, 79, 94, 97, 110, 131, 135, 172, 199], "probabl": [0, 12, 21, 22, 23, 24, 31, 39, 83, 85, 86, 92, 95, 99, 103, 105, 106, 123, 124, 127, 137, 145, 146, 147, 159, 167, 170, 171, 172, 173, 179, 184, 186, 187, 188, 189, 193, 197, 199], "statist": [0, 4, 22, 63, 78, 90, 92, 96, 98, 101, 105, 122, 136, 142, 144, 145, 147, 151, 153, 159, 162, 165, 167, 170, 171, 173, 179, 180, 193, 195, 199], "calculu": [0, 73, 74, 94, 135, 144, 154, 199], "deriv": [0, 22, 31, 61, 73, 79, 83, 87, 90, 95, 96, 99, 106, 119, 121, 135, 136, 153, 154, 155, 162, 169, 172, 184, 186, 187], "od": [0, 61, 135, 146], "highli": [0, 22, 98, 121, 147, 153, 191], "our": [0, 12, 21, 22, 23, 24, 31, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 83, 85, 86, 87, 94, 95, 96, 97, 98, 99, 103, 105, 106, 112, 114, 115, 121, 122, 123, 124, 127, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 159, 161, 162, 163, 167, 169, 170, 171, 172, 173, 177, 179, 180, 184, 186, 187, 188, 189, 196, 197], "refresh": [0, 69, 105, 112, 113, 114, 162, 163, 179, 180, 199], "w0d3": [0, 79, 92, 103], "w0d4": [0, 83], "w0d5": [0, 83, 92, 103, 159, 162], "ask": [0, 12, 23, 24, 26, 33, 37, 73, 78, 83, 85, 99, 106, 138, 146, 162, 193, 195, 196, 197, 199], "question": [0, 22, 26, 31, 33, 67, 68, 69, 73, 74, 78, 79, 83, 85, 86, 87, 88, 92, 96, 103, 114, 119, 121, 123, 124, 127, 142, 144, 145, 146, 151, 153, 161, 162, 170, 171, 179, 193, 195, 196, 199], "discord": [0, 12, 37], "grasp": 0, "along": [0, 12, 21, 67, 68, 72, 85, 94, 96, 112, 113, 121, 122, 154, 155, 162, 163, 187], "crucial": [0, 12, 21, 22, 33, 92, 124, 129, 153, 177], "almost": [0, 21, 78, 79, 92, 106, 121, 137, 147, 161, 188, 189, 195], "anyth": [0, 23, 44, 73, 121, 124, 127, 138, 146, 163, 172, 186, 187], "quantit": [0, 21, 22, 105, 122, 129, 131, 140, 153], "involv": [0, 22, 72, 79, 105, 119, 121, 123, 136, 162, 179, 189], "than": [0, 12, 21, 22, 23, 26, 31, 33, 61, 63, 69, 72, 73, 78, 79, 85, 87, 94, 95, 97, 98, 99, 105, 114, 115, 121, 122, 123, 124, 129, 135, 136, 138, 144, 145, 146, 147, 155, 159, 161, 162, 163, 169, 171, 172, 173, 179, 180, 186, 187, 188, 189, 191, 196, 197, 198], "one": [0, 2, 4, 12, 19, 21, 22, 23, 24, 26, 31, 32, 37, 44, 45, 63, 67, 68, 69, 72, 74, 78, 79, 83, 85, 86, 87, 88, 92, 94, 95, 96, 97, 98, 99, 103, 105, 106, 112, 113, 119, 121, 122, 123, 124, 127, 129, 131, 135, 136, 137, 138, 144, 146, 147, 153, 154, 155, 161, 162, 163, 165, 169, 170, 171, 172, 173, 179, 180, 184, 186, 187, 188, 189, 193, 195, 196, 198, 199], "number": [0, 21, 23, 31, 32, 33, 45, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 99, 105, 106, 110, 112, 113, 115, 121, 122, 123, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 157, 161, 162, 169, 170, 171, 172, 173, 179, 180, 186, 187, 189, 191, 195, 198], "vector": [0, 23, 24, 31, 32, 33, 68, 69, 72, 79, 85, 92, 94, 95, 96, 97, 98, 99, 103, 105, 106, 113, 114, 115, 121, 122, 123, 124, 135, 136, 138, 144, 145, 146, 147, 153, 155, 162, 163, 169, 170, 171, 173, 179, 195, 196], "matrix": [0, 21, 23, 31, 69, 72, 73, 79, 98, 99, 103, 106, 108, 112, 115, 121, 122, 124, 129, 135, 136, 137, 145, 146, 147, 154, 161, 170, 171, 172, 173, 180, 189, 196, 197, 198], "addit": [0, 12, 19, 21, 22, 26, 31, 32, 33, 37, 61, 63, 67, 74, 78, 86, 97, 98, 103, 105, 106, 122, 129, 135, 144, 145, 155, 162, 171, 172, 173, 180, 188, 189, 198], "multipl": [0, 12, 26, 61, 63, 67, 69, 78, 79, 85, 94, 95, 96, 98, 99, 103, 112, 121, 122, 123, 131, 135, 138, 145, 146, 151, 162, 163, 169, 173, 187, 188, 189, 191, 197, 198], "rank": [0, 113, 121, 131, 196], "base": [0, 2, 4, 12, 21, 22, 23, 31, 67, 68, 69, 72, 74, 78, 79, 87, 95, 96, 97, 99, 101, 105, 110, 113, 114, 117, 121, 127, 129, 135, 136, 138, 147, 151, 153, 154, 161, 162, 165, 169, 170, 171, 172, 173, 180, 182, 186, 187, 188, 191, 193, 199], "determin": [0, 12, 22, 23, 24, 31, 32, 33, 67, 72, 78, 83, 99, 106, 114, 115, 119, 121, 122, 124, 127, 135, 136, 144, 146, 147, 149, 151, 153, 154, 155, 161, 162, 169, 170, 171, 175, 179, 180, 186, 187, 195, 196, 197, 198, 199], "invers": [0, 67, 68, 85, 87, 97, 106, 144, 154, 155, 162, 163, 169, 171, 197, 198], "eigenvalu": [0, 113, 114, 136], "decomposit": [0, 31, 115, 123, 131], "In": [0, 12, 21, 22, 23, 24, 31, 32, 33, 37, 45, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 81, 83, 85, 86, 87, 88, 92, 94, 95, 96, 97, 98, 99, 101, 103, 105, 106, 110, 112, 113, 114, 115, 117, 119, 121, 122, 123, 124, 129, 131, 135, 136, 137, 138, 140, 142, 144, 145, 146, 147, 151, 153, 154, 155, 159, 161, 162, 163, 165, 167, 169, 170, 171, 172, 173, 177, 179, 180, 184, 186, 187, 188, 189, 191, 193, 195, 196, 197, 198, 199], "beauti": [0, 31, 73, 74, 81, 145, 157, 191], "seri": [0, 12, 24, 31, 34, 35, 36, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 72, 73, 74, 79, 83, 85, 86, 87, 94, 95, 96, 97, 98, 99, 103, 105, 106, 138, 142, 144, 145, 169, 170, 172, 189, 191, 198, 199], "anoth": [0, 12, 19, 21, 23, 24, 31, 32, 33, 44, 45, 63, 67, 68, 72, 73, 74, 79, 85, 86, 87, 94, 97, 99, 105, 114, 121, 122, 124, 129, 136, 137, 144, 145, 161, 162, 163, 172, 180, 186, 191, 193, 196, 198], "resourc": [0, 72, 73, 78, 79, 86, 146, 157], "khan": 0, "exercis": [0, 12, 21, 22, 73, 162], "understand": [0, 12, 22, 23, 31, 32, 33, 61, 67, 73, 78, 79, 81, 85, 86, 87, 97, 98, 105, 106, 108, 112, 113, 119, 121, 124, 135, 136, 142, 145, 146, 151, 153, 154, 155, 161, 162, 165, 167, 170, 171, 172, 173, 177, 180, 186, 187, 189, 193, 195, 196, 197, 198], "import": [0, 12, 21, 22, 23, 24, 34, 35, 36, 45, 76, 90, 199], "comfort": [0, 31, 159], "varianc": [0, 61, 78, 79, 94, 95, 96, 97, 99, 106, 112, 113, 145, 162, 169, 170, 171, 180, 187, 195], "normal": [0, 12, 21, 23, 24, 31, 32, 33, 63, 69, 72, 73, 74, 78, 79, 85, 87, 94, 95, 96, 98, 99, 105, 106, 112, 113, 114, 117, 121, 122, 123, 124, 129, 137, 138, 161, 162, 169, 170, 171, 173, 187, 195, 196], "distribut": [0, 4, 12, 21, 23, 26, 31, 32, 33, 61, 63, 83, 86, 92, 94, 96, 98, 99, 103, 105, 106, 122, 123, 129, 137, 138, 142, 144, 145, 146, 159, 167, 169, 170, 171, 173, 182, 186, 187, 196], "select": [0, 2, 4, 12, 31, 32, 33, 45, 63, 78, 79, 85, 92, 94, 95, 96, 97, 114, 121, 124, 131, 149, 161, 162, 177, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "read": [0, 24, 31, 52, 61, 63, 78, 96, 97, 98, 162, 163, 169, 173, 187], "i": [0, 12, 21, 22, 23, 24, 26, 31, 32, 33, 37, 63, 67, 68, 69, 72, 73, 74, 78, 79, 81, 83, 85, 86, 87, 94, 95, 96, 97, 101, 103, 105, 106, 108, 112, 113, 114, 115, 117, 121, 122, 123, 124, 129, 131, 135, 137, 138, 145, 147, 149, 151, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 191, 195, 196, 197, 198], "e": [0, 2, 12, 19, 21, 22, 23, 24, 26, 31, 32, 33, 44, 61, 63, 67, 68, 72, 73, 74, 78, 79, 81, 83, 85, 86, 87, 90, 92, 95, 96, 97, 98, 99, 101, 103, 106, 108, 112, 113, 114, 115, 117, 119, 121, 122, 123, 124, 129, 131, 135, 140, 144, 145, 147, 149, 151, 157, 161, 162, 163, 165, 169, 170, 171, 172, 175, 179, 180, 186, 187, 188, 189, 191, 193, 195, 196, 197], "chapter": [0, 12, 90, 140, 149, 157, 172, 186], "6": [0, 19, 21, 23, 24, 31, 32, 37, 68, 69, 73, 78, 85, 87, 90, 92, 94, 95, 96, 97, 98, 105, 106, 113, 114, 115, 117, 121, 122, 123, 124, 131, 135, 136, 137, 138, 140, 144, 145, 146, 147, 153, 154, 155, 165, 172, 173, 175, 180, 182, 186, 187, 188, 189, 195, 196, 197], "7": [0, 19, 21, 23, 24, 29, 31, 37, 68, 69, 72, 73, 74, 78, 81, 85, 86, 94, 95, 96, 101, 105, 106, 113, 114, 115, 122, 123, 124, 129, 135, 136, 137, 138, 145, 146, 147, 153, 154, 155, 172, 173, 175, 180, 186, 187, 191, 195, 196, 197, 198], "russ": 0, "poldrack": 0, "s": [0, 2, 4, 12, 19, 21, 22, 23, 24, 26, 29, 31, 32, 33, 44, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 81, 83, 85, 86, 87, 90, 92, 94, 95, 96, 97, 101, 103, 105, 106, 108, 112, 113, 114, 117, 121, 124, 127, 129, 131, 135, 136, 137, 138, 140, 142, 144, 145, 146, 147, 149, 153, 154, 155, 157, 161, 162, 163, 167, 169, 170, 172, 173, 175, 177, 179, 180, 182, 184, 186, 187, 188, 189, 191, 193, 195, 196, 197, 198, 199], "book": [0, 12, 81, 105, 144, 157, 173, 191], "think": [0, 12, 22, 23, 24, 61, 69, 72, 83, 97, 98, 99, 103, 106, 110, 114, 121, 127, 129, 142, 157, 162, 169, 170, 171, 172, 179, 180, 188, 189, 195, 197], "21st": 0, "centuri": 0, "what": [0, 11, 12, 21, 22, 23, 24, 26, 31, 32, 61, 63, 68, 69, 73, 78, 79, 83, 86, 87, 88, 90, 94, 95, 97, 98, 99, 103, 105, 112, 113, 114, 115, 117, 119, 121, 123, 124, 127, 129, 135, 136, 137, 138, 144, 146, 147, 149, 151, 153, 154, 155, 159, 162, 163, 167, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 191, 193, 195, 196, 197, 198, 199], "integr": [0, 12, 21, 23, 63, 78, 79, 83, 122, 131, 140, 142, 145, 146, 149, 157, 161, 162, 163, 169, 171, 172, 173, 199], "differenti": [0, 61, 99, 114, 117, 121, 124, 136, 137, 140, 146, 153, 154, 173], "equat": [0, 22, 24, 32, 61, 63, 67, 69, 72, 78, 79, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 122, 123, 124, 136, 137, 138, 144, 145, 146, 147, 153, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 186, 187, 188, 195, 197, 198], "memori": [0, 19, 68, 69, 121, 137, 154, 182, 189], "gilbert": 0, "strang": 0, "studi": [0, 12, 72, 73, 74, 85, 103, 121, 122, 123, 124, 136, 137, 144, 145, 146, 147, 153, 154, 155, 162, 184, 186, 189, 198], "0": [0, 2, 21, 23, 24, 29, 37, 61, 63, 68, 69, 74, 78, 79, 81, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 117, 122, 123, 124, 131, 135, 136, 137, 138, 140, 144, 145, 147, 153, 154, 155, 163, 171, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "includ": [0, 4, 12, 22, 23, 24, 26, 31, 61, 67, 68, 69, 73, 78, 79, 87, 97, 105, 106, 112, 113, 114, 119, 121, 124, 135, 137, 138, 142, 153, 154, 155, 159, 163, 169, 170, 172, 173, 179, 180, 186, 187, 195, 197, 198, 199], "jiri": 0, "lebl": 0, "engin": [0, 2, 22, 31, 73, 74, 117, 131, 165, 177, 180], "outsid": [0, 21, 23, 24, 95, 121, 129, 137, 147], "fundament": [0, 12, 33, 81, 96, 105, 106, 161, 162, 187, 198], "watch": [0, 2, 37, 113, 129, 144, 157, 161, 179, 199], "neuro": [0, 12, 19, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 69, 83, 103, 106, 117, 131, 199], "video": [0, 2, 12, 19, 24, 37, 42, 157], "w0d0": 0, "short": [0, 12, 22, 33, 61, 72, 79, 85, 113, 122, 135, 136, 137, 142, 145, 162, 180], "subject": [0, 4, 12, 19, 33, 92, 154, 161, 163, 169, 172, 175, 186], "brain": [0, 4, 12, 19, 21, 23, 24, 26, 33, 34, 35, 36, 72, 73, 81, 83, 85, 106, 110, 119, 121, 122, 123, 124, 129, 131, 142, 145, 146, 151, 153, 154, 161, 162, 163, 165, 167, 169, 170, 171, 172, 173, 175, 177, 179, 184, 186, 193, 195, 196, 197, 199], "fact": [0, 12, 21, 23, 67, 68, 78, 79, 95, 112, 114, 121, 122, 137, 144, 145, 146, 147, 153, 154, 159, 161, 162, 169, 172, 187, 188, 189, 196, 198], "societi": [0, 191], "so": [0, 12, 21, 23, 24, 61, 67, 68, 69, 72, 73, 74, 78, 79, 83, 85, 86, 87, 88, 92, 94, 95, 96, 97, 98, 99, 103, 105, 106, 110, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 191, 195, 196, 197, 198, 199], "look": [0, 4, 21, 23, 24, 31, 67, 68, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 98, 103, 105, 106, 110, 112, 113, 114, 115, 121, 122, 123, 124, 135, 136, 137, 138, 144, 146, 155, 161, 162, 163, 169, 170, 172, 173, 179, 187, 188, 189, 195, 196, 198, 199], "forward": [0, 32, 33, 74, 122, 123, 124, 137, 153, 172], "meet": [0, 12, 22, 105], "soon": [0, 23, 31], "The": [0, 2, 4, 12, 19, 21, 22, 23, 24, 26, 32, 33, 37, 45, 63, 68, 69, 72, 78, 79, 81, 83, 85, 90, 92, 94, 95, 96, 97, 98, 99, 101, 103, 105, 108, 112, 113, 114, 115, 119, 121, 122, 123, 124, 131, 135, 136, 138, 140, 142, 145, 146, 147, 149, 151, 153, 154, 155, 157, 159, 161, 163, 165, 167, 170, 173, 175, 177, 179, 186, 187, 188, 189, 191, 193, 195, 196, 197, 198, 199], "team": [0, 4, 12, 31, 32, 33, 61, 63, 87, 88, 129, 138, 145, 146], "juli": [2, 4, 19, 26], "5": [2, 4, 12, 19, 23, 24, 26, 29, 31, 33, 37, 39, 69, 81, 86, 94, 95, 96, 97, 99, 101, 105, 108, 112, 113, 114, 115, 117, 121, 122, 123, 124, 131, 135, 136, 137, 138, 140, 144, 145, 146, 147, 149, 153, 154, 155, 165, 175, 180, 186, 187, 188, 189, 191, 196, 197], "23": [2, 4, 19, 26, 63, 69, 74, 78, 81, 86, 87, 94, 95, 96, 97, 98, 105, 113, 117, 122, 123, 124, 131, 135, 136, 137, 138, 147, 153, 154, 163, 169, 170, 171, 173, 175, 180, 188, 189, 195, 197, 198], "2021": [2, 4, 11, 19, 26, 73, 74, 117, 121, 122, 123, 131, 149, 155], "new": [2, 4, 12, 22, 26, 31, 33, 61, 63, 67, 69, 72, 79, 81, 90, 96, 99, 103, 106, 113, 114, 115, 121, 129, 136, 137, 140, 144, 145, 146, 149, 153, 154, 155, 157, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 189, 191, 196], "youtub": [2, 4, 19, 26, 157], "kai": [2, 21, 81, 129], "miller": [2, 101, 131, 140, 149, 151], "rare": [2, 12, 78, 94, 127, 198], "intracrani": 2, "electrocorticograph": 2, "record": [2, 4, 12, 21, 23, 26, 63, 67, 68, 73, 78, 79, 85, 86, 87, 92, 97, 101, 105, 106, 108, 112, 119, 121, 122, 123, 124, 131, 140, 144, 145, 146, 147, 154, 171, 172, 173, 180, 187], "clinic": [2, 119, 131], "pleas": [2, 12, 21, 22, 31, 32, 33, 40, 41, 44, 45, 61, 63, 66, 68, 69, 77, 83, 85, 86, 87, 88, 92, 94, 98, 105, 106, 115, 121, 122, 124, 153, 155, 159, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 195, 196, 197, 198], "ted": 2, "talk": [2, 12, 67, 87, 92, 95, 103, 122, 177, 193, 198], "yourself": [2, 12, 22, 68, 73, 78, 138, 144, 161, 162, 169, 171, 198], "type": [2, 12, 21, 22, 23, 31, 37, 61, 67, 69, 72, 73, 74, 79, 85, 86, 88, 92, 97, 98, 103, 105, 106, 110, 115, 119, 121, 122, 123, 124, 127, 129, 131, 136, 137, 138, 140, 145, 146, 147, 151, 153, 155, 171, 173, 187, 189, 191, 196, 199], "less": [2, 12, 24, 33, 69, 72, 78, 79, 83, 85, 105, 106, 114, 121, 161, 170, 187, 188, 196, 198], "same": [2, 12, 21, 22, 23, 31, 32, 44, 61, 63, 67, 68, 69, 72, 74, 78, 79, 83, 85, 87, 88, 94, 95, 96, 97, 98, 105, 106, 115, 119, 121, 122, 123, 124, 129, 135, 136, 137, 140, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197], "difficulti": [2, 31], "all": [2, 12, 19, 21, 22, 23, 24, 26, 29, 31, 32, 33, 61, 63, 67, 68, 69, 72, 78, 79, 83, 85, 86, 87, 90, 92, 95, 96, 97, 99, 103, 105, 106, 110, 112, 113, 114, 117, 121, 122, 123, 124, 127, 129, 135, 136, 137, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 186, 187, 188, 189, 193, 195, 196, 197, 198, 199], "group": [2, 4, 19, 21, 23, 26, 44, 67, 68, 85, 86, 87, 88, 123, 124, 127, 129, 147, 179, 186, 193, 198], "method": [2, 12, 21, 22, 31, 61, 63, 67, 69, 72, 73, 79, 81, 83, 86, 87, 92, 94, 95, 96, 99, 103, 105, 106, 110, 121, 124, 129, 131, 135, 136, 140, 144, 145, 146, 153, 154, 155, 163, 169, 172, 177, 180, 187, 188, 189, 191, 193, 195, 196, 197, 198, 199], "standard": [2, 4, 21, 22, 24, 29, 67, 68, 72, 78, 79, 94, 95, 96, 98, 99, 105, 106, 121, 123, 137, 138, 144, 146, 157, 163, 169, 170, 171, 172, 173, 186, 193, 195, 196, 198], "protocol": 2, "particular": [2, 12, 21, 23, 24, 68, 85, 87, 94, 99, 103, 106, 110, 112, 121, 122, 123, 124, 129, 135, 136, 138, 144, 145, 154, 159, 170, 188, 189, 195, 198], "interest": [2, 12, 19, 21, 22, 23, 24, 83, 85, 86, 87, 92, 105, 115, 122, 124, 135, 137, 142, 145, 146, 151, 153, 161, 162, 163, 186, 188, 189, 195, 196, 198], "sensori": [2, 4, 12, 21, 23, 73, 101, 121, 122, 129, 149, 157, 162, 169, 170, 171, 172, 173], "bci": 2, "slightli": [2, 12, 61, 122, 137, 146, 155, 161, 163, 169, 171, 172, 187, 188], "advanc": [2, 4, 19, 21, 26, 68, 78, 79, 90, 99, 101, 117, 129, 131, 154, 159, 165, 171, 197], "definit": [2, 22, 32, 63, 68, 72, 73, 74, 86, 87, 135, 136, 144, 146, 154, 155, 161, 162, 169, 175, 186, 193, 195, 196, 197, 198], "consid": [2, 4, 12, 22, 67, 73, 74, 79, 85, 86, 87, 95, 97, 98, 106, 114, 121, 124, 129, 135, 136, 137, 147, 153, 155, 161, 162, 163, 169, 171, 172, 173, 180, 186, 187, 188, 195, 196, 197, 198], "steinmetz": [2, 4, 87, 106], "much": [2, 12, 21, 22, 23, 24, 32, 61, 63, 69, 72, 73, 74, 78, 79, 86, 87, 94, 99, 103, 105, 106, 113, 114, 115, 119, 121, 122, 127, 144, 146, 147, 161, 162, 163, 169, 172, 173, 180, 186, 187, 191, 196], "better": [2, 12, 21, 22, 23, 31, 32, 33, 61, 63, 67, 69, 72, 73, 79, 83, 92, 94, 95, 99, 105, 106, 110, 115, 121, 122, 123, 124, 129, 135, 138, 145, 147, 151, 154, 161, 162, 169, 171, 172, 179, 180, 186, 187, 193, 196, 197, 198], "suit": [2, 12, 31, 99, 110, 121, 122, 123], "exploratori": [2, 12, 26], "analys": [2, 4, 12, 19, 22, 26, 78, 121, 155, 163, 199], "divers": [2, 12, 22, 26, 81, 83, 117, 124, 153], "topic": [2, 12, 21, 67, 68, 78, 129, 137, 159, 169, 184, 186, 189, 199], "thei": [2, 12, 21, 22, 23, 24, 26, 39, 67, 68, 73, 74, 78, 79, 83, 85, 86, 87, 95, 96, 97, 98, 103, 105, 106, 110, 112, 113, 115, 119, 121, 122, 123, 124, 129, 135, 136, 137, 138, 145, 146, 147, 154, 161, 162, 163, 171, 172, 173, 179, 186, 187, 188, 189, 195, 196, 197, 198], "comput": [2, 4, 12, 21, 22, 23, 24, 31, 43, 45, 61, 63, 67, 69, 72, 78, 81, 85, 90, 92, 95, 96, 101, 105, 106, 110, 112, 114, 117, 121, 122, 124, 129, 131, 135, 138, 140, 142, 146, 149, 151, 159, 162, 163, 165, 167, 169, 171, 172, 173, 175, 177, 179, 180, 184, 186, 187, 188, 191, 197, 199], "project": [2, 19, 22, 26, 31, 32, 33, 40, 43, 44, 45, 67, 68, 72, 97, 110, 114, 115, 127, 151, 172, 199], "becaus": [2, 12, 19, 21, 22, 23, 24, 26, 72, 73, 78, 79, 83, 85, 87, 95, 97, 99, 105, 106, 113, 114, 115, 121, 122, 123, 124, 127, 129, 137, 138, 144, 145, 146, 147, 151, 153, 161, 162, 163, 169, 171, 172, 177, 179, 187, 188, 195, 196, 197, 198], "high": [2, 12, 22, 26, 31, 32, 72, 98, 99, 110, 112, 113, 115, 117, 121, 123, 124, 131, 135, 138, 140, 144, 146, 153, 155, 161, 165, 169, 170, 179, 180, 186, 187, 196, 197], "dimension": [2, 12, 26, 29, 31, 33, 37, 67, 68, 72, 83, 97, 105, 110, 112, 113, 121, 124, 131, 137, 145, 153, 162, 170, 172, 179, 180, 193, 195, 196, 199], "lot": [2, 11, 12, 19, 21, 22, 23, 67, 69, 72, 78, 79, 96, 98, 99, 121, 123, 137, 161, 162, 169, 196, 199], "neuron": [2, 12, 19, 21, 23, 33, 37, 67, 68, 69, 73, 74, 78, 79, 83, 92, 95, 101, 103, 105, 106, 112, 113, 117, 119, 121, 122, 123, 124, 129, 131, 135, 136, 142, 151, 154, 155, 162, 165, 169, 175, 177, 179, 186, 193, 199], "trial": [2, 4, 12, 21, 23, 24, 78, 106, 112, 122, 124, 129, 131, 144, 145, 146, 163, 169, 173, 186, 187, 188, 189, 196, 197, 198], "support": [2, 4, 12, 26, 61, 67, 73, 85, 87, 92, 106, 180, 196], "nma": [2, 11, 12, 23, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 83, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 157, 159, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 184, 186, 187, 188, 189, 195, 196, 197, 198], "been": [2, 12, 21, 22, 23, 24, 44, 45, 67, 69, 73, 78, 79, 96, 98, 99, 103, 112, 113, 121, 122, 123, 124, 129, 137, 146, 147, 153, 154, 155, 161, 162, 163, 165, 172, 173, 179, 186, 189, 195, 196, 198], "curat": [2, 4, 19, 26, 199], "annot": [2, 19, 68, 106, 187], "gener": [2, 12, 22, 23, 31, 32, 33, 61, 63, 67, 72, 73, 74, 83, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 101, 103, 106, 113, 119, 121, 122, 123, 136, 137, 138, 142, 145, 146, 147, 153, 154, 155, 161, 162, 169, 170, 171, 172, 179, 186, 187, 188, 189, 195, 196, 197, 198, 199], "credit": [2, 4, 19, 26, 68], "mariu": [2, 12, 19, 21, 22, 23, 24, 26, 129], "pachitariu": [2, 12, 19, 21, 26, 117, 129], "ta": [2, 37, 74], "view": [2, 4, 12, 19, 21, 22, 23, 24, 26, 67, 72, 81, 85, 87, 95, 121, 122, 123, 124, 129, 153, 170, 173], "faceshous": 2, "joysticktrack": 2, "memorynback": 2, "motorimageri": 2, "exploreajile12": 2, "k": [2, 12, 19, 21, 22, 24, 26, 61, 63, 67, 68, 69, 74, 78, 81, 90, 95, 97, 99, 101, 106, 108, 112, 113, 114, 115, 117, 122, 123, 124, 129, 131, 135, 136, 137, 138, 140, 144, 145, 146, 147, 149, 153, 154, 155, 157, 162, 163, 165, 171, 172, 173, 180, 182, 186, 187, 189, 191, 195, 196, 197, 198], "j": [2, 12, 19, 26, 31, 32, 33, 61, 63, 67, 68, 69, 72, 79, 81, 90, 97, 101, 105, 106, 108, 113, 117, 131, 140, 145, 149, 154, 155, 157, 161, 165, 170, 172, 173, 175, 180, 182, 186, 191, 195, 196, 197, 198], "herm": 2, "d": [2, 19, 21, 22, 23, 24, 26, 31, 61, 67, 68, 69, 72, 73, 74, 81, 90, 94, 97, 101, 105, 106, 108, 117, 123, 124, 129, 131, 137, 138, 140, 144, 149, 153, 154, 155, 157, 165, 170, 171, 172, 173, 175, 180, 182, 186, 188, 189, 191, 196], "pestilli": 2, "f": [2, 19, 21, 23, 24, 29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 145, 146, 147, 150, 151, 152, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198], "wig": 2, "g": [2, 12, 19, 21, 22, 23, 24, 44, 67, 68, 69, 72, 73, 74, 78, 79, 81, 85, 86, 87, 90, 92, 94, 95, 96, 97, 98, 99, 101, 103, 105, 114, 115, 117, 119, 121, 122, 123, 124, 129, 131, 135, 140, 144, 146, 147, 149, 151, 153, 162, 163, 169, 170, 171, 172, 175, 179, 180, 182, 186, 187, 188, 189, 191, 193, 196], "ojemann": [2, 131], "2017": [2, 19, 22, 81, 90, 101, 117, 131, 191], "percept": [2, 21, 23, 24, 81, 101, 129, 157, 163, 171, 179], "format": [2, 4, 12, 24, 67, 85, 113, 121, 137, 138, 145, 169, 170, 172, 173, 180, 198], "human": [2, 4, 19, 31, 33, 73, 78, 117, 119, 121, 122, 131, 137, 138, 161, 162, 169, 182, 184, 186, 191], "ventral": [2, 117], "tempor": [2, 22, 101, 105, 117, 131, 144, 145, 154, 171, 172, 188, 189, 198], "cortex": [2, 26, 79, 101, 106, 117, 119, 121, 122, 123, 124, 131, 149, 151, 173, 182], "journal": [2, 12, 19, 22, 74, 81, 90, 101, 117, 131, 140, 145, 149, 154, 155, 165, 175, 191], "neurophysiolog": [2, 74, 90, 101, 131, 140, 149, 175], "118": [2, 117], "2614": 2, "2627": 2, "doi": [2, 19, 21, 22, 26, 73, 74, 81, 90, 101, 108, 117, 129, 131, 140, 145, 149, 154, 155, 165, 175, 182, 191], "10": [2, 12, 19, 21, 23, 24, 26, 31, 32, 33, 67, 69, 72, 73, 74, 78, 79, 81, 85, 86, 87, 90, 94, 95, 96, 97, 98, 99, 101, 105, 106, 108, 113, 114, 115, 117, 121, 122, 123, 124, 129, 131, 135, 137, 138, 140, 144, 145, 146, 147, 149, 153, 154, 155, 162, 163, 165, 169, 170, 173, 175, 179, 180, 182, 186, 187, 188, 189, 191, 195, 196, 197, 198], "1152": [2, 90, 101, 131, 140, 149, 175], "jn": [2, 90, 101, 131, 140, 149, 175], "00113": 2, "witthoft": 2, "n": [2, 19, 21, 23, 24, 26, 31, 32, 61, 63, 67, 69, 72, 73, 74, 78, 79, 81, 85, 87, 90, 94, 95, 96, 97, 98, 99, 101, 105, 106, 108, 112, 113, 114, 117, 121, 122, 123, 124, 129, 131, 135, 137, 138, 140, 144, 145, 146, 147, 149, 153, 154, 155, 157, 161, 162, 163, 169, 170, 171, 172, 173, 175, 179, 180, 182, 186, 187, 188, 189, 191, 195, 196, 197, 198], "rao": [2, 131], "r": [2, 19, 21, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 81, 85, 86, 87, 90, 94, 95, 96, 101, 105, 106, 108, 112, 113, 117, 121, 122, 123, 124, 129, 131, 135, 137, 138, 140, 144, 145, 146, 147, 149, 153, 154, 155, 157, 162, 163, 165, 169, 170, 172, 173, 175, 179, 180, 182, 186, 188, 189, 191, 195, 196, 197, 198], "p": [2, 19, 21, 26, 32, 33, 43, 67, 68, 72, 73, 74, 78, 79, 81, 87, 90, 95, 97, 101, 105, 106, 108, 117, 121, 123, 124, 129, 131, 136, 138, 140, 145, 161, 162, 163, 169, 170, 171, 172, 173, 175, 179, 180, 182, 186, 187, 191, 195, 196, 197, 198], "2015": [2, 108, 117, 131, 145, 149, 182, 191], "physiolog": [2, 4, 72, 85, 86, 101, 131, 140], "lobe": 2, "special": [2, 67, 68, 69, 79, 103, 105, 106, 121, 123, 124, 135, 144, 146, 153, 162, 169, 189], "contextu": 2, "novelti": [2, 26], "114": [2, 19, 81, 188], "256": [2, 105, 196], "263": [2, 79], "2fjn": 2, "00131": 2, "schalk": 2, "2016": [2, 81, 101, 108, 115, 117, 131, 182, 191], "spontan": [2, 26, 73, 74, 121, 122, 123, 124], "decod": [2, 12, 23, 31, 32, 33, 68, 95, 101, 103, 110, 119, 122, 145, 157, 165, 199], "object": [2, 19, 23, 24, 79, 117, 119, 167, 177], "cortic": [2, 26, 117, 122, 131, 144, 146, 149, 157], "surfac": [2, 33, 72, 95], "reveal": [2, 117], "complementari": [2, 21, 22, 26, 79, 83], "inform": [2, 4, 12, 19, 21, 22, 23, 24, 31, 33, 63, 68, 73, 78, 79, 83, 85, 86, 90, 101, 105, 106, 113, 114, 115, 117, 119, 121, 122, 123, 124, 129, 131, 136, 144, 146, 151, 153, 154, 157, 161, 163, 165, 169, 170, 171, 172, 173, 175, 179, 186, 187, 189], "event": [2, 39, 68, 78, 79, 86, 87, 135, 136, 144, 145, 146, 147, 161, 162, 173], "relat": [2, 4, 12, 19, 21, 22, 31, 33, 67, 68, 72, 73, 74, 78, 85, 98, 101, 103, 106, 114, 123, 131, 135, 136, 137, 140, 153, 154, 155, 161, 162, 169, 171, 175, 195, 197, 199], "potenti": [2, 12, 21, 63, 74, 78, 79, 83, 85, 86, 87, 96, 97, 99, 103, 105, 121, 123, 129, 142, 144, 145, 147, 161, 162, 163, 173, 187, 188, 189, 198], "broadband": 2, "spectral": [2, 12], "chang": [2, 12, 21, 22, 23, 26, 29, 31, 32, 33, 44, 63, 67, 68, 78, 79, 86, 87, 92, 94, 95, 96, 97, 98, 105, 106, 110, 113, 115, 121, 124, 135, 136, 137, 142, 144, 145, 146, 151, 153, 154, 161, 162, 163, 167, 169, 171, 172, 173, 179, 180, 186, 188, 195, 196, 197, 198, 199], "plo": [2, 4, 22, 74, 81, 101, 117, 131, 165], "biologi": [2, 4, 73, 74, 81, 101, 117, 131, 175, 199], "12": [2, 4, 23, 24, 31, 32, 33, 67, 69, 72, 73, 74, 78, 79, 85, 86, 94, 95, 96, 97, 98, 99, 101, 105, 106, 108, 112, 117, 121, 122, 123, 124, 131, 135, 137, 138, 144, 145, 146, 147, 149, 153, 154, 155, 161, 162, 163, 169, 170, 173, 179, 180, 182, 186, 187, 188, 189, 191, 195, 196, 197, 198, 199], "e1004660": 2, "1371": [2, 22, 74, 81, 101, 117, 131, 165], "pcbi": [2, 22, 81, 101, 117, 131], "1004660": 2, "zano": 2, "fetz": 2, "den": [2, 182], "nij": 2, "m": [2, 12, 19, 21, 23, 26, 67, 74, 81, 86, 90, 95, 101, 106, 108, 117, 121, 123, 124, 129, 131, 138, 140, 146, 147, 149, 154, 155, 157, 161, 162, 165, 169, 170, 171, 175, 180, 182, 186, 191], "2009": [2, 19, 81, 90, 131, 140, 149, 172, 175, 191], "decoupl": 2, "power": [2, 12, 32, 78, 79, 94, 96, 97, 103, 115, 121, 154, 162, 163, 169, 173, 198], "spectrum": [2, 144, 146], "real": [2, 12, 21, 23, 33, 67, 69, 79, 83, 86, 87, 92, 94, 97, 106, 113, 114, 122, 124, 135, 138, 144, 153, 155, 162, 169, 172, 180, 189, 191, 196, 197], "represent": [2, 4, 19, 22, 32, 33, 63, 68, 74, 81, 85, 95, 103, 105, 106, 110, 115, 117, 119, 121, 122, 124, 136, 153, 157, 162, 163, 173, 186, 188, 189], "individu": [2, 12, 19, 22, 37, 63, 67, 85, 114, 121, 123, 124, 142, 153, 154, 155, 161, 169, 188, 189, 198, 199], "finger": 2, "movement": [2, 21, 23, 24, 78, 129, 131, 162, 165, 175, 180, 188], "neurosci": [2, 4, 12, 19, 21, 22, 23, 26, 33, 43, 45, 61, 67, 68, 78, 81, 85, 92, 97, 99, 101, 103, 106, 110, 112, 117, 119, 123, 124, 129, 135, 137, 140, 142, 144, 145, 149, 151, 159, 161, 162, 167, 169, 172, 175, 177, 184, 189, 191, 193, 195, 196, 199], "29": [2, 67, 74, 78, 85, 87, 94, 97, 98, 99, 101, 105, 114, 117, 121, 123, 124, 135, 136, 137, 145, 146, 147, 153, 154, 163, 169, 171, 172, 179, 180, 186, 187, 188, 189, 195, 196, 198], "3132": 2, "3137": 2, "1523": [2, 21, 22, 81, 101, 117, 129, 140, 145, 149, 175], "2fjneurosci": 2, "5506": 2, "08": [2, 12, 67, 69, 94, 105, 182], "honei": 2, "c": [2, 19, 21, 23, 24, 26, 67, 68, 69, 72, 81, 90, 94, 96, 101, 105, 108, 115, 117, 122, 123, 124, 131, 136, 138, 140, 145, 146, 149, 154, 155, 157, 161, 162, 163, 165, 169, 170, 172, 173, 175, 179, 180, 182, 189, 191, 195, 196, 197, 198], "hebb": 2, "A": [2, 4, 12, 19, 21, 22, 23, 24, 26, 29, 31, 33, 61, 63, 67, 68, 73, 78, 81, 85, 86, 87, 90, 92, 99, 101, 105, 106, 108, 117, 119, 121, 122, 129, 131, 136, 137, 140, 144, 145, 146, 147, 149, 153, 154, 157, 161, 165, 169, 171, 172, 173, 175, 179, 180, 182, 186, 187, 189, 195, 197], "o": [2, 61, 67, 72, 73, 74, 78, 94, 97, 101, 105, 106, 113, 114, 117, 121, 122, 123, 124, 131, 136, 145, 146, 154, 155, 157, 169, 171, 173, 188, 189, 191, 195], "ramsei": 2, "knight": 2, "t": [2, 12, 19, 21, 22, 23, 24, 26, 31, 32, 33, 45, 61, 63, 66, 67, 68, 69, 72, 73, 74, 77, 78, 79, 81, 85, 86, 87, 94, 96, 97, 98, 99, 101, 105, 106, 108, 110, 113, 114, 117, 121, 122, 123, 124, 127, 129, 131, 135, 137, 138, 140, 144, 145, 146, 147, 149, 153, 154, 155, 157, 161, 162, 163, 167, 169, 170, 171, 172, 173, 175, 179, 180, 186, 187, 188, 189, 191, 195, 196, 197, 198], "2012": [2, 81, 101, 131, 175], "activ": [2, 12, 19, 21, 23, 26, 32, 33, 67, 68, 72, 73, 79, 86, 87, 92, 101, 103, 106, 110, 112, 113, 119, 124, 131, 140, 142, 144, 146, 149, 151, 165, 167, 170, 171, 173, 177, 189, 195, 197, 198], "phase": [2, 31, 98, 122, 123, 124, 135, 151, 153, 186, 189], "entrain": 2, "underli": [2, 23, 67, 68, 83, 94, 95, 106, 108, 110, 131, 138, 149, 151, 162, 165, 172, 173, 186, 196, 199], "rhythm": 2, "e1002655": 2, "1002655": 2, "kubanek": 2, "anderson": 2, "leuthardt": 2, "wolpaw": 2, "2007": [2, 73, 74, 101, 131, 140, 145], "two": [2, 4, 12, 19, 21, 22, 23, 31, 32, 33, 63, 67, 68, 69, 72, 73, 74, 78, 79, 83, 85, 87, 92, 95, 97, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 136, 138, 140, 144, 145, 146, 147, 151, 154, 155, 159, 161, 162, 163, 167, 169, 170, 172, 173, 177, 179, 180, 186, 187, 188, 189, 196], "trajectori": [2, 69, 137, 138, 155, 170, 171, 172, 180], "signal": [2, 12, 21, 22, 23, 72, 74, 78, 95, 97, 101, 129, 131, 140, 169, 171, 184, 186, 187, 188, 189, 198], "4": [2, 12, 19, 22, 23, 24, 29, 37, 39, 45, 69, 81, 86, 90, 92, 94, 96, 98, 99, 101, 105, 108, 110, 113, 117, 121, 122, 123, 124, 131, 136, 137, 140, 144, 145, 146, 147, 149, 153, 154, 175, 184, 186, 188, 191, 193], "3": [2, 12, 19, 22, 23, 29, 37, 39, 45, 81, 83, 90, 92, 94, 98, 99, 101, 103, 105, 108, 110, 113, 115, 117, 119, 131, 138, 140, 149, 154, 175, 184, 193], "264": 2, "275": [2, 117, 131, 182], "1088": [2, 101], "1741": 2, "2560": 2, "012": [2, 68, 175], "wilson": [2, 81, 90, 117, 131, 149, 151, 175], "smyth": 2, "2008": [2, 19, 90, 101, 117, 131, 140, 175, 182, 191], "control": [2, 12, 21, 37, 44, 61, 74, 78, 79, 83, 86, 87, 92, 105, 108, 112, 121, 122, 123, 124, 129, 131, 145, 146, 151, 153, 154, 155, 159, 161, 162, 167, 169, 170, 171, 177, 182, 184, 186, 188, 189, 193, 197, 198, 199], "75": [2, 63, 68, 72, 73, 74, 94, 96, 122, 123, 124, 144, 145, 146, 147, 169, 170, 173, 186, 189, 197], "84": [2, 131, 169, 189], "008": [2, 61, 101, 147], "brouwer": 2, "hogervorst": 2, "van": [2, 19, 21, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 67, 68, 73, 74, 78, 79, 117, 129, 131, 140, 149, 169, 182], "erp": [2, 4], "b": [2, 12, 19, 21, 22, 23, 24, 26, 31, 32, 63, 67, 68, 69, 72, 74, 78, 81, 85, 86, 87, 88, 95, 96, 101, 105, 108, 112, 113, 117, 121, 124, 131, 135, 136, 137, 138, 140, 144, 145, 146, 147, 149, 153, 154, 155, 157, 161, 162, 163, 169, 170, 171, 172, 173, 175, 179, 180, 186, 187, 189, 191, 195, 196, 197, 198], "heffelaar": 2, "zimmerman": 2, "h": [2, 31, 68, 72, 79, 81, 87, 101, 105, 106, 117, 121, 122, 123, 124, 131, 140, 149, 154, 155, 157, 172, 175, 182], "oostenveld": 2, "estim": [2, 4, 21, 24, 67, 68, 72, 73, 74, 78, 85, 86, 87, 88, 92, 98, 99, 101, 103, 105, 106, 112, 113, 114, 115, 119, 121, 122, 123, 124, 131, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 161, 169, 170, 172, 173, 179, 180, 186, 187, 188, 189, 191, 193, 199], "workload": 2, "back": [2, 21, 22, 23, 24, 31, 32, 73, 95, 97, 98, 105, 119, 121, 124, 129, 137, 138, 146, 155, 161, 162, 169, 171, 172, 173, 180, 188, 198], "task": [2, 4, 26, 31, 32, 33, 79, 83, 94, 96, 103, 105, 106, 119, 122, 131, 138, 169, 172, 180, 186, 187, 188, 189, 198, 199], "9": [2, 23, 24, 31, 32, 67, 69, 72, 73, 74, 78, 79, 81, 94, 96, 97, 101, 106, 114, 115, 117, 121, 123, 124, 131, 135, 136, 137, 138, 140, 144, 145, 146, 147, 149, 153, 154, 155, 163, 165, 172, 173, 175, 179, 180, 186, 187, 188, 189, 191, 195, 196, 197, 198], "045008": 2, "grissmann": 2, "faller": 2, "scharing": 2, "sp\u00fcler": 2, "gerjet": 2, "electroencephalographi": 2, "work": [2, 12, 19, 21, 22, 23, 24, 26, 31, 45, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 97, 98, 105, 114, 117, 121, 123, 124, 129, 135, 138, 154, 159, 161, 162, 163, 169, 171, 172, 173, 177, 179, 180, 187, 189, 191, 193, 195, 196, 197], "load": [2, 12, 33, 85, 87, 113, 114, 115, 129, 186], "affect": [2, 12, 33, 69, 72, 73, 74, 79, 95, 99, 106, 112, 114, 115, 121, 135, 137, 142, 144, 146, 153, 162, 169, 170, 171, 175, 180, 186, 187, 188, 189, 193, 195, 197, 198, 199], "valenc": 2, "emot": [2, 19], "stimuli": [2, 21, 23, 26, 79, 101, 119, 121, 122, 123, 124, 129, 172, 175], "frontier": [2, 19, 117, 189], "11": [2, 69, 78, 79, 85, 94, 95, 96, 97, 99, 101, 105, 106, 108, 112, 113, 114, 115, 117, 121, 122, 123, 124, 131, 135, 137, 140, 144, 145, 146, 147, 149, 153, 154, 155, 162, 163, 170, 180, 182, 186, 187, 188, 189, 198], "616": [2, 108], "3389": [2, 19, 117], "2ffnhum": 2, "00616": 2, "2010": [2, 32, 90, 101, 165], "dure": [2, 12, 23, 26, 31, 32, 33, 37, 61, 63, 67, 68, 69, 72, 78, 79, 83, 92, 98, 99, 101, 119, 122, 127, 129, 131, 136, 144, 161, 163, 165, 172, 175, 186, 189, 199], "execut": [2, 29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "onlin": [2, 12, 72, 78, 81, 127, 129, 149, 157, 172], "feedback": [2, 12, 37, 131, 175], "proceed": [2, 19, 73, 74, 101, 117, 131, 140, 175], "nation": [2, 19, 73, 74, 117, 131, 140, 175], "107": [2, 154, 170], "4430": 2, "4435": 2, "1073": [2, 19, 73, 74, 117, 131, 140, 175], "pna": [2, 19, 73, 74, 117, 131, 140, 175], "0913697107": 2, "peterson": 2, "singh": [2, 53], "wang": [2, 68, 131, 140, 149, 182, 186, 187, 188, 189], "x": [2, 12, 21, 23, 24, 26, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 81, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 117, 121, 122, 123, 124, 129, 135, 136, 137, 138, 145, 146, 149, 153, 154, 155, 161, 162, 170, 171, 172, 173, 179, 180, 182, 186, 188, 189, 195, 196, 197, 198], "brunton": [2, 34, 131, 135, 136, 137, 138], "w": [2, 19, 31, 67, 68, 69, 72, 74, 79, 81, 90, 101, 106, 112, 113, 114, 117, 121, 122, 123, 124, 131, 140, 149, 153, 155, 157, 165, 170, 171, 175, 182, 191, 197, 198], "behavior": [2, 12, 19, 21, 22, 26, 31, 72, 74, 81, 83, 86, 87, 90, 92, 101, 103, 119, 123, 129, 135, 136, 137, 144, 147, 149, 153, 154, 155, 159, 161, 163, 169, 171, 173, 180, 182, 184, 186, 187, 188, 189, 193], "naturalist": [2, 123], "arm": [2, 78, 131, 163, 188, 189], "eneuro": [2, 21, 22, 81, 101, 129], "8": [2, 21, 23, 24, 31, 32, 33, 37, 68, 69, 72, 73, 74, 78, 79, 81, 85, 86, 87, 90, 95, 96, 97, 98, 99, 101, 105, 106, 112, 113, 114, 115, 117, 122, 123, 124, 129, 131, 135, 137, 145, 147, 149, 153, 154, 155, 169, 170, 172, 173, 179, 180, 182, 186, 187, 188, 189, 195, 197, 198], "0007": 2, "21": [2, 24, 63, 69, 74, 78, 79, 81, 86, 87, 90, 94, 95, 96, 97, 98, 99, 105, 106, 108, 112, 113, 117, 121, 124, 131, 135, 136, 137, 138, 144, 145, 147, 149, 153, 154, 155, 161, 163, 169, 170, 173, 179, 180, 182, 187, 188, 189, 195, 196, 197, 198], "mine": 2, "long": [2, 12, 32, 67, 69, 85, 121, 137, 144, 146, 147, 172, 179, 187, 198], "term": [2, 12, 22, 31, 32, 61, 67, 68, 72, 74, 78, 79, 85, 87, 97, 99, 105, 113, 121, 122, 123, 124, 135, 136, 137, 138, 142, 145, 147, 151, 153, 154, 155, 161, 169, 171, 180, 186, 188, 198], "358": 2, "109199": 2, "1016": [2, 12, 19, 26, 81, 90, 101, 108, 117, 131, 140, 149, 154, 155, 165, 175, 182], "jneumeth": [2, 131, 140], "daili": 3, "guid": [3, 21, 22, 37, 41, 68, 81, 83, 106, 124, 127, 129, 137, 162, 167, 199], "everyon": [4, 12, 73, 83, 129, 186], "onli": [4, 12, 19, 21, 22, 23, 24, 31, 32, 33, 45, 61, 67, 68, 69, 72, 74, 78, 79, 85, 86, 87, 96, 97, 99, 105, 106, 113, 114, 115, 119, 121, 122, 123, 127, 129, 136, 138, 144, 145, 146, 147, 151, 153, 154, 155, 157, 161, 162, 163, 167, 169, 170, 171, 172, 179, 180, 184, 186, 187, 188, 189, 195, 196, 197, 198], "veri": [4, 12, 21, 22, 23, 24, 26, 31, 33, 61, 68, 69, 72, 73, 74, 78, 79, 85, 96, 97, 98, 99, 103, 105, 106, 121, 123, 124, 135, 137, 142, 146, 147, 151, 155, 161, 162, 169, 173, 179, 180, 187, 188, 189, 191, 195, 196, 197, 198], "rich": [4, 32, 33, 154], "mani": [4, 12, 19, 21, 22, 23, 24, 26, 33, 67, 68, 72, 73, 74, 78, 79, 85, 86, 87, 96, 97, 103, 105, 106, 110, 112, 114, 121, 122, 123, 124, 136, 145, 146, 147, 153, 154, 159, 161, 162, 163, 169, 171, 179, 180, 184, 186, 187, 188, 195, 197, 198], "pose": [4, 12, 119, 199], "track": [4, 12, 31, 32, 33, 63, 69, 121, 123, 124, 136, 144, 167, 171, 186], "social": [4, 19, 191, 195], "interact": [4, 21, 42, 44, 45, 61, 68, 115, 138, 145, 149, 151, 159, 167, 173, 188, 189, 195], "mice": [4, 26, 85, 106, 119, 121, 122, 123, 180], "code": [4, 12, 19, 21, 22, 23, 26, 42, 43, 44, 45, 73, 83, 101, 108, 117, 157, 162, 182, 191, 199], "templat": [4, 19, 26], "ann": [4, 32, 54, 117], "kennedi": 4, "loader": 4, "notebook": [4, 12, 21, 22, 26, 42, 44, 45, 61, 67, 68, 85, 99, 106, 112, 113, 114, 115, 122, 123, 124, 129, 161, 162, 163, 172, 186, 189, 195, 197, 198], "visual": [4, 12, 19, 21, 22, 23, 24, 26, 33, 61, 63, 67, 68, 69, 73, 74, 78, 79, 86, 87, 94, 95, 96, 97, 98, 99, 101, 105, 106, 110, 112, 113, 117, 119, 129, 131, 135, 136, 137, 138, 144, 145, 146, 149, 151, 154, 155, 161, 163, 167, 169, 170, 171, 172, 173, 175, 179, 180, 186, 187, 188, 195, 196, 197, 198, 199], "decis": [4, 21, 22, 23, 37, 73, 74, 78, 79, 81, 83, 92, 101, 103, 106, 121, 124, 129, 131, 137, 159, 169, 175, 179, 184, 186, 187, 199], "similar": [4, 19, 21, 23, 24, 31, 32, 33, 61, 63, 67, 72, 73, 79, 85, 86, 97, 98, 105, 112, 113, 117, 119, 121, 122, 124, 137, 145, 147, 153, 154, 155, 161, 163, 169, 170, 187, 188, 189, 197, 198], "eric": [4, 21, 129, 161, 162, 186, 187, 188, 189], "dewitt": [4, 21, 129, 161, 162, 186, 187, 188, 189], "current": [4, 12, 22, 24, 29, 31, 63, 68, 72, 73, 74, 79, 86, 108, 119, 121, 124, 131, 140, 145, 146, 153, 154, 155, 169, 170, 171, 172, 173, 175, 179, 180, 182, 186, 187, 188, 189, 195, 196, 198], "avail": [4, 12, 22, 26, 31, 32, 85, 90, 121, 124, 129, 138, 146, 157, 169, 172, 173, 187, 198], "psychometr": 4, "These": [4, 12, 19, 21, 26, 31, 32, 33, 61, 63, 67, 69, 73, 74, 78, 79, 85, 98, 99, 105, 112, 121, 122, 123, 124, 136, 138, 142, 146, 155, 161, 162, 163, 171, 172, 173, 179, 180, 186, 193, 197, 198, 199], "next": [4, 12, 23, 31, 61, 63, 67, 68, 69, 72, 73, 78, 79, 83, 85, 86, 87, 88, 97, 98, 99, 105, 106, 112, 113, 114, 115, 119, 121, 122, 123, 124, 129, 136, 137, 138, 144, 145, 146, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 179, 180, 186, 188, 189, 195, 196, 197, 198, 199], "week": [4, 21, 37, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "explor": [4, 12, 23, 31, 32, 74, 78, 79, 86, 87, 96, 97, 98, 99, 112, 115, 119, 121, 124, 135, 136, 137, 138, 142, 145, 155, 170, 172, 177, 184, 186, 187, 188, 196, 197], "contain": [4, 11, 12, 21, 22, 23, 24, 26, 31, 33, 45, 72, 78, 79, 85, 87, 94, 95, 96, 97, 105, 115, 119, 121, 122, 123, 124, 129, 145, 157, 172, 187, 188, 189, 195, 197], "collect": [4, 12, 21, 22, 23, 61, 63, 67, 73, 74, 78, 79, 96, 129, 161, 169, 170, 171, 172, 173, 180], "motion": [4, 21, 23, 24, 129, 137, 165, 169], "direct": [4, 22, 23, 24, 31, 32, 67, 68, 72, 73, 74, 78, 87, 90, 96, 113, 117, 121, 124, 135, 136, 146, 154, 155, 162, 163, 169, 172, 188, 195, 196], "perform": [4, 12, 21, 22, 23, 24, 29, 31, 32, 33, 63, 67, 68, 72, 79, 94, 99, 105, 106, 110, 115, 117, 119, 121, 122, 123, 131, 137, 138, 144, 146, 163, 169, 170, 172, 173, 180, 186, 187, 188, 189, 195, 196, 198], "reaction": [4, 165], "variou": [4, 67, 78, 79, 85, 86, 94, 95, 96, 97, 98, 99, 110, 122, 124, 144, 151, 161, 172, 179, 189, 197], "83": [4, 79, 169, 189], "214": [4, 81, 191], "author": [4, 12, 24, 105, 106], "strength": [4, 21, 24, 67, 72, 73, 74, 79, 106, 122, 140, 146, 153, 154, 155, 189, 195, 196, 197], "evid": [4, 12, 21, 23, 24, 73, 96, 106, 115, 129, 131, 138, 142, 146, 154, 155, 161, 169, 170, 171], "coher": [4, 131, 169], "prior": [4, 21, 22, 78, 101, 105, 106, 159, 161, 169, 170, 171, 173, 180], "compar": [4, 19, 21, 23, 31, 32, 33, 67, 72, 74, 78, 79, 86, 87, 92, 94, 95, 96, 99, 103, 105, 106, 112, 113, 114, 115, 119, 121, 122, 123, 129, 135, 136, 137, 138, 144, 146, 155, 161, 162, 169, 170, 172, 173, 179, 180, 187, 188, 189, 195, 198, 199], "predict": [4, 12, 21, 22, 23, 24, 31, 32, 33, 69, 72, 74, 78, 79, 87, 94, 97, 98, 99, 101, 103, 106, 117, 121, 122, 123, 124, 129, 131, 136, 137, 138, 169, 171, 172, 179, 180, 182, 188, 189, 191, 198], "bayesian": [4, 19, 37, 90, 101, 157, 159, 163, 170, 171, 172, 191, 193, 199], "observ": [4, 21, 23, 24, 31, 32, 33, 69, 72, 73, 78, 79, 83, 86, 87, 94, 95, 96, 98, 105, 122, 123, 124, 135, 136, 138, 145, 146, 147, 153, 155, 159, 161, 162, 167, 169, 170, 171, 172, 173, 177, 179, 184, 186, 187, 188, 189, 191, 195, 196], "pure": [4, 12, 79, 137, 155, 173], "usual": [4, 12, 21, 23, 24, 83, 105, 121, 129, 144, 153, 173, 186], "pursu": [4, 12, 22], "rel": [4, 12, 21, 23, 24, 26, 31, 33, 63, 79, 85, 87, 99, 121, 122, 123, 129, 136, 147, 161, 162, 171, 187, 189], "do": [4, 12, 19, 21, 22, 23, 24, 26, 31, 32, 33, 37, 44, 45, 61, 68, 69, 74, 78, 79, 83, 85, 87, 88, 92, 94, 95, 96, 97, 98, 99, 105, 112, 114, 115, 119, 121, 122, 123, 124, 127, 129, 135, 137, 138, 144, 146, 147, 151, 153, 154, 155, 157, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 191, 193, 195, 196, 197, 198, 199], "compon": [4, 12, 21, 22, 23, 24, 31, 33, 37, 67, 68, 72, 92, 95, 110, 115, 121, 122, 129, 131, 135, 137, 161, 162, 163, 170, 189, 198], "discuss": [4, 12, 21, 29, 37, 67, 68, 72, 73, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 110, 114, 121, 122, 124, 129, 133, 144, 145, 153, 154, 155, 162, 188, 191, 195, 196], "exampl": [4, 11, 12, 22, 31, 32, 44, 61, 63, 68, 69, 72, 74, 78, 83, 85, 86, 87, 92, 94, 96, 97, 98, 99, 103, 105, 106, 110, 112, 113, 114, 115, 121, 122, 123, 124, 127, 135, 136, 137, 138, 142, 144, 145, 146, 153, 154, 157, 159, 161, 163, 167, 169, 170, 171, 172, 173, 177, 179, 180, 186, 187, 188, 189, 193, 195, 196, 197], "howev": [4, 12, 23, 24, 33, 61, 68, 72, 78, 79, 83, 85, 86, 87, 94, 96, 98, 103, 106, 113, 114, 115, 121, 123, 129, 135, 136, 137, 138, 145, 146, 153, 155, 162, 163, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197], "ani": [4, 12, 21, 22, 23, 24, 31, 32, 45, 61, 67, 68, 69, 72, 73, 78, 79, 83, 85, 87, 92, 95, 98, 99, 105, 106, 113, 114, 115, 117, 121, 122, 123, 124, 129, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 172, 179, 180, 186, 187, 188, 196, 197, 198], "built": [4, 23, 24, 86, 121, 122, 123, 124, 129, 135, 137, 144, 151, 179, 184, 186, 199], "feulner": 4, "clopath": 4, "propos": [4, 12, 73, 74, 83, 86, 96, 144], "how": [4, 12, 21, 22, 23, 24, 31, 32, 33, 45, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 81, 83, 85, 87, 88, 92, 94, 95, 96, 97, 98, 99, 103, 105, 106, 108, 110, 112, 113, 114, 115, 119, 121, 122, 123, 124, 127, 129, 131, 135, 136, 137, 138, 142, 144, 146, 147, 151, 153, 154, 155, 159, 161, 162, 163, 169, 170, 172, 173, 175, 177, 184, 186, 187, 188, 191, 193, 195, 196, 197, 199], "dynam": [4, 12, 21, 22, 31, 37, 63, 72, 73, 74, 78, 79, 83, 86, 92, 101, 103, 117, 136, 137, 138, 142, 144, 145, 147, 149, 151, 154, 155, 159, 161, 165, 167, 170, 173, 175, 177, 184, 186, 188, 196, 197, 198, 199], "link": [4, 21, 23, 37, 39, 45, 67, 79, 99, 106, 124, 129, 131, 146, 155, 162, 163, 193], "connect": [4, 12, 19, 31, 33, 45, 67, 69, 101, 103, 110, 117, 119, 121, 122, 135, 136, 145, 146, 149, 153, 154, 155, 159, 167, 170, 171, 177, 184, 186], "structur": [4, 12, 21, 22, 31, 33, 37, 68, 69, 85, 86, 101, 103, 106, 110, 114, 115, 122, 123, 124, 129, 131, 138, 165, 170, 171, 172, 179, 198, 199], "complex": [4, 12, 22, 33, 72, 73, 78, 79, 86, 92, 97, 98, 99, 105, 106, 117, 119, 121, 123, 131, 135, 142, 144, 153, 155, 161, 163, 165, 184, 186, 188, 189, 199], "cool": [4, 22, 121, 137, 138, 161, 198], "might": [4, 12, 19, 21, 22, 23, 24, 68, 69, 73, 74, 79, 85, 86, 94, 103, 105, 106, 121, 122, 123, 124, 129, 138, 144, 145, 146, 161, 162, 165, 172, 188, 197, 198], "exist": [4, 12, 24, 67, 72, 78, 83, 85, 88, 97, 103, 110, 153, 196], "process": [4, 12, 21, 22, 23, 24, 26, 31, 33, 63, 68, 73, 74, 78, 79, 81, 83, 85, 86, 90, 96, 98, 99, 101, 105, 108, 117, 122, 123, 124, 129, 131, 145, 146, 151, 153, 155, 163, 165, 167, 169, 170, 171, 172, 177, 179, 186, 198, 199], "tool": [4, 12, 22, 26, 31, 32, 33, 83, 85, 92, 97, 110, 119, 129, 138, 146, 162, 173, 193], "name": [4, 12, 21, 29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "descript": [4, 19, 21, 26, 61, 72, 81, 83, 92, 131, 135, 140, 142, 161, 162, 169, 170, 171, 179, 180, 184, 186, 187], "biomodel": 4, "repositori": [4, 22, 117], "mathemat": [4, 12, 22, 23, 24, 61, 67, 72, 73, 74, 78, 81, 85, 90, 97, 103, 121, 135, 137, 140, 142, 144, 146, 153, 159, 162, 163, 169, 170, 171, 172, 179, 191, 195, 197], "biolog": [4, 33, 37, 69, 73, 74, 86, 117, 119, 122, 131, 140, 142, 144, 145, 146, 147, 151, 153, 186, 198, 199], "biomed": [4, 131, 191, 195], "system": [4, 19, 21, 22, 24, 31, 33, 37, 67, 72, 73, 78, 79, 81, 83, 87, 90, 101, 117, 122, 123, 124, 133, 136, 137, 138, 140, 142, 144, 145, 151, 154, 162, 165, 170, 171, 179, 182, 193, 199], "It": [4, 12, 21, 22, 23, 24, 45, 67, 68, 69, 73, 74, 78, 79, 83, 85, 94, 96, 105, 106, 112, 114, 121, 122, 123, 124, 135, 137, 146, 153, 154, 155, 159, 161, 162, 163, 167, 169, 171, 172, 177, 179, 184, 187, 188, 195, 196, 197, 198], "host": [4, 34, 35, 36, 73, 74], "vast": 4, "literatur": [4, 12, 22, 23, 24, 37, 127], "pharmaceut": 4, "relev": [4, 12, 22, 23, 31, 32, 33, 63, 73, 74, 78, 90, 95, 97, 99, 106, 121, 122, 123, 124, 135, 153, 154, 157, 161, 162, 186], "mechanist": [4, 21, 24, 142, 179, 199], "modeldb": 4, "access": [4, 12, 21, 26, 37, 44, 45, 78, 95, 105, 113, 121, 154, 170, 171, 180, 182, 197], "locat": [4, 31, 33, 78, 79, 87, 95, 146, 153, 163, 171, 172, 173, 177, 179, 180, 188, 189], "store": [4, 23, 31, 32, 33, 79, 85, 86, 106, 114, 115, 121, 123, 124, 136, 138, 144, 169, 179, 186, 196], "effici": [4, 12, 31, 32, 63, 94, 97, 121, 122, 123, 137, 146, 173, 175, 184, 198], "retriev": [4, 31, 32, 33, 81, 144, 145, 146, 147, 153, 155], "entri": [4, 79, 85, 87, 105, 170, 197], "sourc": [4, 29, 33, 78, 79, 98, 137, 145, 162, 172, 180, 198], "concis": [4, 12, 31], "citat": 4, "articl": [4, 12, 21, 31, 81, 101, 108, 117, 122, 129, 131, 149, 169, 175, 182], "publish": [4, 73, 74, 191], "open": [4, 12, 22, 39, 44, 96, 105, 106, 121, 122, 123, 124, 136, 146, 153, 170, 172, 189], "share": [4, 12, 31, 33, 37, 63, 67, 85, 87, 106, 122, 123, 129, 145, 161, 162, 171, 175], "collabor": [4, 34, 35, 36, 44, 79], "develop": [4, 12, 21, 22, 85, 95, 98, 106, 113, 121, 122, 127, 129, 137, 138, 142, 145, 146, 151, 153, 157, 163, 172, 173, 186], "crcn": 4, "websit": [4, 43, 122], "marketplac": 4, "forum": [4, 117], "eegbas": 4, "storag": [4, 61, 86], "manag": [4, 67, 147], "eeg": [4, 74, 78, 170, 171, 193, 196], "metadata": 4, "document": [4, 68, 106, 115, 121, 122, 123, 124, 162, 165], "electrophysiolog": [4, 144, 153], "incf": 4, "endors": 4, "nitrc": 4, "neuroimag": [4, 19, 78], "collaboratori": 4, "award": 4, "win": [4, 21, 23, 73], "web": [4, 90, 186], "offer": [4, 26, 83, 106], "comprehens": [4, 61], "ever": [4, 45, 85, 86, 87, 88, 127, 147, 162, 172, 186, 187], "expand": [4, 31, 32, 85, 121, 142], "scope": 4, "neuroinformat": 4, "figshar": 4, "everyth": [4, 21, 79, 85, 97, 105, 161, 162, 172, 198], "openli": 4, "googl": [4, 12, 39, 45, 121, 122, 123, 124, 197], "search": [4, 12, 21, 24, 90, 94, 121, 182, 189, 191, 198], "let": [4, 21, 23, 24, 31, 32, 33, 61, 67, 68, 69, 72, 73, 74, 78, 79, 85, 87, 94, 95, 96, 97, 99, 105, 106, 114, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 187, 188, 189, 195, 196, 197, 198], "specif": [4, 12, 19, 22, 23, 24, 26, 31, 67, 69, 72, 78, 79, 83, 85, 86, 87, 95, 105, 110, 112, 121, 122, 123, 127, 136, 145, 146, 153, 161, 162, 169, 180, 186, 189, 197, 199], "find": [4, 12, 22, 23, 24, 26, 33, 40, 67, 68, 72, 73, 74, 94, 96, 97, 98, 99, 105, 106, 113, 114, 115, 121, 124, 135, 145, 147, 154, 161, 162, 163, 169, 172, 173, 179, 180, 186, 187, 188, 189, 196, 197, 198], "neurovault": 4, "public": [4, 105, 127, 191], "unthreshold": 4, "map": [4, 24, 31, 32, 33, 72, 106, 135, 136, 145, 154, 169, 170, 186, 188, 189], "parcel": 4, "atlas": 4, "mri": [4, 117], "pet": 4, "knowledgespac": 4, "global": [4, 74, 115, 162, 170, 179, 180, 186], "commun": [4, 12, 22, 87, 124, 127, 131, 142, 157, 191], "driven": [4, 72, 86, 131, 140, 144, 146, 147, 153, 199], "encyclopedia": 4, "them": [4, 12, 21, 22, 23, 31, 32, 33, 39, 61, 63, 67, 68, 72, 79, 83, 85, 86, 87, 99, 103, 106, 113, 114, 115, 119, 121, 122, 123, 124, 129, 137, 138, 146, 153, 159, 162, 163, 170, 172, 173, 179, 180, 184, 186, 189, 193, 195, 197, 198, 199], "page": [11, 42, 44, 45, 79, 106, 115], "last": [11, 12, 21, 26, 31, 32, 33, 44, 45, 61, 67, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 131, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "year": [11, 12, 26, 73, 74, 81, 161, 186], "sens": [11, 12, 21, 23, 24, 33, 73, 85, 97, 98, 114, 119, 124, 129, 138, 161, 167, 172, 179, 187, 189], "like": [11, 12, 21, 22, 23, 24, 26, 31, 32, 63, 67, 68, 72, 73, 74, 78, 79, 83, 85, 86, 87, 88, 94, 95, 99, 103, 105, 106, 115, 117, 119, 121, 122, 123, 124, 127, 129, 136, 137, 138, 144, 146, 147, 153, 154, 159, 161, 162, 163, 167, 169, 170, 171, 172, 179, 180, 184, 186, 187, 188, 189, 195, 196, 198], "brainstorm": [11, 12, 21, 23, 24, 129], "idea": [11, 12, 21, 22, 23, 67, 69, 72, 78, 79, 85, 95, 96, 97, 103, 105, 123, 129, 144, 146, 147, 151, 159, 161, 162, 167, 169, 170, 171, 177, 180, 184, 186, 188, 191, 197], "creator": [12, 21, 22, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 85, 86, 87, 88, 91, 94, 95, 96, 97, 98, 99, 102, 105, 106, 109, 112, 113, 114, 115, 118, 121, 122, 123, 124, 126, 129, 132, 135, 136, 137, 138, 141, 144, 145, 146, 147, 150, 153, 154, 155, 158, 161, 162, 163, 166, 169, 170, 171, 172, 173, 176, 179, 180, 183, 186, 187, 188, 189, 192, 195, 196, 197, 198], "scott": [12, 26, 98, 101], "linderman": [12, 26, 131], "courtnei": 12, "dean": 12, "kathryn": 12, "bonnen": 12, "konrad": [12, 36, 85, 86, 87, 88, 129, 163, 195, 196, 197, 198], "kord": [12, 21, 22, 36, 81, 85, 86, 87, 88, 90, 101, 117, 129, 157, 163, 191, 195, 196, 197, 198], "goal": [12, 21, 22, 23, 24, 73, 81, 83, 97, 98, 105, 106, 113, 121, 123, 127, 129, 136, 137, 138, 146, 147, 162, 163, 179, 186, 187, 188, 189, 195], "cours": [12, 23, 24, 31, 32, 33, 43, 45, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 103, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 131, 135, 136, 137, 138, 144, 145, 146, 147, 151, 153, 154, 155, 157, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198, 199], "give": [12, 21, 22, 23, 24, 26, 61, 67, 72, 73, 74, 78, 79, 85, 86, 87, 103, 105, 106, 114, 121, 127, 129, 138, 142, 144, 145, 146, 151, 153, 154, 155, 161, 162, 163, 169, 170, 172, 179, 186, 187, 189, 193, 195, 196], "opportun": [12, 83], "answer": [12, 21, 22, 23, 24, 33, 68, 73, 74, 83, 106, 119, 127, 129, 144, 146, 161, 179, 193, 195, 196, 197, 199], "those": [12, 21, 22, 23, 24, 31, 67, 72, 78, 79, 83, 94, 103, 106, 110, 121, 122, 123, 124, 129, 136, 137, 146, 161, 162, 169, 172, 173, 179, 187, 189], "plan": [12, 127, 129, 163, 177, 182, 186], "explicitli": [12, 23, 24, 78, 85, 92, 123, 127, 157, 159], "encourag": [12, 22, 24, 106, 188], "iter": [12, 31, 32, 33, 61, 63, 99, 121, 123, 124, 127, 173, 180, 186, 197], "natur": [12, 26, 61, 69, 78, 81, 86, 97, 101, 108, 117, 122, 131, 140, 144, 145, 146, 159, 175, 182, 187, 191, 193, 198], "gradual": [12, 31, 136, 146, 170, 179, 186], "refin": [12, 23], "hypothes": [12, 22, 83, 121, 127, 161, 163, 169, 186], "As": [12, 21, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 94, 97, 98, 99, 106, 112, 113, 121, 122, 123, 124, 129, 136, 137, 138, 144, 146, 153, 155, 161, 162, 163, 169, 170, 171, 172, 186, 188, 189, 196, 197, 198], "part": [12, 21, 22, 23, 24, 31, 33, 72, 78, 85, 86, 87, 95, 97, 103, 105, 106, 121, 122, 123, 129, 135, 137, 138, 153, 154, 155, 161, 162, 173, 180, 187, 188, 189, 193, 195], "experi": [12, 21, 22, 23, 24, 26, 31, 32, 33, 45, 73, 74, 78, 79, 85, 103, 105, 106, 114, 121, 129, 138, 155, 161, 162, 163, 169, 171, 172, 184, 186, 189, 193], "deal": [12, 32, 61, 63, 73, 74, 92, 94, 95, 161, 162], "often": [12, 21, 22, 23, 24, 31, 33, 68, 72, 78, 79, 83, 85, 87, 95, 97, 98, 99, 103, 114, 119, 121, 122, 124, 129, 137, 146, 153, 155, 161, 162, 163, 167, 169, 170, 171, 172, 173, 179, 186, 187, 188, 191, 193, 196, 199], "big": [12, 37, 69, 72, 74, 78, 97, 121, 135, 153, 155, 162, 172, 188, 189, 195, 196, 198, 199], "challeng": [12, 19, 32, 33, 95, 121, 172, 173, 180, 187, 188], "its": [12, 21, 22, 23, 31, 61, 67, 69, 72, 74, 78, 79, 85, 86, 87, 92, 94, 95, 99, 105, 106, 113, 114, 121, 122, 123, 124, 131, 135, 136, 137, 140, 144, 146, 147, 153, 154, 155, 162, 163, 167, 171, 172, 173, 179, 180, 186, 187, 188, 189, 191, 196], "when": [12, 21, 22, 23, 24, 31, 32, 33, 45, 61, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 88, 92, 94, 95, 97, 98, 99, 103, 105, 106, 112, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 144, 145, 146, 147, 153, 154, 155, 161, 162, 169, 170, 171, 172, 179, 180, 184, 186, 188, 193, 195, 196, 197, 198, 199], "conduct": [12, 43, 73, 74, 78, 101, 131, 140, 144, 145, 161], "assign": [12, 31, 32, 33, 78, 85, 87, 94, 97, 98, 99, 105, 122, 123, 124, 163, 193], "broad": [12, 171, 184, 186, 193, 199], "fmri": [12, 78, 106, 193, 196], "ecog": 12, "theori": [12, 21, 68, 87, 90, 98, 106, 129, 157, 175, 179, 189], "With": [12, 69, 72, 73, 78, 97, 142, 155, 162, 169, 170, 186, 189], "help": [12, 21, 22, 26, 31, 32, 33, 39, 40, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 119, 121, 122, 123, 124, 129, 138, 144, 145, 146, 147, 151, 153, 154, 155, 161, 162, 163, 167, 170, 172, 173, 179, 180, 184, 188, 189, 198, 199], "each": [12, 13, 21, 22, 23, 24, 26, 31, 32, 33, 37, 39, 42, 44, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 83, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 119, 121, 122, 123, 124, 127, 129, 135, 136, 137, 138, 142, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "split": [12, 21, 23, 31, 32, 33, 87, 99, 106, 122, 123, 124, 129, 187], "balanc": [12, 83, 86, 87, 98, 151, 187, 188, 189], "onc": [12, 21, 22, 23, 24, 45, 69, 74, 79, 85, 86, 96, 99, 103, 114, 115, 121, 123, 124, 129, 136, 146, 154, 172, 173, 180, 186, 187, 188, 189, 195, 198, 199], "paper": [12, 19, 24, 68, 73, 74, 81, 87, 101, 115, 129, 140, 144, 145, 154, 155, 161, 165, 196], "form": [12, 21, 23, 29, 31, 32, 33, 43, 61, 67, 69, 72, 73, 74, 78, 86, 87, 92, 94, 97, 105, 106, 110, 112, 113, 121, 123, 124, 135, 137, 138, 145, 159, 161, 162, 163, 171, 172, 173, 180, 186, 187, 196, 197, 198], "try": [12, 21, 24, 26, 31, 32, 45, 67, 68, 69, 72, 73, 78, 79, 85, 87, 94, 95, 96, 98, 105, 106, 114, 115, 121, 122, 123, 124, 129, 135, 136, 138, 144, 145, 146, 147, 154, 155, 161, 162, 163, 171, 172, 179, 180, 186, 187, 188, 189, 197, 198], "preliminari": [12, 21, 180], "dataset": [12, 21, 23, 79, 83, 87, 94, 95, 97, 105, 106, 114, 115, 119, 121, 122, 123, 129, 138, 163, 172, 173], "dedic": [12, 26], "teach": [12, 31, 103, 171, 177, 193], "strategi": [12, 21, 69, 87, 136, 137, 169, 179, 187, 188, 189, 193, 195], "approach": [12, 21, 22, 23, 24, 31, 72, 79, 94, 95, 96, 97, 99, 103, 106, 119, 123, 124, 127, 138, 153, 154, 157, 159, 161, 162, 163, 172, 173, 179, 184, 186, 188, 191, 193], "appli": [12, 22, 23, 31, 32, 63, 69, 72, 74, 79, 85, 87, 92, 95, 97, 99, 105, 106, 114, 119, 121, 122, 123, 129, 131, 145, 153, 155, 159, 162, 172, 180, 186, 188, 191, 195, 196, 197, 198, 199], "rest": [12, 63, 73, 74, 79, 85, 86, 87, 97, 98, 99, 121, 124, 129, 144, 146, 155, 195, 197, 199], "second": [12, 21, 23, 24, 31, 34, 61, 63, 67, 69, 72, 73, 74, 78, 79, 85, 86, 87, 103, 105, 106, 110, 112, 113, 114, 115, 119, 121, 122, 123, 124, 129, 135, 137, 138, 142, 145, 146, 151, 153, 154, 155, 161, 169, 171, 172, 173, 179, 180, 186, 189, 197, 198], "continu": [12, 21, 61, 63, 69, 72, 74, 79, 85, 86, 87, 92, 99, 137, 138, 145, 154, 159, 161, 167, 169, 171, 173, 177, 189], "analyz": [12, 23, 24, 26, 33, 115, 122, 123, 137, 163, 195, 199], "result": [12, 21, 22, 23, 24, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 81, 83, 85, 87, 94, 95, 97, 105, 112, 115, 121, 122, 123, 124, 136, 137, 138, 144, 145, 146, 155, 162, 163, 169, 171, 172, 179, 180, 186, 187, 188, 189, 195, 197, 199], "least": [12, 24, 67, 69, 79, 95, 96, 98, 99, 105, 121, 124, 137, 155, 172, 179, 196], "testabl": [12, 22], "hypothesi": [12, 22, 23, 24, 61, 85, 92, 96, 123, 198], "swap": [12, 31, 37, 61, 197], "receiv": [12, 22, 33, 63, 86, 122, 144, 145, 146, 153, 162, 179, 184, 186, 187, 188, 189, 195], "focu": [12, 22, 61, 67, 68, 69, 78, 79, 85, 86, 95, 97, 106, 112, 121, 123, 127, 135, 144, 146, 147, 151, 161, 162, 172, 179, 189, 195, 196, 197, 198, 199], "against": [12, 22, 24, 92, 94, 103, 137, 138, 154, 180, 193, 198], "other": [12, 21, 22, 23, 24, 31, 33, 37, 44, 61, 67, 69, 72, 73, 74, 78, 79, 81, 85, 86, 87, 88, 95, 99, 103, 105, 106, 115, 119, 121, 122, 123, 124, 129, 136, 137, 138, 142, 144, 145, 146, 147, 153, 154, 155, 159, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 184, 186, 187, 188, 189, 191, 193, 195, 196, 197, 198], "megapod": 12, "organ": [12, 31, 33, 61, 63, 85, 105, 117, 129, 131], "lead": [12, 21, 24, 32, 63, 68, 73, 79, 95, 121, 123, 145, 147, 151, 153, 155, 161, 169, 180, 186, 187, 188, 189], "tell": [12, 22, 68, 72, 79, 85, 92, 95, 99, 103, 106, 119, 121, 123, 124, 129, 136, 153, 161, 162, 172, 180, 196], "stori": [12, 179], "low": [12, 31, 72, 85, 98, 106, 110, 114, 115, 123, 131, 144, 146, 161, 162, 165, 169, 170, 172, 179, 180, 186], "kei": [12, 22, 23, 24, 33, 63, 67, 94, 95, 97, 98, 99, 110, 112, 119, 121, 123, 162, 167, 189, 198, 199], "wai": [12, 21, 22, 23, 24, 31, 32, 61, 67, 68, 72, 73, 74, 78, 79, 83, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 103, 105, 110, 112, 114, 119, 121, 122, 123, 124, 127, 129, 131, 136, 137, 138, 145, 146, 147, 153, 159, 161, 162, 163, 172, 180, 187, 188, 189, 191, 193, 195, 196, 198], "meant": [12, 23, 24, 119, 121, 122], "product": [12, 21, 22, 24, 31, 32, 33, 61, 63, 68, 69, 73, 74, 78, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 189, 196, 197, 198], "valu": [12, 21, 22, 23, 24, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 78, 79, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 135, 137, 138, 145, 146, 147, 151, 161, 162, 163, 165, 169, 170, 171, 172, 173, 175, 180, 182, 184, 188, 189, 195, 196, 197, 198], "airtabl": [12, 43], "conjunct": 12, "varieti": [12, 21, 23, 67, 68, 119, 122, 129, 135], "starter": 12, "just": [12, 19, 21, 22, 24, 33, 37, 67, 68, 69, 72, 74, 78, 79, 85, 86, 87, 94, 95, 96, 98, 99, 103, 105, 106, 112, 114, 121, 122, 123, 124, 129, 135, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 187, 188, 189, 195, 196, 197, 198, 199], "keyword": [12, 31, 32, 105, 124, 163], "reus": [12, 63, 79, 88, 170, 179], "extens": [12, 31, 33, 78, 97, 106, 112, 162, 186, 187, 189], "don": [12, 21, 22, 24, 45, 66, 67, 73, 77, 79, 85, 86, 87, 97, 98, 99, 105, 106, 113, 114, 115, 121, 124, 127, 129, 145, 161, 162, 163, 170, 171, 172, 173, 179, 186, 187, 195, 196, 197, 198], "design": [12, 19, 21, 23, 26, 33, 63, 73, 74, 98, 99, 129, 172], "enough": [12, 21, 22, 61, 85, 94, 98, 105, 121, 162, 169, 179, 189, 196, 198], "option": [12, 21, 22, 23, 29, 31, 32, 33, 37, 45, 61, 63, 68, 72, 78, 79, 106, 119, 121, 122, 124, 129, 135, 146, 153, 161, 162, 163, 169, 171, 172, 173, 179, 180, 187, 196, 197, 198, 199], "keep": [12, 21, 22, 31, 32, 33, 61, 63, 69, 72, 74, 85, 98, 106, 114, 123, 129, 131, 135, 136, 144, 146, 161, 162, 163, 169, 172, 173, 177, 179, 180, 186, 187], "stick": [12, 22, 187], "Or": [12, 21, 22, 123, 129], "diverg": [12, 153, 155], "test": [12, 21, 31, 32, 33, 61, 72, 78, 79, 83, 87, 92, 99, 105, 106, 112, 121, 122, 123, 129, 138, 140, 147, 163, 172, 179, 180, 186, 188, 189, 198], "flow": [12, 22, 61, 73, 146], "easi": [12, 22, 72, 73, 112, 121, 162, 187, 195, 196, 198], "hard": [12, 21, 22, 23, 78, 197, 199], "hesit": 12, "skip": [12, 61, 63, 115, 121, 122, 124, 169, 186], "complet": [12, 21, 31, 32, 33, 37, 63, 66, 67, 68, 69, 72, 74, 77, 78, 79, 85, 98, 99, 101, 105, 106, 112, 113, 115, 117, 121, 122, 123, 124, 127, 129, 131, 135, 136, 137, 144, 145, 146, 147, 161, 163, 169, 170, 171, 173, 179, 180, 186, 189, 195, 196, 197, 198, 199], "flexibl": [12, 22, 63, 95, 106, 117, 119, 121, 162], "friendli": [12, 26], "expert": [12, 199], "consult": [12, 21, 72, 73, 105, 189, 195], "issu": [12, 23, 24, 29, 31, 33, 74, 135, 161, 172], "aspect": [12, 21, 22, 31, 32, 33, 61, 63, 72, 83, 85, 95, 121, 124, 129, 137, 149, 172, 188, 189, 198], "approxim": [12, 31, 61, 63, 72, 78, 79, 85, 114, 119, 121, 135, 140, 153, 155, 161, 162, 172, 197], "someth": [12, 21, 22, 23, 24, 61, 72, 73, 74, 85, 87, 88, 105, 106, 122, 123, 145, 151, 161, 162, 163, 171, 186, 187, 199], "sometim": [12, 22, 24, 31, 61, 67, 68, 72, 73, 78, 79, 99, 103, 113, 136, 137, 161, 162, 172, 186, 187, 189, 193, 196, 197], "arriv": [12, 69, 86, 87, 94, 95, 96, 146, 147, 161, 171], "unannounc": 12, "late": [12, 122, 157], "earli": [12, 22, 117, 122, 154, 186], "busi": [12, 68], "stop": [12, 21, 23, 61, 63, 105, 129, 144, 173, 187], "were": [12, 21, 22, 23, 31, 72, 79, 85, 86, 87, 99, 105, 119, 121, 122, 123, 124, 129, 138, 145, 146, 147, 161, 162, 169, 170, 172, 173, 179, 180, 184, 186, 196, 198, 199], "resum": 12, "leav": [12, 67, 86, 96, 123, 145, 153, 161, 169], "earlier": [12, 61, 68, 72, 105, 135, 137, 161, 186], "later": [12, 21, 24, 61, 68, 69, 72, 73, 74, 78, 79, 86, 112, 121, 122, 127, 129, 138, 145, 153, 161, 162, 167, 173, 177, 179, 180, 188, 195], "reach": [12, 23, 24, 32, 78, 85, 86, 95, 114, 131, 137, 144, 146, 147, 153, 154, 155, 169, 180], "out": [12, 21, 22, 23, 24, 31, 32, 37, 40, 44, 61, 63, 68, 69, 72, 73, 78, 79, 85, 86, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 121, 122, 123, 124, 129, 135, 136, 138, 144, 145, 146, 147, 151, 153, 155, 157, 161, 162, 163, 169, 171, 172, 173, 177, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198, 199], "extra": [12, 22, 79, 97, 121, 144, 155, 169, 173, 186, 189, 195], "whenev": [12, 63, 106, 123, 147, 179, 186, 189], "post": [12, 37, 69, 72, 85, 87, 88, 117, 138, 145, 146, 147], "channel": [12, 63, 73, 122, 123, 124, 136, 146, 170, 173], "coupl": [12, 67, 69, 74, 79, 87, 146, 153, 154, 155, 162], "throughout": [12, 21, 69, 78, 92, 94, 112, 129, 136, 145, 147, 151, 153, 162, 180, 186, 196, 199], "three": [12, 23, 31, 33, 61, 73, 74, 79, 83, 85, 87, 94, 105, 106, 119, 121, 123, 124, 151, 153, 154, 155, 162, 170, 172, 173, 179, 197, 198], "field": [12, 19, 21, 22, 85, 86, 87, 101, 103, 105, 122, 123, 124, 129, 153, 155, 157, 162, 189, 193, 198, 199], "about": [12, 22, 23, 24, 31, 33, 45, 61, 63, 68, 69, 74, 78, 79, 83, 85, 86, 87, 92, 95, 96, 98, 103, 105, 110, 113, 114, 119, 121, 122, 123, 124, 127, 135, 136, 137, 138, 142, 144, 145, 146, 147, 151, 153, 154, 155, 159, 161, 162, 163, 167, 169, 170, 171, 172, 177, 179, 180, 184, 186, 187, 188, 189, 191, 193, 195, 196, 197, 199], "scientif": [12, 21, 22, 23, 24, 61, 81, 85, 117, 129, 175, 180], "step": [12, 23, 24, 31, 32, 33, 61, 63, 67, 68, 69, 73, 78, 79, 85, 86, 87, 94, 99, 105, 106, 112, 113, 114, 115, 121, 123, 124, 127, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 165, 167, 169, 170, 171, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198, 199], "intention": [12, 187], "creat": [12, 21, 22, 23, 24, 31, 33, 45, 61, 63, 67, 72, 79, 85, 87, 94, 96, 97, 98, 99, 106, 119, 121, 122, 123, 129, 135, 145, 147, 154, 161, 162, 163, 170, 172, 173, 179, 186, 195, 197, 198], "skillset": 12, "who": [12, 22, 197], "confid": [12, 94, 95, 97, 98, 99, 170, 171, 191], "learn": [12, 21, 22, 23, 24, 26, 31, 32, 33, 37, 44, 45, 61, 63, 67, 68, 72, 73, 78, 83, 85, 86, 87, 90, 92, 94, 95, 96, 97, 98, 99, 101, 103, 105, 108, 110, 112, 113, 114, 115, 119, 121, 123, 124, 127, 129, 131, 135, 136, 138, 140, 142, 144, 145, 146, 147, 151, 153, 154, 155, 157, 159, 161, 162, 163, 167, 169, 170, 171, 172, 175, 177, 179, 180, 182, 184, 193, 195, 196, 197, 198, 199], "togeth": [12, 22, 23, 24, 37, 67, 68, 72, 79, 85, 95, 96, 98, 105, 115, 121, 122, 123, 124, 129, 145, 147, 155, 161, 173, 188, 195], "strengthen": [12, 131, 147], "skill": [12, 21, 79], "member": 12, "chanc": [12, 21, 37, 78, 79, 138, 147, 161, 179], "folk": [12, 103], "handoff": 12, "peer": [12, 22], "improv": [12, 22, 31, 32, 33, 61, 63, 74, 86, 117, 121, 122, 129, 161, 171, 186, 189, 196], "15": [12, 37, 61, 63, 67, 68, 69, 72, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 101, 105, 106, 112, 113, 114, 115, 117, 121, 122, 123, 124, 129, 131, 135, 137, 138, 145, 146, 147, 153, 154, 155, 161, 162, 163, 165, 170, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "min": [12, 21, 23, 31, 32, 33, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "introduct": [12, 22, 97, 135, 136, 182], "sai": [12, 22, 37, 67, 68, 72, 73, 78, 79, 87, 92, 95, 99, 123, 124, 135, 136, 161, 162, 169, 187, 195, 198], "few": [12, 23, 24, 31, 32, 33, 61, 63, 69, 73, 74, 79, 85, 105, 114, 115, 121, 122, 123, 124, 138, 142, 144, 145, 147, 159, 161, 171, 172, 186, 196, 197], "thing": [12, 21, 67, 69, 79, 95, 103, 124, 129, 135, 137, 146, 165, 167, 172, 173, 187, 189, 196, 197, 198, 199], "area": [12, 19, 26, 31, 33, 63, 67, 69, 72, 78, 79, 83, 86, 87, 119, 121, 122, 123, 124, 131, 145, 146, 169, 184, 186, 189, 196, 199], "curiou": [12, 85, 146, 195], "listen": [12, 34, 35, 36, 73, 74], "carefulli": [12, 22, 135, 186, 195, 199], "20": [12, 24, 26, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 101, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 131, 135, 136, 137, 144, 145, 146, 147, 153, 154, 155, 161, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "brows": 12, "booklet": [12, 21, 22], "skim": 12, "entir": [12, 26, 85, 96, 122, 129, 136, 137, 138, 153, 154, 163, 172, 180, 188, 197], "slide": [12, 69, 122, 144], "doc": [12, 31, 43, 44, 98], "further": [12, 22, 23, 31, 32, 72, 73, 74, 79, 94, 98, 99, 105, 110, 121, 122, 124, 129, 135, 137, 161, 162, 169, 172, 187, 188, 189], "60": [12, 21, 23, 31, 72, 73, 79, 105, 121, 124, 129, 136, 145, 146, 147, 179, 188, 189], "within": [12, 21, 22, 23, 24, 61, 67, 78, 85, 87, 96, 106, 121, 122, 123, 124, 136, 147, 186, 188, 195, 196, 198, 199], "choos": [12, 22, 33, 68, 72, 78, 79, 83, 87, 94, 95, 96, 97, 98, 99, 114, 121, 124, 135, 137, 146, 155, 161, 162, 169, 171, 172, 175, 177, 179, 188, 189, 199], "concret": [12, 21, 121, 123, 129, 136, 195], "either": [12, 23, 26, 31, 32, 33, 69, 72, 79, 85, 86, 87, 92, 96, 99, 136, 146, 153, 154, 162, 169, 170, 179, 188, 195], "yourselv": [12, 129, 172], "directli": [12, 31, 44, 61, 85, 87, 95, 113, 122, 123, 124, 136, 162, 167, 170, 171, 172, 177, 179, 188, 195, 197, 199], "tip": [12, 22, 67, 95, 180, 187], "No": [12, 21, 29, 30, 31, 32, 33, 37, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "after": [12, 21, 22, 23, 31, 32, 45, 61, 63, 66, 67, 68, 69, 77, 78, 79, 85, 86, 87, 94, 95, 97, 98, 103, 112, 113, 114, 117, 121, 123, 124, 129, 136, 138, 145, 146, 147, 154, 155, 162, 169, 171, 173, 179, 186, 187, 188, 189, 195, 196, 197, 198, 199], "feasibl": [12, 96, 121], "That": [12, 21, 22, 23, 31, 68, 69, 72, 85, 87, 105, 106, 121, 122, 127, 129, 138, 144, 147, 153, 154, 155, 161, 162, 163, 196], "culmin": [12, 123], "peek": [12, 61, 137], "plai": [12, 21, 22, 31, 63, 67, 69, 72, 73, 79, 85, 86, 106, 114, 124, 129, 145, 161, 162, 169, 170, 179, 180, 186, 187], "One": [12, 32, 63, 67, 73, 86, 87, 96, 97, 98, 99, 106, 114, 121, 122, 123, 124, 137, 142, 154, 157, 162, 170, 172, 187, 188, 198], "sort": [12, 33, 67, 85, 97, 105, 112, 113, 114, 121, 124, 131, 145, 173, 195, 199], "actual": [12, 21, 22, 23, 24, 61, 72, 78, 79, 87, 96, 97, 99, 105, 121, 122, 123, 124, 129, 138, 162, 169, 171, 172, 179, 186, 187, 188, 196, 197, 198], "There": [12, 21, 22, 23, 24, 31, 63, 72, 78, 79, 85, 86, 87, 99, 106, 119, 121, 122, 145, 146, 154, 157, 161, 162, 167, 169, 171, 179, 180, 186, 189, 193, 198], "interspers": 12, "among": [12, 32, 33, 87, 175, 187], "even": [12, 24, 31, 33, 61, 67, 68, 69, 73, 74, 78, 85, 87, 94, 103, 105, 106, 119, 121, 122, 123, 131, 136, 137, 146, 147, 154, 159, 162, 163, 169, 170, 172, 179, 187, 188, 189, 191, 195, 197, 198], "especi": [12, 22, 45, 68, 79, 94, 99, 122, 144, 161, 172, 199], "being": [12, 61, 69, 72, 78, 79, 87, 94, 106, 113, 121, 122, 123, 124, 136, 162, 163, 169, 172, 180], "axi": [12, 21, 23, 31, 32, 33, 61, 63, 67, 68, 69, 72, 74, 78, 79, 86, 106, 112, 113, 114, 122, 123, 124, 129, 135, 137, 138, 146, 153, 154, 161, 162, 163, 169, 170, 171, 173, 179, 180, 187, 188, 189, 195, 196, 197, 198], "y": [12, 21, 23, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 94, 95, 96, 97, 98, 99, 101, 105, 106, 108, 112, 113, 114, 115, 117, 121, 122, 123, 124, 129, 131, 135, 137, 140, 145, 149, 153, 155, 161, 162, 163, 165, 171, 172, 173, 179, 180, 182, 186, 188, 189, 195, 196, 197, 198], "Is": [12, 22, 72, 73, 74, 79, 85, 94, 105, 106, 115, 123, 145, 146, 186], "pai": [12, 73, 74, 146, 179, 187, 188, 189], "attent": [12, 73, 74, 146, 149, 155, 180, 189], "bin": [12, 21, 23, 31, 63, 69, 78, 79, 85, 86, 87, 96, 105, 121, 122, 123, 124, 137, 144, 145, 147, 171, 173, 179], "align": [12, 21, 23, 24, 32, 61, 67, 68, 69, 72, 73, 74, 78, 79, 86, 87, 94, 95, 96, 97, 105, 106, 112, 113, 114, 121, 123, 124, 144, 145, 153, 154, 155, 161, 162, 169, 170, 171, 172, 173, 180, 186, 197, 198], "element": [12, 22, 23, 31, 32, 33, 61, 63, 67, 68, 72, 73, 85, 86, 97, 98, 105, 106, 113, 114, 121, 123, 127, 135, 136, 137, 138, 155, 161, 163, 170, 172, 173, 179, 187, 191, 195, 196, 197, 198], "small": [12, 21, 23, 61, 63, 66, 69, 72, 73, 77, 78, 79, 85, 86, 95, 106, 121, 122, 123, 124, 129, 135, 137, 138, 145, 146, 151, 153, 161, 169, 172, 180, 186, 189, 197], "appear": [12, 63, 67, 69, 85, 105, 106, 114, 115, 121, 122, 123, 124, 145, 172, 186, 188, 189, 196], "Be": [12, 21, 22, 67, 78, 85, 198], "lookout": 12, "notic": [12, 21, 22, 23, 24, 31, 61, 72, 79, 103, 106, 121, 123, 136, 137, 138, 144, 145, 147, 153, 155, 180, 186, 188, 189, 197], "unexpect": 12, "dig": [12, 21], "deeper": [12, 21, 61, 103, 113, 121, 122, 146, 155], "must": [12, 22, 68, 73, 79, 85, 86, 87, 99, 113, 115, 121, 124, 136, 161, 169, 170, 180, 187, 188, 189, 197, 198], "mind": [12, 21, 22, 31, 61, 73, 74, 98, 106, 129, 162], "trick": [12, 73, 79, 121, 123, 173], "hardest": [12, 21, 83, 129], "technic": [12, 32, 67, 68, 122, 179, 186], "wrestl": 12, "easier": [12, 21, 22, 31, 61, 124, 127, 129, 138, 163, 171, 180], "equal": [12, 23, 31, 61, 67, 68, 69, 72, 74, 78, 79, 86, 87, 94, 95, 106, 112, 113, 115, 123, 137, 144, 153, 161, 162, 169, 171, 173, 179, 180, 186, 187, 195, 196, 197, 198], "network": [12, 19, 29, 31, 32, 33, 37, 73, 74, 79, 81, 83, 92, 101, 108, 110, 119, 131, 140, 142, 146, 147, 151, 154, 182, 191, 195, 197, 198, 199], "simul": [12, 21, 22, 23, 24, 63, 69, 73, 74, 78, 79, 81, 86, 92, 94, 95, 96, 97, 98, 99, 112, 129, 135, 136, 138, 145, 155, 163, 172, 179, 180, 186, 187, 189, 197], "still": [12, 21, 24, 26, 31, 32, 67, 69, 79, 85, 86, 94, 96, 97, 121, 122, 124, 129, 131, 136, 146, 153, 157, 179, 180, 187, 195, 197, 198], "becom": [12, 31, 33, 68, 69, 72, 73, 74, 79, 87, 137, 144, 146, 155, 170, 171, 173, 180, 196, 197, 198], "opposit": [12, 31, 67, 72, 121, 146, 169, 195, 196, 198], "happen": [12, 22, 44, 68, 69, 72, 73, 74, 78, 85, 86, 97, 105, 106, 112, 113, 124, 135, 144, 145, 146, 147, 151, 153, 154, 155, 161, 162, 169, 171, 179, 180, 186, 195, 196, 199], "realiz": [12, 61, 63, 145, 146], "alwai": [12, 22, 23, 24, 31, 32, 67, 68, 69, 72, 74, 79, 85, 87, 94, 95, 96, 97, 103, 121, 123, 136, 145, 146, 147, 153, 154, 155, 159, 161, 170, 179, 187, 188, 189, 198], "bug": 12, "too": [12, 21, 22, 23, 24, 73, 78, 79, 85, 86, 98, 105, 106, 113, 121, 129, 162, 172, 180, 186, 187, 189, 196, 197], "true": [12, 21, 23, 24, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 169, 170, 172, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "train": [12, 21, 22, 99, 105, 115, 117, 119, 121, 122, 123, 127, 129, 138, 140, 144, 146, 147, 186], "simpl": [12, 22, 23, 24, 31, 32, 61, 67, 69, 72, 73, 78, 79, 81, 85, 86, 87, 90, 92, 94, 95, 96, 97, 98, 99, 103, 105, 106, 110, 112, 119, 121, 122, 123, 127, 135, 136, 138, 140, 142, 144, 145, 146, 147, 149, 154, 159, 161, 162, 163, 165, 167, 170, 179, 184, 186, 187, 188, 189, 195, 197, 198, 199], "where": [12, 21, 22, 23, 24, 31, 44, 45, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 97, 98, 99, 105, 106, 110, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 159, 162, 163, 167, 169, 170, 171, 172, 173, 177, 180, 184, 186, 187, 188, 189, 193, 195, 197, 198], "matter": [12, 21, 22, 24, 31, 63, 67, 79, 106, 121, 129, 146, 153, 155, 161, 162, 191, 198], "tune": [12, 101, 119, 121, 122, 149, 175], "curv": [12, 21, 23, 72, 73, 79, 85, 97, 101, 105, 106, 121, 122, 144, 145, 155, 170, 171, 173, 180], "doe": [12, 21, 22, 23, 24, 26, 29, 33, 44, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 92, 95, 96, 105, 106, 112, 114, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 186, 187, 188, 189, 193, 195, 196, 197, 198], "rememb": [12, 21, 22, 67, 68, 69, 72, 78, 79, 87, 106, 113, 121, 124, 129, 135, 136, 138, 144, 145, 161, 162, 173, 179, 180, 187, 189, 195, 196, 198], "quick": [12, 87, 108, 162, 196], "survei": [12, 21, 37, 90], "thought": [12, 21, 31, 68, 72, 88, 122, 124, 127, 129, 159, 173, 186, 187, 191], "past": [12, 74, 105, 117, 138, 170, 171, 172, 173, 179, 189], "origin": [12, 22, 24, 31, 32, 33, 63, 67, 68, 69, 72, 73, 85, 94, 95, 96, 97, 112, 113, 114, 142, 155, 162, 163, 172, 173, 187, 197], "situat": [12, 67, 72, 95, 97, 106, 122, 161, 162, 169, 179, 180, 186, 189, 196], "hint": [12, 21, 72, 78, 79, 85, 87, 96, 97, 98, 105, 106, 113, 114, 121, 124, 129, 135, 136, 137, 144, 146, 153, 155, 161, 162, 163, 169, 170, 173, 179, 186, 198], "suggest": [12, 24, 63, 72, 85, 96, 97, 106, 114, 115, 163, 169, 173], "depend": [12, 21, 22, 24, 29, 31, 33, 63, 69, 74, 78, 79, 83, 85, 86, 92, 94, 95, 96, 97, 98, 99, 105, 106, 115, 121, 122, 127, 129, 131, 136, 137, 138, 142, 144, 145, 146, 154, 155, 161, 162, 163, 169, 170, 171, 180, 186, 195], "could": [12, 21, 22, 23, 24, 31, 33, 68, 69, 72, 73, 74, 78, 79, 81, 83, 85, 86, 87, 92, 97, 99, 105, 110, 112, 115, 121, 122, 123, 124, 129, 145, 147, 153, 159, 161, 162, 163, 170, 171, 172, 179, 180, 186, 187, 197, 198], "sever": [12, 23, 31, 32, 63, 67, 68, 72, 78, 85, 94, 99, 103, 106, 110, 121, 122, 142, 146, 147, 151, 153, 155, 162, 173, 180, 186, 189, 199], "wrangl": 12, "simpli": [12, 21, 24, 69, 72, 74, 85, 87, 95, 106, 121, 123, 124, 138, 144, 157, 172, 179, 187, 189, 198], "right": [12, 21, 22, 23, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 87, 94, 96, 98, 99, 105, 106, 121, 122, 123, 124, 129, 136, 137, 146, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 187, 188, 189, 195, 196, 197, 198], "psth": 12, "scatter": [12, 21, 23, 63, 69, 73, 74, 78, 94, 95, 96, 97, 106, 112, 113, 115, 123, 129, 135, 138, 163, 170, 171, 172, 195, 196, 197, 198], "differ": [12, 19, 21, 22, 23, 24, 31, 32, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 83, 85, 86, 92, 94, 95, 96, 98, 99, 103, 105, 112, 113, 121, 122, 123, 124, 127, 129, 135, 136, 137, 138, 145, 147, 153, 155, 157, 161, 163, 169, 170, 171, 172, 173, 180, 187, 188, 189, 191, 195, 196, 197, 198], "across": [12, 19, 21, 23, 24, 26, 61, 68, 73, 78, 83, 85, 86, 87, 94, 98, 106, 112, 113, 117, 121, 122, 123, 124, 131, 146, 147, 161, 163, 169, 172, 173, 179, 186, 188, 189, 193], "most": [12, 19, 22, 26, 31, 61, 63, 67, 69, 72, 73, 74, 78, 79, 83, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 117, 119, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 177, 179, 180, 184, 186, 187, 188, 189, 195, 196, 197, 198, 199], "session": [12, 33, 34, 35, 36, 37, 45, 85, 188, 189], "pick": [12, 23, 72, 79, 94, 99, 106, 121, 123, 124, 179, 187, 199], "qualiti": [12, 33, 79, 96, 98, 99, 172, 179, 196, 198], "deep": [12, 19, 22, 29, 31, 33, 37, 45, 81, 83, 92, 103, 110, 119, 124, 182, 184, 186, 199], "stage": [12, 21], "popul": [12, 19, 23, 26, 67, 68, 72, 85, 92, 101, 103, 110, 112, 119, 121, 122, 123, 124, 131, 147, 149, 151, 155, 175, 195], "voxel": [12, 19, 106], "encod": [12, 31, 32, 33, 67, 101, 103, 106, 119, 121, 122, 131, 173, 196, 199], "certain": [12, 21, 23, 33, 72, 73, 74, 79, 86, 87, 106, 129, 136, 144, 145, 155, 162, 169, 170, 172, 179, 187, 188, 189, 196], "By": [12, 21, 22, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 67, 68, 69, 72, 73, 78, 79, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 159, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "far": [12, 21, 23, 69, 95, 97, 113, 121, 129, 135, 137, 147, 154, 162, 187], "regress": [12, 21, 23, 92, 96, 98, 99, 103, 110, 121, 123, 129, 138, 193, 195, 196], "pca": [12, 32, 33, 110, 112, 123], "cluster": [12, 31, 32, 85, 115], "binari": [12, 21, 24, 31, 32, 33, 78, 79, 92, 106, 122, 138, 145, 146, 147, 159, 162, 167, 169, 173, 177, 179, 180, 196, 198], "categor": [12, 78, 79, 117, 123], "pipelin": [12, 21, 23, 129, 163], "switch": [12, 31, 67, 79, 121, 131, 170, 173, 179], "predictor": [12, 138], "scikit": [12, 23, 31, 99, 197, 198], "reduc": [12, 31, 32, 79, 87, 99, 106, 113, 114, 117, 121, 122, 155, 163, 172, 180, 186], "kind": [12, 19, 21, 23, 73, 78, 83, 88, 99, 105, 114, 121, 123, 127, 135, 144, 146, 162, 180, 186, 187, 193], "pc": 12, "size": [12, 21, 24, 31, 32, 33, 63, 67, 68, 73, 74, 78, 79, 96, 99, 105, 112, 113, 114, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 169, 170, 173, 179, 186, 187, 195, 197, 198], "averag": [12, 19, 21, 23, 24, 72, 74, 78, 79, 85, 86, 94, 99, 103, 105, 106, 121, 122, 123, 124, 129, 136, 137, 144, 145, 146, 147, 151, 153, 154, 155, 161, 162, 169, 170, 171, 173, 179, 186, 187, 189, 195], "simplest": [12, 24, 86, 137, 144, 145, 146, 153, 187, 189], "complic": [12, 74, 86, 97, 103, 123, 161, 165, 186], "nonlinear": [12, 23, 29, 73, 74, 101, 131, 153, 165, 171, 195, 196, 197, 198], "fail": [12, 21, 22, 31, 33, 85, 105, 106, 121, 122, 123, 124, 129, 172, 173, 195, 196, 197, 198], "choic": [12, 19, 21, 23, 24, 26, 31, 32, 33, 78, 83, 87, 92, 94, 96, 99, 103, 105, 106, 112, 114, 115, 121, 123, 124, 129, 131, 153, 159, 162, 165, 169, 170, 180, 186, 187, 188, 189, 195, 196, 197, 198], "fanci": [12, 72], "tsne": [12, 115, 123], "dead": 12, "end": [12, 21, 23, 24, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 78, 79, 86, 87, 94, 95, 96, 97, 98, 99, 103, 105, 106, 112, 113, 114, 121, 122, 123, 124, 127, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 159, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 197, 198, 199], "die": [12, 155], "progress": [12, 31, 73, 101, 121, 123, 124, 129, 137, 146, 186, 188], "greatli": 12, "reason": [12, 68, 73, 74, 78, 83, 86, 94, 97, 110, 121, 122, 144, 145, 146, 147, 153, 162, 163, 170, 179, 188, 189], "interpret": [12, 21, 22, 23, 33, 78, 103, 106, 115, 117, 121, 122, 123, 129, 136, 167, 169, 171, 172, 180, 195, 198], "function": [12, 19, 22, 24, 61, 83, 101, 103, 117, 119, 131, 142, 167, 177], "black": [12, 31, 61, 63, 73, 74, 122, 137, 145, 146, 147, 161, 165, 170, 171, 173], "box": [12, 22, 63, 67, 69, 78, 99, 146, 170, 179], "paramet": [12, 21, 22, 23, 24, 31, 32, 33, 63, 68, 72, 74, 85, 86, 92, 94, 95, 96, 97, 98, 99, 103, 105, 112, 113, 115, 121, 122, 123, 124, 129, 135, 136, 145, 146, 147, 154, 161, 163, 169, 170, 171, 172, 180, 186, 187, 188, 189, 195, 197, 198], "replac": [12, 29, 31, 32, 33, 74, 78, 99, 114, 121, 123, 124, 146, 153, 180, 186, 187], "sne": [12, 108, 110, 123], "umap": [12, 108], "leiden": 12, "louvain": 12, "unlik": [12, 31, 44, 79, 86, 105, 106, 115, 137, 179, 188], "noisi": [12, 21, 23, 24, 31, 79, 94, 96, 97, 98, 114, 129, 135, 155, 162, 163, 170, 171, 172, 173, 180, 187], "reduct": [12, 29, 31, 33, 37, 81, 83, 110, 112, 113, 122, 144, 145, 193, 199], "instead": [12, 63, 67, 68, 69, 72, 73, 74, 79, 85, 87, 94, 95, 96, 99, 105, 106, 110, 121, 123, 124, 137, 138, 145, 146, 153, 154, 155, 161, 162, 169, 170, 172, 179, 187, 188, 189, 196, 197, 198, 199], "valid": [12, 23, 73, 90, 92, 94, 95, 96, 97, 98, 103, 122, 124, 184, 186, 198], "simpler": [12, 98, 113, 119, 121, 122], "algorithm": [12, 21, 23, 31, 32, 72, 85, 90, 96, 103, 105, 106, 108, 114, 121, 123, 124, 129, 153, 154, 155, 157, 167, 170, 177, 184, 186, 187, 189, 191], "hdbscan": 12, "tend": [12, 22, 78, 85, 86, 97, 98, 114, 122, 124, 154, 186], "unstabl": [12, 95, 155, 180], "difficult": [12, 45, 79, 98, 110, 123, 124, 198], "configur": 12, "resembl": [12, 31, 61, 122, 123, 162, 169, 186], "30": [12, 24, 37, 63, 67, 69, 72, 73, 74, 79, 85, 90, 94, 95, 96, 97, 98, 99, 105, 106, 112, 114, 115, 121, 123, 124, 135, 136, 138, 144, 145, 146, 147, 153, 154, 155, 161, 163, 169, 171, 172, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "spend": [12, 21, 79, 88, 135, 161, 195], "minut": [12, 67, 68, 72, 73, 74, 79, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 136, 137, 138, 145, 153, 154, 161, 162, 169, 170, 171, 196, 198], "todai": [12, 21, 23, 67, 68, 72, 79, 81, 83, 92, 94, 97, 103, 106, 110, 121, 127, 129, 133, 135, 142, 151, 159, 161, 167, 169, 170, 171, 173, 177, 180, 193, 195, 196, 197, 198], "reflect": [12, 23, 37, 66, 68, 72, 77, 79, 88, 114, 146, 154, 162, 169, 175], "done": [12, 21, 22, 23, 24, 44, 72, 78, 79, 85, 86, 87, 92, 119, 121, 123, 124, 129, 135, 147, 179, 180, 189], "guidanc": [12, 129], "identifi": [12, 19, 21, 22, 31, 32, 33, 63, 67, 99, 122, 124, 138, 142, 144, 147, 151, 154, 180, 186, 187, 188, 189, 198], "would": [12, 21, 22, 23, 24, 26, 31, 61, 67, 68, 72, 73, 74, 78, 79, 85, 87, 88, 96, 97, 99, 105, 106, 114, 121, 122, 124, 127, 129, 136, 138, 145, 147, 153, 161, 162, 163, 169, 170, 171, 172, 180, 187, 188, 189, 195, 196, 198], "ramp": [12, 165, 180], "introduc": [12, 31, 32, 33, 61, 69, 72, 73, 74, 79, 87, 103, 106, 110, 119, 127, 129, 136, 142, 144, 145, 146, 147, 151, 153, 154, 159, 161, 162, 169, 172, 173, 179, 189, 193, 195, 197, 198], "review": [12, 22, 31, 32, 33, 37, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 67, 68, 72, 73, 74, 78, 79, 81, 83, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 105, 106, 110, 112, 113, 114, 115, 121, 122, 123, 124, 127, 131, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 159, 161, 162, 163, 169, 170, 171, 173, 179, 180, 186, 187, 188, 189, 191, 195, 196, 197, 198], "llm": 12, "app": [12, 129], "categori": [12, 115, 122, 142], "etc": [12, 19, 22, 24, 31, 33, 44, 67, 69, 83, 86, 97, 99, 105, 144, 151, 153, 161, 163, 184, 186, 193, 196, 197], "hour": [12, 37, 67, 68, 105, 106, 121, 123, 135, 144, 146, 153, 154, 161, 162, 170, 171, 186, 198], "outro": [12, 33, 37, 92, 103, 110, 119, 142, 151, 177, 193], "four": [12, 32, 61, 67, 74, 135, 155, 188], "hypothet": [12, 22, 87], "illus": [12, 21, 127, 129], "phenomenon": [12, 22, 83, 85, 98, 127, 146, 169], "state": [12, 22, 23, 24, 33, 63, 67, 74, 79, 86, 121, 131, 135, 146, 147, 151, 154, 155, 159, 167, 169, 170, 172, 173, 177, 184, 186, 187, 188, 189, 195, 196, 198, 199], "art": [12, 23, 24, 121], "ingredi": [12, 22, 127], "formul": [12, 61, 92, 114, 138, 173], "defin": [12, 22, 24, 31, 32, 63, 68, 72, 74, 78, 79, 85, 86, 87, 94, 105, 106, 113, 114, 115, 121, 123, 124, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 159, 161, 162, 163, 169, 172, 179, 180, 184, 186, 187, 188, 189, 196, 197, 198], "illustr": [12, 31, 33, 69, 72, 73, 74, 87, 92, 94, 98, 113, 122, 124, 144, 146, 157, 169, 188], "planner": [12, 127, 189], "between": [12, 21, 23, 24, 31, 32, 33, 61, 67, 68, 72, 73, 74, 78, 79, 83, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 103, 105, 112, 114, 115, 121, 122, 123, 124, 129, 135, 137, 138, 140, 144, 146, 147, 155, 161, 162, 169, 170, 171, 172, 173, 182, 186, 187, 188, 189, 193, 195, 196, 197, 198], "beyond": [12, 69, 97, 98, 172, 189], "At": [12, 63, 106, 121, 137, 146, 151, 161, 179, 186, 187, 188, 189, 198], "section": [12, 21, 22, 90, 127, 129, 199], "feel": [12, 21, 23, 24, 31, 73, 74, 78, 112, 123, 129, 159, 161, 171, 179, 188], "order": [12, 21, 22, 23, 42, 45, 63, 67, 73, 85, 87, 95, 98, 99, 106, 112, 113, 114, 121, 122, 123, 124, 127, 129, 145, 146, 147, 153, 155, 163, 172, 173, 180, 186, 187, 188, 196, 198, 199], "prescript": 12, "wherev": 12, "freeli": [12, 79, 90, 172], "summer": [12, 19, 129], "context": [12, 31, 68, 72, 86, 95, 131, 145, 161, 162, 169, 173, 199], "acquir": [12, 21, 31, 67, 129, 188, 189], "timelin": [12, 171, 179, 180], "On": [12, 23, 31, 74, 79, 81, 92, 99, 106, 115, 146, 161, 169, 186, 187, 199], "scholar": 12, "promis": 12, "ones": [12, 21, 22, 23, 61, 63, 67, 73, 74, 79, 87, 97, 98, 99, 106, 124, 129, 138, 144, 145, 146, 147, 153, 154, 155, 170, 172, 173, 179, 180, 186, 188, 189, 195], "report": [12, 63, 79, 99, 117, 121, 122, 123, 124, 172, 187], "whole": [12, 22, 23, 79, 85, 92, 106, 114, 121, 123, 131, 135, 146, 162, 170, 188, 195, 198], "found": [12, 21, 29, 45, 72, 78, 87, 95, 105, 106, 112, 114, 121, 144, 153, 163, 172, 187, 198], "pool": [12, 122, 145, 146], "contradictori": 12, "wa": [12, 19, 21, 22, 23, 24, 26, 31, 33, 61, 68, 73, 74, 78, 79, 85, 86, 87, 95, 96, 97, 98, 105, 106, 115, 119, 121, 122, 123, 124, 129, 136, 144, 146, 147, 161, 162, 163, 172, 173, 179, 186, 187, 198], "common": [12, 21, 69, 72, 78, 79, 85, 87, 99, 101, 103, 106, 114, 119, 121, 135, 142, 145, 146, 161, 162, 163, 186, 188, 189, 193, 196, 197], "down": [12, 21, 22, 45, 72, 73, 74, 78, 86, 121, 123, 129, 138, 153, 173, 188, 189], "edu": [12, 19, 68, 81, 90, 105, 108, 157, 165, 175, 182, 186, 191], "domain": [12, 31, 32, 33, 169, 170, 171], "vpn": 12, "full": [12, 13, 22, 23, 24, 31, 32, 33, 43, 69, 72, 73, 74, 78, 79, 86, 95, 96, 105, 113, 117, 121, 122, 123, 124, 127, 157, 161, 169, 180, 188, 196, 197, 198], "preprint": [12, 81, 90, 101, 106, 108, 117, 121, 122, 123, 124, 131, 140, 149, 182, 191], "server": [12, 29], "arxiv": [12, 101, 106, 108, 117, 129, 131, 149, 191], "biorxiv": [12, 26, 90, 106, 117, 121, 122, 123, 124, 149, 182], "turn": [12, 31, 67, 69, 73, 74, 78, 79, 95, 97, 103, 106, 121, 122, 123, 124, 138, 144, 145, 153, 155, 171, 172, 180, 188, 189, 196], "someon": [12, 79, 161, 169, 172], "univers": [12, 39, 81, 90, 140, 149, 157, 172, 191], "pretti": [12, 74, 92, 96, 112, 138, 163, 195, 196, 198], "describ": [12, 21, 22, 61, 67, 68, 73, 74, 78, 79, 83, 85, 86, 95, 96, 112, 113, 121, 124, 135, 136, 137, 144, 145, 146, 147, 153, 154, 155, 159, 161, 162, 163, 167, 169, 170, 172, 177, 179, 186, 187, 188, 195], "methodolog": [12, 191], "signific": [12, 33, 114, 196, 198], "And": [12, 23, 24, 61, 67, 69, 72, 81, 105, 135, 144, 169, 171, 187, 195], "why": [12, 21, 22, 23, 31, 32, 33, 61, 63, 68, 74, 78, 79, 81, 83, 85, 88, 103, 108, 117, 121, 123, 124, 129, 135, 137, 144, 145, 146, 147, 153, 154, 161, 162, 169, 170, 171, 172, 179, 180, 186, 188, 189, 191, 195, 196, 197, 199], "point": [12, 21, 22, 23, 24, 31, 61, 67, 69, 72, 73, 74, 78, 79, 81, 85, 86, 87, 94, 95, 96, 97, 101, 105, 106, 112, 119, 121, 123, 129, 135, 136, 137, 138, 144, 145, 146, 147, 151, 154, 162, 163, 169, 170, 172, 173, 179, 180, 186, 188, 193, 195, 196], "messag": [12, 22, 33, 79, 85], "convei": [12, 22, 69], "address": [12, 21, 22, 23, 24, 31, 33, 73, 83, 85, 92, 105, 124, 129, 151, 172, 179, 198], "60min": 12, "understood": [12, 121, 135, 136, 144, 155], "word": [12, 21, 22, 67, 68, 69, 72, 73, 74, 78, 87, 119, 121, 135, 137, 138, 146, 153, 154, 161, 162, 170, 180, 189, 196], "break": [12, 37, 68, 72, 73, 74, 86, 188, 189], "text": [12, 24, 29, 30, 31, 32, 33, 37, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "written": [12, 67, 69, 73, 74, 78, 79, 97, 121, 122, 135, 136, 137, 138, 153, 154, 163, 171, 186, 196], "worri": [12, 73, 85, 86, 129, 198], "paragraph": [12, 23, 24], "200": [12, 23, 24, 68, 85, 87, 105, 121, 124, 138, 144, 145, 146, 147, 169, 171, 172, 187, 189, 198], "300": [12, 78, 136, 137, 144, 146, 147, 173], "possibl": [12, 22, 23, 24, 29, 31, 32, 61, 67, 68, 69, 72, 74, 78, 79, 85, 86, 87, 94, 103, 106, 110, 121, 124, 136, 137, 145, 147, 153, 155, 161, 162, 163, 170, 171, 179, 180, 186, 187, 188, 189, 193, 195, 196, 197, 198], "readi": [12, 21, 22, 79, 85, 87, 137, 146], "submit": 12, "mandatori": 12, "won": [12, 79, 106, 121, 123, 129, 135, 162, 163, 188, 197], "evalu": [12, 21, 31, 32, 33, 63, 72, 78, 79, 83, 87, 94, 98, 99, 121, 127, 129, 135, 138, 162, 163, 187, 188, 189], "overal": [12, 19, 21, 22, 23, 31, 79, 99, 103, 115, 129, 146, 169, 193, 195], "vagu": 12, "take": [12, 21, 22, 24, 29, 31, 32, 33, 44, 61, 68, 72, 73, 78, 79, 85, 86, 87, 94, 95, 99, 105, 106, 112, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 145, 146, 147, 153, 155, 161, 162, 163, 169, 170, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198, 199], "best": [12, 21, 22, 23, 24, 31, 72, 74, 83, 85, 88, 92, 94, 95, 97, 98, 99, 106, 119, 121, 124, 127, 129, 137, 138, 144, 145, 146, 153, 154, 155, 157, 171, 179, 186, 187, 188], "thesi": 12, "confer": [12, 117], "intermedi": [12, 19, 61, 106], "wait": [12, 74, 85, 180], "requir": [12, 19, 21, 22, 23, 29, 31, 32, 33, 37, 45, 61, 68, 72, 78, 85, 87, 114, 117, 121, 122, 129, 153, 162, 172, 179, 187, 188, 189, 196, 198], "lack": [12, 21, 22, 31, 129], "oomph": 12, "sound": [12, 78, 79, 106, 163], "check": [12, 21, 22, 23, 31, 32, 33, 40, 44, 63, 66, 67, 68, 72, 77, 79, 85, 86, 96, 105, 106, 112, 113, 122, 123, 129, 138, 144, 145, 146, 153, 154, 155, 162, 163, 169, 172, 179, 180, 186, 188, 195, 197, 198], "facet": [12, 73, 83], "enjoy": 12, "sinc": [12, 23, 24, 31, 32, 33, 44, 61, 63, 87, 95, 97, 98, 106, 112, 114, 119, 121, 122, 123, 124, 129, 136, 138, 144, 145, 147, 155, 161, 162, 163, 169, 170, 173, 179, 180, 187, 189, 196, 197, 198], "abc": 12, "build": [12, 21, 22, 23, 24, 29, 31, 33, 67, 73, 74, 79, 83, 86, 94, 95, 96, 97, 98, 99, 103, 105, 112, 114, 119, 121, 122, 124, 129, 137, 138, 142, 144, 147, 151, 153, 155, 159, 161, 163, 171, 179, 186, 189, 199], "ten": [12, 22, 33, 81, 90, 186], "rule": [12, 22, 69, 79, 81, 90, 94, 119, 121, 135, 137, 147, 155, 159, 162, 165, 171, 186, 187, 188, 189, 195, 198], "close": [12, 22, 31, 37, 72, 73, 74, 78, 79, 85, 94, 103, 105, 121, 122, 123, 124, 136, 137, 138, 144, 145, 146, 147, 153, 161, 162, 170, 172, 173, 186, 195, 196, 197, 198], "figur": [12, 21, 22, 23, 24, 177], "specifi": [12, 21, 22, 23, 31, 32, 33, 61, 63, 69, 78, 79, 85, 86, 94, 112, 113, 121, 122, 123, 124, 129, 135, 153, 170, 172, 179, 186, 189, 195, 196, 197, 198], "refer": [12, 22, 23, 24, 31, 33, 67, 69, 79, 86, 87, 97, 98, 99, 103, 105, 121, 122, 123, 124, 135, 136, 137, 138, 145, 146, 154, 155, 162, 163, 169, 170, 171, 172, 173, 180, 186, 187, 188, 189, 197], "principl": [12, 22, 79, 81, 83, 119, 121, 140, 163, 177, 180, 199], "problem": [12, 21, 22, 23, 68, 72, 74, 78, 79, 83, 86, 87, 90, 94, 95, 97, 99, 105, 106, 121, 122, 129, 138, 142, 151, 159, 161, 162, 169, 171, 173, 175, 180, 184, 186, 187, 188, 193, 197], "solut": [12, 22, 31, 32, 33, 61, 63, 67, 68, 69, 72, 78, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 124, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "45": [12, 37, 63, 67, 72, 73, 74, 78, 86, 87, 88, 94, 105, 113, 122, 123, 124, 135, 136, 137, 138, 146, 153, 154, 163, 169, 171, 172, 179, 180, 187, 189, 196, 197, 198], "style": [12, 24, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 191, 195, 196, 197, 198], "scientist": [12, 97, 161, 162], "writer": [12, 22, 31], "importantli": [12, 21, 69, 83, 99, 103, 105, 122, 136, 137, 159, 161, 184, 199], "sentenc": [12, 22], "previou": [12, 21, 22, 23, 24, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 79, 86, 87, 95, 97, 106, 113, 114, 115, 121, 122, 123, 124, 129, 135, 137, 138, 144, 145, 146, 147, 153, 154, 155, 163, 169, 170, 171, 172, 173, 179, 186, 188, 189, 195, 196, 199], "left": [12, 21, 22, 23, 24, 31, 32, 33, 45, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 87, 94, 98, 99, 105, 106, 121, 122, 123, 124, 129, 135, 136, 137, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 187, 188, 189, 195], "jargon": 12, "without": [12, 21, 22, 31, 33, 61, 67, 78, 95, 99, 105, 113, 121, 124, 129, 131, 137, 163, 170, 172, 179, 180, 189, 195, 198], "cohes": 12, "copi": [12, 23, 31, 32, 33, 44, 79, 123, 124, 154, 155], "put": [12, 22, 23, 24, 74, 78, 97, 105, 112, 121, 136, 146, 155, 161, 162], "did": [12, 21, 22, 23, 24, 79, 85, 86, 88, 98, 124, 129, 136, 147, 153, 154, 161, 162, 179, 180, 186, 187, 188, 196, 197], "show": [12, 21, 22, 23, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 103, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 151, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 191, 195, 196, 197, 198], "explicit": [12, 21, 22, 99, 154, 161], "shorter": [12, 85, 87, 196], "30min": 12, "1h": 12, "mode": [12, 32, 131, 151, 162, 163, 173, 175, 188, 189, 197], "2h": 12, "alreadi": [12, 19, 21, 24, 31, 33, 69, 72, 85, 87, 98, 99, 103, 110, 112, 113, 114, 123, 127, 129, 137, 144, 146, 147, 163, 170, 172, 177, 179, 180, 187, 188, 189, 196, 197, 198], "mayb": [12, 21, 22, 23, 24, 73, 79, 106, 129, 196, 197], "match": [12, 21, 33, 61, 68, 72, 78, 79, 85, 86, 106, 121, 122, 123, 124, 129, 136, 145, 161, 163, 171, 173], "mondai": [12, 37], "inspir": [12, 34, 35, 36, 68, 86, 94, 105, 122, 191], "speak": [12, 22, 23, 24, 161, 186, 195], "cover": [12, 21, 22, 31, 34, 35, 36, 67, 68, 69, 72, 73, 78, 79, 92, 94, 95, 97, 110, 119, 121, 122, 135, 136, 146, 147, 153, 157, 161, 162, 163, 169, 172, 179, 184, 186, 196, 197, 198, 199], "materi": [12, 22, 43, 67, 68, 72, 73, 78, 83, 92, 110, 153, 154, 159, 163, 167, 169, 172, 173, 186, 193, 199], "afraid": [12, 22], "sparsiti": [12, 101, 124], "spark": 12, "mix": [12, 21, 23, 31, 79, 129, 162, 163], "respond": [12, 68, 72, 74, 79, 105, 121, 122, 144, 146, 153, 169, 189], "stimulu": [12, 23, 26, 74, 78, 79, 95, 103, 105, 106, 119, 121, 122, 123, 124, 149, 155, 172, 186, 193], "increas": [12, 23, 24, 31, 32, 72, 73, 74, 78, 79, 85, 86, 87, 95, 106, 112, 121, 122, 124, 135, 137, 144, 145, 146, 153, 155, 161, 162, 170, 172, 173, 180, 186, 188, 196, 197], "facilit": [12, 22, 140], "arbitrari": [12, 21, 24, 72, 87, 106, 112, 113, 121, 122, 123, 162, 163, 180], "transform": [12, 21, 23, 31, 32, 33, 69, 79, 85, 95, 106, 110, 112, 113, 115, 119, 121, 122, 123, 124, 129, 145, 161, 162, 170, 171, 195, 196, 197, 198], "toi": [12, 23, 24, 69, 87, 121, 180], "label": [12, 19, 21, 23, 24, 31, 32, 33, 61, 63, 67, 69, 72, 73, 74, 78, 79, 85, 87, 94, 95, 96, 98, 99, 105, 106, 112, 113, 115, 121, 122, 123, 124, 136, 137, 138, 144, 145, 146, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197], "line": [12, 21, 23, 31, 32, 33, 61, 63, 67, 68, 69, 72, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "combin": [12, 23, 24, 29, 69, 72, 74, 79, 87, 101, 124, 142, 145, 155, 157, 161, 162, 163, 167, 169, 170, 172, 173, 177, 179, 180, 186, 187, 188, 189, 191], "rather": [12, 21, 23, 31, 33, 61, 85, 87, 114, 121, 123, 124, 136, 146, 162, 169, 172, 186, 188, 193, 195, 197], "input": [12, 21, 22, 23, 24, 31, 32, 33, 63, 67, 68, 69, 74, 79, 85, 87, 94, 95, 96, 97, 98, 99, 101, 105, 106, 112, 119, 121, 122, 123, 124, 129, 131, 135, 140, 142, 149, 151, 154, 155, 169, 171, 172, 179, 196, 197, 198], "fire": [12, 21, 23, 61, 63, 72, 78, 85, 87, 112, 121, 129, 140, 142, 145, 146, 151, 153, 154, 155, 173, 195, 199], "ch": [12, 140, 149], "dayan": [12, 73, 74, 81, 83, 140, 144, 182], "abbott": [12, 73, 74, 83, 140, 144], "theoret": [12, 73, 74, 81, 140, 144, 151, 175, 180, 199], "critic": [12, 22, 68, 78, 155, 187], "assumpt": [12, 21, 78, 79, 86, 95, 106, 122, 146, 161, 163, 186, 187, 197, 198], "impli": [12, 68, 85, 97, 145, 196, 197], "region": [12, 19, 31, 33, 45, 72, 85, 122, 154, 162, 169, 189, 193], "transfer": [12, 73, 131, 142, 144, 153, 154, 155], "basi": [12, 68, 69, 72, 86, 87, 94, 114, 124, 145, 159], "dictionari": [12, 31, 32, 33, 97, 98, 99, 105, 144, 145, 146, 147, 153, 154, 155, 172, 186, 187, 188, 189, 197, 198], "featur": [12, 23, 34, 35, 36, 85, 97, 98, 99, 115, 117, 122, 124, 146, 155, 186, 197], "ensembl": [12, 101, 131], "syllabl": 12, "suffici": [12, 22, 61, 124, 137, 144, 155, 172, 180, 187], "band": [12, 74, 153], "alpha": [12, 31, 32, 33, 61, 63, 67, 68, 69, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 121, 137, 138, 144, 145, 146, 147, 153, 154, 155, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 188, 189, 195, 196, 197, 198], "associ": [12, 24, 32, 78, 79, 145, 187, 189, 195, 196], "gamma": [12, 74, 162, 173, 186, 188, 189], "cell": [12, 26, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 101, 106, 112, 113, 114, 115, 117, 121, 123, 124, 131, 135, 136, 137, 138, 140, 144, 145, 146, 147, 153, 154, 155, 161, 162, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "1146": [12, 131, 191], "annurev": [12, 131, 191], "26": [12, 61, 63, 67, 69, 74, 85, 87, 94, 96, 97, 98, 105, 106, 114, 121, 123, 124, 135, 136, 137, 145, 146, 147, 153, 154, 155, 163, 169, 171, 172, 173, 180, 186, 188, 189, 195, 196, 197, 198], "041002": 12, "131022": 12, "mcn": 12, "2006": [12, 90, 140, 171, 172, 191], "001": [12, 24, 61, 63, 67, 79, 121, 135, 136, 175, 186, 187, 197, 198], "narrow": [12, 121], "posit": [12, 21, 23, 31, 33, 61, 67, 68, 69, 72, 73, 74, 79, 85, 99, 105, 106, 114, 121, 122, 123, 124, 135, 137, 138, 146, 147, 153, 154, 157, 159, 162, 169, 171, 172, 175, 179, 180, 186, 188, 189], "neg": [12, 31, 63, 67, 69, 72, 73, 74, 79, 85, 86, 87, 95, 101, 105, 106, 112, 114, 121, 122, 123, 124, 138, 146, 147, 153, 155, 161, 162, 163, 169, 171, 172, 188, 198], "toward": [12, 69, 78, 85, 86, 136, 137, 146, 147, 153, 154, 161, 162, 169, 188, 189], "discourag": 12, "month": [12, 21], "toolkit": [12, 21, 129, 199], "otherwis": [12, 21, 44, 61, 68, 79, 85, 99, 106, 115, 121, 124, 145, 146, 147, 161, 162, 171, 179, 187, 188, 195, 196, 198], "implement": [12, 21, 31, 32, 33, 61, 63, 67, 68, 72, 74, 78, 87, 94, 95, 96, 97, 105, 112, 115, 121, 122, 123, 124, 135, 136, 137, 144, 146, 154, 155, 161, 162, 167, 169, 170, 177, 186, 189, 196, 198], "scratch": [12, 33, 144, 199], "knowledg": [12, 22, 31, 67, 68, 79, 85, 105, 110, 113, 124, 136, 137, 159, 161, 162, 163, 169, 177, 196, 199], "absolut": [12, 63, 69, 87, 99, 106, 124, 161, 162, 169], "ok": [12, 24, 105, 106, 121, 122, 123, 124, 172], "Then": [12, 21, 22, 68, 73, 85, 92, 97, 112, 113, 114, 121, 122, 123, 124, 138, 142, 145, 153, 155, 161, 170, 198, 199], "initi": [12, 21, 32, 33, 61, 63, 67, 74, 78, 79, 86, 96, 99, 105, 106, 112, 115, 121, 122, 123, 124, 131, 136, 137, 144, 145, 146, 147, 155, 161, 163, 170, 171, 172, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "limit": [12, 22, 23, 24, 31, 61, 68, 69, 72, 73, 78, 79, 83, 87, 95, 99, 103, 114, 124, 137, 146, 161, 162, 163, 171, 173, 180, 188, 189, 197, 198], "somebodi": 12, "somedai": 12, "shuffl": [12, 31, 32, 33, 145], "logic": [12, 21, 81, 121, 124, 129, 157, 179, 195], "accident": [12, 198], "peak": [12, 21, 23, 72, 85, 87, 124, 129, 137, 145, 147, 162], "respons": [12, 19, 61, 67, 68, 69, 72, 73, 74, 79, 86, 87, 94, 95, 96, 97, 101, 103, 105, 106, 117, 122, 123, 124, 151, 153, 154, 155, 162, 165, 169, 171, 186, 198], "sequenc": [12, 31, 61, 72, 85, 94, 95, 96, 97, 121, 122, 138, 144, 145, 146, 147, 165, 169, 170, 171, 172, 179, 180, 186, 188, 189], "circular": [12, 112, 124], "obviou": [12, 161, 187], "catch": [12, 161, 169, 177, 180], "experienc": [12, 21, 23, 24, 129, 188, 189], "off": [12, 31, 32, 33, 68, 79, 94, 95, 96, 97, 99, 105, 106, 112, 113, 122, 123, 124, 161, 162, 169, 172, 173, 195, 196, 197, 198], "guard": 12, "branch": [12, 19, 72, 117, 124], "again": [12, 21, 32, 69, 72, 74, 78, 79, 85, 86, 92, 95, 96, 98, 99, 106, 110, 121, 123, 124, 136, 138, 147, 154, 162, 172, 187, 188, 189, 195, 196, 198, 199], "necessari": [12, 21, 22, 61, 67, 83, 87, 92, 106, 114, 124, 129, 159, 163], "calendar": 12, "http": [12, 21, 26, 29, 30, 31, 32, 33, 34, 35, 36, 40, 43, 44, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "compneuro": [12, 43], "io": [12, 21, 40, 43, 81, 85, 87, 105, 106, 108, 117, 121, 122, 123, 124, 129, 172], "daily_schedul": 12, "html": [12, 19, 40, 98, 99, 101, 106, 115, 117, 149, 165, 170, 171, 173, 179, 180, 186, 191, 198], "screen": [12, 105, 121, 129, 172], "graphic": [12, 22, 78, 79, 98, 131, 153, 154, 163, 175], "told": [12, 72, 138, 163], "had": [12, 23, 24, 69, 73, 78, 79, 86, 87, 95, 106, 136, 137, 138, 145, 161, 162, 163, 169, 172, 180, 186], "taught": [12, 127, 173], "via": [12, 72, 79, 94, 112, 117, 121, 123, 124, 131, 140, 145, 162, 170, 172, 180, 189, 197], "greet": 12, "round": [12, 72, 123, 137, 162, 170, 173], "call": [12, 21, 22, 23, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 103, 105, 106, 110, 112, 113, 114, 115, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "zoom": [12, 37, 114, 136, 151], "themselv": [12, 22, 67, 68, 72, 145], "hi": [12, 87, 94, 103, 105, 142, 162, 186], "jonni": 12, "wiggli": 12, "caterpillar": 12, "am": [12, 131, 198], "phd": 12, "notr": 12, "dame": 12, "pari": 12, "fli": [12, 137], "my": [12, 21, 22, 63, 83, 92, 103, 129, 138, 172], "bike": [12, 72], "ride": 12, "40": [12, 21, 23, 63, 69, 72, 74, 78, 79, 85, 86, 90, 97, 105, 106, 112, 113, 114, 121, 122, 124, 129, 137, 144, 146, 147, 153, 155, 161, 162, 169, 171, 173, 180, 186, 188, 189, 195, 196, 198], "approx": [12, 31, 74, 87, 95, 105, 106, 153, 195], "per": [12, 19, 21, 23, 31, 32, 33, 73, 78, 85, 86, 97, 115, 129, 136, 145, 169, 179, 188, 189, 196, 198], "person": [12, 44, 129, 161, 172], "wast": [12, 189], "join": [12, 33, 105, 135, 146], "appropri": [12, 19, 21, 22, 23, 105, 129, 161, 169, 180, 187, 198], "breakout": 12, "room": [12, 31, 86, 121], "miss": [12, 21, 22, 33, 78, 79, 85, 86, 88, 94, 99, 105, 106, 121, 124, 127, 129, 172, 179, 186, 187], "anyon": [12, 33], "futur": [12, 22, 23, 24, 29, 61, 63, 67, 68, 74, 117, 123, 137, 138, 145, 161, 172, 173, 184, 186, 188, 189], "perhap": [12, 33, 124, 180, 187, 195], "surpris": [12, 22, 87, 106, 172], "techniqu": [12, 31, 32, 33, 61, 63, 87, 92, 94, 110, 119, 121, 122, 123, 171, 188, 193, 197, 198], "immedi": [12, 21, 23, 74, 129, 188, 189], "subgroup": 12, "separ": [12, 22, 23, 26, 31, 32, 61, 72, 115, 122, 161, 162, 163, 169, 179, 180], "larg": [12, 32, 33, 69, 72, 74, 78, 79, 85, 105, 108, 114, 117, 119, 121, 122, 123, 124, 127, 129, 131, 135, 137, 145, 146, 151, 153, 155, 157, 161, 162, 171, 172, 179, 180, 184, 186, 189], "powerpoint": 12, "primarili": [12, 172], "ensur": [12, 21, 22, 31, 63, 72, 78, 86, 94, 95, 96, 97, 105, 121, 123, 124, 127, 137, 138, 146, 196], "superpod": 12, "cutoff": 12, "mark": [12, 163], "conclus": [12, 121, 155], "floor": [12, 69, 95, 123], "seem": [12, 21, 23, 24, 31, 69, 73, 74, 78, 85, 121, 122, 124, 129, 137, 147, 154, 155, 161, 162, 186, 187, 188, 193, 198], "imposs": [12, 21, 22, 23, 33, 106, 162], "elev": 12, "pitch": 12, "poster": 12, "zuckerberg": 12, "secur": 12, "million": [12, 32, 73, 74], "dollar": 12, "fund": 12, "act": [12, 67, 72, 87, 122, 124, 177, 184, 186, 189], "music": [12, 73, 74], "instrument": [12, 193, 195, 196, 197], "rehears": 12, "doesn": [12, 19, 21, 22, 23, 24, 31, 69, 72, 73, 86, 87, 105, 106, 113, 121, 124, 129, 153, 167, 173, 179, 187, 189, 198], "WILL": 12, "annoi": 12, "tenth": [12, 146], "secret": 12, "professor": 12, "prepar": [12, 67, 79, 122, 131, 172], "anecdot": 12, "magic": 12, "engag": [12, 26], "passiv": 12, "bore": 12, "grab": 12, "smart": 12, "while": [12, 21, 23, 31, 32, 37, 42, 69, 72, 73, 74, 78, 79, 85, 94, 96, 106, 113, 115, 119, 121, 124, 144, 145, 146, 147, 151, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 179, 180, 187, 188, 189, 193, 195, 197, 198], "main": [12, 21, 22, 23, 24, 26, 61, 63, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 105, 106, 110, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 169, 171, 172, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "anywai": 12, "bind": 12, "didn": [12, 21, 22, 72, 78, 85, 94, 123, 129], "hear": [12, 73, 74, 110, 136, 137], "furthermor": [12, 189], "clear": [12, 21, 79, 121, 123, 124, 129, 146, 155], "got": [12, 31, 94, 138, 169, 187], "dream": [12, 189], "whether": [12, 21, 23, 24, 31, 32, 33, 68, 69, 72, 74, 78, 79, 92, 105, 106, 110, 115, 121, 122, 123, 129, 142, 145, 146, 147, 153, 155, 161, 162, 179, 198], "pictur": [12, 67, 85, 122, 155], "oppos": [12, 23, 72, 79, 96, 162, 163], "except": [12, 37, 67, 69, 105, 106, 121, 122, 123, 124, 147, 171, 172, 186, 195, 198], "rambl": 12, "avoid": [12, 21, 22, 31, 33, 61, 63, 87, 121, 123, 124, 129, 135, 162, 163, 186, 187, 188, 189], "life": [12, 97, 113, 137, 162], "given": [12, 21, 23, 61, 63, 67, 68, 69, 72, 74, 78, 79, 85, 86, 87, 94, 95, 97, 98, 99, 105, 106, 112, 113, 121, 122, 123, 124, 135, 136, 137, 138, 144, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 198], "constraint": [12, 21, 31, 32, 79, 85, 108, 122, 191], "click": [13, 21, 22, 31, 32, 33, 39, 41, 44, 45, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "imag": [13, 26, 31, 32, 63, 67, 69, 79, 95, 106, 110, 114, 115, 117, 119, 121, 122, 123, 124, 167, 172, 193, 195, 199], "browser": [13, 44, 73, 74], "2020": [19, 21, 22, 33, 61, 63, 73, 74, 81, 101, 112, 113, 114, 115, 117, 129, 131, 137, 138, 144, 145, 147, 149, 153, 155, 157, 163, 172, 173, 175, 182, 186], "gambl": 19, "languag": [19, 21, 22, 127, 129, 196], "preprocess": [19, 99, 172], "john": [19, 65, 71, 72, 73, 74, 76, 82, 91, 102, 109, 112, 113, 114, 115, 118, 126, 132, 135, 136, 137, 138, 141, 144, 145, 146, 147, 150, 153, 154, 155, 158, 166, 169, 170, 173, 176, 183, 192, 199], "murrai": [19, 112, 113, 114, 115, 144, 145, 146, 147, 153, 154, 155], "saad": 19, "jbabdi": 19, "barch": 19, "burgess": [19, 81], "harm": 19, "petersen": 19, "schlaggar": 19, "l": [19, 31, 32, 61, 73, 74, 79, 90, 95, 99, 101, 106, 117, 121, 123, 124, 131, 140, 145, 147, 149, 162, 165, 169, 170, 172, 173, 175, 180, 182, 186, 188, 189], "corbetta": 19, "essen": 19, "2013": [19, 81, 101, 131, 149, 157, 191], "connectom": 19, "80": [19, 63, 68, 72, 144, 146, 169, 186], "169": [19, 67, 79, 140], "189": 19, "05": [19, 31, 32, 33, 61, 63, 67, 69, 72, 79, 87, 101, 114, 122, 123, 124, 131, 137, 144, 145, 147, 155, 161, 163, 169, 170, 173, 179, 180, 189, 197, 198], "033": 19, "complement": 19, "brainwid": [19, 26], "none": [19, 23, 31, 32, 33, 45, 63, 67, 68, 69, 72, 78, 79, 86, 95, 97, 98, 99, 105, 106, 115, 121, 122, 123, 124, 135, 138, 145, 146, 147, 153, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "recept": [19, 101, 103, 105, 122, 162], "model": [19, 31, 32, 68, 69, 72, 79, 81, 83, 92, 94, 96, 101, 103, 110, 112, 115, 119, 121, 122, 127, 129, 135, 136, 142, 145, 151, 159, 161, 162, 167, 171, 172, 175, 177, 179, 180, 184, 186, 187, 188, 191, 193, 196, 198, 199], "ml": [19, 103, 191], "savi": 19, "hierarchi": [19, 122], "benson": 19, "jamison": 19, "arcaro": 19, "vu": 19, "glasser": 19, "coalson": 19, "2018": [19, 31, 32, 33, 81, 101, 108, 117, 131, 149, 175, 182, 191], "tesla": 19, "vision": [19, 21, 23, 24, 31, 33, 117, 129], "18": [19, 61, 63, 67, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 115, 121, 122, 123, 124, 135, 136, 137, 140, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 182, 187, 188, 189, 195, 196, 197, 198], "13": [19, 22, 29, 67, 78, 79, 81, 85, 94, 96, 97, 98, 99, 105, 106, 108, 112, 113, 114, 117, 121, 122, 123, 124, 131, 135, 137, 145, 147, 149, 153, 154, 155, 161, 163, 170, 172, 179, 180, 186, 187, 189, 196, 197, 198], "1167": 19, "michael": [19, 31, 32, 33, 54, 61, 63, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 153, 154, 155, 163, 169, 170, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "waskom": [19, 31, 32, 33, 61, 63, 85, 86, 87, 94, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 153, 154, 155, 163, 169, 170, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "v1": [19, 26, 68, 106, 117, 121, 122, 123, 124, 198], "v2": [19, 198], "v3": 19, "v4": [19, 122], "naselari": 19, "prenger": 19, "gallant": 19, "452": 19, "7185": 19, "352": 19, "355": 19, "1038": [19, 26, 81, 101, 108, 117, 131, 140, 145, 175, 182, 191], "nature06713": 19, "oliv": 19, "reconstruct": [19, 31, 32, 115], "63": [19, 79, 124, 153, 179, 189], "902": 19, "915": 19, "09": [19, 90, 101], "006": [19, 61, 140], "di": [19, 72, 123, 154, 155], "static": [19, 69, 121, 180, 188], "navig": [19, 101, 121, 137, 162, 180, 188], "kshitij": [19, 31, 32, 33, 121, 122, 123, 124], "dwivedi": [19, 31, 32, 33, 121, 122, 123, 124], "anim": [19, 69, 74, 78, 79, 103, 106, 121, 124, 138, 161, 169, 177, 179, 184, 186, 193], "clip": [19, 33, 63, 171, 197, 198], "kriegeskort": [19, 117], "mur": [19, 117, 169], "bandettini": [19, 117], "2": [19, 22, 23, 29, 37, 39, 45, 81, 83, 90, 92, 99, 101, 103, 110, 119, 131, 140, 149, 175, 182, 184, 191, 193], "06": [19, 61, 117, 153], "004": [19, 61, 117, 172], "epstein": 19, "afford": [19, 31, 97, 121], "4793": 19, "4798": 19, "1618228114": 19, "pantazi": [19, 117], "oliva": [19, 117, 119, 122], "2014": [19, 31, 32, 33, 73, 74, 101, 108, 117, 140, 149, 157, 175, 191], "resolv": [19, 21, 23, 24, 29, 85, 129], "recognit": [19, 90, 117, 119, 122, 123, 171, 172], "space": [19, 21, 69, 78, 85, 106, 110, 112, 114, 115, 122, 131, 135, 146, 159, 161, 162, 172], "17": [19, 63, 67, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 101, 105, 106, 108, 112, 113, 114, 121, 122, 123, 124, 135, 137, 140, 145, 147, 149, 153, 154, 155, 161, 163, 169, 170, 172, 173, 175, 179, 180, 187, 188, 189, 191, 196, 198], "455": [19, 173], "462": 19, "nn": [19, 31, 32, 33, 101, 108, 121, 122, 123, 124, 197], "3635": 19, "url": [19, 21, 26, 29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 195, 196, 197, 198], "csail": 19, "mit": [19, 81, 101, 131, 140, 157, 172, 175, 182, 186, 191], "hart": [21, 22, 23, 24, 129], "megan": [21, 22, 23, 24, 129], "peter": [21, 22, 23, 24, 129, 144, 191], "paul": [21, 22, 23, 24, 34, 35, 36, 129], "schrater": [21, 22, 23, 24, 81, 129], "gunnar": [21, 22, 23, 24, 35, 129], "blohm": [21, 22, 23, 24, 35, 81, 129], "tara": [21, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 129], "viegen": [21, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 129], "editor": [21, 22, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 144, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 189, 195, 196, 197, 198], "ella": [21, 22, 53, 58, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 153, 154, 155, 161, 162, 169, 170, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "batti": [21, 22, 53, 58, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 117, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 153, 154, 155, 161, 162, 169, 170, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "w1d2": 21, "eas": [21, 33, 154], "yesterdai": [21, 72, 106, 144, 146, 153, 169, 170, 171, 180], "gain": [21, 22, 23, 24, 69, 78, 86, 97, 112, 119, 129, 135, 137, 153, 154, 155, 161, 162, 170, 171, 172, 189], "bui": [21, 129], "But": [21, 23, 24, 72, 73, 74, 79, 83, 95, 99, 105, 114, 115, 121, 123, 129, 137, 138, 144, 145, 155, 161, 162, 165, 171, 187, 189, 196, 197, 198], "clarifi": [21, 129, 162], "assum": [21, 23, 69, 72, 78, 79, 86, 87, 95, 96, 105, 106, 112, 113, 129, 136, 137, 144, 146, 147, 153, 161, 162, 163, 169, 170, 172, 173, 177, 186, 189, 196, 197], "first": [21, 22, 23, 24, 31, 32, 33, 35, 37, 45, 61, 63, 67, 68, 72, 73, 74, 78, 79, 83, 85, 86, 87, 94, 96, 97, 98, 99, 103, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 127, 129, 135, 136, 137, 138, 142, 144, 145, 146, 147, 151, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 184, 186, 187, 189, 191, 195, 197, 198, 199], "et": [21, 24, 26, 85, 87, 106, 115, 121, 122, 123, 124, 129, 172], "al": [21, 24, 26, 85, 87, 106, 115, 121, 122, 123, 124, 129, 172], "2019": [21, 22, 24, 26, 68, 81, 85, 87, 90, 101, 106, 117, 121, 122, 123, 124, 129, 131, 149, 165, 175, 191], "frame": [21, 22, 23, 24, 67, 68, 105, 162], "remain": [21, 22, 33, 68, 87, 112, 136, 137, 146, 147, 153, 155, 163, 180, 186, 187], "revit": 21, "move": [21, 23, 24, 67, 69, 74, 78, 79, 85, 121, 122, 129, 137, 154, 155, 162, 163, 169, 170, 171, 177, 179, 186, 188, 189, 196, 197, 199], "maxim": [21, 31, 67, 72, 79, 87, 95, 96, 106, 113, 123, 124, 161, 163, 165, 177, 179, 186, 187, 188], "succeed": [21, 124], "tabl": [21, 72, 79, 161, 188, 189], "side": [21, 31, 33, 61, 67, 73, 74, 86, 114, 122, 123, 124, 135, 144, 154, 162, 169, 179, 188, 195], "introductori": 21, "explain": [21, 22, 23, 24, 67, 68, 79, 85, 86, 87, 94, 95, 103, 112, 113, 117, 123, 124, 129, 136, 142, 145, 149, 154, 161, 162, 165, 169, 171, 179, 182, 189, 197], "roleplai": 21, "showcas": [21, 33], "pitfal": [21, 22, 103, 129], "around": [21, 23, 32, 67, 74, 78, 85, 86, 87, 94, 95, 96, 97, 98, 99, 113, 114, 129, 135, 137, 145, 149, 153, 155, 161, 162, 163, 170, 171, 172, 179, 180, 188, 196, 198], "appreci": [21, 22, 81, 83, 129, 142, 151], "np": [21, 23, 24, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "pyplot": [21, 23, 24, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "plt": [21, 23, 24, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "random": [21, 23, 24, 31, 32, 33, 72, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 121, 123, 124, 129, 136, 138, 144, 145, 146, 147, 153, 155, 161, 162, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 193, 196, 197, 198], "stat": [21, 23, 24, 78, 79, 86, 87, 95, 123, 129, 162, 169, 170, 171, 172, 173], "norm": [21, 23, 24, 31, 32, 67, 69, 78, 79, 95, 105, 122, 129, 154, 159, 161, 169, 170, 171], "poisson": [21, 23, 86, 101, 103, 106, 129, 136, 144, 145, 146, 147], "logist": [21, 23, 101, 103, 105, 123, 129], "sklearn": [21, 23, 31, 32, 33, 99, 103, 106, 114, 115, 123, 129, 197, 198], "linear_model": [21, 23, 106, 129, 197, 198], "logisticregress": [21, 23, 106, 129], "model_select": [21, 23, 99, 106, 129], "cross_val_scor": [21, 23, 106, 129], "titl": [21, 23, 29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "def": [21, 23, 24, 29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "rasterplot": [21, 23, 129], "spike": [21, 23, 31, 33, 72, 74, 78, 83, 92, 97, 101, 103, 106, 129, 131, 142, 146, 151, 153, 165, 193], "timepoint": [21, 23, 79, 105, 129], "trial_spik": [21, 23, 129], "trial_ev": [21, 23, 129], "nonzero": [21, 23, 106, 113, 129, 144, 173], "150": [21, 23, 34, 35, 36, 61, 67, 129, 169, 195, 196, 197, 198], "100": [21, 22, 23, 24, 34, 35, 36, 73, 74, 78, 79, 86, 95, 105, 106, 110, 114, 121, 123, 124, 129, 137, 138, 144, 145, 146, 153, 154, 155, 163, 169, 170, 172, 179, 180, 186, 188, 189, 195, 196, 197, 198], "dt": [21, 23, 24, 61, 63, 72, 73, 74, 86, 105, 129, 135, 136, 144, 145, 146, 147, 153, 155, 173], "eventplot": [21, 23, 85, 129], "linewidth": [21, 23, 63, 67, 68, 72, 78, 79, 95, 96, 97, 105, 112, 113, 124, 129, 135, 138, 162, 163, 170, 171, 172, 173, 179], "ylabel": [21, 23, 24, 31, 32, 33, 61, 63, 67, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 171, 172, 173, 180, 187, 188, 189, 195, 196, 197, 198], "xlabel": [21, 23, 24, 31, 32, 33, 61, 63, 67, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 171, 172, 173, 180, 187, 188, 189, 195, 196, 197, 198], "plotcrossvalaccuraci": [21, 23, 129], "accuraci": [21, 23, 74, 96, 117, 119, 124, 129, 140, 165, 172, 180, 187], "ax": [21, 23, 24, 31, 32, 33, 67, 68, 69, 72, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 105, 106, 114, 121, 122, 123, 124, 129, 135, 137, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "subplot": [21, 23, 24, 31, 32, 33, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 105, 106, 114, 121, 122, 123, 124, 129, 135, 137, 144, 146, 147, 154, 155, 162, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "figsiz": [21, 23, 24, 31, 32, 33, 63, 67, 68, 69, 72, 73, 74, 86, 87, 94, 95, 96, 105, 106, 112, 113, 121, 122, 123, 124, 129, 135, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 187, 188, 189, 195, 196, 197, 198], "boxplot": [21, 23, 99, 106, 129], "vert": [21, 23, 106, 129], "fals": [21, 22, 23, 31, 32, 33, 61, 63, 67, 68, 69, 72, 79, 86, 99, 103, 105, 106, 114, 115, 121, 122, 123, 124, 129, 135, 144, 145, 146, 147, 153, 155, 161, 162, 169, 170, 171, 172, 179, 180, 186, 188, 195, 196, 197, 198], "width": [21, 23, 34, 35, 36, 67, 68, 69, 72, 73, 74, 85, 98, 106, 122, 123, 124, 129, 135, 144, 146, 147, 161, 162, 170, 171, 179, 180, 195, 196, 197, 198], "ytick": [21, 23, 32, 33, 67, 68, 69, 72, 73, 74, 85, 106, 124, 129, 136, 146, 161, 162, 173], "spine": [21, 23, 67, 68, 69, 72, 105, 106, 122, 123, 129, 161, 169, 179], "set_vis": [21, 23, 67, 69, 106, 122, 123, 129, 147, 161, 169], "generatespiketrain": [21, 23, 129], "50": [21, 23, 24, 61, 63, 67, 73, 74, 79, 85, 87, 95, 96, 97, 98, 99, 105, 106, 112, 114, 115, 121, 123, 124, 129, 144, 145, 146, 147, 154, 155, 161, 163, 169, 170, 171, 172, 173, 180, 186, 196, 197, 198], "repetit": [21, 23, 24, 129], "800": [21, 23, 129], "seed": [21, 23, 31, 61, 63, 78, 79, 86, 94, 95, 96, 97, 98, 99, 106, 112, 113, 114, 121, 123, 124, 129, 136, 137, 138, 144, 145, 146, 147, 153, 155, 169, 170, 171, 172, 173, 179, 186, 187, 188, 189, 195, 196, 197, 198], "37": [21, 23, 69, 78, 79, 85, 86, 87, 96, 97, 99, 105, 106, 108, 112, 113, 124, 129, 137, 140, 144, 147, 153, 161, 169, 173, 175, 179, 180, 187, 189, 195, 196], "arang": [21, 23, 31, 32, 33, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 98, 99, 105, 106, 113, 114, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 173, 179, 180, 186, 188, 189], "interv": [21, 23, 63, 68, 69, 72, 74, 78, 83, 86, 87, 94, 95, 97, 98, 99, 129, 144, 145, 146, 147, 171, 173, 186, 191], "velocity_sigma": [21, 23, 129], "std": [21, 23, 61, 79, 96, 124, 129, 137, 138, 144, 163, 169, 180, 196, 198], "dev": [21, 23, 79, 129], "veloc": [21, 23, 24, 72, 129, 175], "profil": [21, 23, 129], "velocity_profil": [21, 23, 129], "pdf": [21, 23, 63, 78, 79, 81, 87, 95, 101, 108, 117, 129, 131, 140, 149, 162, 165, 169, 170, 171, 175, 182, 191], "gaussian": [21, 23, 31, 72, 96, 112, 113, 122, 123, 124, 129, 131, 137, 146, 159, 167, 169, 171, 177, 187, 191], "properti": [21, 22, 23, 61, 68, 72, 78, 79, 83, 96, 114, 121, 122, 123, 124, 129, 136, 137, 142, 145, 149, 151, 159, 161, 162, 169, 170, 171, 195], "rand": [21, 23, 94, 95, 96, 123, 129, 145, 146, 147, 173], "sensit": [21, 23, 72, 79, 115, 122, 129, 145], "fr": [21, 23, 94, 95, 129], "rate": [21, 23, 31, 32, 63, 67, 72, 74, 78, 85, 86, 87, 105, 106, 112, 121, 123, 124, 129, 135, 136, 137, 138, 145, 151, 154, 155, 169, 173, 175, 187, 188, 189], "output": [21, 22, 23, 24, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 123, 124, 129, 131, 135, 136, 137, 138, 142, 144, 146, 147, 153, 154, 155, 161, 163, 169, 170, 171, 172, 179, 186, 187, 188, 189, 195, 196, 198], "target_shap": [21, 23, 129], "len": [21, 23, 24, 31, 32, 33, 63, 68, 69, 72, 73, 74, 79, 85, 86, 87, 94, 95, 97, 99, 105, 106, 113, 114, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 154, 155, 163, 169, 170, 171, 172, 173, 179, 180, 187, 188, 189, 195, 196, 197, 198], "repeat": [21, 23, 61, 69, 79, 96, 99, 122, 129, 147, 154, 161, 163, 169, 170, 179, 189], "reshap": [21, 23, 31, 32, 33, 68, 97, 114, 129, 161, 163, 173, 188, 189, 196, 198], "multipli": [21, 23, 67, 68, 69, 72, 73, 79, 95, 114, 121, 123, 124, 129, 145, 163, 171, 173, 180, 186], "s_gain": [21, 23, 129], "s_move": [21, 23, 129], "arrai": [21, 23, 24, 31, 32, 33, 63, 67, 68, 69, 72, 74, 78, 79, 85, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "top": [21, 23, 31, 33, 44, 45, 67, 68, 69, 72, 73, 74, 85, 92, 94, 97, 105, 106, 112, 113, 114, 115, 121, 123, 129, 137, 138, 147, 154, 169, 188, 189, 196, 197], "baselin": [21, 23, 33, 103, 129, 144, 145, 146], "s_fr": [21, 23, 129], "lower": [21, 23, 24, 31, 32, 33, 63, 67, 78, 79, 86, 95, 97, 98, 106, 110, 122, 124, 129, 154, 155, 161, 162, 169, 172, 173, 179, 180, 187, 188, 189, 196, 199], "correct": [21, 23, 61, 63, 69, 79, 87, 98, 105, 106, 124, 129, 131, 153, 155, 161, 162, 169, 170, 171, 172, 186, 193, 195, 196, 197, 198], "rv": [21, 23, 24, 86, 95, 129, 169, 170, 172, 173, 179], "return": [21, 23, 24, 29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "subsetpercept": [21, 23, 129], "400": [21, 23, 26, 129, 144, 145, 146, 147, 162, 186, 189], "subset": [21, 23, 63, 67, 87, 96, 99, 106, 121, 124, 129, 172, 197], "hwin": [21, 23, 129], "num_mov": [21, 23, 129], "zero": [21, 23, 31, 32, 33, 63, 67, 68, 69, 72, 74, 78, 79, 85, 86, 87, 94, 95, 96, 98, 99, 105, 106, 112, 113, 114, 122, 123, 124, 129, 135, 136, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "ground": [21, 23, 31, 32, 33, 96, 113, 129, 145, 162, 170, 195, 196, 199], "truth": [21, 23, 31, 32, 33, 81, 96, 113, 129, 145, 162, 170, 195, 198], "y_train": [21, 23, 31, 32, 33, 98, 99, 124, 129], "y_test": [21, 23, 31, 32, 33, 98, 99, 124, 129], "m_train": [21, 23, 129], "m_test": [21, 23, 129], "reproduc": [21, 22, 23, 31, 78, 85, 86, 97, 121, 123, 124, 129, 146, 172, 187, 188, 189, 195, 196, 197, 198], "w_idx": [21, 23, 129], "ab": [21, 23, 31, 32, 33, 67, 68, 69, 87, 122, 123, 124, 129, 153, 162, 163, 169, 171, 195, 196, 197], "w_0": [21, 23, 129], "w_1": [21, 23, 112, 129], "max": [21, 22, 23, 31, 32, 33, 61, 63, 67, 68, 69, 73, 74, 78, 79, 85, 86, 87, 94, 95, 97, 98, 99, 105, 106, 112, 121, 122, 124, 129, 135, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "total": [21, 23, 72, 87, 105, 106, 114, 121, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 169, 170, 171, 173, 179, 187, 188, 189, 196], "count": [21, 23, 31, 32, 33, 63, 73, 74, 78, 79, 86, 87, 92, 96, 106, 129, 136, 144, 145, 146, 173, 179, 187], "stationari": [21, 23, 24, 129, 146, 147], "spikes_stat": [21, 23, 129], "sum": [21, 23, 24, 61, 67, 69, 78, 79, 85, 87, 95, 97, 99, 105, 106, 114, 121, 122, 123, 124, 129, 135, 136, 137, 145, 146, 147, 155, 161, 162, 163, 169, 170, 171, 173, 179, 180, 186, 187, 188, 189, 195], "spikes_mov": [21, 23, 129], "train_spikes_stat": [21, 23, 129], "train_spikes_mov": [21, 23, 129], "test_spikes_stat": [21, 23, 129], "test_spikes_mov": [21, 23, 129], "x_train": [21, 23, 31, 32, 33, 98, 99, 129], "concaten": [21, 23, 33, 85, 105, 122, 123, 124, 129, 169, 195, 196, 197, 198], "x_test": [21, 23, 31, 32, 33, 98, 99, 129, 138], "fit": [21, 22, 23, 24, 31, 37, 63, 68, 73, 79, 83, 92, 94, 95, 96, 98, 99, 103, 110, 115, 117, 119, 121, 122, 123, 124, 129, 151, 159, 161, 188, 193, 195, 196, 198, 199], "population_model": [21, 23, 129], "solver": [21, 23, 106, 129, 135], "liblinear": [21, 23, 129], "random_st": [21, 23, 115, 123, 129, 195, 196, 197, 198], "newton": [21, 23, 129], "cg": [21, 23, 129], "lbfg": [21, 23, 129], "sag": [21, 23, 129], "saga": [21, 23, 106, 129], "coef_": [21, 23, 106, 129, 197, 198], "slope": [21, 23, 31, 72, 85, 94, 95, 96, 97, 121, 129, 145, 155], "intercept_": [21, 23, 129], "intercept": [21, 23, 85, 97, 105, 121, 129, 138, 197, 198], "ground_truth": [21, 23, 129], "getdata": [21, 23, 129], "ipywidget": [21, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 106, 112, 113, 114, 115, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 196, 197, 198], "widget": [21, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 106, 112, 113, 114, 115, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 196, 197, 198], "ipython": [21, 34, 35, 36, 67, 73, 74, 106, 121, 122, 129, 161, 162, 170, 171, 173, 179, 180], "displai": [21, 22, 23, 31, 32, 33, 34, 35, 36, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 106, 112, 113, 114, 115, 121, 122, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 169, 170, 171, 172, 173, 179, 180, 186, 187, 195, 196, 197, 198], "markdown": [21, 23, 31, 34, 35, 36, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 106, 112, 113, 114, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 179, 180, 186, 187, 188, 195, 196, 197, 198], "markdown1": [21, 129], "br": [21, 129], "font": [21, 67, 68, 72, 79, 129], "3pt": [21, 129], "occur": [21, 23, 24, 63, 67, 72, 78, 86, 87, 124, 129, 135, 136, 138, 147, 161, 186, 195, 198], "sit": [21, 23, 24, 87, 129, 138], "window": [21, 23, 24, 67, 105, 129, 136, 146], "suddenli": [21, 23, 24, 129], "wrong": [21, 22, 23, 24, 69, 74, 79, 87, 161, 163, 169, 195, 196], "vice": [21, 23, 24, 31, 74, 123, 129, 154, 155], "versa": [21, 23, 24, 31, 74, 123, 129, 154, 155], "surround": [21, 23, 24, 122, 123, 124, 129, 149, 151], "disambigu": [21, 23, 24, 129], "strong": [21, 22, 23, 24, 63, 79, 106, 114, 129, 144, 146, 187, 191, 198], "vibrat": [21, 23, 24, 129], "indic": [21, 23, 24, 31, 67, 73, 74, 79, 96, 99, 106, 112, 113, 121, 123, 124, 129, 135, 154, 155, 169, 172, 186, 189], "inde": [21, 23, 24, 78, 79, 86, 92, 95, 105, 106, 122, 124, 129, 144, 145, 153], "vestibular": [21, 23, 129], "illusori": [21, 24], "self": [21, 23, 24, 32, 33, 63, 67, 79, 87, 121, 122, 123, 124, 129, 131, 135, 138, 179, 180, 186, 188, 189], "markdown2": [21, 129], "colab": [21, 23, 45, 121, 122, 123, 124, 129], "accumul": [21, 23, 24, 73, 78, 121, 129, 131, 163, 169, 188, 189], "case": [21, 22, 23, 24, 31, 45, 61, 63, 67, 68, 69, 72, 78, 79, 85, 87, 94, 95, 97, 103, 105, 106, 121, 122, 123, 124, 129, 135, 144, 145, 146, 153, 155, 161, 162, 167, 169, 171, 172, 179, 180, 186, 187, 188, 189, 195], "pretend": [21, 23, 129, 172, 195], "hold": [21, 23, 24, 87, 97, 121, 122, 124, 129, 198], "condit": [21, 23, 24, 33, 61, 63, 69, 74, 83, 92, 112, 121, 129, 136, 137, 144, 145, 146, 153, 154, 155, 161, 162, 170, 171, 179, 180, 186, 188, 195, 197, 198], "slowli": [21, 23, 129, 180], "acceler": [21, 23, 24, 45, 117, 124, 129], "faster": [21, 23, 33, 105, 115, 123, 129, 155, 163, 169, 171, 179, 196], "correl": [21, 23, 24, 101, 105, 110, 131, 144, 169, 172, 175, 193, 195, 197, 198, 199], "judgement": [21, 23, 129], "out2": [21, 129], "out1": [21, 129], "tab": [21, 22, 129, 180], "set_titl": [21, 24, 31, 32, 33, 68, 72, 87, 106, 122, 123, 124, 129, 147, 163, 169, 170, 179, 180, 186, 195, 196, 198], "25": [21, 29, 33, 37, 61, 63, 67, 69, 74, 78, 79, 85, 86, 87, 97, 98, 99, 101, 105, 106, 113, 114, 121, 123, 124, 135, 136, 137, 138, 140, 145, 147, 149, 153, 154, 155, 161, 162, 163, 169, 170, 171, 173, 180, 187, 188, 189, 195, 196, 197, 198], "write": [21, 23, 24, 33, 42, 44, 45, 61, 67, 68, 69, 73, 74, 79, 86, 87, 94, 95, 105, 106, 112, 113, 121, 122, 123, 124, 129, 135, 137, 138, 144, 145, 146, 153, 154, 161, 163, 169, 172, 173, 179, 186, 187, 188, 189, 195], "remind": [21, 78, 79, 94, 122, 129, 135], "exact": [21, 23, 69, 72, 74, 78, 83, 95, 98, 99, 115, 122, 124, 129, 136, 153, 162], "clearli": [21, 22, 23, 24, 85, 137, 146, 172, 188], "precis": [21, 22, 26, 79, 85, 113, 117, 129, 135, 169, 172, 187, 197], "lost": [21, 22, 99, 172], "guarante": [21, 106, 153, 169, 173, 175, 197], "yet": [21, 24, 96, 99, 105, 121, 147, 153, 154, 161, 162, 187, 189], "comparison": [21, 22, 24, 31, 79, 92, 117, 119, 129, 171, 173, 196, 198], "essenti": [21, 22, 23, 24, 61, 67, 72, 78, 79, 98, 99, 121, 122, 124, 142, 153, 161, 162, 180, 191], "interfac": [21, 22, 29, 85, 105, 110, 131, 165, 171, 172, 177], "phenomena": [21, 22, 23, 24, 78, 85, 106, 140, 147, 151, 155, 170, 186, 189], "investig": [21, 24, 33, 74, 85, 110, 123, 137, 144, 146, 147, 153, 154, 155, 172, 180, 186, 189], "recap": [21, 22, 67, 68, 69, 72, 73, 74, 78, 79, 94, 95, 97, 98, 106, 112, 121, 122, 129, 135, 136, 144, 153, 154, 161, 162, 169, 195], "unclear": [21, 129], "meaning": [21, 129, 179], "chosen": [21, 72, 74, 79, 121, 129, 153, 154, 163, 179, 186, 187, 188, 189, 199], "prevent": [21, 22, 129, 146], "deepli": [21, 22, 129], "behind": [21, 69, 110, 121, 124, 129, 137, 161, 163, 169, 187, 199], "properli": [21, 85, 129], "BUT": [21, 68, 129, 195], "anywher": [21, 67, 122, 129, 188, 189], "revisit": [21, 79, 95, 129, 162], "frequent": [21, 24, 72, 129, 193], "necess": [21, 129], "bad": [21, 22, 23, 79, 90, 121, 122, 124, 129, 138, 162, 171, 182, 188], "nest": [21, 79, 106], "known": [21, 23, 24, 33, 73, 74, 78, 79, 85, 87, 94, 97, 105, 127, 135, 136, 137, 138, 146, 147, 169, 171, 172, 180, 186, 188, 189], "examin": [21, 23, 24, 69, 72, 78, 79, 83, 113, 124, 127, 135, 144, 153, 154, 155, 162, 170, 172, 180, 196, 197, 198], "attempt": [21, 24, 106, 163, 186, 189, 196], "perceptu": [21, 24, 131], "markdown21": 21, "4d": [21, 23, 122, 173], "integ": [21, 23, 31, 32, 33, 61, 68, 86, 92, 105, 123, 137, 138], "2d": [21, 23, 33, 67, 68, 69, 105, 106, 113, 114, 121, 123, 154, 163, 170, 173, 179, 188], "markdown22": 21, "dimens": [21, 23, 31, 68, 72, 85, 86, 97, 98, 105, 110, 112, 114, 121, 122, 123, 124, 131, 137, 138, 153, 154, 162, 171, 172, 173], "simultan": [21, 23, 26, 78, 101, 121, 131, 136, 145, 189, 193, 195, 196, 198], "third": [21, 23, 32, 36, 97, 114, 135, 142, 153, 155], "ms": [21, 23, 63, 72, 73, 74, 85, 105, 144, 145, 146, 147, 153, 154, 155], "fourth": [21, 23, 154], "perfect": [21, 23, 24, 73, 157, 195, 196, 198], "closer": [21, 23, 86, 94, 97, 114, 122, 123, 137, 162], "mi": [21, 23, 129, 172], "markdown23": 21, "blue": [21, 23, 61, 67, 72, 73, 74, 79, 97, 112, 113, 114, 121, 122, 135, 137, 147, 153, 154, 161, 162, 169, 170, 186], "produc": [21, 22, 23, 31, 32, 63, 83, 86, 87, 94, 95, 96, 97, 99, 105, 106, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 155, 161, 162, 169, 173, 180, 186, 188, 193, 196], "flat": [21, 23, 79, 162], "orang": [21, 23, 68, 72, 79, 85, 95, 137, 147, 154, 155, 169, 170, 171, 172, 186], "green": [21, 23, 67, 68, 73, 74, 78, 122, 161, 162, 170, 172, 180, 186, 189], "bell": [21, 23, 31, 186], "correspond": [21, 23, 24, 31, 32, 61, 67, 68, 69, 72, 78, 79, 85, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 117, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 180, 187, 188, 189, 195, 196, 198], "consider": [21, 22, 23, 99, 193], "nois": [21, 23, 24, 31, 72, 79, 94, 96, 97, 98, 99, 101, 105, 106, 115, 121, 124, 129, 138, 146, 147, 149, 153, 155, 163, 169, 170, 171, 172, 179, 195, 198], "exactli": [21, 23, 61, 73, 74, 78, 86, 87, 105, 121, 122, 123, 137, 153, 155, 157, 162, 172, 186, 198], "singl": [21, 23, 31, 32, 33, 61, 63, 67, 69, 72, 73, 78, 79, 86, 87, 94, 95, 97, 101, 103, 105, 112, 114, 119, 121, 122, 123, 124, 131, 135, 137, 138, 140, 144, 146, 147, 149, 154, 161, 162, 163, 169, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "markdown24": 21, "abov": [21, 23, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 97, 98, 99, 106, 112, 113, 115, 121, 122, 123, 124, 129, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 169, 171, 172, 173, 179, 180, 186, 187, 188, 189, 193, 195, 196, 197, 198], "distinguish": [21, 23, 31, 78, 115, 191], "ey": [21, 23, 105, 114, 131, 135, 173, 195, 196, 197, 198], "ball": [21, 23, 162], "seen": [21, 23, 63, 67, 69, 72, 73, 85, 86, 87, 96, 98, 99, 105, 106, 113, 114, 123, 124, 136, 138, 144, 145, 146, 153, 154, 155, 159, 161, 162, 163, 170, 179, 180, 184, 186, 187, 188, 193, 198], "extract": [21, 23, 61, 83, 85, 105, 115, 123, 124, 129, 131, 137, 138, 195, 196, 197, 198], "move_no": [21, 23], "legend": [21, 22, 23, 24, 31, 61, 63, 67, 69, 72, 73, 74, 78, 79, 85, 94, 95, 96, 97, 98, 105, 112, 113, 123, 124, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 197, 198], "thorough": 21, "exhaust": [21, 198], "emit": [21, 79, 87, 105, 170], "altern": [21, 24, 31, 33, 67, 72, 78, 92, 105, 114, 123, 136, 138, 173, 188, 193, 196, 197, 198], "math": [21, 22, 68, 78, 86, 110, 121, 129, 138, 145, 153, 163, 169, 172, 179, 180], "v": [21, 24, 31, 32, 33, 61, 63, 67, 68, 69, 72, 74, 79, 86, 90, 101, 123, 131, 135, 136, 140, 144, 145, 146, 147, 149, 161, 170, 171, 175, 179, 182, 186, 188, 189, 197, 198], "threshold": [21, 61, 63, 72, 73, 86, 114, 140, 144, 145, 146, 147, 153, 154, 155], "\u03b8": 21, "filter": [21, 24, 78, 105, 123, 124, 144, 146], "mechan": [21, 22, 23, 29, 33, 61, 83, 86, 87, 129, 149, 151, 173, 179, 180, 196, 198], "somehow": [21, 23, 129], "classic": [21, 23, 68, 79, 96, 114, 121, 123, 124, 129, 162, 169, 171, 186, 188, 198], "classif": [21, 23, 31, 103, 106, 122, 124, 129], "raw": [21, 23, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "pre": [21, 23, 61, 69, 73, 85, 86, 87, 105, 122, 129, 135, 136, 142, 144, 145, 146, 154, 161, 162, 163, 170, 199], "10m": [21, 23], "sub": [21, 31, 72, 187], "perceiv": [21, 23, 33, 78, 106, 129], "classifi": [21, 23, 83, 123, 124, 199], "render": [21, 29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "allow": [21, 22, 23, 24, 61, 67, 69, 74, 78, 79, 83, 85, 92, 94, 96, 97, 99, 103, 105, 106, 113, 119, 121, 122, 124, 144, 146, 159, 161, 162, 163, 167, 169, 170, 171, 179, 184, 186, 189, 193, 197, 198], "constant": [21, 24, 61, 67, 72, 73, 74, 85, 86, 87, 97, 99, 105, 124, 136, 144, 145, 146, 147, 153, 155, 161, 162, 163, 169, 171, 180, 186, 195], "over": [21, 23, 24, 61, 63, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 121, 122, 123, 124, 129, 135, 136, 137, 144, 145, 146, 147, 153, 155, 161, 162, 163, 167, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 191, 195, 196, 197, 198, 199], "omit": [21, 186], "measur": [21, 22, 31, 67, 72, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 113, 129, 136, 138, 140, 144, 155, 161, 162, 169, 172, 173, 179, 186, 195, 196, 197, 198, 199], "latent": [21, 92, 114, 167, 169, 170, 171, 173, 179, 180, 187], "abstract": [21, 23, 69, 73, 101, 117, 121, 122, 123, 124, 127, 144, 165, 175, 189, 197], "instanti": [21, 121, 171], "util": [21, 83, 146, 159, 177, 179, 189], "uncertainti": [21, 87, 92, 95, 96, 159, 162, 170, 171, 182], "cost": [21, 32, 85, 87, 94, 95, 103, 121, 179, 187, 188, 189, 198], "salienc": [21, 172], "plant": 21, "intuit": [21, 22, 68, 69, 72, 73, 74, 78, 79, 83, 86, 106, 112, 113, 114, 121, 123, 135, 137, 138, 144, 145, 155, 157, 159, 161, 162, 163, 167, 170, 171, 172, 173, 179, 180, 186, 193, 197], "inventori": 21, "anymor": [21, 129, 153], "Not": [21, 22, 87, 129, 138, 146, 157, 189, 191, 198], "latex": [21, 129], "jupyterbook": [21, 129], "relationship": [21, 22, 23, 24, 33, 67, 69, 73, 74, 79, 85, 95, 97, 106, 123, 136, 138, 144, 145, 146, 155, 161, 162, 171, 195, 196, 197], "amplitud": [21, 24, 69, 72, 145, 146, 155], "div": 21, "center": [21, 31, 32, 33, 67, 68, 69, 72, 78, 79, 106, 113, 117, 122, 123, 124, 137, 146, 154, 155, 161, 162, 163, 169, 170, 172, 179], "em": [21, 165], "frequenc": [21, 24, 63, 72, 73, 74, 122, 123, 124, 144, 146, 149, 153, 154, 155, 170], "occurr": [21, 24, 136, 147], "deviat": [21, 24, 31, 72, 78, 79, 95, 123, 124, 137, 138, 144, 146, 155, 162, 163, 169, 170, 171], "sup": 21, "stand": [21, 24, 86, 163, 173], "\u03c3": [21, 162], "drive": [21, 23, 26, 44, 72, 86, 90, 129, 144, 146, 155, 172, 193], "strongest": [21, 23, 124, 129, 161], "decid": [21, 22, 23, 24, 98, 106, 121, 129, 162, 169, 172, 179, 187, 188], "period": [21, 22, 23, 33, 61, 74, 85, 87, 129, 136, 144, 146, 155, 186, 187], "ratio": [21, 23, 24, 32, 72, 85, 112, 129, 145, 146, 147, 161, 171, 172, 197, 198], "higher": [21, 23, 24, 72, 87, 97, 98, 114, 117, 121, 122, 129, 131, 146, 147, 161, 179, 180, 188, 198], "came": [21, 23, 24, 73], "focuss": [21, 22, 23, 129], "hyp": [21, 23], "vs": [21, 22, 23, 24, 31, 68, 94, 95, 106, 115, 124, 137, 138, 144, 145, 147, 154, 155, 161, 162, 163, 171, 172, 179, 187, 193, 195, 197, 199], "slower": [21, 23, 144, 169, 171, 187], "simplic": [21, 23, 81, 95, 97, 105, 112, 115, 138, 147, 180, 187, 189, 198], "accum": [21, 23], "fast": [21, 23, 72, 121, 149, 154, 172, 186, 188], "slow": [21, 23, 72, 105, 173, 186], "denot": [21, 23, 61, 68, 74, 114, 121, 123, 124, 146, 147, 153, 162, 170, 171, 172, 180, 187], "argument": [21, 23, 31, 32, 33, 61, 63, 67, 85, 86, 94, 105, 121, 122, 123, 124, 153, 155, 163, 171, 188, 193, 197, 198], "outcom": [21, 22, 23, 24, 73, 78, 79, 106, 136, 161, 169, 180, 188, 189, 195, 196, 197, 198], "consist": [21, 22, 67, 68, 69, 74, 78, 97, 114, 119, 121, 122, 135, 136, 146, 154, 169, 172, 175, 189, 195], "consecut": [21, 85], "influenc": [21, 22, 24, 86, 94, 99, 105, 106, 144, 147, 153, 161, 186, 187, 193, 197], "express": [21, 22, 32, 33, 61, 68, 72, 87, 94, 97, 105, 106, 112, 113, 114, 123, 135, 136, 147, 153, 154, 155, 171, 172, 173, 180, 186, 187, 188, 189], "z": [21, 24, 31, 32, 33, 67, 69, 72, 78, 106, 117, 121, 122, 124, 145, 162, 171, 172, 182, 198], "captur": [21, 31, 32, 67, 72, 85, 86, 92, 97, 98, 101, 113, 114, 117, 123, 124, 144, 147, 162, 196, 197, 198], "hand": [21, 22, 23, 31, 68, 73, 74, 79, 87, 94, 121, 122, 131, 135, 137, 146, 153, 155, 159, 163, 173, 188, 198], "justifi": 21, "loop": [21, 22, 32, 63, 69, 74, 86, 94, 96, 97, 98, 99, 106, 117, 121, 123, 124, 129, 136, 137, 144, 163, 169, 171, 179, 188, 189, 195, 196, 198], "clariti": [21, 22, 129, 193], "OR": [21, 68, 129, 136, 161], "kp": [21, 22, 129], "pr": [21, 22, 79, 129, 169], "0352": [21, 22, 81, 129], "19": [21, 22, 63, 67, 69, 74, 78, 79, 81, 86, 87, 94, 95, 96, 97, 98, 99, 101, 105, 112, 113, 121, 122, 124, 129, 135, 136, 137, 145, 147, 153, 154, 155, 161, 163, 169, 170, 171, 172, 173, 179, 180, 187, 188, 189, 196, 198], "nbdt": [21, 129], "scholasticahq": [21, 129], "com": [21, 29, 30, 31, 32, 33, 34, 35, 36, 43, 44, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "16723": [21, 129], "mk": [21, 129], "osf": [21, 22, 81, 85, 87, 105, 106, 121, 122, 123, 124, 129, 172], "w56vt": [21, 81, 129], "jean": [22, 23], "lauren": [22, 23], "dive": [22, 32, 61, 68, 79, 83, 105, 121, 153, 155, 162, 163, 169, 199], "satisfact": 22, "empow": 22, "chose": [22, 24, 106], "physic": [22, 73, 74, 85, 86, 131, 146, 167, 179], "repres": [22, 24, 31, 63, 67, 68, 72, 73, 74, 78, 79, 85, 87, 110, 112, 113, 114, 119, 121, 122, 123, 124, 131, 135, 145, 146, 147, 153, 154, 155, 159, 161, 162, 163, 170, 172, 173, 179, 186, 187, 189, 195, 196, 197, 198], "granular": [22, 94], "scale": [22, 24, 31, 68, 72, 78, 85, 86, 87, 106, 108, 119, 121, 124, 131, 136, 137, 151, 154, 155, 162, 163, 169, 170, 171, 172, 173, 180, 195, 197], "stai": [22, 68, 119, 136, 137, 153, 155, 170, 179, 188, 189], "span": [22, 31, 32, 68, 154, 173, 199], "wider": [22, 98, 121, 122, 137], "behaviour": [22, 29, 78, 79, 103, 106, 163, 191], "lumpabl": 22, "solv": [22, 31, 67, 72, 73, 74, 79, 95, 96, 97, 105, 121, 122, 123, 124, 135, 138, 153, 154, 155, 171, 172, 179, 184, 186, 188, 189], "analyt": [22, 31, 73, 74, 78, 94, 95, 96, 97, 105, 137, 153, 161, 162, 169, 172, 186], "numer": [22, 31, 32, 61, 67, 73, 78, 79, 83, 86, 94, 95, 97, 99, 105, 115, 135, 144, 147, 161, 163, 173, 180, 187], "spatial": [22, 117, 122, 123, 124, 131, 144, 188], "resolut": [22, 24, 122, 123, 124, 173], "regard": [22, 24, 103], "els": [22, 23, 31, 32, 33, 63, 67, 68, 69, 72, 73, 78, 79, 85, 86, 87, 96, 105, 106, 121, 122, 123, 124, 144, 145, 146, 147, 153, 154, 155, 161, 162, 169, 170, 171, 172, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "sake": [22, 163], "dl": [22, 121, 173, 191], "Being": 22, "w1d1": [22, 142], "meaningfulli": 22, "constrain": [22, 32, 87, 124], "add": [22, 24, 31, 32, 39, 61, 63, 67, 68, 72, 73, 74, 78, 79, 85, 86, 97, 98, 99, 105, 106, 121, 122, 123, 135, 137, 138, 144, 146, 147, 153, 154, 155, 161, 169, 170, 171, 172, 180, 187, 189], "needless": 22, "care": [22, 31, 78, 99, 106, 121, 161, 162, 193, 198], "highlight": [22, 24, 72, 78, 103, 189, 191], "outlin": [22, 74, 94, 123, 196, 197, 198], "draw": [22, 33, 61, 67, 68, 73, 78, 87, 94, 96, 97, 106, 121, 123, 124, 137, 144, 146, 163, 177, 179, 187], "diagram": [22, 99, 121, 136, 198], "sketch": 22, "formal": [22, 67, 72, 85, 123, 124, 161, 162, 177, 179, 184, 186, 188], "thu": [22, 67, 72, 79, 83, 87, 97, 98, 99, 106, 121, 122, 123, 124, 144, 146, 147, 163, 169, 173, 180, 186, 188, 189], "huge": [22, 151, 189], "broken": 22, "portenti": 22, "ideal": [22, 86, 87, 98, 121, 124, 187], "arrow": [22, 67, 68, 69, 135, 154, 195, 196, 197, 198], "intern": [22, 32, 33, 63, 105, 110, 117, 119, 122, 123, 175, 180, 189], "place": [22, 68, 74, 78, 83, 105, 161, 162, 179, 180, 187, 188, 189], "explan": [22, 81, 113, 122, 146, 186, 195, 196], "rough": [22, 79], "forget": [22, 66, 67, 77, 79, 105, 106, 114, 115, 145, 163, 171, 180, 198], "recurs": [22, 169, 170, 171, 173, 186], "insid": [22, 61, 63, 78, 85, 121, 155], "icon": [22, 179], "unit": [22, 23, 24, 32, 33, 61, 67, 68, 78, 85, 86, 87, 95, 105, 112, 119, 121, 122, 123, 135, 138, 144, 145, 146, 169, 171, 179, 186, 187], "easiest": [22, 83, 161, 198], "ad": [22, 29, 32, 33, 67, 72, 79, 85, 86, 95, 97, 105, 106, 121, 123, 135, 137, 138, 155, 162, 169, 171, 173, 180, 189, 195, 197], "accomplish": [22, 98, 198], "surprisingli": [22, 189], "remov": [22, 29, 31, 32, 61, 63, 67, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 121, 123, 124, 135, 137, 144, 145, 146, 147, 153, 154, 161, 163, 169, 171, 172, 180, 187, 188, 189, 195, 196, 197, 198], "insight": [22, 24, 31, 74, 83, 110, 122, 142], "isn": [22, 68, 94, 124, 162, 179, 187], "stabil": [22, 72, 95, 135, 136, 151, 154, 173, 180, 186], "equilibrium": [22, 74, 137, 138, 155, 171], "asymptot": [22, 188], "isol": [22, 29, 31, 61, 131, 135, 162], "mistak": [22, 170, 172], "debug": [22, 61, 163], "wore": 22, "nice": [22, 72, 73, 78, 122, 124, 162, 187, 195, 197], "useless": 22, "distract": 22, "reader": 22, "alreali": 22, "achiev": [22, 83, 86, 122, 169, 173, 188, 189], "handi": [22, 61, 97, 180], "finish": [22, 33, 37, 79, 87, 94, 95, 96, 97, 98, 99, 105, 113, 146, 147, 153, 154, 169, 186, 196], "criterion": [22, 31, 32, 33, 96, 169], "satisfi": [22, 67, 87, 94, 112, 198], "criteria": [22, 87, 135, 198], "parametr": 22, "elimin": 22, "met": [22, 197], "board": 22, "endless": 22, "benchmark": [22, 114, 140, 177, 191], "neglect": 22, "warrant": 22, "cannot": [22, 72, 73, 74, 85, 124, 136, 162, 163, 170, 171, 180, 186, 187], "ultim": [22, 67, 83, 127, 163], "qualit": [22, 32, 74, 95, 97, 105, 122, 135, 144, 179, 196], "upfront": 22, "amount": [22, 32, 68, 72, 79, 85, 86, 99, 114, 124, 136, 138, 146, 147, 161, 162, 169, 171, 172, 179, 180, 186, 195, 198], "w1d3": [22, 103, 119, 121, 193], "breadth": 22, "bic": 22, "aic": 22, "fair": 22, "respect": [22, 31, 69, 72, 74, 78, 79, 86, 87, 94, 95, 99, 105, 114, 121, 122, 123, 124, 135, 146, 147, 153, 154, 155, 162, 170, 172, 179, 189], "subsumpt": 22, "uncov": [22, 26, 33, 94, 123, 199], "falsifi": 22, "demonstr": [22, 23, 24, 67, 69, 121, 127, 155, 189], "appar": [22, 31, 114], "alon": [22, 172], "leverl": 22, "avenu": 22, "experiment": [22, 24, 26, 74, 83, 86, 92, 124, 146, 163, 169, 172, 175, 186, 191, 196, 198], "target": [22, 31, 33, 69, 105, 106, 115, 121, 124, 131, 162, 177, 180, 186, 188], "experimentalist": [22, 146, 163], "analog": [22, 171, 196], "famou": [22, 73, 188], "worth": [22, 122, 172, 175, 179], "1000": [22, 24, 72, 73, 74, 78, 79, 85, 86, 95, 99, 110, 112, 113, 123, 124, 136, 137, 144, 145, 146, 147, 153, 162, 163, 173, 187, 188, 189, 196], "parallel": [22, 26, 68, 129, 135, 186], "convinc": [22, 137, 138], "AND": [22, 68], "impact": [22, 74, 101, 145, 151, 170, 172, 187, 189, 198], "accept": [22, 31, 32, 33, 68, 79, 96, 124, 153, 154, 155, 180], "frget": 22, "spell": 22, "unreason": 22, "claim": [22, 169], "reject": [22, 96, 151, 198], "mesi": 22, "rightfulli": 22, "cleanli": 22, "comment": [22, 33, 63, 79, 85, 86, 87, 105, 114, 115, 136, 151, 163, 179, 187, 188, 189], "stereotyp": 22, "piec": [22, 31, 105, 124, 162], "condens": [22, 97, 172], "To": [22, 23, 24, 31, 33, 44, 69, 72, 73, 74, 78, 79, 85, 86, 87, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 123, 124, 135, 136, 137, 138, 144, 146, 147, 153, 155, 161, 162, 163, 169, 171, 172, 175, 179, 180, 186, 189, 195, 197], "summari": [22, 172], "summar": [22, 23, 24, 63, 68, 79, 99, 112, 135, 161, 170], "articul": [22, 23, 24], "tri": [22, 23, 24, 61, 94, 95, 106, 138, 161, 171, 188], "overview": [22, 23, 24, 112, 113, 114, 115, 135, 153, 191], "conclud": [22, 23, 24], "briefli": [22, 23, 24, 69, 110, 136, 172, 173], "argu": [22, 23, 24, 193], "plausibl": [22, 23, 24, 33, 74, 101, 119, 199], "instruct": [22, 31, 32, 33, 79, 94, 123, 179], "guidelin": [22, 23, 24], "effect": [22, 31, 32, 33, 63, 72, 74, 78, 79, 81, 86, 87, 92, 95, 97, 101, 108, 121, 122, 146, 149, 153, 163, 169, 170, 172, 186, 187, 189, 191, 193, 195, 196, 197, 198], "mensh": 22, "schedul": [22, 186], "schemat": [22, 106, 195], "necessarili": [22, 69, 98, 154, 162, 186], "upload": 22, "github": [22, 29, 33, 40, 90, 106, 108, 115, 117, 121, 135, 172], "forc": [22, 32, 67, 106, 121, 179, 195, 196], "succinctli": [22, 97], "commit": 22, "purpos": [22, 23, 24, 61, 68, 69, 72, 74, 79, 86, 94, 99, 105, 106, 121, 124, 138, 144, 163, 172], "walk": [22, 123, 135, 136, 138, 169, 172, 175], "biol": [22, 73, 74], "e1005619": 22, "1005619": 22, "disclaim": [23, 24, 68], "procedur": [23, 24, 90, 94, 96, 98, 106, 124, 145, 159, 198], "pip": [23, 24, 29, 32, 45, 72, 172, 198], "tqdm": 23, "quiet": [23, 24, 29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "matric": [23, 31, 67, 69, 92, 97, 98, 106, 114, 121, 123, 124, 135, 138, 170, 172, 180, 195, 196, 197, 198], "begin": [23, 24, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 175, 179, 180, 186, 187, 188, 195, 197, 198], "301": 23, "36": [23, 61, 78, 79, 96, 99, 105, 106, 112, 114, 121, 124, 131, 137, 147, 169, 171, 172, 173, 179, 189, 195, 196, 198], "7575": 23, "975": 23, "m_r": 23, "m_p": 23, "mathbb": [23, 68, 87, 98, 113, 144, 161, 162, 172, 186, 187, 195], "c_": [23, 24, 86, 105, 122, 198], "cdot": [23, 24, 67, 68, 72, 74, 78, 106, 112, 121, 123, 124, 145, 147, 153, 155, 162, 170, 173], "w1d4": [23, 193], "glm": [23, 83, 92, 103, 106, 119], "whiteboard": [23, 24], "convert": [23, 31, 32, 33, 87, 121, 122, 123, 124, 144, 145, 146, 169, 171, 173], "belong": [23, 85, 124], "half": [23, 32, 74, 96, 122, 137, 180], "halfwin": 23, "a_r": 23, "cross": [23, 31, 32, 33, 63, 74, 86, 90, 94, 95, 96, 97, 98, 103, 105, 123, 124, 135, 145, 153, 169], "getdesignmatrix": 23, "arg": [23, 24, 31, 32, 33, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 186, 187, 188, 189, 195, 196, 197, 198], "ndarrai": [23, 31, 32, 33, 67, 68, 69, 72, 78, 79, 85, 87, 94, 95, 96, 97, 98, 99, 115, 121, 123, 124, 135, 136, 137, 144, 161, 171, 172, 180, 186, 187, 188, 189, 195, 196, 197, 198], "length": [23, 32, 33, 67, 68, 69, 72, 85, 97, 106, 112, 121, 136, 138, 145, 146, 169, 170, 173, 179, 180, 195, 198], "float": [23, 31, 32, 33, 61, 63, 69, 78, 79, 85, 86, 94, 95, 96, 106, 112, 113, 114, 115, 121, 122, 123, 124, 135, 137, 138, 144, 147, 153, 162, 163, 169, 170, 173, 179, 180, 186, 187, 188, 189, 196, 197, 198], "extent": [23, 33, 67, 95, 114, 163], "1d": [23, 67, 85, 86, 94, 95, 97, 105, 106, 121, 123, 124, 153, 155, 169, 170, 171, 180], "movstim": 23, "win_idx": 23, "desmat": 23, "mov": [23, 24], "76": [23, 63, 144, 146, 169, 170, 189], "33475": 23, "77": [23, 63, 73, 79, 169, 189], "53275": 23, "78": [23, 63, 131, 169, 180, 191], "61975": 23, "calcul": [23, 31, 32, 33, 68, 69, 73, 74, 78, 79, 85, 94, 95, 96, 97, 98, 99, 112, 121, 123, 135, 136, 137, 144, 145, 146, 147, 154, 155, 162, 169, 170, 171, 173, 179, 180, 186, 187, 188, 196, 197, 198], "correctli": [23, 32, 79, 97, 169, 179, 180, 195, 198], "saw": [23, 31, 33, 67, 68, 69, 72, 74, 85, 86, 99, 106, 113, 114, 121, 123, 136, 144, 146, 155, 161, 162, 163, 170, 171, 186, 187, 196, 198], "cv": [23, 106, 144, 146], "dot": [23, 24, 61, 63, 68, 73, 74, 78, 86, 87, 98, 99, 105, 106, 112, 113, 135, 136, 137, 138, 146, 162, 163, 169, 195, 196, 197, 198], "graph": [23, 74, 98, 115, 124, 131, 136, 173, 180, 195, 196, 198], "56": [23, 105, 124, 131, 136, 144, 153, 154, 169, 188, 189, 195, 196], "72": [23, 26, 67, 79, 87, 121, 124, 131, 144, 149, 154, 155, 169, 170, 180, 189], "65": [23, 68, 79, 81, 124, 146, 147, 153, 155, 161, 162, 169, 179, 189], "median": [23, 96, 162, 163, 196], "accord": [23, 68, 72, 78, 83, 85, 95, 96, 97, 99, 112, 123, 147, 169, 171, 173, 179, 180, 186, 188, 195], "magnitud": [23, 106, 124, 135, 147, 171, 180, 196], "ignor": [23, 33, 79, 97, 105, 106, 115, 121, 123, 124, 154, 155, 161, 162, 163, 172, 193], "maximum": [23, 31, 32, 33, 69, 72, 78, 85, 94, 96, 97, 98, 99, 101, 103, 105, 106, 113, 123, 124, 146, 147, 153, 159, 161, 179, 180, 186, 187, 188, 189], "discrimin": [23, 114, 119, 121, 122], "classifymotionfromspik": 23, "750": [23, 99, 146], "int": [23, 24, 31, 32, 33, 61, 68, 69, 72, 78, 79, 85, 86, 96, 106, 114, 115, 121, 123, 124, 138, 144, 145, 146, 147, 153, 155, 169, 170, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "regular": [23, 61, 103, 121, 144, 146, 159, 189, 197], "intend": [23, 171, 196], "ye": [23, 24, 138, 144, 145, 179], "somewhat": [23, 79, 172], "contrast": [23, 72, 79, 97, 115, 170, 173, 177, 189, 199], "quit": [23, 94, 98, 105, 121, 163, 187, 189, 198], "presenc": [23, 153, 198], "runanalysi": 23, "050": 23, "class_set": 23, "empti": [23, 67, 69, 78, 105, 144, 170, 179], "halfwin_no": 23, "lty": 23, "leg_hw": 23, "classes_no": 23, "leg_class": 23, "color": [23, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 85, 86, 94, 95, 96, 97, 105, 106, 112, 113, 115, 122, 123, 124, 135, 137, 138, 144, 145, 146, 147, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 189, 195, 196, 197, 198, 199], "purpl": [23, 68], "motions_no": 23, "cond_acc": 23, "m_acc": 23, "simplifi": [23, 61, 72, 74, 79, 86, 95, 98, 142, 147, 173], "plotaccuraci": 23, "accuarci": 23, "xlim": [23, 31, 32, 33, 67, 68, 69, 72, 73, 74, 78, 85, 86, 87, 95, 96, 114, 121, 124, 136, 137, 145, 146, 147, 155, 161, 172, 173, 188, 189, 197, 198], "ylim": [23, 31, 32, 33, 67, 68, 69, 72, 73, 74, 78, 85, 86, 87, 95, 96, 113, 114, 121, 124, 137, 144, 145, 146, 147, 153, 155, 161, 172, 173, 187, 188, 189], "proport": [23, 24, 79, 94, 106, 114, 137, 145, 161, 162, 169, 170, 172, 195, 197, 198], "xtick": [23, 32, 33, 63, 67, 68, 69, 72, 105, 106, 113, 124, 138, 161, 187], "tick": [23, 31, 114, 115, 123, 186, 195, 196], "loc": [23, 67, 68, 69, 72, 74, 97, 105, 123, 137, 144, 145, 146, 147, 153, 154, 155, 162, 169, 170, 171, 179, 180, 188, 189], "job": [23, 105, 121, 138, 169, 188, 195, 197], "dash": [23, 73, 74, 144, 145, 146, 153, 162, 163, 169, 170, 180], "wors": [23, 123, 162, 196], "longer": [23, 32, 79, 146, 147, 162, 186, 187, 189], "harder": [23, 73, 124, 169, 191, 197], "clearer": [23, 63], "judgment": [23, 24, 117, 119, 165], "sensor": [23, 171, 172], "notion": [23, 72, 106, 151, 161], "Of": [23, 79, 161, 196], "contribut": [23, 61, 72, 86, 88, 95, 97, 175, 188, 191], "adjac": [23, 24, 67, 72, 85, 138, 145, 173], "unknown": [23, 24, 72, 74, 94, 161, 162, 187], "effort": [23, 94, 172, 179], "cumul": [23, 72, 114, 136, 137, 169, 186, 188], "instantan": [23, 145, 147, 179, 188], "world": [23, 31, 32, 67, 73, 79, 95, 122, 137, 159, 161, 162, 167, 169, 171, 177, 179, 184, 186, 188, 191, 197, 199], "scenario": [23, 31, 61, 87, 97, 147, 161, 180, 186, 187], "causal": [23, 37, 85, 103, 131, 142, 151, 191, 193, 199], "letter": [23, 24, 73], "paraphras": [23, 24], "extrem": [23, 24, 31, 69, 78, 79, 94, 105, 161, 179, 187], "artifici": [23, 24, 31, 81, 117, 119, 138, 146, 147, 163, 184, 186], "hopefulli": [23, 24, 31, 33, 61, 67, 78, 83, 122, 123, 137, 196], "hit": [23, 24, 144, 162, 188], "roadblock": [23, 24], "somewher": [23, 24, 105, 171, 179], "optim": [23, 31, 32, 33, 37, 72, 78, 83, 95, 96, 97, 98, 99, 103, 106, 114, 117, 119, 122, 123, 124, 131, 153, 154, 155, 159, 161, 162, 163, 167, 170, 173, 175, 177, 184, 186, 187, 188, 189, 199], "neuroscientist": [23, 78, 81, 110, 119, 153, 173], "weight": [23, 32, 33, 67, 68, 69, 74, 78, 87, 97, 98, 99, 105, 106, 113, 115, 121, 123, 142, 146, 153, 161, 162, 163, 171, 186, 195, 196, 197, 198], "role": [23, 31, 79, 101, 106, 112, 131, 145, 153, 186, 191], "demo": [24, 159, 163], "theta": [24, 31, 32, 33, 67, 72, 79, 94, 95, 96, 97, 98, 99, 105, 106, 112, 122, 123, 124, 144, 153, 154, 155, 172, 173, 179, 195, 196, 197, 198], "mathbf": [24, 67, 68, 69, 79, 94, 95, 96, 97, 105, 113, 121, 123, 124, 135, 136, 138], "sigma": [24, 31, 61, 63, 72, 78, 79, 95, 98, 99, 106, 112, 113, 122, 123, 124, 137, 138, 144, 162, 163, 169, 170, 171, 172, 195, 197, 198], "drift": [24, 73, 74, 138, 165, 180], "diffus": [24, 73, 74, 138, 146, 165, 170], "establish": [24, 138], "framework": [24, 69, 79, 101, 103, 105, 106, 117, 138, 142, 159, 184, 186, 189, 196], "frac": [24, 32, 61, 67, 72, 73, 74, 78, 79, 86, 87, 94, 95, 97, 99, 105, 106, 112, 113, 114, 121, 123, 124, 135, 137, 144, 145, 146, 147, 153, 161, 162, 169, 171, 172, 173, 179, 180, 187, 197], "de": [24, 87, 145, 154, 155, 175], "leakag": [24, 86], "instal": [24, 45, 76], "panda": [24, 171], "dark_background": 24, "vestibular_sign": 24, "sig": [24, 137, 138, 144, 145, 146, 153, 155], "scalar": [24, 67, 68, 69, 72, 78, 79, 86, 97, 98, 99, 105, 106, 112, 113, 114, 121, 123, 124, 135, 136, 137, 138, 161, 162, 163, 169, 171, 180, 198], "sd": [24, 105], "white": [24, 31, 85, 95, 105, 114, 122, 146, 171], "1m": 24, "linspac": [24, 31, 32, 33, 61, 63, 68, 78, 79, 85, 87, 94, 95, 97, 105, 106, 121, 122, 123, 124, 138, 144, 147, 153, 154, 155, 162, 163, 169, 170, 171, 173, 180, 188, 189, 195, 196, 197, 198], "14": [24, 26, 67, 72, 74, 78, 79, 85, 86, 94, 95, 96, 97, 98, 99, 101, 105, 106, 113, 117, 121, 122, 123, 124, 135, 137, 140, 145, 146, 147, 153, 154, 155, 163, 170, 172, 180, 186, 187, 188, 189, 195, 196, 198], "1001": 24, "exp": [24, 72, 73, 74, 78, 79, 85, 95, 105, 106, 122, 123, 124, 135, 153, 154, 155, 162, 163, 169, 171, 173, 195, 196, 197, 198], "diff": [24, 72, 85, 86, 87, 136, 144, 146, 173], "u": [24, 31, 32, 33, 61, 67, 69, 72, 78, 101, 112, 113, 117, 121, 146, 153, 154, 155, 157, 161, 171, 180, 188, 189, 191], "leaki": [24, 61, 86, 87, 131, 142, 145, 199], "append": [24, 31, 32, 33, 73, 74, 85, 86, 97, 99, 106, 121, 123, 124, 136, 144, 145, 146, 147, 153, 154, 155, 169, 170, 173, 179, 180, 198], "thr": [24, 146], "run_model": 24, "selfmot": 24, "aris": [24, 68, 123, 144, 151, 155, 163, 197], "fool": [24, 186], "conceptu": 24, "behav": [24, 86, 137, 146, 162, 171, 173, 186, 188, 198], "regim": [24, 121, 140, 144, 146, 149, 155], "itertool": [24, 68], "automat": [24, 31, 63, 117, 121, 124, 175], "param": [24, 32, 135, 138, 163, 171, 172, 179, 188, 189], "zip": [24, 31, 32, 33, 67, 69, 87, 94, 95, 106, 122, 123, 147, 161, 172, 173], "temp": 24, "hypothsi": 24, "pd": [24, 171], "df": [24, 72, 153, 154, 155, 171], "datafram": [24, 171], "column": [24, 31, 61, 68, 72, 79, 97, 98, 99, 105, 112, 113, 114, 121, 122, 123, 124, 161, 163, 197], "multi": [24, 123, 131, 149, 186], "panel": [24, 45, 73, 74, 106], "layout": [24, 32, 72, 73, 74, 78, 79, 144, 145, 146, 147, 161, 162, 170, 171, 173, 179], "constrained_layout": 24, "absent": 24, "present": [24, 26, 31, 33, 37, 79, 97, 105, 117, 119, 121, 122, 123, 136, 153, 163, 172, 186, 195], "mov_": 24, "uniqu": [24, 67, 74, 87, 105, 121, 123, 124, 136], "thr_": 24, "sig_": 24, "thr_n": 24, "c_n": [24, 67], "subdf0": 24, "groupbi": 24, "subdf1": 24, "im0": [24, 195], "im1": [24, 195], "4f": [24, 31, 32, 33, 79, 124, 138, 153, 186], "set_ylim": [24, 68, 69, 87, 124, 137, 147, 155, 161, 162, 169, 170, 171, 173, 179], "set_xlim": [24, 68, 69, 87, 124, 147, 161, 162, 171, 173, 179], "450": 24, "set_xlabel": [24, 72, 78, 79, 87, 105, 121, 122, 123, 124, 135, 147, 154, 155, 161, 162, 163, 169, 170, 171, 179, 180, 186, 195, 197, 198], "set_ylabel": [24, 67, 72, 78, 79, 87, 105, 121, 122, 123, 124, 135, 147, 154, 155, 161, 162, 163, 169, 170, 171, 173, 179, 180, 186, 195, 196, 197, 198], "set_facecolor": [24, 163], "grei": [24, 63, 68, 73, 74, 161, 162, 163, 170, 172], "redund": 24, "sensibl": [24, 137], "0004": 24, "d0": 24, "d1": 24, "detect": [24, 26, 172], "57": [24, 74, 81, 105, 124, 136, 144, 154, 155, 169, 188, 189, 198], "roughli": [24, 105, 115, 186, 196], "likelihood": [24, 78, 90, 92, 94, 96, 97, 98, 99, 101, 103, 105, 106, 123, 124, 159, 162, 167, 169, 170, 171, 173, 188], "201": 24, "monoton": [24, 72, 79, 85, 95, 124, 146, 153, 173], "satur": [24, 121, 153], "push": 24, "larger": [24, 72, 74, 105, 106, 113, 119, 121, 122, 124, 137, 138, 161, 186, 187, 193, 196, 197, 198], "linearli": [24, 67, 74, 137, 195], "error": [24, 31, 32, 33, 45, 67, 68, 85, 87, 90, 95, 96, 97, 99, 105, 106, 114, 121, 131, 137, 138, 153, 154, 155, 162, 169, 171, 172, 175, 180, 188, 189, 198], "construct": [24, 31, 85, 86, 87, 103, 105, 121, 123, 124, 137, 138, 163], "under": [24, 31, 32, 45, 68, 72, 99, 123, 124, 144, 145, 146, 154, 155, 165, 170, 179, 180, 186], "variat": [24, 74, 85, 86, 113, 136, 144, 186], "probabilist": [24, 78, 79, 101, 136, 161, 172, 191], "dokka": 24, "head": [24, 67, 68, 137, 187], "39": [26, 69, 79, 86, 105, 106, 112, 113, 121, 124, 137, 144, 146, 161, 169, 171, 173, 188, 189, 195, 196, 197, 198], "neuropixel": [26, 85, 106], "700": [26, 122], "mous": [26, 106, 110, 121, 122, 123, 124, 131, 162, 180], "superior": [26, 172], "colliculu": 26, "pathwai": [26, 131], "lfp": [26, 196], "waveform": 26, "zatka": 26, "haa": 26, "carandini": 26, "harri": [26, 131], "action": [26, 63, 83, 98, 142, 144, 147, 157, 161, 162, 163, 167, 173, 175, 177, 179, 184, 186, 188, 189, 199], "576": 26, "7786": 26, "266": [26, 67], "273": 26, "s41586": [26, 182], "019": [26, 117, 131, 182], "1787": 26, "neurostar": 26, "org": [26, 43, 67, 73, 74, 81, 90, 99, 101, 106, 108, 115, 117, 121, 122, 123, 124, 131, 149, 157, 175, 182, 191, 198], "14539": 26, "000": [26, 31, 61, 114, 115, 121, 122, 123, 124, 153, 163, 196], "grate": [26, 119, 121, 122, 123, 124], "whisk": 26, "snif": 26, "tast": [26, 63, 85], "orient": [26, 31, 33, 67, 78, 79, 97, 119, 121, 122, 124, 154, 162, 197], "reddi": 26, "multidimension": [26, 97], "364": 26, "6437": 26, "eaav7893": 26, "1126": [26, 81, 131, 140, 149, 175, 182], "aav7893": 26, "michaelo": [26, 117], "tsyboulski": [26, 117], "lindo": [26, 117], "184": [26, 117], "2767": [26, 117], "2778": [26, 117], "03": [26, 74, 90, 101, 117, 123, 140, 149, 155, 162, 175], "042": [26, 117, 153], "beginn": [26, 31, 63, 157], "novel": [26, 78, 79], "excitatori": [26, 74, 86, 87, 149, 151, 155], "vip": 26, "sst": 26, "lm": [26, 153], "focus": [26, 67, 68, 79, 85, 99, 127, 144, 157, 191], "dataload": 26, "sdk": 26, "atla": 26, "swdb": 26, "databook": 26, "marina": 26, "garret": 26, "iryna": 26, "yavorska": 26, "doug": 26, "ollerenshaw": 26, "garrett": 26, "2023": 26, "circuit": [26, 67, 101, 122, 146, 149], "www": [26, 67, 73, 74, 90, 108, 117, 121, 122, 123, 124, 131, 157, 175, 198], "1101": [26, 90, 117, 121, 122, 123, 124, 149, 182], "02": [26, 61, 63, 72, 74, 106, 123, 131, 136, 137, 138, 144, 146, 149, 153, 154, 155, 161, 162, 170, 173], "528085v2": 26, "bonu": [29, 33, 85, 110, 119, 138, 142, 154, 162, 167], "autoencod": [29, 110], "pip3": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "vibecheck": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "datatop": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "datatopscontentreviewcontain": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "content_review": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "notebook_sect": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "str": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "prompt": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "pmyvdlilci": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "api": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "east": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "amazonaw": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "klab": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "neuromatch_cn": [29, 30, 31, 32, 33, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "user_kei": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "y1x3mpx5": [29, 30, 31, 32, 33, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "feedback_prefix": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "bonus_autoencoders_intro": 29, "33m": 29, "deprec": [29, 137, 138], "legaci": 29, "setup": 29, "py": [29, 67, 79, 121, 124, 135, 137, 138, 153, 161, 196, 197], "bdist_wheel": 29, "enforc": [29, 31, 121, 124], "pep517": 29, "pyproject": 29, "toml": 29, "file": [29, 33, 67, 79, 105, 121, 124, 129, 135, 140, 153], "tree": [29, 182], "pypa": 29, "6334": 29, "0m": 29, "31merror": 29, "account": [29, 45, 73, 78, 79, 92, 99, 105, 137, 138, 147, 149, 161, 162, 165, 171, 172, 180], "packag": [29, 31, 61, 67, 79, 86, 121, 124, 135, 153, 172, 196, 197], "conflict": [29, 98], "jupyt": [29, 106, 115, 135], "client": 29, "incompat": 29, "31m": 29, "_video": [29, 30, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 127, 128, 133, 134, 142, 143, 151, 152, 159, 160, 167, 168, 177, 178, 184, 185, 193, 194], "bonus_autoencoders_outro": 30, "marco": [31, 32, 33, 61, 63], "brigham": [31, 32, 33, 61, 63], "ccnss": [31, 32, 33, 61, 63], "itzel": [31, 32, 33, 171, 179], "olivo": [31, 32, 33, 171, 179], "karen": [31, 32, 33], "schroeder": [31, 32, 33], "karolina": [31, 32, 33, 61, 63, 135, 136, 163, 179, 180], "stosio": [31, 32, 33, 61, 63, 135, 136, 163, 179, 180], "spiro": [31, 32, 33, 61, 63, 72, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 189, 195, 196, 197, 198], "chavli": [31, 32, 33, 61, 63, 72, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 189, 195, 196, 197, 198], "robust": [31, 32, 33, 81, 115], "famili": [31, 68, 85], "auxiliari": [31, 171], "primari": [31, 79, 121, 123, 131], "compress": [31, 32, 33, 110], "throw": 31, "awai": [31, 33, 69, 79, 86, 137, 146, 161, 162, 172, 188, 197], "fictiti": 31, "cognit": [31, 32, 33, 81, 90, 101, 108, 117, 137, 140, 149, 172], "bundl": 31, "elabor": 31, "guess": [31, 78, 79, 96, 105, 138, 147, 153, 162, 169, 171, 172, 186, 188], "occlud": [31, 33], "recov": [31, 33, 68, 79, 146, 155, 163, 171, 173, 180, 187, 196, 198], "handwritten": [31, 114], "digit": [31, 32, 72, 95, 114, 115, 121, 123, 124, 138], "bottleneck": [31, 32, 33], "layer": [31, 32, 33, 105, 106, 119, 121, 140], "fewer": [31, 99, 114, 121, 122, 169, 198], "enabl": [31, 32, 45, 63, 67, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 106, 112, 113, 114, 121, 124, 135, 136, 137, 144, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 179, 180, 186, 187, 195, 196, 197, 198], "roadmap": 31, "typic": [31, 32, 83, 85, 92, 121, 122, 124, 135, 144, 145, 146, 147, 161, 163, 172, 173, 186, 193], "architectur": [31, 33, 119, 121, 122, 123, 189], "extend": [31, 33, 69, 72, 73, 74, 97, 105, 121, 146, 151, 153, 154, 161, 162, 169, 180, 199], "acquaint": 31, "princip": [31, 110, 114, 115, 135], "non": [31, 32, 33, 68, 74, 85, 86, 87, 106, 110, 119, 121, 122, 123, 135, 146, 151, 153, 162, 171, 180, 191], "factor": [31, 69, 72, 73, 74, 85, 86, 87, 95, 108, 124, 131, 135, 145, 153, 162, 171, 188, 189], "hidden": [31, 32, 37, 63, 78, 79, 85, 101, 106, 121, 123, 124, 131, 159, 163, 167, 171, 172, 173, 177, 179, 184, 186, 197, 199], "inspect": [31, 32, 33, 45, 69, 97, 154, 179, 180, 197], "bonus_autoencoders_t1": 31, "torch": [31, 32, 33, 121, 122, 123, 124], "fetch_openml": [31, 32, 33, 114, 115], "log": [31, 32, 33, 45, 61, 63, 66, 68, 69, 72, 73, 74, 77, 78, 79, 85, 86, 87, 90, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "getlogg": [31, 32, 33, 61, 63, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "font_manag": [31, 32, 33, 61, 63, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "disabl": [31, 32, 33, 61, 63, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "config": [31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "inlinebackend": [31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "figure_format": [31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "retina": [31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "githubusercont": [31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "neuromatchacademi": [31, 32, 33, 40, 43, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "nma2020": [31, 32, 33, 163, 169, 170, 173], "mplstyle": [31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "fig_w": [31, 63, 72], "fig_h": [31, 63, 72], "rcparam": [31, 63, 68, 69, 72, 79], "downloadmnist": [31, 32, 33], "tensor": [31, 32, 33, 121, 122, 123, 124, 131, 173], "60000": [31, 32, 33], "28": [31, 32, 33, 61, 67, 69, 74, 87, 90, 94, 96, 105, 112, 114, 117, 121, 122, 123, 124, 135, 136, 137, 145, 146, 147, 153, 154, 155, 163, 169, 171, 172, 175, 179, 180, 186, 187, 189, 195, 196, 197, 198], "10000": [31, 32, 33, 63, 69, 85, 136, 137, 145, 179, 196, 197, 198], "mnist_784": [31, 32, 33, 114, 115], "return_x_i": [31, 32, 33], "as_fram": [31, 32, 33, 114, 115], "trunk": [31, 32, 33], "n_train": [31, 32, 33, 121, 123, 124], "n_test": [31, 32, 33, 124], "train_idx": [31, 32, 33], "test_idx": [31, 32, 33], "from_numpi": [31, 32, 33, 122, 123, 124], "astyp": [31, 32, 33, 69, 122, 123, 124, 144, 146, 147, 162, 179], "float32": [31, 32, 33, 85, 121, 122, 123, 124], "init_weights_kaiming_uniform": [31, 32, 33], "pytorch": [31, 32, 33, 119, 124], "kaim": [31, 32, 33], "uniform": [31, 32, 33, 61, 72, 79, 87, 94, 95, 96, 97, 98, 99, 114, 162, 172, 179, 186, 188, 189], "modul": [31, 32, 33, 34, 35, 36, 45, 63, 85, 99, 105, 112, 113, 114, 115, 121, 122, 123, 124, 138, 144, 145, 146, 147, 149, 153, 154, 155, 170, 196, 199], "noth": [31, 32, 33, 63, 78, 79, 112, 113, 114, 115, 121, 123, 124, 135, 146, 162, 180, 195, 196, 197, 198], "isinst": [31, 32, 33, 67, 153], "init": [31, 32, 33, 121, 124, 153, 154, 155, 180], "kaiming_uniform_": [31, 32, 33], "init_weights_kaiming_norm": [31, 32, 33], "kaiming_normal_": [31, 32, 33], "get_layer_weight": [31, 32, 33], "learnabl": [31, 32, 33], "item": [31, 32, 33, 85, 105, 106, 121, 123, 124, 147, 153, 173, 179], "detach": [31, 32, 33, 122, 123, 124], "eval_ms": [31, 32, 33], "y_pred": [31, 32, 33, 106, 124], "y_true": [31, 32, 33, 96], "squar": [31, 32, 33, 61, 67, 68, 78, 95, 96, 98, 99, 105, 112, 113, 115, 121, 124, 145, 161, 162, 172, 189], "mse": [31, 32, 33, 95, 96, 98, 99, 121, 124, 162, 172, 180], "no_grad": [31, 32, 33], "mseloss": [31, 32, 33, 121, 124], "eval_bc": [31, 32, 33], "entropi": [31, 32, 33, 123, 124], "bce": [31, 32, 33], "bceloss": [31, 32, 33, 123], "plot_weights_ab": 31, "encoder_w_a": 31, "encoder_w_b": 31, "decoder_w_a": 31, "decoder_w_b": 31, "label_a": 31, "label_b": 31, "bins_encod": 31, "bins_decod": 31, "row": [31, 32, 33, 61, 63, 68, 72, 79, 85, 97, 105, 114, 115, 121, 122, 123, 124, 137, 145, 146, 147, 161, 163, 170, 173, 179, 189, 197], "histogram": [31, 78, 79, 85, 86, 95, 137, 138, 144, 145, 147, 171, 179], "checkpoint": [31, 33], "string": [31, 32, 33, 105, 106, 123, 135, 163, 179, 186], "num": [31, 61, 188, 189], "32": [31, 32, 33, 63, 67, 85, 97, 98, 99, 105, 106, 114, 117, 121, 123, 124, 135, 146, 153, 154, 155, 161, 163, 169, 172, 173, 179, 186, 187, 188, 189, 195, 198], "221": [31, 146], "hist": [31, 63, 78, 79, 85, 87, 95, 96, 136, 137, 138, 144, 149, 171, 179], "flatten": [31, 97, 123, 124, 161, 170, 173, 195, 196, 197, 198], "222": [31, 155], "223": [31, 146], "224": [31, 146, 155], "tight_layout": [31, 32, 33, 63, 97, 105, 106, 114, 121, 123, 124, 144, 146, 147, 154, 155, 171, 179, 180, 186, 196, 197], "plot_row": [31, 32, 33], "show_n": [31, 32, 33], "image_shap": [31, 32, 33], "randomli": [31, 32, 33, 78, 79, 96, 105, 114, 121, 124, 137, 138, 170, 173, 186, 187, 188, 189, 193, 195], "tupl": [31, 32, 33, 85, 106, 123, 124, 135, 153, 163, 198], "items_idx": [31, 32, 33], "enumer": [31, 32, 33, 63, 67, 68, 73, 94, 95, 96, 99, 105, 122, 123, 124, 135, 137, 138, 169, 172, 173, 179, 187, 189, 196, 197, 198], "ndim": [31, 32, 33, 97, 98, 99, 122, 137, 138, 188, 189], "expand_dim": [31, 32, 33, 195, 196], "image_idx": [31, 32, 33], "imshow": [31, 32, 33, 63, 67, 79, 95, 106, 114, 121, 122, 123, 124, 163, 172, 186, 188, 189, 195, 196, 197, 198], "cmap": [31, 32, 33, 63, 67, 69, 72, 95, 97, 105, 114, 115, 121, 122, 123, 124, 135, 161, 162, 188, 189, 195, 196, 197, 198], "grai": [31, 32, 33, 122, 154, 155, 171, 180, 189], "vmin": [31, 32, 33, 67, 69, 95, 114, 121, 122, 123, 124, 161, 195, 196, 197, 198], "vmax": [31, 32, 33, 67, 69, 95, 114, 121, 122, 123, 124, 161, 195, 196, 197, 198], "xy_lim": [31, 32, 33], "minimum": [31, 32, 33, 67, 72, 85, 94, 105, 106, 121, 144, 153, 161, 180], "x_min": [31, 32, 33], "x_max": [31, 32, 33], "finfo": [31, 32, 33, 153, 163], "ep": [31, 32, 33, 79, 153, 163, 196, 197], "plot_gen": [31, 32, 33], "decoder_fn": [31, 32, 33], "n_row": [31, 32, 33], "16": [31, 32, 33, 61, 63, 67, 68, 72, 74, 78, 79, 85, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 117, 121, 122, 123, 124, 135, 136, 137, 145, 146, 147, 153, 154, 155, 161, 163, 169, 170, 172, 173, 179, 180, 186, 187, 188, 189, 191, 196, 198], "grid": [31, 32, 33, 63, 67, 68, 69, 72, 79, 94, 97, 106, 122, 123, 124, 135, 137, 144, 154, 188, 189], "coordin": [31, 32, 33, 39, 63, 67, 68, 78, 135, 154, 155, 162, 172], "dx": [31, 32, 33, 68, 72, 74, 135, 153, 154, 155, 162], "canva": [31, 32, 33, 67], "get_cmap": [31, 32, 33, 95, 97, 173], "latent_i": [31, 32, 33], "latent_x": [31, 32, 33], "dtype": [31, 32, 33, 79, 85, 106, 121, 122, 123, 124, 135, 153, 170, 173, 179], "x_decod": [31, 32, 33], "plot_lat": [31, 32, 33], "500": [31, 32, 33, 63, 78, 99, 124, 131, 136, 137, 138, 140, 144, 146, 169, 171, 188, 189], "fontdict": [31, 32, 33], "xy_label": [31, 32, 33], "bold": [31, 32, 33, 78, 92, 146, 147, 155, 195, 196, 197, 198], "tab10": [31, 32, 33, 115, 173], "my_x": [31, 32, 33], "my_i": [31, 32, 33], "horizontalalign": [31, 32, 33, 69, 146, 154, 155], "verticalalign": [31, 32, 33, 69, 146, 154, 155], "z_1": [31, 32, 33, 123], "z_2": [31, 32, 33, 123], "plot_latent_gen": [31, 32, 33], "horizont": [31, 32, 33, 68, 72, 74, 78, 79, 85, 106, 112, 122, 138], "fig": [31, 32, 33, 67, 68, 69, 72, 73, 74, 78, 79, 86, 87, 94, 95, 96, 97, 98, 106, 112, 113, 114, 121, 122, 123, 124, 135, 137, 138, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "suptitl": [31, 32, 33, 68, 78, 79, 121, 122, 123, 124, 135, 180, 195, 196, 197, 198], "add_subplot": [31, 32, 33, 67, 72, 112, 113, 163, 171], "121": [31, 32, 33, 94, 95, 96, 97, 101, 114, 124, 144, 146, 154, 155, 173], "122": [31, 32, 33, 114, 124, 144, 146, 147, 154, 155, 173], "plot_latent_ab": [31, 33], "x1": [31, 33, 72, 97, 135, 138], "x2": [31, 33, 97, 135, 138], "selected_idx": [31, 32, 33], "title_a": [31, 33], "title_b": [31, 33], "index": [31, 33, 79, 85, 87, 105, 113, 114, 122, 123, 124, 138, 173, 186, 189, 195, 196, 197, 198], "s2": [31, 32, 33], "boolean": [31, 32, 33, 105, 114, 121, 122, 123, 124, 135, 144, 145, 146, 147, 153, 155, 172, 186, 187], "3d": [31, 33, 67, 68, 69, 72, 97, 115, 173], "spheric": [31, 33], "phi": [31, 32, 33, 121, 122, 123, 124], "runsgd": [31, 32, 33], "net": [31, 32, 33, 103, 117, 121, 123, 124, 169], "input_train": [31, 32, 33], "input_test": [31, 32, 33], "n_epoch": [31, 32, 33, 121, 123, 124], "batch_siz": [31, 32, 33, 123], "verbos": [31, 32, 33, 169], "stochast": [31, 32, 33, 61, 92, 101, 123, 136, 144, 171, 172, 179, 180, 186, 187, 199], "gradient": [31, 32, 33, 79, 117, 122, 123, 124, 137], "descent": [31, 32, 33, 79, 98, 123, 124], "adam": [31, 32, 33, 131], "opoch": [31, 32, 33], "minibatch": [31, 32, 33, 123], "mini": [31, 32, 33, 121, 123], "batch": [31, 32, 33, 117, 121, 123, 124, 170, 172], "loss_fn": [31, 32, 33, 121, 123, 124], "elif": [31, 32, 33, 68, 69, 72, 79, 81, 90, 101, 105, 106, 121, 122, 123, 124, 131, 136, 144, 145, 146, 147, 149, 153, 162, 169, 172, 179, 180, 188, 189], "sgd": [31, 32, 33, 123, 124], "placehold": [31, 32, 33, 121, 123, 124], "track_loss": [31, 32, 33, 123], "epoch": [31, 32, 33, 121, 123, 124, 173], "shuffle_idx": [31, 32, 33], "permut": [31, 32, 33], "output_train": [31, 32, 33], "zero_grad": [31, 32, 33, 121, 123, 124], "backward": [31, 32, 33, 121, 123, 124, 172, 186], "loss_epoch": [31, 32, 33], "loss_train": [31, 32, 33], "output_test": [31, 32, 33], "loss_test": [31, 32, 33, 124], "loss_ms": [31, 32, 33], "nmse": [31, 32, 33], "loss_bc": [31, 32, 33], "ceil": [31, 32, 33, 68, 95, 173], "x_rang": [31, 32, 33, 87], "c0": [31, 32, 33, 61, 63, 79, 97, 186], "_intro_video": [31, 83, 92, 163], "_autoencoders_video": 31, "decompress": [31, 32, 33], "character": [31, 101, 153, 154, 179], "trigger": [31, 101, 103, 105], "backpropag": [31, 117, 121], "adjust": [31, 32, 33, 61, 63, 67, 69, 78, 85, 106, 135, 171, 179, 186, 198], "unseen": [31, 33, 106, 124], "fulli": [31, 32, 33, 67, 68, 79, 97, 101, 119, 122, 155, 161, 179, 189, 196], "aan": 31, "due": [31, 32, 63, 67, 73, 85, 86, 121, 131, 142, 146, 163, 172, 186, 187, 196, 198], "stretch": [31, 135], "28x28": [31, 114], "pixel": [31, 33, 67, 110, 114, 122, 123, 124, 172], "grayscal": [31, 114, 122, 123], "uncom": [31, 32, 33, 68, 79, 122, 138, 188], "255": [31, 32, 33, 114], "rescal": [31, 136, 172], "favor": [31, 169], "input_s": [31, 32, 33], "prod": [31, 32, 33, 123, 124], "test_selected_idx": [31, 32, 33], "train_selected_idx": [31, 32, 33], "bottom": [31, 33, 39, 67, 68, 69, 72, 73, 74, 79, 114, 122, 123, 146, 147, 154, 155, 161, 162, 169, 179, 180, 188, 189, 195, 196, 199], "w1d5": [31, 123, 193], "overlaid": [31, 172], "overlai": [31, 67, 172, 173], "pca1": 31, "pca2": 31, "Their": [31, 195], "usag": [31, 146, 196], "straightforward": [31, 138, 146], "shown": [31, 63, 72, 79, 105, 121, 122, 136, 144, 147, 155, 169, 179, 180, 186, 195, 196], "truncat": [31, 114, 115], "svd": [31, 195, 196, 197, 198], "truncatedsvd": 31, "n_compon": [31, 115, 123, 170, 173], "svd_latent_train": 31, "svd_latent_test": 31, "svd_reconstruction_train": 31, "inverse_transform": 31, "svd_reconstruction_test": 31, "obtain": [31, 33, 61, 72, 78, 85, 94, 97, 105, 106, 121, 144, 145, 146, 153, 155, 162, 172, 179, 180, 186, 188, 189, 195, 197, 198], "todo": [31, 32, 61, 63, 67, 69, 72, 74, 78, 79, 85, 94, 95, 96, 97, 98, 99, 106, 112, 113, 114, 115, 122, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 169, 172, 186, 187, 188, 189, 195, 196, 197, 198], "rais": [31, 32, 33, 61, 63, 67, 69, 72, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "notimplementederror": [31, 32, 33, 61, 63, 67, 69, 72, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "make_design_matrix": [31, 97, 98, 99, 105], "pca_latent_test": 31, "_visualize_pca_latent_space_exercis": 31, "similarli": [31, 33, 68, 72, 123, 146, 147, 155, 170, 180], "recogniz": 31, "components_": 31, "colormap": [31, 135, 163], "sign": [31, 45, 68, 72, 105, 113, 122, 138, 153, 155, 169], "thick": [31, 153], "thin": 31, "indistinguish": [31, 188], "confus": [31, 106, 146, 162, 172], "pca_compon": 31, "pca_output_test": 31, "shallow": [31, 32, 117, 121], "program": [31, 33, 175, 180, 186], "oop": [31, 33], "w3d4": [31, 33, 119, 142], "equival": [31, 61, 68, 72, 78, 85, 87, 105, 121, 161, 162, 163, 169], "deepnetrelu": [31, 121, 124], "sequenti": [31, 32, 33, 131, 188], "n_input": [31, 121, 124], "n_hidden": [31, 121, 124], "n_output": 31, "hyper": 31, "nielsen": [31, 117], "excel": [31, 113, 122], "ian": 31, "goodfellow": 31, "yoshua": 31, "bengio": [31, 117], "aaron": 31, "courvil": 31, "coverag": 31, "momentum": [31, 117, 121, 123, 124], "decai": [31, 69, 74, 85, 137, 146, 147, 153, 155, 186], "smith": [31, 175], "rectifi": [31, 121, 122, 153], "encoding_dim": 31, "sigmoid": [31, 32, 33, 72, 121, 123, 153, 154, 195, 196, 197, 198], "compat": 31, "Such": [31, 33, 72, 83, 122, 123, 135, 137, 146, 151, 155], "finit": [31, 72, 78, 85, 96, 180], "addition": [31, 112, 122, 124, 138, 145, 162, 195], "greater": [31, 69, 78, 121, 161], "input_shap": 31, "encoding_s": [31, 32, 33], "insert": [31, 63, 79, 86, 87, 115, 136, 137, 138, 163, 169, 170, 173, 180, 195, 196, 197, 198], "in_featur": 31, "784": [31, 32, 33, 114], "out_featur": 31, "bia": [31, 33, 79, 94, 95, 96, 97, 99, 105, 106, 121, 122, 123, 124], "_design_ann_autoencoder_exercis": 31, "hat": [31, 79, 94, 95, 96, 97, 98, 99, 105, 106, 113, 114, 162, 171, 172, 180, 198], "64": [31, 32, 61, 79, 87, 122, 123, 124, 131, 153, 175, 179, 180, 188, 189], "translat": [31, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 122, 131, 144, 162], "middl": [31, 33, 73, 74, 87, 122, 154, 161, 162, 189], "priorit": [31, 182], "penal": 31, "gentl": 31, "quadrat": [31, 94], "rise": [31, 79, 86, 87, 145], "dramat": [31, 155], "dark": [31, 79, 162], "wherea": [31, 106, 122, 138, 146, 147, 172], "verifi": [31, 33, 45, 87, 153, 155], "subtl": [31, 121, 179], "converg": [31, 106, 121, 137, 153, 154, 155, 171, 186, 197], "retrain": [31, 99, 106], "accentu": 31, "opt": [31, 67, 72, 79, 121, 124, 135, 153, 154, 155, 180, 196, 197], "prelu": [31, 32, 33], "wiggl": 31, "latent_test": [31, 32, 33], "wise": [31, 67, 85, 163, 173, 179, 195, 196, 197, 198], "capac": [31, 32], "oper": [31, 32, 68, 121, 122, 123, 124, 137, 138, 163, 179, 188, 191], "successfulli": [31, 32, 146, 173], "despit": [31, 69, 172, 187, 195], "charact": 31, "advantag": [31, 32, 79, 99, 122, 189], "pattern": [31, 32, 73, 86, 90, 92, 97, 98, 106, 117, 121, 131, 138, 142, 144, 146, 147, 149, 161, 169, 171, 172, 177, 187, 195], "richer": [31, 135, 197], "tackl": [31, 67, 103, 173, 188], "_wrapup_video": [31, 32, 33], "default": [31, 61, 68, 69, 78, 79, 85, 106, 121, 122, 123, 124, 144, 146, 153, 154, 155, 171, 172, 188, 189], "rng": [31, 61, 79], "manual_se": [31, 121, 123, 124], "afterward": [31, 61, 163, 186], "success": [31, 94, 173, 179, 186], "rai": 31, "recal": [31, 78, 79, 87, 95, 97, 106, 112, 114, 122, 124, 155, 169, 172, 186, 187, 188, 189, 195, 197], "sqrt": [31, 32, 33, 61, 67, 78, 95, 112, 113, 114, 123, 135, 144, 145, 146, 153, 155, 161, 162, 169, 170, 171, 180], "fan_in": 31, "increment": [31, 61, 63, 144, 145, 146, 147, 154, 155], "central": [31, 78, 140, 162, 193], "theorem": [31, 74, 78, 145, 169, 175], "clt": 31, "independ": [31, 72, 79, 86, 94, 95, 96, 97, 99, 106, 108, 122, 136, 137, 145, 146, 161, 162, 163, 169, 170, 172, 173], "inter": [31, 83, 86, 87, 136, 144, 145, 146, 186], "collaps": [31, 32, 85], "unchang": [31, 72, 112, 161], "bias": [31, 79, 99, 121, 123, 124, 169, 193], "torch_se": 31, "reset": [31, 33, 61, 63, 74, 86, 144, 145, 146, 147, 186], "encoder_w_init": 31, "encoder_b_init": 31, "decoder_w_init": 31, "decoder_b_init": 31, "encoder_w_train": 31, "encoder_b_train": 31, "decoder_w_train": 31, "decoder_b_train": 31, "popular": [31, 86, 106, 137, 187], "mathcal": [31, 61, 63, 72, 74, 78, 79, 95, 99, 106, 112, 124, 162, 169, 170, 171, 172, 195], "fan": 31, "_in": 31, "mu": [31, 63, 78, 79, 95, 123, 136, 137, 144, 146, 162, 163, 169, 170, 171, 172, 187], "backprop": 31, "feedforward": [31, 153, 175], "delv": [31, 69, 72, 73, 103], "surpass": 31, "imagenet": [31, 122], "_choosing_weight_initialization_bonus_exercis": 31, "proce": [31, 33, 186], "sk": 31, "furthest": 31, "apart": [31, 162], "shift": [31, 72, 117, 122, 123, 124, 138, 155, 171, 186], "nmf_latent_test": 31, "nmf_compon": 31, "nmf_output_test": 31, "sphere": [32, 33], "geometri": [32, 112, 113, 131], "degre": [32, 33, 67, 78, 79, 97, 98, 99, 112, 121, 122, 123, 124, 137, 138, 140, 145, 162], "freedom": 32, "plotli": 32, "bonus_autoencoders_t2": 32, "graph_object": 32, "print_parameter_count": 32, "params_n": 32, "layer_idx": 32, "params_layer_n": 32, "ntotal": 32, "sampl": [32, 33, 63, 72, 79, 86, 87, 94, 95, 96, 97, 98, 99, 114, 115, 121, 122, 123, 124, 137, 138, 145, 147, 153, 154, 155, 162, 163, 169, 170, 171, 173, 187, 188, 189, 191, 198], "loss": [32, 33, 68, 117, 123, 161], "to_s2": [32, 33], "pi": [32, 33, 61, 68, 72, 74, 78, 79, 95, 99, 112, 113, 114, 122, 123, 124, 162, 169, 171, 172, 180, 186, 187, 195, 196, 197, 198], "arcco": [32, 33, 113, 114], "arctan2": [32, 33], "to_u3": [32, 33], "sin": [32, 33, 61, 68, 72, 74, 122, 123, 124, 171, 180, 195, 196, 197, 198], "co": [32, 33, 67, 68, 72, 74, 105, 122, 123, 124, 195, 196, 197, 198], "varphi": [32, 33], "plot_latent_3d": 32, "show_text": 32, "marker": [32, 61, 63, 73, 74, 105, 106, 169, 171, 172, 173, 188, 189], "margin": [32, 68, 106, 112, 170, 173, 175], "scene": [32, 117, 121, 122, 124], "xaxi": [32, 67, 68, 161, 179, 186, 195, 196], "showspik": 32, "z1": 32, "yaxi": [32, 67, 68, 105, 161, 171, 195, 196], "z2": 32, "zaxi": 32, "z3": 32, "t10": 32, "idx": [32, 33, 85, 124, 144, 162, 163, 179, 189, 196, 197, 198], "trace": [32, 61, 72, 86, 169, 172], "scatter3d": 32, "textfont": 32, "hovermod": 32, "hoverinfo": 32, "opac": 32, "normalizelay": 32, "l2": [32, 33, 103, 106, 124], "inherit": [32, 33], "__init__": [32, 33, 63, 67, 79, 121, 122, 123, 124, 135, 179, 180, 186, 188, 189], "super": [32, 33, 67, 121, 122, 123, 124, 180, 186, 191], "dim": [32, 33, 123, 124, 172], "_extensions_video": 32, "leverag": [32, 45, 188, 198], "capabl": [32, 33, 78, 87, 121, 123, 137, 187], "layerwis": 32, "depthwis": 32, "392": 32, "aim": [32, 81, 94, 124, 187], "trainabl": 32, "doubl": [32, 63, 67, 85, 98], "halv": 32, "667k": 32, "333k": 32, "diminish": [32, 147, 186], "2x": [32, 72, 94], "3x": 32, "particularli": [32, 79, 103, 121, 122, 162], "drove": 32, "revolut": 32, "n_l": 32, "fill": [32, 33, 37, 61, 63, 67, 69, 78, 79, 85, 86, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 123, 124, 129, 135, 144, 145, 147, 153, 161, 163, 169, 171, 172, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "_build_deeper_autoencoder_exercis": 32, "128": [32, 33, 196], "skew": [32, 162], "lean": 32, "recogn": [32, 123], "spread": [32, 78, 96, 112, 137, 162], "z_3": 32, "indefinit": [32, 72], "eventu": [32, 87, 153, 154, 169, 180, 187], "divid": [32, 61, 67, 72, 74, 99, 121, 138, 144, 145, 146, 154, 161, 169, 180, 195, 196, 197, 198], "l_2": 32, "longmapsto": 32, "s_1": [32, 170], "s_3": 32, "_2": [32, 67, 69, 121, 135, 138], "radiu": 32, "custom": [32, 124, 198], "_deep_autoencoder_with_latent_spherical_space_exercis": 32, "arctan": 32, "angl": [32, 67, 68, 112, 121, 122, 123, 124, 154, 155], "un": [32, 87, 170], "unfold": 32, "sophist": [32, 121, 187, 195, 197, 198], "8m": [32, 105], "equip": [33, 147], "encount": [33, 67, 68, 69, 72, 78, 97, 151, 159, 161, 173, 196, 197], "evolv": [33, 63, 69, 135, 137, 138, 147, 153, 154, 155, 170, 172, 180, 186], "bonus_autoencoders_t3": 33, "os": [33, 105, 106, 121, 122, 123, 124, 172], "ndimag": [33, 124], "s_2": 33, "out_train": 33, "out_test": [33, 124], "different_output": 33, "batches_out": 33, "batch_idx": 33, "image_occlus": 33, "quadrant": [33, 74, 113, 114], "image_rot": 33, "deg": [33, 137, 145], "my_deg": 33, "prefilt": 33, "autoencoderclass": 33, "activatino": 33, "enc1": 33, "enc1_f": 33, "enc2": 33, "enc2_f": 33, "enc3": 33, "enc3_f": 33, "dec1": 33, "dec1_f": 33, "dec2": 33, "dec2_f": 33, "dec3": 33, "dec3_f": 33, "pass": [33, 67, 72, 105, 106, 121, 123, 124, 144, 146, 153, 154, 155, 172, 173, 179, 180, 189, 195, 198], "save_checkpoint": 33, "filenam": [33, 67, 122, 124], "save": [33, 44, 86, 97, 105, 115, 121, 123, 124, 129, 173, 186, 189], "model_state_dict": 33, "state_dict": [33, 186], "optimizer_state_dict": 33, "pt": [33, 123, 137], "load_checkpoint": 33, "local": [33, 39, 44, 67, 72, 74, 79, 85, 86, 101, 105, 115, 121, 122, 123, 124, 131, 135, 149, 153, 154, 155, 187], "path": [33, 105, 106, 121, 122, 123, 124, 172, 191], "isfil": [33, 105, 106, 121, 122, 123, 124, 172], "wget": 33, "reset_checkpoint": 33, "load_state_dict": 33, "_applications_video": 33, "test_subset_idx": 33, "onto": [33, 68, 110, 114, 123, 124, 129, 136, 187], "lengthi": 33, "ident": [33, 68, 79, 114, 124, 146, 147, 155, 163, 169, 172, 186], "filename_path": 33, "eval": [33, 72, 106, 113, 114, 155], "repo": 33, "3rd": 33, "root": [33, 67, 72, 95, 145, 153, 154, 155, 199], "mpbrigham": 33, "colaboratori": 33, "master": [33, 61, 67, 182, 191, 195, 196, 197, 198], "ae_6h_prelu_bce_adam_25e_32b": 33, "_s2": 33, "abil": [33, 79, 87, 105, 119, 122, 170, 188, 189, 196], "invari": [33, 87, 122, 180, 191], "latent_test_ref": 33, "clean": [33, 61, 112, 172, 186], "noise_factor": 33, "input_train_noisi": 33, "input_test_noisi": 33, "output_test_noisi": 33, "latent_test_noisi": 33, "regener": 33, "denois": 33, "caus": [33, 68, 81, 106, 142, 146, 151, 163, 171, 180, 186, 191, 195, 197, 198], "compos": [33, 79, 85, 87, 153, 154, 186], "characterist": [33, 85], "adapt": [33, 90, 101, 121, 131, 175, 189], "partial": [33, 95, 121, 179], "input_train_mask": 33, "input_test_mask": 33, "output_test_mask": 33, "latent_test_mask": 33, "arguabl": [33, 92], "input_train_rot": 33, "90": [33, 63, 67, 73, 79, 112, 114, 122, 123, 149, 169, 171, 187, 189, 195, 196], "input_test_rot": 33, "output_test_rot": 33, "latent_test_rot": 33, "melt": 33, "my_input_train": 33, "my_input_test": 33, "my_y_test": 33, "my_latent_test": 33, "occupi": [33, 122, 123, 124], "Will": [33, 124, 145, 146, 153], "evenli": [33, 68, 87, 187, 196], "intersect": [33, 153, 154, 155], "cond_a": 33, "cond_b": 33, "missing_a": 33, "missing_b": 33, "47335": 33, "7885": 33, "_removing_the_most_dominant_class_exercis": 33, "asia": 33, "supposedli": 33, "revers": [33, 67, 72, 144, 145, 146, 147, 169, 172], "shuffle_image_idx": 33, "unshuffl": 33, "input_shuffl": 33, "shuffle_rev_image_idx": 33, "empty_lik": 33, "pos_idx": 33, "po": [33, 122, 169], "input_train_shuffl": 33, "input_test_shuffl": 33, "input_train_shuffle_noisi": 33, "input_test_shuffle_noisi": 33, "confirm": [33, 195], "latent_test_shuffle_noisi": 33, "output_test_shuffle_noisi": 33, "hoorai": [33, 138, 147], "hope": [33, 96, 187], "embed": [33, 34, 35, 36, 115, 172], "imprint": 33, "coin": [33, 137, 138, 187], "daniel": 33, "kahneman": 33, "psycholog": [33, 117, 131, 161, 184, 186], "replic": [33, 61, 122], "middlebrook": [34, 35, 36], "panelist": [34, 35, 36], "adrienn": 34, "fairhal": 34, "bing": [34, 135, 136, 137, 138], "kanaka": 34, "rajan": 34, "audio": [34, 35, 36, 73, 74, 79], "ifram": [34, 35, 36], "src": [34, 35, 36], "braininspir": [34, 35, 36], "casto": [34, 35, 36], "player": [34, 35, 36], "563932": 34, "height": [34, 35, 36, 63, 72, 122, 123, 124, 161, 162], "athena": [35, 175, 180], "akrami": 35, "demba": 35, "ba": 35, "kunlin": 35, "wei": [35, 90, 154, 155], "560014": 35, "yael": 36, "niv": [36, 182], "sam": 36, "gershman": 36, "tim": 36, "behren": 36, "569670": 36, "tuesdai": 37, "wednesdai": 37, "thursdai": 37, "fridai": 37, "reinforc": [37, 83, 92, 119, 159, 167, 177, 182, 184, 186, 187, 188, 199], "graduat": 37, "00": [37, 106, 108, 121, 138, 144, 197], "pod": 37, "ii": [37, 72, 74, 146, 154, 155, 189], "asynchron": [37, 199], "synchron": [37, 142], "info": [37, 74, 179], "farewel": 37, "ceremoni": 37, "certiic": 37, "cour": 37, "goodby": 37, "impos": [37, 180], "slot": [39, 187], "utc": 39, "zone": 39, "tz": 40, "launch": [42, 44, 45], "environ": [42, 44, 45, 61, 67, 78, 106, 115, 119, 179, 186, 187, 188, 189], "portal": 43, "violat": 43, "precours": [43, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 83], "exempt": 43, "shrubhlgswj8dua7": 43, "attend": 43, "waiver": 43, "bi_ssrrhyrfg_": 43, "button": [44, 45, 85, 179], "overwrit": [44, 79], "git": 44, "ipynb": 44, "china": 45, "substitut": [45, 67, 68, 69, 95, 169, 196], "regist": [45, 163], "asococi": 45, "workaround": 45, "user": [45, 79, 124, 172], "phone": 45, "gpu": [45, 121], "internet": 45, "sidebar": 45, "enter": [45, 85, 114, 138, 188], "credenti": 45, "kernel": [45, 122, 123, 124, 144, 146, 147], "restart": 45, "newli": [45, 96], "grant": [45, 121], "NOT": [45, 68, 163, 179], "comp": [45, 69, 199], "drop": [45, 72, 95, 99, 113, 145, 146, 179], "menu": [45, 72, 124], "artwork": [46, 47, 80, 130, 139, 148], "daniela": [46, 47, 80], "buchwald": [46, 47, 80], "arvind": [48, 58, 72, 73, 74, 144, 145, 146, 147, 153, 154, 155], "kumar": [48, 53, 58, 72, 73, 74, 131, 144, 145, 146, 147, 153, 154, 155], "caption": [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "ashish": [48, 55, 59], "sahoo": [48, 55, 59], "kushaan": [48, 55, 59], "gupta": [48, 55, 59, 165], "cynthia": 48, "castillo": [48, 171, 179], "shuze": [48, 50, 52, 53, 54, 55, 56, 57, 58, 59], "liu": [48, 50, 52, 53, 54, 55, 56, 57, 58, 59, 195, 196, 197, 198], "8zxfvwxw": [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79], "w0d0_t1": 48, "jen": 49, "kremkow": 49, "jiaxin": [49, 52, 56], "tu": [49, 52, 56], "pooya": [49, 53, 54, 67, 68, 78, 79], "pakarian": [49, 53, 54, 67, 68, 78, 79], "maryam": [49, 85, 86, 87, 144, 145, 146, 153, 154, 155], "ansari": 49, "antoni": 49, "puthusseri": 49, "w0d0_t10": 49, "emanuela": 50, "santini": 50, "ethan": [50, 51, 55, 78, 79, 136, 144], "cheng": [50, 51, 55, 78, 79, 136, 144, 186, 187, 188, 189], "anoop": [50, 51, 55, 59, 67, 68, 78, 79, 161, 162, 186, 187, 188, 189], "kulkarni": [50, 51, 55, 59, 67, 68, 78, 79, 101, 161, 162, 186, 187, 188, 189], "manisha": [50, 51, 52, 56, 58], "sinha": [50, 51, 52, 56, 58], "andrew": [50, 57, 58], "sun": [50, 57, 58, 117], "carolina": [50, 54, 55], "shimabukuro": [50, 55], "yihe": 50, "lu": 50, "w0d0_t11": 50, "christof": 51, "koch": [51, 165], "lili": [51, 186, 187, 188, 189], "ghinwa": [51, 57], "el": [51, 57, 61, 63], "masri": [51, 57], "w0d0_t12": 51, "jenni": 52, "zahra": [52, 57, 161, 162], "arjmandi": [52, 57, 161, 162], "lui": [52, 53, 56, 57, 58, 59], "alvarez": [52, 53, 56, 57, 58, 59], "tong": 52, "liang": 52, "w0d0_t2": 52, "swapnil": [53, 73, 74], "jeremi": [53, 54], "forest": [53, 54], "aditya": 53, "yang": [53, 55, 59], "lin": [53, 55, 59], "w0d0_t3": 53, "churchland": [54, 81, 131], "chaoqun": 54, "yin": 54, "alex": [54, 94, 95, 96, 97, 98, 99, 112, 113, 114, 115], "kostiuk": 54, "luka": 54, "oesch": 54, "ryan": 54, "ashlei": 54, "chen": [54, 131, 165], "joao": 54, "couto": 54, "oluwatomisin": [54, 59], "faniyan": [54, 59], "sirisha": [54, 56, 73], "sripada": [54, 56, 73], "shimabuku": 54, "w0d0_t4": 54, "thoma": [55, 131], "tago": 55, "w0d0_t5": 55, "gaut": 56, "einevol": 56, "richard": [56, 112, 113, 114, 115, 117, 135, 136, 137, 138, 142, 144, 145, 146, 147, 153, 154, 155, 157], "gao": [56, 112, 113, 114, 115, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 165], "zhanao": [56, 57], "fu": [56, 57], "w0d0_t6": 56, "nihan": 57, "alp": 57, "natali": [57, 78, 79, 112, 113, 114, 115], "schaworonkow": [57, 78, 79, 112, 113, 114, 115], "w0d0_t7": 57, "pedro": 58, "vald": 58, "sosa": 58, "benjamin": [58, 101, 105, 106, 195, 196, 197, 198], "becker": 58, "carlo": [58, 79], "lopez": 58, "liangyou": 58, "zhang": [58, 117], "w0d0_t8": 58, "yeka": 59, "apont": 59, "matt": [59, 72, 85, 86, 87, 88, 112, 113, 114, 115, 163, 169, 170, 172, 173, 179, 180, 186, 187, 188, 189], "mccann": [59, 72, 73, 74], "w0d0_t9": 59, "fun": [61, 79, 105, 135, 137, 153, 154, 186], "sneak": 61, "workhors": 61, "unlock": 61, "couldn": 61, "evolut": [61, 63, 69, 117, 153, 154], "w0d1_t1": 61, "_python_basics_and_the_lif_model_video": 61, "tau_m": [61, 73, 74, 144, 145, 146, 147], "e_": [61, 146, 147], "quad": [61, 63, 74, 86, 87, 94, 95, 96, 97, 105, 106, 112, 113, 114, 144, 145, 146, 153, 155, 187], "leq": [61, 106], "v_": [61, 63, 79, 86, 144, 186], "th": [61, 63, 73, 87, 97, 105, 113, 114, 121, 123, 144, 146, 147, 169], "leak": [61, 74, 144, 145, 146, 147, 155], "resist": [61, 73, 74, 86, 144], "voltag": [61, 63, 72, 73, 74, 86, 140, 144, 145, 146, 147, 170, 198], "v_m": [61, 63, 86], "conveni": [61, 67, 79, 86, 95, 114, 136, 147, 169, 172, 179], "charg": [61, 86], "ordinari": [61, 72, 98, 99, 105, 135, 146], "_nano_recap_of_comments_and_strings_video": 61, "modifi": [61, 112, 121, 123, 124, 137, 144, 147, 179, 198], "t_max": [61, 63, 171], "150e": [61, 63], "1e": [61, 63, 85, 121, 124, 147, 153, 154, 155, 170, 196, 197], "tau": [61, 63, 72, 144, 153, 171], "20e": [61, 63], "60e": [61, 63], "milivolt": [61, 63], "vr": [61, 63], "70e": [61, 63], "vth": [61, 63], "50e": [61, 63], "100e6": [61, 63], "ohm": [61, 63, 146], "i_mean": [61, 63, 72, 144], "25e": [61, 63], "amper": [61, 63], "07": [61, 106, 117, 149, 163, 173, 175], "100000000": 61, "5e": [61, 105, 124], "_defining_parameters_ecercis": 61, "notat": [61, 69, 78, 79, 135, 155, 162, 163, 171, 172, 180, 195, 198], "goe": [61, 72, 73, 78, 122, 135, 144, 147, 153, 161, 162, 169, 170, 188, 189], "sinusoid": [61, 74, 180], "i_": [61, 72, 73, 74, 86, 144, 146, 147, 153, 155], "01": [61, 63, 72, 73, 74, 79, 81, 85, 86, 96, 101, 106, 122, 123, 124, 131, 136, 137, 140, 144, 153, 154, 155, 161, 162, 163, 170, 171, 172, 179, 180, 187, 195, 196, 197, 198], "009": [61, 81, 131, 175, 198], "delta": [61, 74, 137, 144, 146, 154, 155, 169, 170, 171, 189], "block": [61, 73, 103, 119, 122, 123, 136, 142, 151, 161, 195], "syntax": [61, 121, 153], "sine": 61, "dagger": 61, "nameerror": [61, 74, 105, 112, 113, 114, 115, 123, 124, 137, 138, 147, 155, 163, 172, 173, 180, 186, 187, 188, 195, 198], "traceback": [61, 63, 67, 69, 72, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "recent": [61, 63, 67, 69, 72, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 135, 136, 137, 138, 142, 144, 145, 146, 147, 153, 154, 155, 161, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "969463130731183e": 61, "877641290737885e": 61, "9694631307311837e": 61, "5000000000000007e": 61, "0305368692688176e": 61, "2235870926211617e": 61, "223587092621159e": 61, "0305368692688186e": 61, "_simulating_an_input_current_ecercis": 61, "3f": [61, 121, 124, 135, 136, 138, 144, 145, 146, 147, 153, 154, 155, 172, 196, 197, 198], "decim": 61, "4e": 61, "exponenti": [61, 72, 73, 74, 83, 85, 86, 87, 95, 105, 135, 145, 146, 147, 153, 162, 171, 173, 186], "14159265e": 61, "314": 61, "1416e": 61, "step_end": [61, 63], "5000e": 61, "9695e": 61, "002": [61, 63, 101, 117, 124, 173], "8776e": 61, "003": [61, 131, 172, 182], "005": [61, 85, 108, 140, 149, 161, 172], "0305e": 61, "007": [61, 63, 73, 74, 140], "2236e": 61, "_printing_pretty_numbers_ecercis": 61, "_for_loops_and_discrete_time_integration_video": 61, "indent": [61, 72, 170, 171], "stepsiz": [61, 78, 79, 154], "_nano_recap_of_discrete_time_integration_video": 61, "qquad": [61, 73, 74, 146, 153, 154, 155], "manipul": [61, 73, 74, 86, 169, 170, 171, 179, 186], "euler": [61, 72, 83, 144, 146, 147, 153, 154, 155], "e_l": [61, 73, 74, 144, 146, 147], "reorgan": 61, "eq": [61, 146, 155, 180, 195], "v0": 61, "8750e": 61, "6828e": 61, "4548e": 61, "2381e": 61, "0778e": 61, "9989e": 61, "9974e": 61, "0414e": 61, "0832e": 61, "0775e": 61, "_simulating_membrane_potential_exercis": 61, "_intro_to_plotting_video": 61, "_nano_recap_of_plotting_video": 61, "024": [61, 147], "ko": [61, 153, 154, 155], "24": [61, 63, 67, 69, 73, 74, 78, 85, 86, 87, 95, 96, 97, 101, 105, 106, 112, 122, 124, 135, 136, 137, 138, 140, 145, 146, 147, 149, 154, 155, 163, 169, 171, 173, 175, 179, 180, 186, 188, 189, 195, 197, 198], "curent": 61, "_plotting_current_exercis": 61, "t_": [61, 63, 72, 73, 74, 135, 144, 146, 147, 173, 198], "nearest": [61, 123], "smaller": [61, 69, 72, 74, 87, 106, 121, 122, 123, 124, 138, 145, 146, 147, 154, 155], "_plotting_membrane_potential_exercis": 61, "perspect": [61, 67, 68, 81, 117, 122, 131, 191], "xi": [61, 144, 153, 173], "sim": [61, 78, 86, 95, 112, 137, 153, 169, 170, 171, 172, 186, 195, 198], "pseudo": [61, 79, 96], "random_num": [61, 78], "_adding_randomness_exercis": 61, "_lists_": 61, "_ensemble_statistics_video": 61, "_nano_recap_of_ensemble_statistics_": 61, "_lists_video": 61, "impress": [61, 106], "autocovari": [61, 144], "v_n": [61, 63], "langl": 61, "rangl": 61, "sum_": [61, 63, 67, 79, 87, 94, 95, 97, 106, 113, 114, 121, 122, 123, 124, 145, 147, 161, 169, 172, 173, 180, 186, 195], "command": [61, 121], "symbol": [61, 72, 97], "beta": [61, 79, 86, 106, 162, 198], "tex": 61, "markup": 61, "intiati": 61, "xkcd": [61, 72, 73, 74, 79, 163, 173, 188], "transpar": 61, "34": [61, 72, 74, 78, 96, 97, 99, 105, 113, 115, 117, 121, 123, 124, 135, 137, 146, 153, 163, 172, 173, 175, 179, 186, 187, 195, 196, 198], "_storing_simulations_in_lists_exercis": 61, "v_mean": [61, 63], "_plotting_sample_mean_exercis": 61, "equiv": [61, 106, 153, 161, 180], "var": [61, 79, 98, 106, 112, 114, 123, 137, 145, 161, 170, 171, 173, 180, 198], "v_var": 61, "49": [61, 63, 74, 79, 99, 124, 144, 172, 186, 189, 198], "81": [61, 63, 79, 131, 180], "v_var_n": 61, "v_std": 61, "markers": [61, 72, 98, 124, 137, 171, 179], "c7": 61, "38": [61, 63, 73, 79, 85, 87, 96, 97, 105, 106, 112, 113, 121, 124, 137, 144, 146, 147, 169, 171, 173, 179, 187, 196, 197, 198], "_plotting_sample_standard_deviation_exercis": 61, "_using_numpy_video": 61, "updat": [61, 63, 67, 69, 72, 79, 86, 113, 121, 123, 124, 135, 137, 144, 145, 146, 147, 153, 154, 155, 159, 161, 169, 170, 171, 172, 173, 177, 179, 186, 188, 195, 197, 198], "significantli": [61, 122], "narr": [61, 63], "_nano_recap_of_using_numpy_video": 61, "t_rang": [61, 63], "endpoint": [61, 162, 195, 196, 197, 198], "44": [61, 63, 72, 74, 78, 124, 135, 154, 169, 171, 172, 175, 179, 180, 195, 196], "_rewriting_with_numpy_exercis": 61, "i_step": 61, "46": [61, 63, 124, 154, 163, 169, 171, 172, 186, 189, 195, 198], "_using_enumerate_and_indexing_exercis": 61, "_aggregation_video": 61, "_nano_recap_of_aggregation_video": 61, "transpos": [61, 97, 170, 195, 197, 198], "52": [61, 74, 94, 99, 124, 144, 154, 169, 172, 186, 189, 195, 198], "_using_2d_arrays_exercis": 61, "pm": [61, 169], "54": [61, 124, 136, 144, 145, 154, 169, 179, 189, 195, 198], "_plotting_sample_mean_and_standard_deviation_exercis": 61, "_overview_video": 61, "repeatedli": [63, 187, 189], "elsewher": [63, 162], "w0d2_t1": 63, "creation": [63, 68, 69, 72, 73, 74, 78, 79], "plot_al": 63, "spikes_mean": 63, "membran": [63, 72, 74, 86, 87, 131, 140, 144, 145, 147, 170], "ax1": [63, 72, 86, 95, 96, 112, 113, 121, 124, 147, 154, 155, 170, 172, 179, 180, 186, 187, 188], "c1": [63, 79, 85, 94, 96, 97, 186], "auto": [63, 95, 114, 115, 121, 123, 124, 131, 138, 161, 163, 172, 188, 189, 198], "sharex": [63, 105, 106, 154, 155, 161, 162, 180], "ones_lik": [63, 105, 138, 162, 196, 197], "hz": [63, 72, 73, 74, 145, 146, 147, 173], "_histograms_video": 63, "t_k": [63, 74, 146], "m_j": 63, "fall": [63, 67, 69, 85, 87, 96, 105, 121, 122, 123, 124, 142, 179], "nbin": 63, "histtyp": [63, 85, 95], "stepfil": [63, 85, 95], "patch": [63, 67, 122, 123, 124, 161, 170, 173, 198], "edg": [63, 85, 86, 87, 122, 124, 187, 188, 195], "_nano_recap_of_histograms_video": 63, "_plotting_a_histogram_exercis": 63, "_dictionaries_": 63, "_introducing_spikes_video": 63, "geq": [63, 105, 144, 186], "_nano_recap_of_dictionaries_video": 63, "spike_tim": [63, 73, 74, 86, 87, 144], "sharei": [63, 105, 106, 123, 154, 155, 161, 162, 180], "1st": [63, 135, 146, 179], "my_data_left": 63, "my_data_right": 63, "spikes_n": 63, "vm": 63, "22": [63, 67, 69, 74, 78, 79, 86, 87, 90, 95, 96, 97, 101, 105, 112, 113, 114, 117, 121, 122, 123, 124, 135, 136, 137, 138, 145, 147, 153, 154, 161, 163, 169, 170, 171, 173, 179, 180, 188, 189, 195, 196, 197, 198], "_adding_spiking_to_the_lif_neuron_exercis": 63, "_boolean_indexes_video": 63, "itself": [63, 67, 69, 72, 73, 85, 106, 121, 138, 147, 159, 172, 188], "_nano_recap_of_boolean_indexes_video": 63, "v_rest": 63, "__main__": [63, 69, 85, 99, 112, 113, 114, 115, 123, 138, 144, 145, 146, 147, 153, 154, 155, 170], "v_thr": 63, "_using_boolean_indexing_exercis": 63, "v_reset": [63, 73, 74, 144, 145, 146, 147], "_making_a_binary_raster_plot_exercis": 63, "_refractory_period_video": 63, "millisecond": [63, 86, 147], "synapt": [63, 69, 72, 101, 122, 142, 144, 145, 149, 153, 155], "2nd": [63, 68, 73, 74, 135, 179, 187], "biophys": [63, 140, 149, 154, 155], "_nano_recap_of_refractory_period_video": 63, "ref": [63, 144], "lambda": [63, 67, 68, 69, 74, 78, 86, 105, 137, 138, 145, 153, 170, 173], "clamp": [63, 72, 144, 177, 186, 195, 198], "t_ref": 63, "last_spik": 63, "_investigating_refractory_periods_exercis": 63, "random_ref_period": 63, "syn": [63, 145, 146], "_": [63, 67, 68, 69, 72, 73, 74, 78, 79, 86, 87, 94, 95, 98, 112, 113, 114, 121, 124, 135, 136, 144, 145, 146, 147, 153, 155, 163, 169, 171, 172, 173, 179, 180, 186, 189, 195, 196, 197, 198], "_random_refractory_period_interactive_demo": 63, "_functions_video": 63, "_nano_recap_of_functions_video": 63, "spike_clamp": 63, "ode_step": 63, "discret": [63, 74, 79, 85, 87, 131, 135, 137, 144, 145, 146, 147, 153, 154, 155, 162, 163, 165, 169, 170, 171, 172, 180], "delta_spik": 63, "87": [63, 137, 169, 175], "89": [63, 169, 189], "92": [63, 135, 140, 147, 173], "93": [63, 67, 101, 131, 135, 189], "27": [63, 67, 69, 74, 85, 87, 94, 95, 97, 99, 105, 106, 112, 114, 117, 121, 123, 124, 135, 136, 137, 145, 146, 147, 153, 154, 155, 163, 170, 171, 173, 179, 180, 187, 189, 197, 198], "41": [63, 68, 97, 105, 106, 113, 117, 124, 137, 144, 147, 154, 163, 169, 171, 179, 180, 189, 195, 196, 197, 198], "43": [63, 69, 79, 86, 94, 105, 106, 112, 113, 117, 124, 131, 137, 154, 161, 163, 169, 171, 172, 180, 189, 195, 196, 198], "47": [63, 74, 78, 101, 124, 135, 154, 171, 172, 189, 195, 198], "48": [63, 74, 78, 79, 99, 122, 123, 124, 135, 144, 163, 171, 172, 186, 198], "_rewriting_code_with_functions_exercis": 63, "_classes_video": 63, "reliabl": [63, 105, 145, 146, 161], "unimport": 63, "attribut": [63, 67, 85, 121, 122, 123, 124, 161, 186], "_nano_recap_of_classes_video": 63, "lifneuron": 63, "spike_and_clamp": 63, "t_ref_mu": 63, "t_ref_sigma": 63, "histori": [63, 69, 79, 101, 136, 138, 142, 146, 169, 172, 179, 189], "ran": [63, 169, 189], "74": [63, 67, 124, 169, 170, 180, 189], "_making_a_lif_class_exercis": 63, "_last_concepts_": 63, "_recap_video": 63, "butler": [65, 71, 72, 73, 74, 76, 82, 91, 102, 109, 118, 126, 132, 135, 136, 137, 138, 141, 150, 158, 166, 169, 170, 173, 176, 183, 192, 199], "w0d3_daysummari": 65, "_slide": [65, 71, 76], "patient": [66, 67, 69, 77, 171], "delai": [66, 77, 85, 138, 145, 186, 188], "redirect": [66, 77], "keith": [67, 68, 74, 78, 79, 169], "antwerp": [67, 68, 78, 79, 169], "siddharth": [67, 68, 112, 113, 114, 115, 153, 154, 155], "suresh": [67, 68, 112, 113, 114, 115, 153, 154, 155], "geometr": [67, 68, 97, 113], "w0d3_t1": 67, "fix": [67, 68, 78, 79, 87, 94, 95, 96, 97, 124, 144, 145, 146, 151, 154, 162, 170, 171, 172, 179, 180, 186, 187, 195, 196, 197, 199], "fancyarrowpatch": 67, "mpl_toolkit": [67, 68, 72, 105, 195, 198], "mplot3d": [67, 68, 72], "proj3d": 67, "visualize_vector": 67, "v_unit": 67, "aesthet": 67, "set_color": [67, 68, 69, 72, 106, 147], "set_posit": [67, 68, 69, 72, 179], "zorder": [67, 69, 105, 123, 124, 137, 145, 146, 147, 153, 155, 162, 172, 179], "v_arr": 67, "648fff": [67, 69], "length_includes_head": [67, 68, 69, 135, 195, 196, 197, 198], "v_unit_arr": 67, "dc267f": [67, 69], "leg": [67, 69], "tild": [67, 99, 121, 123, 124, 163], "handlelength": [67, 69, 154, 155], "fontsiz": [67, 68, 69, 72, 106, 137, 145, 146, 147, 153, 154, 170, 173, 179, 180, 195, 197], "upper": [67, 72, 74, 78, 85, 87, 105, 123, 124, 162, 169, 170, 171, 179, 180, 189, 195], "handl": [67, 69, 81, 86, 96, 99, 117, 173, 188, 189, 198], "legendhandl": [67, 69], "get_facecolor": [67, 69], "arrow3d": 67, "xs": [67, 85], "ys": [67, 85], "zs": 67, "kwarg": [67, 68, 86, 121, 124, 144, 145, 146, 147, 153, 154, 155], "_verts3d": 67, "xs3d": 67, "ys3d": 67, "zs3d": 67, "proj_transform": 67, "do_3d_project": 67, "_why_do_we_care_about_linear_algebra_video": 67, "_vector_definition_": 67, "_properties_video": 67, "bmatrix": [67, 68, 69, 97, 106, 121, 123, 124, 155, 170, 172, 195, 197], "_i": [67, 69, 79, 94, 97, 106, 113, 123, 145, 154, 155, 163], "x_1": [67, 68, 78, 79, 87, 95, 97, 112, 135, 137, 138, 195], "x_2": [67, 68, 78, 79, 87, 97, 112, 135, 138, 195], "x_3": [67, 68, 79, 87, 195], "normalize_vector": 67, "input_vector": 67, "n_dim": 67, "linalg": [67, 68, 69, 79, 97, 98, 99, 105, 113, 114, 135, 136, 138, 155, 195, 196, 197, 198], "vector_length": 67, "normalized_vector": 67, "33": [67, 78, 79, 85, 97, 98, 99, 101, 105, 112, 114, 115, 117, 121, 124, 135, 137, 145, 146, 153, 154, 155, 163, 169, 171, 172, 173, 179, 186, 187, 189, 195, 198], "_normalizing_vectors_exercis": 67, "_linear_combinations_of_vectors_video": 67, "180": [67, 112, 122, 123, 124, 144], "_1": [67, 69, 121, 135, 138, 169, 172, 197], "vdot": [67, 97, 123, 124], "_n": [67, 97], "stack": [67, 97, 98, 99, 112, 122, 123, 136, 170, 173, 188, 195], "tail": [67, 68, 187], "essenc": [67, 98, 162], "parallelogram": 67, "4th": [67, 68], "vertex": 67, "c_1": [67, 69], "c_2": [67, 69], "fraction": [67, 85, 114, 124, 136, 145, 146, 171, 197, 198], "slider": [67, 69, 72, 78, 79, 85, 86, 87, 112, 113, 114, 135, 154, 161, 169, 170, 171, 179, 180, 186, 197], "releas": [67, 69, 146], "desir": [67, 69, 78, 112, 113, 162, 169, 177, 189, 198], "plot_arrow": [67, 69], "a_times_x": [67, 69], "b_times_i": [67, 69], "set_aspect": [67, 68, 69, 121, 123, 124, 163, 171, 180, 195, 196, 197, 198], "xticklabel": [67, 69, 105, 161], "yticklabel": [67, 69, 161], "z_arr": [67, 69], "x_orig": [67, 69], "y_orig": [67, 69], "ax_arr": [67, 69], "by_arr": [67, 69], "bbox_to_anchor": [67, 69, 72, 123, 169, 170], "get_color": [67, 69], "floatslid": [67, 69, 73, 74, 78, 85, 94, 95, 112, 135, 144, 146, 147, 153, 154, 155, 161, 162, 169, 170, 171, 172, 179, 180, 186, 187], "plot_linear_combin": [67, 69], "_linear_combinations_of_vectors_interactive_demo": 67, "35": [67, 68, 79, 85, 86, 87, 97, 98, 99, 105, 106, 112, 114, 115, 117, 121, 123, 124, 135, 137, 145, 146, 147, 153, 154, 161, 162, 169, 170, 171, 172, 179, 187, 189, 195, 196, 197, 198], "_span_and_linear_independence_video": 67, "rm": [67, 144, 145, 146, 147, 153, 155, 170, 171, 172, 179], "111": [67, 72, 81, 117, 155, 163, 171, 188], "mutation_scal": 67, "lw": [67, 68, 85, 106, 144, 146, 147, 153, 155, 170, 171], "arrowstyl": [67, 135], "add_artist": 67, "785ef0": 67, "ffb000": 67, "zlim": 67, "zlabel": [67, 72, 97], "attributeerror": [67, 124], "callback": [67, 79, 153], "_draw_all_if_interact": 67, "0x7ff83bd2f550": 67, "post_execut": 67, "typeerror": 67, "hostedtoolcach": [67, 79, 121, 124, 135, 153, 196, 197], "x64": [67, 79, 121, 124, 135, 153, 196, 197], "lib": [67, 79, 121, 124, 135, 153, 196, 197], "python3": [67, 79, 121, 124, 135, 153, 196, 197], "site": [67, 72, 79, 121, 124, 135, 153, 179, 196, 197], "268": 67, "267": 67, "is_interact": 67, "draw_al": 67, "_pylab_help": 67, "131": 67, "gcf": 67, "cl": 67, "129": [67, 175], "get_all_fig_manag": 67, "130": 67, "stale": 67, "draw_idl": 67, "backend_bas": 67, "1905": [67, 131], "figurecanvasbas": 67, "1903": 67, "_is_idle_draw": 67, "1904": 67, "_idle_draw_cntx": 67, "backend": [67, 68, 72], "backend_agg": 67, "387": [67, 101], "figurecanvasagg": 67, "384": 67, "lock": [67, 187], "cach": [67, 79, 105, 189], "385": 67, "toolbar": 67, "_wait_cursor_for_draw_cm": 67, "386": 67, "nullcontext": 67, "388": [67, 131], "gui": 67, "389": [67, 172], "superclass": 67, "390": 67, "artist": 67, "95": [67, 73, 96, 131, 135, 137, 140, 145, 163, 179, 180], "_finalize_raster": 67, "draw_wrapp": 67, "wrap": 67, "94": [67, 101, 135, 189], "96": [67, 135, 154, 155, 179, 189], "_raster": 67, "97": [67, 73, 74, 96, 101, 131, 135, 140, 189], "stop_raster": 67, "allow_raster": 67, "69": [67, 79, 121, 124, 169, 170, 180], "get_agg_filt": 67, "70": [67, 74, 79, 114, 121, 124, 144, 161, 170, 180, 186], "start_filt": 67, "73": [67, 79, 121, 124, 144, 169, 180, 189], "3162": 67, "3159": 67, "valueerror": 67, "resiz": 67, "3161": 67, "mimag": 67, "_draw_list_compositing_imag": 67, "3163": 67, "suppresscomposit": 67, "3165": 67, "close_group": 67, "3166": 67, "132": 67, "parent": [67, 121, 124], "suppress_composit": 67, "not_composit": 67, "has_imag": 67, "133": 67, "134": 67, "composit": [67, 87, 131], "135": 67, "image_group": 67, "axes3d": [67, 68, 72], "441": 67, "437": [67, 165], "zorder_offset": 67, "get_zord": 67, "438": 67, "_axis_map": 67, "439": 67, "collection_zord": 67, "patch_zord": 67, "collections_and_patch": 67, "442": 67, "443": 67, "444": 67, "mcoll": 67, "445": 67, "instanc": [67, 79, 99, 115, 121, 137, 144, 147, 155, 170, 172, 173, 186, 187, 189], "nonetyp": 67, "formatt": 67, "340": [67, 81, 131], "baseformatt": 67, "__call__": 67, "obj": 67, "338": [67, 101], "339": [67, 81, 131, 140], "printer": 67, "341": 67, "342": 67, "get_real_method": 67, "print_method": 67, "pylabtool": 67, "retina_figur": 67, "base64": 67, "160": [67, 189], "161": 67, "png": [67, 106], "162": [67, 79], "163": [67, 79], "byte": 67, "167": [67, 136], "168": [67, 79], "pngdata": 67, "print_figur": 67, "fmt": [67, 106], "170": 67, "171": 67, "172": 67, "152": [67, 135], "bbox_inch": 67, "149": [67, 140], "bytes_io": 67, "kw": [67, 105], "153": [67, 81, 135, 175], "getvalu": 67, "154": [67, 135], "svg": 67, "2175": 67, "dpi": [67, 68], "facecolor": [67, 68, 72, 96, 154, 155, 161, 170, 173, 180], "edgecolor": [67, 68, 72, 171], "pad_inch": 67, "bbox_extra_artist": 67, "2172": [67, 175], "draw_without_rend": 67, "2173": 67, "inject": [67, 72, 144, 145, 146, 153, 155, 195, 198], "2174": 67, "getattr": 67, "_draw_dis": 67, "2176": 67, "2177": 67, "tight": [67, 86, 193], "800x600": [67, 137, 153], "o\u011ful": 67, "yurdakul": 67, "geogebra": 67, "hherq78z": 67, "_determing_dependence_discuss": 67, "_basis_vectors_video": 67, "tradit": 67, "applic": [67, 73, 74, 96, 103, 108, 119, 122, 131, 138, 140, 154, 155, 169, 170, 171, 172, 177, 191, 195, 198], "unwieldi": 67, "though": [67, 68, 69, 85, 86, 87, 94, 98, 99, 106, 121, 124, 136, 146, 147, 159, 162, 169, 172, 186, 187, 196], "plane": [67, 68, 72, 97, 151, 153], "unusu": [67, 105], "tightli": 67, "subspac": 67, "r3": 67, "xx": [67, 95, 97, 105, 122, 123, 124, 138, 162], "yy": [67, 95, 97, 122, 123, 124, 138, 162], "meshgrid": [67, 68, 72, 122, 123, 124, 135, 154, 155, 161], "plot_surfac": [67, 72, 97], "invert_xaxi": 67, "_figuring_out_a_basis_discuss": 67, "hr": [67, 106, 121, 161], "_the_dot_product_video": 67, "retin": [67, 68, 69, 97, 101, 117], "synaps": [67, 131, 142, 145, 195], "dot_prod": 67, "r_1": [67, 68, 121], "r_2": [67, 68, 121], "w_1r_1": 67, "w_2r_2": 67, "heatmap": [67, 79, 105, 121, 124, 188, 189, 195, 196, 197], "combo": 67, "highest": [67, 79, 87, 97, 124, 161, 162, 187], "postsynapt": [67, 140, 144, 145, 146], "minim": [67, 68, 79, 94, 95, 96, 97, 105, 114, 121, 123, 124, 163, 179, 180], "x_vec": 67, "y_vec": 67, "n_pixel": 67, "coord1": 67, "coord2": 67, "circle_mask": 67, "coord_i": 67, "coord_j": 67, "mask": [67, 172], "plot_heatmap": 67, "masked_x": 67, "masked_i": 67, "outer": 67, "im": [67, 79, 95, 122, 124, 186, 188, 189, 195, 196, 197, 198], "bwr": [67, 122, 124], "cbar": [67, 79, 121, 123, 124, 163, 195, 196], "colorbar": [67, 69, 72, 79, 95, 105, 114, 115, 121, 122, 123, 124, 163, 186, 188, 189, 195, 196, 197, 198], "set_label": [67, 163], "rotat": [67, 68, 69, 73, 74, 79, 112, 123, 154, 155, 171, 195, 196], "270": 67, "labelpad": [67, 135, 136, 171, 195, 196], "set_label_coord": [67, 179], "fr_arr": 67, "40b0a6": 67, "we_arr": 67, "frameon": [67, 147, 162], "description_width": [67, 161], "neuron1_fir": 67, "neuron2_fir": 67, "firing_r": 67, "_lgn_firing_interactive_demo": 67, "_the_geometry_of_the_dot_product_video": 67, "largest": [67, 74, 97, 187, 195, 198], "smallest": [67, 97], "perpendicular": 67, "axiom": 67, "cd": 67, "mostli": [67, 79, 105, 106, 123, 146, 172, 191, 195, 197], "p_3": [67, 78], "c_o": 67, "c_1x": 67, "c_2x": 67, "c_3x": 67, "c_0": 67, "c_3": 67, "obei": [67, 136], "prove": [67, 98, 169], "law": [67, 146], "cosin": 67, "formula": [67, 68, 72, 74, 78, 79, 87, 99, 123, 124, 137, 145, 162, 169, 195], "subtract": [67, 72, 112, 113, 114, 121, 123], "aderogba": [68, 72], "bayo": [68, 72], "openedx": 68, "sea": [68, 175], "gwu": 68, "gw": 68, "engcomp4": 68, "plot_linear_transform": 68, "licens": 68, "bsd": 68, "claus": 68, "lorena": 68, "barba": 68, "tingyu": 68, "IS": 68, "BY": 68, "THE": 68, "copyright": 68, "holder": 68, "contributor": 68, "AS": 68, "warranti": 68, "TO": [68, 114, 115, 121, 123, 124, 170], "OF": [68, 73, 74], "merchant": 68, "FOR": 68, "IN": 68, "NO": 68, "shall": [68, 97, 155], "BE": 68, "liabl": 68, "indirect": [68, 162], "incident": 68, "exemplari": 68, "consequenti": 68, "damag": 68, "procur": 68, "servic": 68, "profit": 68, "interrupt": [68, 172], "ON": [68, 105], "liabil": 68, "contract": 68, "strict": 68, "tort": 68, "neglig": 68, "IF": 68, "advis": 68, "SUCH": 68, "w0d3_t2": 68, "inv": [68, 69, 97, 98, 99, 105], "eig": [68, 69, 135, 136, 153, 155], "ticker": [68, 186], "get_backend": 68, "rc": 68, "cycl": [68, 135, 173], "_int_backend": 68, "gtk3agg": 68, "gtk3cairo": 68, "macosx": 68, "nbagg": 68, "qt4agg": 68, "qt4cairo": 68, "qt5agg": 68, "qt5cairo": 68, "tkagg": 68, "tkcairo": 68, "webagg": 68, "wx": 68, "wxagg": 68, "wxcairo": 68, "_backend": 68, "shrink": [68, 106, 171, 195, 196], "fig_scal": 68, "808080": 68, "gold": [68, 81, 94, 161, 196], "cab18c": 68, "lightblu": 68, "0096d6": 68, "008367": 68, "red": [68, 72, 74, 78, 79, 86, 95, 112, 113, 114, 135, 146, 147, 153, 154, 161, 162, 169, 170, 171, 179, 189], "e31937": 68, "darkblu": 68, "004065": 68, "pink": [68, 121, 124], "yellow": [68, 72, 74, 171, 189], "brown": [68, 101, 131, 145, 157, 191], "ef7b9d": 68, "fbd349": 68, "ffa500": 68, "a35cff": 68, "731d1d": 68, "quiver_param": 68, "xy": [68, 154, 155, 161, 162], "scale_unit": [68, 154, 155], "grid_param": 68, "set_rc": 68, "func": [68, 153, 154, 155], "wrapper": [68, 196, 197, 198], "serif": 68, "axisbelow": 68, "titles": [68, 72], "plot_vector": 68, "assert": [68, 161, 162, 169, 170, 195, 196, 197, 198], "zeros_lik": [68, 78, 79, 135, 136, 137, 138, 153, 162, 163, 169, 172, 187], "tile": [68, 122, 163, 170, 173, 188, 189], "nvector": 68, "ntail": 68, "xlimit": [68, 114], "ylimit": 68, "hstack": [68, 79, 97, 98, 99, 173], "quiver": [68, 154, 155, 188, 189], "finer": [68, 69], "get_xtick": [68, 186], "get_ytick": 68, "dy": [68, 72, 74], "multipleloc": 68, "set_major_loc": [68, 105, 186], "hide": [68, 69], "plot_transformation_help": 68, "unit_vector": 68, "unit_circl": 68, "helper": [68, 79, 85, 95, 96, 105, 112, 135, 137, 144, 153, 170, 188, 195], "2x2": [68, 135, 155, 161], "bool": [68, 169, 170], "circl": [68, 74, 154, 155], "grid_rang": 68, "x_": [68, 74, 94, 96, 97, 98, 105, 135, 137, 138, 173, 195, 196, 197, 198], "y_": [68, 74, 94, 96, 98, 173, 198], "color_cycl": 68, "vector_": 68, "vstack": [68, 136, 138], "circle_tran": 68, "set_linewidth": [68, 106, 186], "axis1": 68, "axis2": 68, "plot_eig_vec_transform": 68, "vec_nam": 68, "vec": [68, 69, 155, 195, 196, 197, 198], "prop_cycl": [68, 69], "by_kei": [68, 69], "i_vec": 68, "head_width": [68, 135, 195, 196, 197, 198], "transformed_vec": 68, "matmul": [68, 113, 114], "_systems_of_equations_video": 68, "3x_1": 68, "2x_2": 68, "y_1": [68, 74, 95, 121, 162], "7x_1": 68, "2x_3": 68, "y_2": [68, 121, 162], "y_3": 68, "appeal": 68, "cast": 68, "lgn": [68, 69], "dictat": [68, 136], "g_": [68, 146, 147, 171, 180, 186], "p_1": [68, 74, 78, 124], "p_2": [68, 78, 124], "3r_2": 68, "2r_1": 68, "_p": [68, 121], "g_p": 68, "ellipsi": [68, 78], "q": [68, 140, 162, 172, 180, 187], "invert": [68, 79, 106, 197], "g_q": 68, "_understanding_neural_transformations_exercis": 68, "_linear_transformations_video": 68, "enact": 68, "manner": [68, 103, 144, 146], "straight": [68, 74], "flip": [68, 113, 114, 137, 138, 187], "bar": [68, 72, 79, 97, 98, 99, 113, 122, 123, 136, 145, 146, 147, 161, 171, 180, 187], "_creating_matrices_for_transformations_exercis": 68, "_rank_": 68, "_null_space_video": 68, "alter": [68, 87, 153, 186], "li": [68, 69, 97, 105, 117, 144, 145, 146, 147, 153, 154, 155, 173], "aren": [68, 121, 161, 162, 187], "intrins": [68, 114, 175], "_neural_coding_discuss": 68, "_eigenstuff_video": 68, "infinit": [68, 78, 106, 121, 162, 180], "jog": 68, "expans": 68, "vertic": [68, 72, 74, 79, 86, 122, 123, 124], "_identifying_transformations_from_eigenvectors_discuss": 68, "_matrix_multiplication_video": 68, "pen": [68, 161], "wr": 68, "matrix1": 68, "matrix2": 68, "_computation_corner_exercis": 68, "interconnect": [69, 195], "explod": [69, 153, 180], "w0d3_bonu": 69, "plot_circuit_respons": 69, "cs": [69, 182], "textz": 69, "tracker_text": 69, "transax": [69, 124], "eigval": 69, "eigvec": 69, "lc1": 69, "lc2": 69, "cm": [69, 121, 122, 123, 124, 135, 161, 163], "coolwarm": [69, 97, 105, 195, 196, 197, 198], "a_1": [69, 195, 198], "a_2": 69, "scalarmapp": 69, "get_eigval_specified_matrix": 69, "target_eig": 69, "unless": [69, 162], "distinct": [69, 162, 173, 180], "diag": [69, 153, 173], "bc": 69, "squeez": [69, 105, 106, 122, 124, 173], "_a_neural_circuit_video": 69, "subscript": [69, 95, 146], "a_": [69, 135, 147, 154, 155, 173, 179, 180, 186, 187, 188, 195], "w_": [69, 74, 124, 154, 155, 171], "chop": 69, "weird": 69, "faithfulli": 69, "symmetr": [69, 112, 113, 123, 162, 169], "mess": [69, 198], "luckili": [69, 72, 97, 99, 162, 197], "concern": [69, 72, 95, 145, 147], "quantiti": [69, 78, 121, 123, 124, 146, 147, 162, 172, 184, 186], "unsurprisingli": 69, "embrac": 69, "tomorrow": [69, 137, 161], "w2d2": [69, 73, 142, 151], "circuit_implement": 69, "_0": [69, 135, 172, 195, 197], "a0": 69, "i_t": [69, 195], "u0": [69, 146], "42": [69, 74, 78, 86, 105, 106, 112, 113, 124, 135, 137, 144, 161, 163, 169, 171, 173, 175, 179, 180, 189, 195, 196, 197, 198], "_implementing_the_circuit_exercis": 69, "infin": 69, "incred": 69, "115": [69, 72, 117, 175], "31": [69, 72, 74, 78, 99, 112, 114, 117, 121, 123, 124, 135, 137, 146, 147, 153, 155, 163, 169, 172, 179, 186, 187, 188, 189, 195, 198], "a_i": [69, 154, 155, 173], "ia_0": 69, "a_0": [69, 195, 196, 197, 198], "_looking_at_activity_along_an_eigenvector_video": 69, "rewrit": [69, 105, 114, 153, 154, 155, 169], "subsitut": 69, "subsequ": [69, 123], "lie": [69, 137], "plot_system": 69, "_changing_the_eigenvalue_interactive_demo": 69, "_understanding_general_dynamics_using_eigenstuff_video": 69, "lambda_1": 69, "lambda_2": 69, "a0_1": 69, "a0_2": 69, "eigenvalue1": 69, "eigenvalue2": 69, "lag": [69, 105, 145, 197, 198], "update_rang": 69, "_changing_both_eigenvalues_interactive_demo": 69, "until": [69, 86, 99, 122, 129, 137, 146, 169, 171, 172, 188], "proof": [69, 117, 188], "sustain": 69, "_t": [69, 171, 172, 179, 180, 195, 197, 198], "takeawai": [69, 196, 198], "whose": [69, 72, 78, 87, 113, 121, 123, 124, 137, 146, 171, 188], "w0d4_daysummari": 71, "tessi": [72, 73], "tom": [72, 73], "matthew": [72, 73, 74, 135, 136, 137, 138, 144, 145, 146, 147, 186, 187, 188, 189], "rusti": 72, "w0d4_t1": 72, "sp": [72, 78, 79, 144, 146], "toolbox": [72, 78, 90, 117], "rendr": 72, "my_layout": [72, 73, 74, 144, 145, 146, 147], "my_fonts": 72, "my_param": 72, "labels": [72, 179, 195, 196], "move_sympyplot_to_ax": 72, "process_seri": 72, "plot_funct": [72, 106, 171], "show_deriv": 72, "show_integr": 72, "2t": [72, 169], "parabol": 72, "diff_f": 72, "p1": [72, 169, 170], "line_color": 72, "int_f": 72, "plot_alpha_func": 72, "df_dt": 72, "au": 72, "plot_charge_transf": 72, "psp": [72, 146], "numerical_integr": 72, "_why_do_we_care_about_calculus_video": 72, "_a_geometrical_interpretation_of_differentiation_and_integration_video": 72, "eigenfunct": 72, "contin": 72, "slight": [72, 79, 187, 188], "distanc": [72, 78, 115, 162, 179], "travel": [72, 78], "vehicl": 72, "decreas": [72, 74, 85, 86, 87, 106, 112, 113, 114, 124, 144, 146, 147, 155, 173], "different": 72, "5t": 72, "4t": 72, "function_opt": 72, "dropdown": [72, 124, 135, 162], "checkbox": [72, 146, 161, 170, 171], "on_value_chang": 72, "eigenvector": [72, 114, 136], "imagin": [72, 78, 79, 97, 106, 112, 124, 146, 147, 162, 169, 170, 171, 187, 189, 195, 198], "_geometrical_understanding_interactive_demo": 72, "_differentiation_video": 72, "trusti": 72, "friend": 72, "wikipedia": 72, "nt": [72, 105], "me": 72, "3t": 72, "du": [72, 146], "dv": [72, 73, 74, 86, 144, 145, 146, 147], "u_t": 72, "v_t": [72, 180], "du_dt": 72, "dv_dt": 72, "_derivative_of_the_postsynaptic_potential_alpha_function_exercis": 72, "dr": [72, 103, 146, 153, 155, 172, 186], "da": [72, 173], "expon": [72, 87], "_chain_rule_math_exercis": 72, "hood": 72, "fd": 72, "rightarrow": [72, 74, 95, 106, 123, 136, 147, 154, 155, 170], "accur": [72, 74, 98, 110, 124, 131, 135, 138, 145, 161, 163, 171, 172, 179, 197], "numerical_derivative_demo": 72, "tx": 72, "sine_fun": 72, "diffrenti": 72, "cos_fun": 72, "n_tx": 72, "n_sine_fun": 72, "sine_diff": 72, "ncol": [72, 86, 87, 94, 95, 96, 105, 170, 171, 172, 187, 188, 189], "fancybox": 72, "_numerical_differentiation_of_the_sine_function_interactive_demo": 72, "dc": [72, 105, 146], "eta": [72, 137, 138, 144, 153, 172, 198], "visit": [72, 78], "timestep": [72, 74, 86, 135, 136, 172, 180, 186, 195, 196, 197, 198], "compute_rate_and_gain": 72, "current_timestep": 72, "plot_rate_and_gain": 72, "i_1": [72, 145], "rate_1": 72, "i_2": [72, 145], "rate_2": 72, "input_rang": 72, "output_rang": 72, "ital": 72, "bbox": [72, 170], "pad": [72, 105, 122, 123, 124, 161, 195, 197, 198], "_calculating_the_transfer_function_and_gain_of_a_neuron_interactive_demo": 72, "_functions_of_multiple_variables_video": 72, "inhibitori": [72, 74, 87, 149, 151, 155], "derriv": 72, "multivari": [72, 97, 114, 121, 198], "2xy": 72, "2y": 72, "curvi": 72, "f2d_string": 72, "plot_partial_deriv": 72, "f2d": 72, "f2d_dx": 72, "f2d_dy": 72, "plot3d": 72, "p2": 72, "p3": 72, "jacobian": [72, 154], "_visualize_partial_derivatives_interactive_demo": 72, "_numerical_integration_video": 72, "wish": [72, 94, 97, 146, 169, 198], "rectangl": [72, 173], "approcah": 72, "cut": 72, "stripe": 72, "downsid": 72, "underestim": 72, "overestim": 72, "riemann_sum_demo": 72, "step_siz": [72, 78], "min_val": [72, 173], "max_val": [72, 173], "ftn": 72, "int_ftn": 72, "r_tx": 72, "fun_valu": 72, "r_sum": 72, "cumsum": [72, 114, 136, 137, 162, 169, 173, 180], "lebesgu": 72, "rung": 72, "kutta": 72, "_riemann_sum_vs_analytical_integral_with_changing_step_size_interactive_demo": 72, "68": [72, 85, 146, 180], "incom": [72, 86, 146, 171], "elicit": [72, 146, 147], "tau_": [72, 74, 144, 146, 147, 153, 154, 155], "t_sp": [72, 145, 146, 147], "rectangle_area": 72, "_calculating_charge_transfer_with_excitatory_input_exercis": 72, "_filtering_operations_video": 72, "consequ": [72, 146, 161, 162, 171, 172, 180], "akin": 72, "shock": 72, "absorb": 72, "noise_sign": 72, "wave": 72, "x1_diff": 72, "x1_integr": 72, "sec": [72, 144, 145], "0x7fb22d07ffd0": 72, "amplifi": [72, 151], "suppress": [72, 149, 151], "smooth": [72, 85, 87, 97, 124, 186], "easili": [72, 79, 94, 97, 119, 121, 123, 129, 161, 170, 172, 187], "took": [72, 161, 163, 171, 187, 188], "tradeoff": [72, 99, 106, 187], "trough": 72, "smoothen": 72, "enhanc": 72, "inhibit": [72, 74, 83, 146, 151, 154], "sigmoid_funct": 72, "exc_input": 72, "inh_input": 72, "exc_a": 72, "exc_theta": 72, "inh_a": 72, "inh_theta": 72, "jj": 72, "lg_txt": 72, "ax2": [72, 86, 95, 96, 112, 113, 121, 124, 147, 154, 155, 170, 171, 172, 179, 186, 187, 188], "ax3": [72, 112, 113, 187], "surf": 72, "rstride": 72, "cstride": 72, "viridi": 72, "set_zlabel": 72, "expectedli": 72, "downward": 72, "tediou": [72, 105, 135], "plot_2d_neuron_transfer_funct": 72, "rate_d": 72, "rate_di": 72, "surf1": 72, "exc": [72, 86, 146, 155], "inh": [72, 86, 146], "view_init": 72, "xde": 72, "yde": 72, "surf2": 72, "wrt": 72, "xdi": 72, "ydi": 72, "surf3": 72, "_numerical_partial_derivatives_bonus_discuss": 72, "rebecca": 73, "bradi": 73, "gate": 73, "blood": 73, "nobel": 73, "prize": 73, "hodgkin": [73, 131], "huxlei": [73, 131], "axon": [73, 140], "paradox": [73, 149], "mc": [73, 74], "escher": 73, "paint": 73, "motiv": [73, 74, 85, 103, 199], "raster": [73, 74, 145, 147, 173], "breakdown": 73, "w0d4_t2": 73, "ipd": [73, 74], "gridspec": [73, 74, 161, 180], "plot_dpdt": 73, "birth": [73, 74, 198], "gs": [73, 74, 112, 113, 161, 180], "dpdt": 73, "fucntion": 73, "plot_v_no_input": 73, "v_rang": 73, "dvdt": 73, "hline": [73, 74, 79, 162], "linestyl": [73, 74, 86, 105, 106, 147, 162, 169, 170, 171, 180, 188, 189], "vline": [73, 74, 86, 94, 95, 162, 179], "mv": [73, 74, 144, 145, 146, 147], "plot_if": [73, 74], "height_ratio": [73, 74, 186], "na": [73, 74, 197], "plot_dvdt": 73, "85": [73, 149, 169, 173, 180, 189], "g_l": [73, 144, 145, 146], "exact_integrate_and_fir": 73, "v_exact": 73, "t_isi": [73, 74], "v_th": [73, 74, 144, 145, 146, 147], "_why_do_we_care_about_differential_equations_video": 73, "_population_differential_equation_video": 73, "_interpretating_the_behavior_of_a_linear_population_equation_discuss": 73, "obscur": 73, "p_0": [73, 74], "grow": [73, 119, 135, 137, 153, 155], "declin": 73, "asid": [73, 123], "mathematician": 73, "taunt": 73, "3p": 73, "generaliz": 73, "countri": 73, "transit": [73, 79, 135, 151, 170, 172, 173, 180, 186, 188, 189], "450px": [73, 74, 144, 146], "pop_widget": [73, 74], "_parameter_change_interactive_demo": 73, "simplif": [73, 86], "pronounc": 73, "growth": [73, 74, 85], "extern": [73, 74, 103, 124, 144, 145, 146, 147, 149, 154, 155], "weather": 73, "predat": [73, 124], "prei": [73, 171], "_the_leaky_integrate_and_fire_model_video": 73, "loui": [73, 144], "\u00e9douard": [73, 144], "lapicqu": [73, 74, 140, 144], "1907": [73, 74, 140, 144], "subthreshold": [73, 144], "r_mi": [73, 74], "r_m": [73, 74, 86], "minu": [73, 105, 123, 124, 162], "arrang": [73, 74, 123], "_effect_of_membrane_potential_interactive_demo": 73, "91": [73, 189], "61": [73, 124, 149, 153, 169, 188, 189, 196], "v_reset_widget": 73, "_initial_condition_vreset_interactive_demo": 73, "_the_impact_of_input_interactive_demo": 73, "t_rest": 73, "_adding_firing_to_the_lif_video": 73, "plateau": 73, "isi": [73, 83, 86, 146], "\ud835\udc46\ud835\udc5d\ud835\udc56\ud835\udc58\ud835\udc52": 73, "discontinu": [73, 74], "eleg": [73, 74, 103], "electrophysiologist": [73, 74], "_input_on_spikes_interactive_demo": 73, "exectur": 73, "fi": 73, "i_rang": 73, "spike_r": [73, 146], "weak": [73, 79, 162, 169, 187], "_summary_video": [73, 74, 79, 195, 196, 198], "lotka": [73, 74], "1920": [73, 74], "rhythmic": [73, 74], "inorgan": [73, 74], "410": [73, 74], "415": [73, 74, 149], "brunel": [73, 74, 140, 149, 151], "rossum": [73, 74, 140], "frog": [73, 74, 140], "cybern": [73, 74], "dec": [73, 74], "337": [73, 74, 131, 140], "1007": [73, 74, 81, 101, 131, 140, 175, 191], "s00422": [73, 74, 131, 140], "0190": [73, 74, 140], "epub": [73, 74], "oct": [73, 74], "pmid": [73, 74], "17968583": [73, 74], "2001": [73, 74, 83, 117, 131, 175], "strogatz": [73, 74], "chao": [73, 74, 149], "chemistri": [73, 74], "westview": [73, 74], "press": [73, 74, 81, 85, 90, 101, 117, 131, 140, 149, 157, 175, 182, 186, 191], "lindsai": [73, 74, 117, 149], "bloomsburi": [73, 74], "2004": [73, 74, 90, 101, 105, 140, 146], "sync": [73, 74, 170, 171], "emerg": [73, 74, 81, 117, 131, 145, 188, 193], "penguin": [73, 74], "uk": [73, 74, 90, 101, 117, 157], "joi": [73, 74], "quantamagazin": [73, 74], "tag": [73, 74, 169, 170, 180], "quanta": [73, 74], "magazin": [73, 74], "harvei": [74, 101], "mccone": 74, "odd": [74, 78, 122, 123, 170], "mysteri": 74, "w0d4_t3": 74, "plot_slop": 74, "og": 74, "plot_stepeul": 74, "bo": [74, 144, 145, 147, 153, 154], "t_1": [74, 135], "e_1": 74, "visualize_population_approx": 74, "e_k": 74, "plot_reri": 74, "r_e": [74, 146, 153], "r_i": [74, 123, 155], "plot_reri_simpl": 74, "plot_reri_matrix": 74, "null_r": 74, "null_ri": 74, "_intro_to_numerical_methods_for_differential_equations_video": 74, "leonhard": 74, "1707": 74, "1783": 74, "t_0": [74, 135, 136], "y_0": [74, 172], "_slope_of_a_line_interactive_demo": 74, "p_0e": 74, "rearrang": [74, 112], "henc": [74, 78, 79, 147, 169, 195], "_euler_error_of_single_step_interactive_demo": 74, "_taking_more_steps_video": 74, "segment": [74, 94], "t_2": [74, 135], "t_3": 74, "t_4": 74, "times1": 74, "_step_step_step_exercis": 74, "_leaky_integrate_and_fire_video": 74, "v_k": 74, "euler_integrate_and_fir": 74, "esitm": 74, "53": [74, 99, 105, 106, 108, 136, 144, 145, 154, 163, 169, 172, 188, 189, 198], "_lif_and_euler_exercis": 74, "_systems_of_differential_equations_video": 74, "grip": 74, "regul": [74, 175, 196], "dr_e": [74, 146, 155], "ee": [74, 154, 155], "ei": [74, 154, 155], "tau_i": [74, 154, 155], "dr_i": [74, 155], "ie": [74, 105, 146, 153, 154, 155, 180, 198], "timescal": [74, 131, 135, 147, 153, 154, 155, 171, 195, 196, 197, 198], "120": [74, 105, 147, 154], "100m": 74, "120m": 74, "01m": 74, "r_": [74, 86, 145, 153, 186, 187], "euler_simple_linear_system": 74, "_euler_on_a_simple_system_exercis": 74, "_simple_euler_solution_to_the_wilson_cowan_model_discuss": 74, "stabl": [74, 99, 135, 149, 155, 180, 198], "orbit": 74, "_discuss_the_plots_discuss": 74, "re_": 74, "re_k": 74, "ri_k": 74, "ri_": 74, "re_0": 74, "ri_0": 74, "willson": 74, "euler_linear_system_matrix": 74, "w_ee": 74, "n_er": 74, "dre": [74, 153, 154, 155], "n_ir": 74, "dri": [74, 154, 155], "w_ei": 74, "w_ie": 74, "w_ii": 74, "_oscillations_discuss": 74, "62": [74, 79, 124, 149, 153, 169, 188, 189, 196], "maintain": [74, 86, 137, 172, 180], "_small_change_changes_everything_interactive_demo": 74, "k_1": 74, "y_k": 74, "k_2": 74, "k_3": 74, "k_4": 74, "tk_3": 74, "2k_2": 74, "2k_3": 74, "p_": [74, 79, 163, 169, 170, 173, 179], "rk4": 74, "t_fine": 74, "prk4": 74, "dp": [74, 173], "k1": [74, 114], "k2": [74, 114], "k3": 74, "k4": 74, "ro": [74, 78, 147, 154], "entre": 74, "constitut": [74, 193], "essai": [74, 81], "dowl": 74, "florencia": 74, "assaneo": 74, "omega": 74, "x_k": [74, 137, 138], "x_0": [74, 105, 135, 137, 138, 195], "plot_stuart_landa": 74, "width_ratio": [74, 105, 180], "euler_stuart_landau": 74, "lamba": 74, "doell": 74, "perfectli": [74, 123], "lamda": 74, "_oscillator_bonus_interactive_demo": 74, "4hz": 74, "freq": 74, "flash": 74, "50hz": 74, "_stuart_landau_system_bonus_interactive_demo": 74, "e3001234": 74, "pbio": 74, "3001234": 74, "gadget": 76, "w0d5_daysummari": 76, "ulrik": [78, 79], "beierholm": [78, 79], "hyosub": [78, 79, 161, 162], "kim": [78, 79, 131, 161, 162], "previous": [78, 79, 87, 96, 105, 106, 115, 146, 155, 177, 179, 189], "w0d5_t1": 78, "hbox": [78, 79, 161, 162, 170, 171, 173], "vbox": [78, 79, 161, 162, 170, 171, 173], "interact_manu": [78, 79, 187], "plot_random_sampl": 78, "figtitl": [78, 79, 135], "datax": 78, "datai": 78, "plot_random_walk": 78, "plot_hist": [78, 79], "num_bin": [78, 79], "my_plot_singl": 78, "px": [78, 79, 161], "c2": [78, 79, 85, 186], "plot_gaussian_samples_tru": [78, 79], "xspace": [78, 79], "num_sampl": [78, 79, 169], "densiti": [78, 79, 95, 135, 162, 163, 171], "_stochastic_world_video": 78, "bound": [78, 79, 87, 137, 147, 172], "generate_random_sampl": 78, "num_point": [78, 79, 170], "uniformli": [78, 87, 97, 135, 136, 145, 146, 147, 173, 179], "_create_randomness_exercis": 78, "although": [78, 105, 136, 137, 146], "smoothli": [78, 85, 87], "increasingli": [78, 122, 199], "gen_and_plot_random_sampl": 78, "selectionslid": 78, "_random_sample_generation_from_uniform_distribution_interactive_demo": 78, "_random_walk_video": 78, "rat": [78, 79, 131, 169], "generate_random_walk": 78, "enclos": 78, "num_step": 78, "random_x_step": 78, "random_y_step": 78, "restrict": [78, 85, 121, 145, 180], "_modeling_a_random_walk_exercis": 78, "arena": 78, "intslid": [78, 79, 86, 87, 106, 154, 170, 171, 172, 186, 187, 197], "gen_and_plot_random_walk": 78, "_varying_parameters_of_a_random_walk_interactive_demo": 78, "nevertheless": 78, "preview": [78, 79], "_binomial_distribution_video": 78, "bernoulli": [78, 106, 123, 138, 198], "thankfulli": 78, "maze": [78, 79, 188], "food": [78, 79, 124, 137, 179, 186], "mutual": [78, 162], "exclus": [78, 195], "binom": 78, "coeffici": [78, 97, 106, 112, 121, 123, 124, 138, 144, 145, 162, 172, 195, 196, 197, 198], "mass": 78, "sum_k": [78, 146], "n_sampl": [78, 79, 94, 95, 96, 97, 98, 99, 106, 115], "visualis": 78, "left_turn_samples_1000": 78, "_binomial_distribution_sampling_discuss": 78, "p_4": 78, "sum_i": [78, 79, 87, 99, 106, 161, 163, 173], "p_i": [78, 79, 87, 124, 147], "multinomi": 78, "markov": [78, 131, 167, 171, 172, 173, 177, 179, 184, 186], "chain": [78, 94, 121, 155, 170, 172, 173], "_poisson_distribution_video": 78, "encapsul": [78, 79], "sampled_spike_count": 78, "drawn": [78, 79, 95, 121, 124, 137, 170, 180, 187], "_poisson_distribution_sampling_exercis": 78, "asymmetr": [78, 162], "lambda_valu": 78, "gen_and_plot_possion_sampl": 78, "_varying_parameters_of_poisson_distribution_interactive_demo": 78, "typo": [78, 79], "vido": 78, "mu_1": [78, 162], "sigma_1": [78, 112, 162], "mu_2": [78, 162], "sigma_2": [78, 112, 162], "_continuous_distributions_video": 78, "ourselv": [78, 79, 106, 121, 135, 137, 180, 197], "000120141": 78, "believ": [78, 94, 106, 138, 162], "int_": [78, 163, 172], "int_a": 78, "infti": [78, 106, 137, 138, 162, 180, 186], "permit": [78, 162], "particip": [78, 79, 92, 163], "portion": [78, 189, 198], "my_gaussian": [78, 79, 163], "therefor": [78, 85, 94, 96, 105, 119, 121, 122, 123, 124, 136, 145, 146, 147, 153, 154, 155, 161, 163, 188, 189, 197], "x_point": [78, 79, 163], "normalis": [78, 79], "_gaussian_distribution_exercis": 78, "standard_dev": 78, "gen_and_plot_normal_sampl": 78, "distriut": 78, "everywher": [78, 92, 162, 193, 195], "_sampling_from_a_gaussian_distribution_interactive_demo": 78, "gotten": [78, 138], "textbook": [78, 171], "summaris": 79, "maximis": 79, "w0d5_t2": 79, "default_rng": 79, "plot_likelihood": 79, "mean_val": 79, "variance_v": 79, "va": [79, 106, 161, 195, 196], "set_xtick": [79, 114, 121, 122, 123, 124, 161, 170, 173, 179, 188, 189, 195, 196, 198], "set_ytick": [79, 114, 121, 122, 123, 124, 161, 162, 170, 171, 179, 188, 189], "set_xticklabel": [79, 112, 161, 173, 186, 188, 189, 195, 196, 198], "set_yticklabel": [79, 124, 161, 170, 171, 179, 188, 189], "posterior_plot": 79, "posterior_pointwis": 79, "auditori": 79, "plot_classical_vs_bayesian_norm": 79, "mu_class": 79, "var_class": 79, "mu_bay": 79, "var_bay": 79, "_basic_probability_video": 79, "marginalis": 79, "cap": 79, "summat": [79, 146], "b0": 79, "db": [79, 171], "hubel": [79, 122], "wiesel": [79, 122], "1959": 79, "fiction": 79, "inact": 79, "h_": [79, 122, 123, 172], "h_0": [79, 198], "v_0": 79, "percent": [79, 186, 197], "horizon": [79, 179, 180, 188], "lastli": [79, 193], "latter": 79, "_probability_example_main_exercis": 79, "_markov_chains_video": 79, "memoryless": 79, "bright": 79, "state_i": 79, "state_": 79, "determinist": [79, 87, 136, 171, 186, 189], "tt": 79, "jth": 79, "transition_matrix": [79, 180], "p0": [79, 169, 170], "matrix_pow": 79, "p4": 79, "4311": 79, "spent": [79, 136, 137], "implicit": 79, "ergod": 79, "p_random": 79, "p_average_time_sp": 79, "4473": 79, "4211": 79, "1316": 79, "_markov_chains_exercis": 79, "satiat": 79, "tire": 79, "mont": 79, "_statistical_inference_and_likelihood_video": 79, "x_i": [79, 87, 94, 95, 97, 106, 112, 113, 163, 173], "unbias": [79, 193], "x_n": [79, 87, 95], "prod_": [79, 95, 169], "emphas": [79, 144, 161], "logarithm": [79, 87, 95, 124], "compute_likelihood_norm": 79, "standard_dev_v": 79, "p_data": 79, "true_mean": 79, "true_standard_dev": 79, "guess_mean": 79, "guess_standard_dev": 79, "92904": 79, "meaningless": 79, "ry": 79, "initialis": 79, "gvien": 79, "idxmean": 79, "idxvar": 79, "_computing_likelihood_exercis": 79, "_maximum_likelihood_video": 79, "implicitli": [79, 92], "underset": [79, 95, 124, 187], "operatornam": [79, 95, 98, 187], "argmax": [79, 95, 106, 124, 162, 163, 173, 179, 187, 188, 189], "gave": 79, "manual": [79, 124], "bunch": [79, 136, 169], "val": [79, 99, 106], "plotfnc": 79, "loglikelihood": [79, 163], "_maximum_likelihood_inference_interactive_demo": 79, "machin": [79, 90, 98, 101, 103, 106, 110, 114, 117, 121, 122, 124, 131, 138, 171, 172, 175, 187, 189, 193, 197, 199], "minimis": 79, "optimis": 79, "hundr": [79, 85, 121], "negloglik": 79, "bnd": 79, "optimal_paramet": 79, "_minim": 79, "713": 79, "x0": [79, 85, 97, 105, 135, 136, 137, 138, 153, 155], "jac": [79, 153], "hess": 79, "hessp": 79, "tol": [79, 105, 153], "710": 79, "_minimize_newtoncg": 79, "711": 79, "712": 79, "meth": [79, 153], "bfg": 79, "_minimize_lbfgsb": 79, "714": 79, "715": 79, "tnc": 79, "716": 79, "_minimize_tnc": 79, "717": 79, "_lbfgsb_py": 79, "347": [79, 191], "disp": 79, "maxcor": 79, "ftol": 79, "gtol": 79, "maxfun": 79, "maxit": 79, "iprint": 79, "maxl": 79, "finite_diff_rel_step": 79, "unknown_opt": [79, 153], "344": 79, "346": [79, 117], "_prepare_scalar_funct": 79, "sf": [79, 122, 123, 124], "epsilon": [79, 95, 97, 153, 169, 188, 189, 195, 196, 197, 198], "348": 79, "349": 79, "351": 79, "func_and_grad": 79, "fun_and_grad": 79, "353": 79, "fortran_int": 79, "_lbfgsb": 79, "intvar": 79, "_optim": 79, "288": 79, "284": 79, "inf": [79, 153, 173], "286": 79, "scalarfunct": 79, "grad": [79, 121], "287": 79, "289": 79, "291": [79, 117], "_differentiable_funct": 79, "166": 79, "finite_diff_bound": 79, "fun_wrap": [79, 135], "165": 79, "_update_fun_impl": 79, "update_fun": 79, "_update_fun": 79, "callabl": [79, 106], "262": 79, "260": 79, "261": 79, "f_updat": 79, "145": 79, "141": [79, 81, 145], "nfev": [79, 135], "142": 79, "send": [79, 162], "143": [79, 145], "undefin": [79, 87], "144": [79, 124, 163], "fx": 79, "146": 79, "147": 79, "isscalar": 79, "280": 79, "148": 79, "_maximum_likelihood_estimation_exercis": 79, "9547432925098045": 79, "9870331586690259": 79, "theseparamet": 79, "mle": [79, 105, 161], "wiki": 79, "_analytical_solution_exercis": 79, "_bayesian_inference_with_gaussian_distribution_video": 79, "denomin": [79, 99, 196, 197], "classic_vs_bayesian_norm": 79, "mean_class": 79, "mean_bay": 79, "ndata": 79, "random_num_gener": 79, "xsupp": 79, "compris": [79, 121, 122, 123, 124], "benefici": [79, 87, 172], "_bayesian_inference_with_gaussian_distribution_discuss": 79, "_conjugate_priors_video": 79, "binomi": [79, 101, 179], "mathrm": [79, 86, 95, 97, 98, 99, 105, 144, 147, 153, 155], "priorl": 79, "priorr": 79, "numl": 79, "numr": 79, "betapdf": 79, "betaprior": 79, "datapoint": [79, 106], "stabilis": 79, "fluctuat": [79, 140, 144, 146, 147, 155], "willing": 79, "peaki": 79, "conid": 79, "regularis": [79, 197], "badli": 79, "benefit": [79, 179, 189, 198], "_conjugate_priors_interactive_demo": 79, "skeleton": [79, 121], "pointwis": [79, 163], "predefin": 79, "compute_posterior_pointwis": 79, "localization_simul": 79, "mu_auditori": 79, "sigma_auditori": 79, "mu_visu": 79, "sigma_visu": 79, "82": [79, 180, 189], "79": [79, 90, 169], "71": [79, 124, 170, 180, 189], "66": [79, 131, 179, 180, 189], "devot": 79, "_finding_the_posterior_computationally_bonus_exercis": 79, "belief": [79, 159, 171, 187, 188], "frequentist": 79, "paradigm": [79, 186], "aka": [79, 83, 105, 124, 186, 188], "hous": 79, "unreli": [79, 162, 171], "sprinkler": 79, "water": 79, "grass": 79, "rain": 79, "wet": 79, "obvious": [79, 189], "999": [79, 101, 131, 140, 172], "99": [79, 121, 123, 124, 161, 162, 173, 189, 196], "home": 79, "eqnarrai": [79, 135, 144, 146, 147, 162, 163, 172, 173, 180], "pw1r1s1": 79, "pw1r1s0": 79, "pw1r0s1": 79, "pw1r0s0": 79, "ps": [79, 161], "7522": 79, "neighbour": 79, "_bayes_net_bonus_exercis": 79, "stuctur": 79, "_causality_in_the_brain_bonus_discuss": 79, "bassett": 81, "zurn": 81, "566": 81, "578": [81, 149], "s41583": [81, 117], "018": [81, 108, 117, 131, 182, 191], "0038": 81, "postprint": [81, 101, 108, 117, 131, 140, 149, 175, 182, 191], "europepmc": [81, 101, 108, 117, 131, 149, 175, 182], "pmc6466618": 81, "bennett": 81, "hacker": 81, "2003": [81, 90, 140, 149, 157], "philosoph": 81, "foundat": [81, 110, 137, 159, 167, 172, 179, 191, 199], "wilei": 81, "blackwel": 81, "1998": [81, 140, 171, 172], "occam": [81, 90], "razor": [81, 90], "philosophi": 81, "pp": [81, 117, 131, 191], "195": [81, 131], "clarendon": 81, "oxford": [81, 157], "chandrasekhar": 81, "chicago": 81, "chater": 81, "oaksford": 81, "1999": [81, 101], "ration": 81, "trend": [81, 90, 179], "s1364": 81, "6613": 81, "98": [81, 106, 131, 135, 149, 175, 186, 189], "01273": 81, "sejnowski": [81, 149], "1990": 81, "343": 81, "382": [81, 140, 149], "2307": 81, "2214198": 81, "cnl": 81, "salk": 81, "20represent": 81, "20and": 81, "20neural": 81, "20comput": 81, "201990": 81, "3325": 81, "1988": [81, 145], "242": 81, "4879": 81, "741": 81, "745": [81, 172], "3055294": 81, "cichi": [81, 117], "kaiser": 81, "305": 81, "317": 81, "tic": [81, 90], "2005": [81, 101, 140, 169, 182], "feldman": 81, "interdisciplinari": 81, "330": 81, "1002": 81, "wc": 81, "1406": 81, "pmc5125387": 81, "gillett": 81, "cambridg": [81, 90, 140, 149, 157, 191], "goldstein": [81, 117], "e40018": 81, "7554": [81, 90, 101, 131, 149], "40018": 81, "jona": [81, 191], "microprocessor": 81, "e1005268": 81, "1005268": 81, "josephson": 81, "ed": [81, 101, 157], "1996": [81, 131, 140, 149, 157], "abduct": 81, "infer": [81, 85, 90, 94, 95, 96, 97, 98, 99, 101, 114, 115, 119, 131, 157, 159, 161, 167, 169, 171, 172, 173, 177, 179, 184, 191, 195, 199], "technolog": 81, "kaplan": 81, "2011": [81, 101, 157, 165], "synthes": [81, 171], "183": [81, 149, 191], "373": 81, "s11229": 81, "011": [81, 90, 101, 117], "9970": 81, "31219": 81, "3vy69": 81, "lee": 81, "criss": 81, "devez": 81, "donkin": 81, "etz": 81, "leit": 81, "vandekerckhov": 81, "31234": 81, "dmfhk": 81, "lombrozo": 81, "1093": 81, "oxfordhb": 81, "9780199734689": 81, "013": 81, "0014": 81, "marr": 81, "poggio": 81, "1976": [81, 175], "circuitri": 81, "intellig": [81, 117, 184, 186], "laboratori": 81, "memo": 81, "massachusett": 81, "institut": 81, "357": 81, "dspace": [81, 191], "1721": [81, 191], "5782": 81, "parker": 81, "metasci": 81, "vol": [81, 90, 157, 180, 191], "s11016": 81, "9567": 81, "pearl": [81, 191, 193], "mackenzi": [81, 191], "russel": 81, "1917": 81, "mystic": 81, "5962": 81, "bhl": 81, "19230": 81, "archiv": 81, "download": [81, 85, 105, 106, 121, 122, 123, 124, 172], "mysticismlogicot00russiala": 81, "mysticismlogicot00russiala_bw": 81, "simon": 81, "1969": 81, "ma": [81, 90, 157, 175, 180], "trappenberg": 81, "oup": 81, "collin": [81, 90, 131], "e49547": [81, 90], "49547": [81, 90], "w1d1_daysummari": 82, "_day_summari": [82, 91, 102, 109, 118, 126, 132, 141, 176, 183], "meta": [83, 182], "remaind": 83, "compactli": 83, "quantifi": [83, 87, 96, 114, 121, 123, 137, 144, 161, 169, 179, 180, 195, 196, 198], "bay": [83, 103, 157, 159, 167, 169, 177], "quest": 83, "t1": [83, 92, 103, 162], "t3": 83, "w1d1_intro": 83, "w1d1_outro": 84, "_outro_video": [84, 93, 163], "laport": [85, 86, 87, 88], "byron": [85, 86, 87, 88, 94, 95, 96, 97, 108, 110, 169, 172, 186, 187, 188, 189], "galbraith": [85, 86, 87, 88, 94, 95, 96, 97, 169, 172, 186, 187, 188, 189], "dalin": [85, 86, 87], "guo": [85, 86, 87], "aishwarya": [85, 86, 87], "balwani": [85, 86, 87], "madineh": [85, 86, 87, 95, 121, 122, 123, 124, 195, 196, 197, 198], "sarvestani": [85, 86, 87, 95, 121, 122, 123, 124, 195, 196, 197, 198], "vaziri": [85, 86, 87, 144, 145, 146, 153, 154, 155], "pashkam": [85, 86, 87, 144, 145, 146, 153, 154, 155], "gagana": [85, 86, 87, 88, 112, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 186, 187, 189, 195, 196, 197, 198], "acknowledg": [85, 87, 94, 105, 106, 172, 173], "flavor": [85, 86, 87, 106], "w1d1_t1": 85, "script": [85, 163], "corner": [85, 189, 196], "keyboard": 85, "shortcut": [85, 189], "cmd": 85, "mac": 85, "ctrl": 85, "bracket": 85, "inlin": [85, 86, 87, 105, 106, 122, 123, 129, 162, 163, 180], "plot_isi": 85, "single_neuron_isi": 85, "axvlin": [85, 86, 94, 95, 96, 123, 147, 154, 162, 163, 180, 189], "durat": [85, 105, 135, 136, 137, 144, 145, 146, 147, 153, 154, 155, 171, 173], "request": [85, 87, 105, 106, 121, 122, 123, 124, 172], "sy5xt": [85, 87], "status_cod": [85, 87, 105, 106, 121, 122, 123, 124, 172], "bytesio": [85, 87, 172], "allow_pickl": [85, 87, 172], "_what_models_video": [85, 135], "probe": [85, 106], "implant": 85, "electr": [85, 86, 146, 165], "electrod": [85, 86], "nearbi": 85, "preced": [85, 105, 163, 169, 186], "incomplet": [85, 163, 169, 170], "partli": 85, "undocu": 85, "circumst": [85, 195], "unfamiliar": 85, "ahead": [85, 170], "734": 85, "sep": [85, 87], "826": 85, "321": [85, 147], "9723": 85, "i_neuron": 85, "i_print": 85, "slice": [85, 195, 196, 197, 198], "8149": 85, "822467": 85, "9646": 85, "1436": 85, "8709": 85, "0698667": 85, "1536334": 85, "2403667": 85, "7072": 85, "799": 85, "n_neuron": [85, 106, 121, 122, 123, 124, 195, 196, 197, 198], "total_spikes_per_neuron": 85, "spike_times_i": 85, "five": [85, 96, 147, 170, 172], "2818": 85, "3953": [85, 131], "646": 85, "1115": [85, 131], "_exploring_the_dataset_video": 85, "loud": [85, 162, 163], "percentag": [85, 138, 187], "mean_spike_count": 85, "frac_below_mean": 85, "major": [85, 179, 188, 189], "exception": 85, "median_spike_count": 85, "limegreen": [85, 171, 172], "50th": 85, "percentil": [85, 96, 121, 124], "interquartil": 85, "_comparing_mean_and_median_neurons_exercis": 85, "restrict_spike_tim": 85, "inner": 85, "interval_spike_tim": 85, "interval_mask": 85, "t_interv": 85, "original_count": 85, "interval_count": 85, "frac_interval_spik": 85, "ptp": 85, "spike_times_flat": 85, "experiment_dur": 85, "interval_dur": 85, "frac_interval_tim": 85, "neuron_idx": [85, 87, 195, 196, 197, 198], "51": [85, 124, 131, 136, 144, 145, 162, 172, 186, 189, 198], "5th": 85, "_visualizing_activity_video": 85, "energi": [85, 86, 87, 175], "cellular": 85, "machineri": 85, "refractori": [85, 144, 145, 146, 147, 195], "metabol": 85, "longest": 85, "interspik": [85, 87, 144, 147], "compute_single_neuron_isi": 85, "single_neuron_spik": 85, "283": [85, 87, 175], "predomin": 85, "rapidli": [85, 86, 105, 155, 171, 189], "absenc": [85, 137], "agre": [85, 123, 138], "domin": [85, 145, 146], "_isis_and_their_distributions_exercis": 85, "_isi_distribution_video": 85, "maxima": [85, 187], "parameter": [85, 95, 121, 153, 179], "offset": [85, 97, 105, 162, 169, 170, 179, 197, 198], "y0": [85, 135], "single_neuron_idx": 85, "c4": 85, "exp_scal": 85, "20000": [85, 105, 186, 198], "250": [85, 99, 114, 137, 144, 179, 197], "exp_rat": 85, "exp_x0": 85, "inv_scal": 85, "3e2": 85, "inv_x0": 85, "lin_slop": 85, "1e5": 85, "6e5": 85, "lin_y0": 85, "4e4": 85, "fit_plot": 85, "2000": [85, 86, 96, 108, 115, 140, 149, 175, 191, 196, 198], "func_param": 85, "fill_between": [85, 86, 87, 162, 169, 171, 179, 180, 196, 197, 198], "_isi_functions_explorer_interactive_demo_and_discuss": 85, "_fitting_models_by_hand_video": 85, "_reflecting_on_what_models_discuss": 85, "poke": 85, "realist": [86, 144, 153, 180, 186, 188], "w1d1_t2": 86, "ax_arg": 86, "duplic": 86, "shade": [86, 87], "drawstyl": [86, 87], "heurist": [86, 103], "ymin": [86, 94, 95, 170], "ymax": [86, 87, 94, 95, 170, 173], "yscale": 86, "autoscal": 86, "plot_neuron_stat": 86, "n_bin": [86, 87, 122, 124], "xmax": [86, 95], "_how_models_video": 86, "discharg": [86, 149], "preserv": [86, 87, 95], "presynapt": [86, 146], "ge": [86, 146, 147], "suitabl": [86, 87, 94], "lif_neuron": 86, "alia": 86, "n_step": [86, 186, 187], "precomput": [86, 106, 115, 172], "_compute_dvm_exercis": 86, "_lif_neuron": 86, "floatlogslid": [86, 172, 187], "plot_lif_neuron": 86, "_linear_if_neuron_interactive_demo_and_discuss": 86, "_linear_if_models_video": 86, "empir": [86, 96, 99, 101, 136, 162, 173], "upon": [86, 123, 171, 177, 186, 187, 189, 195, 199], "tendenc": [86, 137, 198], "steadi": [86, 153, 154, 155], "lambda_": [86, 173], "lif_neuron_inh": 86, "exc_rat": [86, 146], "inh_rat": [86, 146], "_compute_dvm_with_inhibitory_signals_exercis": 86, "_lif_neuron_inh": 86, "_lif_and_inhibition_neuron_interactive_demo_and_discuss": 86, "_lif_and_inhibition_video": 86, "_reflecting_on_how_models_discuss": 86, "c_m": [86, 144], "capacit": [86, 144], "ion": [86, 136, 146, 170], "revert": 86, "insul": 86, "capacitor": 86, "resistor": 86, "millivolt": 86, "megaohm": 86, "w1d1_t3": 87, "plot_pmf": 87, "isi_rang": 87, "pmf_": 87, "steinmetz_spik": 87, "_why_models_video": 87, "consum": [87, 146], "deplet": 87, "replenish": 87, "downstream": [87, 131, 145], "shannon": 87, "h_b": 87, "log_b": [87, 173], "nat": 87, "subdivid": 87, "concentr": [87, 195], "log2": [87, 196], "nan": [87, 124, 144, 189], "convent": [87, 123, 172], "exclud": [87, 99], "2f": [87, 94, 95, 96, 97, 121, 124, 135, 137, 138, 144, 145, 161, 179, 180, 187, 196, 197, 198], "_optimization_and_information_exercis": 87, "log_2": 87, "regardless": [87, 122, 161, 188], "likewis": [87, 136], "taller": 87, "certainti": [87, 186], "h_2": 87, "_entropy_of_different_distributions_video": 87, "nervou": 87, "budget": 87, "expenditur": 87, "mean_isi": 87, "025": [87, 101, 124, 147], "mean_idx": 87, "searchsort": 87, "pmf_singl": 87, "pmf_uniform": 87, "pmf_exp": 87, "dist": 87, "_probabilities_from_histogram_video": 87, "n_i": 87, "nolimits_": 87, "taken": [87, 121, 123, 145, 153, 172, 179, 180, 184, 187, 188, 189], "pmf_from_count": 87, "_probability_mass_function_exercis": 87, "_calculating_entropy_from_pmf_video": 87, "_pmf_from_count": 87, "_entropi": 87, "steinmetz_pmf": 87, "_entropy_of_neurons_interactive_demo": 87, "_reflecting_on_why_models_discuss": 87, "_summary_of_model_types_video": 87, "congratul": [87, 144, 146, 154, 163, 186], "discov": [87, 117, 122, 124, 172, 179], "closest": [87, 103, 123, 163], "exhibit": [87, 154], "1948": 87, "claud": 87, "began": 87, "subdivis": 87, "i_b": 87, "unsurpris": 87, "prefer": [88, 99, 106, 124, 187], "w1d1_t4": 88, "favorit": [88, 103, 112], "_model_discussions_discuss": 88, "palminteri": 90, "wyart": 90, "koechlin": 90, "falsif": 90, "425": 90, "433": 90, "079798": 90, "bishop": [90, 171, 172], "nasrabadi": 90, "738": 90, "york": [90, 157, 172, 191], "springer": [90, 157, 191], "microsoft": 90, "en": 90, "cmbishop": 90, "mackai": [90, 157], "itprnn": [90, 157], "arlot": 90, "celiss": 90, "1214": 90, "ss054": 90, "acerbi": 90, "lacerbi": 90, "boyd": [90, 97, 105, 180], "vandenbergh": [90, 97, 105], "convex": [90, 94, 95, 103, 105, 121, 173], "stanford": [90, 105, 186], "cvxbook": 90, "motor": [90, 131, 163, 175, 177], "101": [90, 131, 170, 173], "655": 90, "664": 90, "90545": 90, "w1d2_daysummari": 91, "confront": 92, "systemat": [92, 127, 131, 138, 145, 196], "bread": 92, "butter": 92, "zoo": 92, "embodi": [92, 163], "assess": [92, 96, 99, 110, 117, 140], "t2": [92, 103], "w1d2_intro": 92, "w1d2_outro": 93, "pierr": [94, 95, 96, 97, 98, 99, 105, 106], "\u00e9tienn": [94, 95, 96, 97, 98, 99], "fiquet": [94, 95, 96, 97, 98, 99, 105, 106], "anqi": [94, 95, 96, 97, 98, 99, 103], "wu": [94, 95, 96, 97, 98, 99, 165, 179, 180], "hyafil": [94, 95, 96, 97, 98, 99], "lina": [94, 95, 96, 97, 98, 99], "teichmann": [94, 95, 96, 97, 98, 99], "saeed": [94, 96, 97, 161, 162, 163, 179, 180], "salehi": [94, 96, 97, 161, 162, 163, 179, 180], "patrick": [94, 95, 96, 97, 98, 99], "mineault": [94, 95, 96, 97, 98, 99], "bootstrap": [94, 95, 97, 98, 99], "polynomi": [94, 95, 96, 98, 99], "trade": [94, 95, 96, 97, 99, 117, 169, 172, 188], "thank": [94, 97, 105], "eero": 94, "simoncelli": [94, 101, 131], "mathtool": 94, "w1d2_t1": 94, "plot_observed_vs_predict": 94, "y_hat": [94, 96, 97, 98, 99], "theta_hat": [94, 95, 96, 97, 98, 99], "residu": [94, 97, 98, 99, 117, 121], "_mean_squared_error_video": 94, "old": [94, 103, 138], "ls": [94, 144, 146, 147, 154, 162, 163, 169, 179], "suppos": [94, 173, 180, 197, 198], "explanatori": 94, "corrupt": [94, 105, 106, 114, 121, 122, 123, 124, 172], "epsilon_": 94, "synthet": [94, 96, 138, 163], "luxuri": [94, 96], "psuedorandom": [94, 95, 96, 97], "randn": [94, 95, 96, 97, 98, 99, 144, 145, 146, 153, 155, 171, 180, 195], "_compute_mse_exercis": 94, "lowest": [94, 99], "plot_data_estim": 94, "_mse_explorer_interactive_demo_discuss": 94, "landscap": [94, 117, 121], "textrm": [94, 95, 105, 106, 161, 162, 169], "theta_hat_grid": 94, "best_error": 94, "argmin": [94, 123, 162, 163, 180], "theta_": [94, 154, 155], "candid": [94, 169, 172, 179, 189], "solve_normal_eqn": [94, 96], "_solve_for_the_optimal_estimator_exercis": 94, "y_i": [94, 95, 96, 97, 99, 106], "2x_i": [94, 96], "waskomli": 95, "incorpor": [95, 97, 99, 121, 123, 124, 131, 136, 138, 146, 170, 187, 189], "w1d2_t2": 95, "plot_density_imag": 95, "xmin": 95, "wistia": [95, 161], "_maximum_likelihood_estimation_video": 95, "treat": [95, 119, 123, 124, 153, 198], "nuisanc": 95, "plot_normal_dist": 95, "_gaussian_distribution_explorer_interactive_demo_and_discuss": 95, "pair": [95, 103, 108, 115, 121, 123, 124, 138, 145, 147, 154, 155, 161, 162, 186, 188, 189, 195, 198], "invok": [95, 96, 97, 106, 121, 124, 195, 196], "get_ylim": [95, 96, 124, 170, 171, 173], "inher": [95, 172], "11344443599846923": 95, "_likelihood_function_exercis": 95, "joint": [95, 112, 113, 146, 161, 162, 173], "y_n": 95, "arithmet": 95, "underflow": 95, "circumv": 95, "routin": [95, 97, 151, 189], "likelihhood": 95, "remark": [95, 114], "theta_hat_ml": 95, "gaug": 96, "w1d2_t3": 96, "plot_original_and_resampl": 96, "get_xlim": [96, 124, 173], "haven": [96, 99], "_confidence_intervals_and_bootstrapping_video": 96, "bradlei": 96, "efron": 96, "epsilon_i": 96, "resample_with_replac": 96, "sample_idx": 96, "_resample_dataset_with_replacement_exercis": 96, "thata_hat": 96, "bootstrap_estim": 96, "123": [96, 154, 175], "27550888": 96, "17317819": 96, "18198819": 96, "25329255": 96, "20714664": 96, "_bootsrap_estimates_exercis": 96, "get_legend_handles_label": 96, "set_alpha": 96, "uncertain": 96, "ci": 96, "reassur": 96, "ag": 96, "trevor": 96, "hasti": [96, 98, 169], "w1d2_t4": 97, "evaluate_fit": 97, "order_list": [97, 99], "mse_list": 97, "plot_fitted_polynomi": 97, "x_grid": 97, "max_ord": [97, 98, 99], "x_design": [97, 98, 99], "univari": 97, "regressor": [97, 105, 197, 198], "theta_0": 97, "theta_1": 97, "theta_2": 97, "theta_d": 97, "x_d": 97, "boldsymbol": [97, 105], "ol": 97, "_multiple_linear_regression_and_polynomial_regression_video": 97, "ganglion": [97, 101, 117], "light": [97, 121, 123, 163, 172, 189], "1234": 97, "n_regressor": [97, 98, 99], "ordinary_least_squar": [97, 98, 99], "13861386": 97, "09395731": 97, "16370742": 97, "_ordinary_least_squares_estimator_exercis": 97, "mgrid": [97, 162], "50j": 97, "y_hat_grid": 97, "theta_3": 97, "theta_4": 97, "output_nois": 97, "input_nois": 97, "ldot": [97, 121, 123, 124], "_m": 97, "broadcast": [97, 98, 99], "design_matrix": [97, 98, 99], "51194917": 97, "35259945": 97, "solve_poly_reg": [97, 98, 99], "this_theta": [97, 98, 99], "lapack": 97, "stephen": [97, 105, 131, 180], "lieven": [97, 105], "w1d2_t5": 98, "plot_mse_poly_fit": 98, "mse_train": 98, "mse_test": 98, "held": [98, 99, 121], "_bias_variance_tradeoff_video": 98, "n_train_sampl": [98, 99], "n_test_sampl": [98, 99], "overli": [98, 191], "underfit": [98, 99], "overfit": [98, 99, 103, 121, 124, 138], "fortmann": 98, "roe": 98, "biasvari": 98, "metric": [98, 115, 123, 191, 195], "t4": 98, "port": 98, "evaluate_poly_reg": [98, 99], "evalute_poly_reg": 98, "compute_ms": 98, "_compute_train_vs_test_error_exercis": 98, "strike": 98, "modern": 98, "tibshirani": 98, "friedman": [98, 195, 196, 197, 198], "_proof_bias_variance_for_mse_bonus_exercis": 98, "w1d2_t6": 99, "kfold": 99, "plot_cross_validate_ms": 99, "mse_al": 99, "k_fold": 99, "n_split": 99, "plot_aic": 99, "aic_list": 99, "_crossvalidation_video": 99, "commonli": [99, 106, 121, 123, 124, 137, 162], "hasn": [99, 106, 187], "reassign": 99, "fold": [99, 106, 117], "divis": [99, 123], "sacrif": 99, "preciou": 99, "consensu": 99, "former": 99, "cross_valid": 99, "wrongli": 99, "kfold_iter": 99, "i_split": 99, "train_indic": 99, "val_indic": 99, "x_cv_train": 99, "y_cv_train": 99, "x_cv_val": 99, "y_cv_val": 99, "mse_this_split": 99, "_implement_cross_validation_exercis": 99, "strive": 99, "2k": 99, "plug": [99, 106, 121, 153], "cancel": [99, 145, 169], "sse": 99, "this_aic": 99, "_compute_aic_bonus_exercis": 99, "gerwinn": 101, "bethg": [101, 117], "mack": [101, 105, 106], "seeger": 101, "neurip": 101, "cc": [101, 117, 145, 165], "hash": [101, 117, 165], "46ba9f2a6976570b0353203ec4474217": 101, "glaser": 101, "farhoodi": [101, 121, 122, 123, 124, 179, 180], "supervis": [101, 105, 106, 117], "neurobiolog": [101, 108, 140, 182], "175": 101, "126": 101, "137": [101, 145], "pneurobio": 101, "pmc8454059": 101, "chowdhuri": 101, "perich": 101, "0506": 101, "hardcastl": 101, "maheswaranathan": [101, 117], "ganguli": [101, 117, 131], "giocomo": 101, "multiplex": 101, "heterogen": 101, "medial": 101, "entorhin": 101, "375": 101, "latim": [101, 165], "riek": 101, "pillow": [101, 105, 131, 165], "e47012": 101, "47012": 101, "bues": 101, "cunningham": [101, 108, 131], "yu": [101, 108, 110, 131], "shenoi": [101, 131], "sahani": [101, 131], "nip": [101, 117, 165], "7143d7fbadfa4693b9eec507d9d37443": 101, "kastner": 101, "baccu": [101, 117], "multilay": [101, 117], "e1006291": 101, "1006291": 101, "mccullagh": 101, "nelder": 101, "1989": [101, 169, 186, 188], "chapman": [101, 157], "hall": [101, 157], "london": 101, "mcfarland": 101, "cui": 101, "butt": 101, "e1003143": 101, "1003143": 101, "paninski": [101, 117, 131, 140, 149], "cascad": 101, "243": 101, "0954": 101, "898x": 101, "panzeri": 101, "piasini": 101, "latham": 101, "fellin": 101, "crack": 101, "intervent": [101, 191, 196, 198], "491": [101, 157, 191], "507": 101, "036": 101, "park": [101, 103], "covari": [101, 103, 112, 114, 117, 145, 171, 172, 180, 197, 198], "6395ebd0f4b478145ecfbaf939454fa4": 101, "e1002219": 101, "1002219": 101, "meister": 101, "huk": [101, 165, 169], "pariet": 101, "sensorimotor": [101, 108], "1395": 101, "1403": 101, "3800": 101, "pmc4176983": 101, "uzzel": [101, 105], "chichilniski": [101, 105, 131], "11003": 101, "11013": 101, "jneurosci": [101, 117, 140, 145, 149, 175], "3305": 101, "shlen": [101, 108, 131], "sher": [101, 117, 131], "litk": [101, 117, 131], "spatio": [101, 117, 131], "454": [101, 131], "7207": [101, 131], "995": [101, 131], "nature07140": [101, 131], "pmc2684455": [101, 131], "b55ec28c52d5f6205684a473a2193564": 101, "1404": [101, 108], "schwartz": 101, "327": 101, "gazzaniga": 101, "iii": 101, "stevenson": 101, "obi": [101, 108], "sach": 101, "reimer": 101, "englitz": 101, "e1002775": 101, "1002775": 101, "truccolo": 101, "eden": [101, 157, 191], "fellow": 101, "donoghu": [101, 165], "extrins": [101, 114], "1074": 101, "1089": [101, 175], "00697": 101, "vidn": 101, "ahmadian": [101, 149], "s10827": 101, "0376": 101, "pmc3560841": 101, "weber": 101, "repertoir": [101, 142], "3260": 101, "3289": 101, "1162": [101, 117, 149], "neco_a_01021": 101, "1602": 101, "07389": 101, "zhao": 101, "iyengar": 101, "nonconverg": 101, "1231": 101, "1244": 101, "neco": 101, "982": 101, "w1d3_daysummari": 102, "unifi": [103, 140, 149, 171, 172], "swiss": 103, "armi": 103, "knife": 103, "intent": 103, "spot": [103, 138, 195], "protect": 103, "l1": [103, 106, 124], "reverend": 103, "christina": 103, "savin": [103, 172], "canon": [103, 186], "she": [103, 142, 146, 151], "qu": 103, "assist": 103, "prof": 103, "georgia": 103, "tech": 103, "mem": [103, 146], "cat": [103, 122, 177, 180], "he": [103, 110, 117, 129, 138, 142, 151], "danger": [103, 162, 179, 180, 189], "touch": [103, 121], "readout": [103, 145], "w1d3_intro": 103, "_day_intro": 103, "w1d3_outro": 104, "_day_outro": 104, "etienn": [105, 106], "ari": [105, 106, 195, 196, 197, 198], "jakob": [105, 106], "david": [105, 106, 157], "valeriani": [105, 106], "alish": [105, 106], "dipani": [105, 106], "ej": 105, "permiss": 105, "jonathan": 105, "w1d3_t1": 105, "loadmat": 105, "plot_stim_and_spik": 105, "stim": [105, 172], "intens": 105, "ax_stim": 105, "ax_spik": 105, "nrow": [105, 186, 188, 189], "plot_glm_matric": 105, "boundarynorm": 105, "axes_grid1": [105, 195, 198], "make_axes_locat": [105, 195, 198], "skinni": 105, "ax_x": [105, 161, 162], "ax_i": [105, 161, 162], "gridspec_kw": [105, 186], "imx": 105, "pcolormesh": 105, "setp": 105, "visibl": [105, 146, 157], "divx": 105, "caxx": 105, "append_ax": [105, 195, 198], "cbarx": 105, "cax": [105, 121, 122, 124, 195, 198], "set_tick": 105, "set_ticklabel": 105, "imi": 105, "magma": 105, "invert_yaxi": [105, 163], "divi": 105, "caxi": 105, "cbari": 105, "plot_spike_filt": 105, "gca": [105, 122, 123, 124, 173, 195, 196, 197], "axhlin": [105, 106, 144, 146, 163, 186], "plot_spikes_with_predict": 105, "predicted_spik": 105, "t0": [105, 135], "stem": [105, 106, 186], "set_zord": [105, 124], "setdefault": [105, 153], "yhat": 105, "maxnloc": 105, "hashlib": [105, 106, 121, 122, 123, 124, 172], "fname": [105, 106, 121, 122, 123, 124, 172], "rgcdata": 105, "mat": [105, 106], "mzuj": 105, "expected_md5": [105, 106, 121, 122, 123, 124, 172], "1b2977453020bce5319f2608c94d38d0": 105, "connectionerror": [105, 106, 121, 122, 123, 124, 172], "md5": [105, 106, 121, 122, 123, 124, 172], "hexdigest": [105, 106, 121, 122, 123, 124, 172], "wb": [105, 106, 121, 122, 123, 124, 172], "fid": [105, 106, 121, 122, 123, 124, 172], "_linear_gaussian_model_video": 105, "lumin": 105, "rgc": 105, "flicker": 105, "120hz": 105, "144051": 105, "spcount": 105, "dtstim": 105, "dt_stim": 105, "cellnum": 105, "keep_timepoint": 105, "ij": [105, 113, 122, 123, 124, 145, 170, 173, 195], "onset": 105, "padded_stim": 105, "_create_design_matrix_exercis": 105, "augment": 105, "column_stack": [105, 112, 113], "lg": 105, "theta_lg": 105, "predict_spike_counts_lg": 105, "predicted_count": 105, "_predict_counts_with_linear_gaussian_model_exercis": 105, "bump": [105, 162], "troublingli": 105, "failur": [105, 197], "subcas": 105, "sta": 105, "statement": [105, 179, 195, 198], "_bonus_challenge_act": 105, "_generalized_linear_model_video": 105, "unfortun": [105, 161, 198], "stuck": [105, 187], "chord": 105, "4g": 105, "566e": 105, "88846e": 105, "bear": 105, "emphasi": 105, "moment": [105, 131, 136, 146, 186, 189], "start_point": 105, "mew": 105, "lnp": 105, "mid": [105, 163, 170, 195, 197], "sum_t": [105, 179], "y_t": [105, 172, 173, 198], "x_t": [105, 170, 173, 195, 196], "lambda_t": 105, "neg_log_lik_lnp": 105, "loglik": 105, "log_lik": 105, "fit_lnp": 105, "theta_lnp": 105, "59": [105, 124, 169, 188, 189, 196], "_fitting_the_poisson_glm_exercis": 105, "broadli": [105, 184, 186], "predict_spike_counts_lnp": 105, "_predict_spike_counts_exercis": 105, "_predict_spike_counts_bonu": 105, "oftentim": 106, "awak": [106, 119], "asleep": 106, "car": 106, "bu": 106, "choi": 106, "hyperparamet": [106, 121, 186, 197, 198], "w1d3_t2": 106, "plot_weight": [106, 122, 124], "atleast_1d": [106, 153], "set_mark": 106, "c3": 106, "plot_model_select": 106, "c_valu": 106, "set_xscal": 106, "best_c": 106, "1g": 106, "plot_non_zero_coef": 106, "non_zero_l1": 106, "n_voxel": 106, "r9gh8": 106, "w1d4_steinmetz_data": 106, "npz": [106, 121, 122, 123, 124, 172], "d19716354fed0981267456b80db07ea8": 106, "load_steinmetz_data": 106, "data_fnam": [106, 172], "dobj": [106, 121, 122, 123, 124, 172], "_logistic_regression_video": 106, "coinflip": 106, "squash": [106, 123, 195], "Its": [106, 123, 162], "_implement_the_sigmoid_function_exercis": 106, "wheel": 106, "gabor": [106, 122, 123, 124], "kordinglab": 106, "nogo": 106, "n_trial": [106, 145, 173, 186, 187, 196, 197, 198], "0s": [106, 195], "1s": [106, 195], "276": 106, "691": 106, "n_featur": [106, 115], "log_reg": 106, "rerun": [106, 115, 124], "trust": [106, 115], "unabl": [106, 115, 155, 197], "nbviewer": [106, 115], "logisticregressionifittedlogisticregress": 106, "score": [106, 113, 114, 115, 117, 121, 122, 124, 129], "compute_accuraci": 106, "train_accuraci": 106, "_classifier_accuracy_video": 106, "idiosyncrat": 106, "justcv": 106, "brief": [106, 155, 196, 199], "tini": 106, "_regularization_video": [106, 124], "priori": 106, "idiosyncrasi": 106, "ridg": 106, "beta2": 106, "theta_i": [106, 154, 155], "unregular": 106, "log_reg_l2": 106, "log_c_step": 106, "penalized_model": 106, "log_c": 106, "max_it": [106, 197, 198], "5000": [106, 136, 137, 186, 195, 196, 197, 198], "plot_observ": [106, 197, 198], "frac1": 106, "lasso": [106, 198], "log_reg_l1": 106, "ugli": [106, 182], "warn": [106, 124, 161, 162, 179, 186], "spars": [106, 115, 149, 195, 196, 197, 198], "unpack": 106, "dens": 106, "m_spars": 106, "text_kw": 106, "iter_part": 106, "1f": [106, 112, 113, 137, 138, 144, 147, 153, 155], "count_non_zero_coef": 106, "non_zero_coef": 106, "coef": 106, "non_zero": 106, "logspac": [106, 169], "_effect_of_l1_on_sparsity_exercis": 106, "bigger": [106, 121, 196], "sparser": [106, 124], "thalamu": 106, "carri": [106, 113, 121, 186], "scheme": [106, 123, 135, 144, 147], "acc": 106, "_model_selection_exercis": 106, "poorli": [106, 115, 121, 198], "risk": [106, 117, 161, 187, 189], "ny_i": 106, "fresh": [106, 171], "proper": [106, 155, 199], "1708": 106, "00909": 106, "1100": 108, "hyvarinen": 108, "oja": 108, "411": 108, "430": [108, 149], "s0893": 108, "6080": 108, "00026": 108, "cse": 108, "msu": 108, "cse902": 108, "s03": 108, "icasurvei": 108, "gilli": 108, "nonneg": 108, "1401": 108, "5226": 108, "coenen": 108, "pearc": 108, "wattenberg": [108, 115], "viega": 108, "johnson": [108, 131], "distil": [108, 115, 117], "23915": [108, 117], "00002": 108, "1500": 108, "1509": 108, "3776": 108, "pmc4433019": 108, "golub": [108, 131], "chase": [108, 162], "batista": 108, "dissect": [108, 117], "opinion": [108, 140, 182], "58": [108, 124, 144, 188, 196, 198], "conb": [108, 140, 182], "sadtler": 108, "ryu": [108, 131], "tyler": 108, "kabara": 108, "reassoci": 108, "607": 108, "s41593": [108, 117, 182], "0095": 108, "pmc5876156": 108, "512": 108, "7515": 108, "423": 108, "426": 108, "nature13665": 108, "pmc4393644": 108, "w1d4_daysummari": 109, "orthonorm": [110, 113, 114], "constantli": [110, 153, 180], "w1d4_intro": 110, "_intro": [110, 119], "w1d4_outro": 111, "_outro": 111, "cayco": [112, 113, 114, 115], "gajic": [112, 113, 114, 115], "roozbeh": [112, 113, 114, 115, 121, 122, 123, 124, 179, 180], "farhoudi": [112, 113, 114, 115], "kraus": [112, 113, 114, 115, 135, 136, 137, 138, 144, 145, 146, 147, 163, 169, 170, 172, 173, 179, 180, 186, 187, 188, 189], "w1d4_t1": 112, "plot_data": [112, 113], "bivari": [112, 113, 198], "add_gridspec": [112, 113], "markerfacecolor": [112, 113], "markeredgewidth": [112, 113, 145, 146, 147], "corr": [112, 113, 145, 161, 162, 195, 196, 197, 198], "corrcoef": [112, 113, 123, 195, 196, 197, 198], "plot_basis_vector": [112, 113], "plot_data_new_basi": [112, 113], "ascend": [112, 113], "_geometric_view_of_data_video": 112, "mu_i": [112, 145, 162], "sigma_i": [112, 145, 162], "rho": [112, 161, 162, 180], "cov": [112, 113, 123, 145, 161, 171, 172, 180, 198], "bf": [112, 113, 114, 135, 180], "pmatrix": [112, 170], "diagon": [112, 123, 173], "_multivariate_data_video": 112, "get_data": [112, 113, 121, 124], "cov_matrix": [112, 113, 114], "multivariate_norm": [112, 113, 162, 172, 195, 196, 197, 198], "indices_for_sort": [112, 113], "argsort": [112, 113, 114, 124], "calculate_cov_matrix": [112, 113], "var_1": [112, 113], "var_2": [112, 113], "corr_coef": [112, 113, 123], "variance_1": [112, 113], "variance_2": [112, 113], "_draw_samples_from_a_distribution_exercis": 112, "cloud": 112, "_calculate_cov_matrix": 112, "visualize_correlated_data": 112, "_correlation_effect_on_data_interactive_demo_and_discuss": 112, "_orthonormal_bases_video": 112, "u_1": 112, "u_2": 112, "w_2": 112, "orthogon": [112, 113, 114], "define_orthonormal_basi": [112, 113], "orthonom": 112, "_find_an_orthonormal_basis_exercis": 112, "_change_of_basis_video": 112, "change_of_basi": [112, 113, 114], "_change_to_orthonormal_basis_exercis": 112, "uncorrel": [112, 113, 147, 198], "tan": 112, "_play_with_basis_vectors_interactive_demo_and_discuss": 112, "mixtur": [112, 146], "decorrel": 112, "beautifulli": [113, 191], "w1d4_t2": 113, "plot_eigenvalu": [113, 114], "scree": 113, "sort_evals_descend": [113, 114], "evector": [113, 114], "_pca_video": 113, "sigma_": [113, 144, 145, 153, 161, 162, 163, 171], "x_j": 113, "n_": 113, "_j": 113, "get_sample_cov_matrix": [113, 114], "sample_cov_matrix": 113, "99315313": 113, "82347589": 113, "01281397": 113, "_calculate_the_covariance_matrix_exercis": 113, "eigh": [113, 114], "descend": [113, 121], "_eigenvectors_of_the_covariance_matrix_exercis": 113, "_pca_implementation_exercis": 113, "_exploration_of_the_correlation_coefficient_interactive_demo_and_discuss": 113, "lose": [113, 161], "_properties_of_pca_bonus_video": 113, "w1d4_t3": 114, "plot_variance_explain": 114, "variance_explain": 114, "plot_mnist_reconstruct": 114, "x_reconstruct": 114, "keep_dim": 114, "tick_param": [114, 171, 173, 179, 195, 196], "labelbottom": 114, "clim": [114, 115], "plot_mnist_sampl": 114, "plot_mnist_weight": 114, "seismic": 114, "add_nois": 114, "frac_noisy_pixel": 114, "x_noisi": 114, "n_noise_ix": 114, "noise_ix": 114, "_pca_for_dimensionality_reduction_video": 114, "unravel": 114, "nine": 114, "parser": [114, 115], "elbow": 114, "_scree_plot_of_mnist_exercis": 114, "lambda_i": [114, 173], "get_variance_explain": 114, "csum": 114, "_plot_the_explained_variance_exercis": 114, "_data_reconstruction_video": 114, "reconstruct_data": 114, "x_mean": 114, "_data_reconstruction_exercis": 114, "_reconstruct_the_data_matrix_using_different_numbers_of_pcs_interactive_demo_and_discuss": 114, "100th": 114, "500th": 114, "700th": 114, "_visualization_of_the_weights_exercis": 114, "inflat": 114, "implic": [114, 146], "salt": 114, "pepper": 114, "score_noisi": 114, "evectors_noisi": 114, "evals_noisi": 114, "variance_explained_noisi": 114, "_add_noise_to_the_data_bonus_exercis": 114, "x_noisy_mean": 114, "projx_noisi": 114, "_denoising_bonus_exercis": 114, "w1d4_t4": 115, "visualize_compon": 115, "component1": 115, "component2": 115, "_pca_applications_video": 115, "reload": 115, "x_all": 115, "labels_al": 115, "pca_model": 115, "pcaifittedpca": 115, "_base": 115, "_pca": 115, "x_new": 115, "_visualization_of_mnist_in_2d_using_pca_exercis": 115, "overlap": [115, 123, 187, 191], "_pca_visualization_discuss": 115, "_nonlinear_methods_video": 115, "manifold": [115, 123], "tsne_model": 115, "fit_transform": [115, 123], "_t_sne": 115, "csr": 115, "csc": 115, "coo": 115, "barnes_hut": 115, "emb": 115, "_apply_tsne_on_mnist_exercis": 115, "explore_perplex": 115, "perp": 115, "redefin": 115, "_run_tsne_with_different_perplexities_exercis": 115, "_tsne_visualization_discuss": 115, "openreview": 117, "id": [117, 145, 147, 172], "bjjsrmfcz": 117, "lillicrap": 117, "beaudoin": 117, "bogacz": 117, "christensen": 117, "1761": [117, 121, 124], "1770": 117, "0520": 117, "ncbi": [117, 131, 175], "nlm": [117, 131, 175], "nih": [117, 131, 175], "gov": [117, 131, 175], "pmc": [117, 131, 175], "pmc7115933": 117, "convolut": [117, 119], "2031": 117, "jocn_a_01544": 117, "07092": 117, "dnn": 117, "khosla": [117, 170, 173], "torralba": 117, "hierarch": [117, 122], "srep27755": 117, "hasson": 117, "nastas": 117, "evolutionari": 117, "105": [117, 131, 154], "416": 117, "434": 117, "heuer": 117, "gulban": 117, "bazin": 117, "osoianu": 117, "valabregu": 117, "santin": 117, "toro": 117, "neocort": [117, 140, 144, 146], "phylogenet": 117, "primat": [117, 122, 131], "speci": [117, 169], "04": [117, 149, 165, 197, 198], "zhou": 117, "lapedriza": 117, "detector": 117, "cnn": 117, "iclr": 117, "san": 117, "diego": 117, "ca": 117, "usa": 117, "1412": 117, "6856": 117, "bau": 117, "ieee": [117, 131, 175], "transact": [117, 131, 175], "2131": 117, "2145": 117, "1109": [117, 131, 175], "tpami": 117, "2858759": 117, "stringer": [117, 121, 122, 123, 124], "e15": 117, "679324": 117, "merel": 117, "brackbil": 117, "heitman": 117, "recurr": [117, 131, 155], "toulon": 117, "franc": 117, "hkei22jeg": 117, "cadena": 117, "denfield": 117, "walker": [117, 188], "gati": 117, "tolia": 117, "ecker": 117, "macaqu": 117, "e1006897": 117, "1006897": 117, "mcintosh": 117, "nayebi": 117, "a1d33d0dfec820b41b54430b50e96b5c": 117, "sinz": 117, "cobo": 117, "muhammad": 117, "froudaraki": 117, "fahei": 117, "incept": 117, "2060": 117, "2065": 117, "0517": 117, "guclu": 117, "gerven": 117, "stream": [117, 167, 172, 187], "10005": 117, "10014": 117, "5023": 117, "khaligh": 117, "razavi": 117, "unsupervis": [117, 131, 145, 147], "IT": [117, 122], "e1003915": 117, "1003915": 117, "mohsenzadeh": [117, 123], "mullin": 117, "lahner": 117, "peripheri": 117, "s41598": 117, "020": 117, "61409": 117, "yamin": 117, "hong": 117, "cadieu": 117, "solomon": 117, "seibert": 117, "dicarlo": 117, "8619": 117, "8624": 117, "1403112111": 117, "pmc4060707": 117, "goh": 117, "e6": 117, "00006": 117, "ren": 117, "770": 117, "778": 117, "ieeexplor": 117, "stamp": 117, "jsp": 117, "arnumb": 117, "7780459": 117, "ioff": 117, "szegedi": 117, "448": [117, 145], "456": 117, "pmlr": 117, "mlr": 117, "v37": 117, "ioffe15": 117, "xu": [117, 175], "taylor": 117, "studer": 117, "a41b3bb3e6b050b6c9067c67f663b915": 117, "neuralnetworksanddeeplearn": 117, "chap4": 117, "olah": 117, "conv": [117, 122, 123, 124, 188, 189], "modular": 117, "colah": 117, "jozwik": 117, "storr": 117, "outperform": 117, "1726": [117, 149], "fpsyg": 117, "01726": 117, "dougla": 117, "1148": 117, "1160": 117, "0210": 117, "pmc6706072": 117, "kietzmann": 117, "spoerer": 117, "s\u00f6rensen": 117, "hauk": 117, "116": [117, 131, 140], "21854": 117, "21863": 117, "1905544116": 117, "kubiliu": 117, "schrimpf": 117, "kar": 117, "rajalingham": 117, "majaj": 117, "nips2019": 117, "santoro": 117, "marri": 117, "akerman": 117, "hinton": 117, "335": 117, "0277": 117, "ora": 117, "ox": 117, "ac": 117, "uuid": 117, "862189c1": 117, "0088": 117, "4f78": 117, "b17a": 117, "2748c2019209": 117, "download_fil": 117, "safe_filenam": 117, "lillicrap_v6_2020": 117, "file_format": 117, "type_of_work": 117, "nili": 117, "wingfield": 117, "walther": 117, "su": 117, "marslen": 117, "e1003553": 117, "1003553": 117, "issa": 117, "407007": 117, "mehrer": 117, "charest": 117, "e1008215": 117, "1008215": 117, "inferior": 117, "2044": 117, "2064": 117, "jocn_a_01755": 117, "ubn": 117, "ru": 117, "nl": 117, "bitstream": [117, 191], "2066": 117, "237374": 117, "tang": 117, "lotter": 117, "moerman": 117, "pared": 117, "caro": 117, "kreiman": 117, "8835": 117, "8840": 117, "1719397115": 117, "chamber": 117, "seethapathi": 117, "saluja": 117, "loeb": 117, "pierc": 117, "bogen": 117, "infant": [117, 119, 198], "neuromotor": 117, "rehabilit": 117, "2431": 117, "2442": 117, "tnsre": 117, "3029121": 117, "pmc8011647": 117, "w1d5_daysummari": 118, "aud": [119, 122], "propag": [119, 121, 142, 170, 172], "caveat": 119, "taskonomi": 119, "reward": [119, 182, 184, 188, 189], "w1d5_intro": 119, "w1d5_outro": 120, "_outro_video1": 120, "_outro_video2": 120, "jorg": [121, 122, 123, 124], "menendez": [121, 122, 123, 124], "carsen": [121, 122, 123, 124], "thrive": 121, "w1d5_t1": 121, "mpl": [121, 122, 123, 124, 163], "plot_data_matrix": [121, 124], "plot_train_loss": 121, "train_loss": [121, 124], "load_data": [121, 123, 124], "data_nam": [121, 122, 123, 124], "bin_width": [121, 123, 124], "679324v2": [121, 122, 123, 124], "calcium": [121, 122, 123, 124, 146, 173], "smoother": [121, 123, 124, 144, 172], "resp": [121, 123, 124], "n_stimuli": [121, 122, 123, 124], "mention": [121, 122, 123, 124, 144, 145, 146, 172, 173], "360": [121, 123, 124], "stimuli_bin": [121, 123, 124], "resp_bin": [121, 123, 124], "resp_tensor": [121, 123, 124], "stimuli_tensor": [121, 122, 123, 124], "unsqueez": [121, 122, 123, 124], "singleton": [121, 123, 124, 173], "n_stim": [121, 124], "train_data": [121, 123, 124], "train_label": [121, 123, 124], "radian": [121, 122, 123, 124], "istim": [121, 124], "ori": [121, 122, 123, 124], "w3d4_stringer_oribinned1": [121, 123, 124], "683xc": [121, 123, 124], "436599dfd8ebe6019f066c38aed20580": [121, 123, 124], "_decoding_from_neural_data_video": 121, "front": 121, "photon": 121, "thousand": 121, "24000": 121, "circ": [121, 124], "resp_al": [121, 124], "stimuli_al": [121, 124], "ineuron": [121, 123, 124], "stimuli_train": [121, 124], "resp_train": [121, 122, 124], "stimuli_test": [121, 124], "resp_test": [121, 122, 124], "ishuffl": [121, 123, 124], "randperm": [121, 123, 124], "itrain": [121, 124], "itest": [121, 124], "entail": 121, "r_n": 121, "infrastructur": 121, "deepnet": 121, "declar": [121, 122], "in_lay": [121, 124], "out_lay": [121, 124], "sent": [121, 188], "_nonlinear_activation_functions_video": 121, "relu": [121, 122, 123, 124, 153], "sole": 121, "tanh": [121, 153], "rectif": 121, "ctifi": 121, "inear": 121, "nit": 121, "nonsens": 121, "1751": [121, 124], "_wrapped_call_impl": [121, 124], "1749": [121, 124], "_compiled_call_impl": [121, 124], "misc": [121, 124], "1750": [121, 124], "_call_impl": [121, 124], "1762": [121, 124], "1757": [121, 124], "hook": [121, 123, 124], "1758": [121, 124], "1759": [121, 124], "_backward_hook": [121, 124], "_backward_pre_hook": [121, 124], "_forward_hook": [121, 124], "_forward_pre_hook": [121, 124], "1760": [121, 124], "_global_backward_pre_hook": [121, 124], "_global_backward_hook": [121, 124], "_global_forward_hook": [121, 124], "_global_forward_pre_hook": [121, 124], "forward_cal": [121, 124], "1764": [121, 124], "1765": [121, 124], "called_always_called_hook": [121, 124], "139": 121, "_nonlinear_activations_exercis": 121, "_loss_functions_and_gradient_descent_video": 121, "nowher": 121, "shortli": [121, 122, 147, 186], "y_p": 121, "42949": 121, "dw": [121, 147], "accordingli": [121, 124, 137, 146, 155], "realiti": 121, "rocki": 121, "gif": [121, 122], "blob": 121, "grad_desc": 121, "lr": [121, 123, 124], "blank": 121, "learning_r": [121, 123, 124], "67": [121, 124, 170, 179, 180, 189], "_gradient_descent_in_pytorch_exercis": 121, "wrote": [121, 123, 124, 196], "monkei": [121, 169, 173], "xor": [121, 179], "drastic": 121, "neat": 121, "truli": [121, 138, 188], "said": [121, 122, 136], "prone": 121, "rescu": 121, "leftarrow": [121, 186, 187, 188, 198], "minima": [121, 163, 187], "odot": [121, 163], "prime": 121, "hadamard": [121, 163], "elementwis": [121, 170], "infeas": [121, 173, 198], "bypass": 121, "demand": 121, "subsampl": [121, 197], "induc": [121, 146, 147, 196], "whatev": 121, "suffic": 121, "w1d5_t2": 122, "show_stimulu": [122, 123], "img": [122, 123, 172], "conv_channel": [122, 124], "wmax": [122, 124], "cb_ax": 122, "add_ax": [122, 124, 161, 162], "plot_example_activ": 122, "load_data_split": [122, 124], "imaging": [122, 123, 124], "resp_train_tensor": [122, 124], "resp_test_tensor": [122, 124], "out_channel": [122, 123, 124], "wide_gaussian": [122, 123, 124], "center_surround": [122, 123, 124], "lam": [122, 123, 124, 135, 136, 137, 138], "newaxi": [122, 123, 124, 138, 173, 188, 189], "640": [122, 123, 124], "480": [122, 123, 124], "deg2rad": [122, 123, 124], "wpix": [122, 123, 124], "hpix": [122, 123, 124], "xcent": [122, 123, 124], "ycent": [122, 123, 124], "xxc": [122, 123, 124], "yyc": [122, 123, 124], "icirc": [122, 123, 124], "w3d4_stringer_oribinned6_split": [122, 124], "p3aeb": [122, 124], "b3f7245c6221234a676b71a1f43c3bb5": [122, 124], "slid": 122, "k_x": 122, "k_y": 122, "miro": 122, "medium": 122, "5bwzuqaqffp5f3wkyq6wjg": 122, "_2d_convolutions_video": 122, "revolution": 122, "alexnet": 122, "depict": 122, "downsampl": 122, "attach": [122, 123, 124, 171], "proxim": 122, "stride": [122, 124], "convolutionallay": 122, "conv2d": [122, 123, 124], "barrel": 122, "whisker": 122, "unsolv": 122, "advent": 122, "790": 122, "1okwhewf5kctipafib4xaa": 122, "counterpart": [122, 189], "substanti": [122, 155, 163, 172, 173], "versu": [122, 138, 170, 171, 173, 195], "n_col": [122, 123], "0f": [122, 123, 124], "c_in": [122, 123, 124, 145], "c_out": [122, 123, 124], "kernel_s": [122, 123, 124], "predesign": 122, "example_filt": [122, 124], "convout": 122, "in_channel": 122, "convlay": [122, 124], "h_in": [122, 123], "w_in": [122, 123, 124], "_2d_convolution_in_pytorch_exercis": 122, "_output_and_weight_shapes_conv_layer_discuss": 122, "vocabulari": 122, "teas": 122, "wherebi": [122, 123], "union": 122, "firstli": [122, 123], "mammalian": [122, 123], "mammal": 122, "secondli": [122, 123], "_visualizing_convolutional_filter_weights_bonus_exercis": 122, "_complex_cell_bonus_discuss": 122, "yalda": 123, "shed": 123, "rsa": 123, "w1d5_t3": 123, "zscore": 123, "plot_corr_matrix": 123, "plot_multiple_rdm": 123, "rdm_dict": 123, "resp_dict": 123, "plot_rdm_rdm_correl": 123, "rdm_sim": 123, "nwith": [123, 155], "plot_rdm_row": 123, "ori_list": 123, "rdm_ori": 123, "ori_plot": 123, "iori": 123, "nto": 123, "tilt": 123, "maxpool2d": 123, "fc": 123, "convolv": [123, 188, 189], "kpool": 123, "10d": 123, "0005": 123, "cf": 123, "appendix": [123, 172, 195], "minibatch_data": 123, "minibatch_label": 123, "2e": [123, 144], "get_hidden_act": 123, "layer_label": 123, "hidden_act": 123, "module_label": 123, "_modul": 123, "argwher": [123, 195], "register_forward_hook": 123, "children": 123, "pred": [123, 172], "_deep_convolutional_network_for_orientation_discrimination_video": 123, "conceiv": 123, "courtesi": 123, "10e": 123, "17e": 123, "32e": 123, "29e": 123, "08e": 123, "resp_v1": 123, "resp_model": 123, "aggreg": 123, "_quantitative_comparisons_of_cnns_and_neural_activity_video": 123, "zz": [123, 162], "zresp": 123, "dictcomp": 123, "_compute_rdms_exercis": 123, "_solution_discussion_video": 123, "m_": [123, 169, 170, 171, 172, 179], "ss": 123, "overcount": 123, "moreov": [123, 142, 151, 180], "correlate_rdm": 123, "rdm1": 123, "rdm2": 123, "ioffdiag": 123, "triu_indic": 123, "rdm1_offdiag": 123, "rdm2_offdiag": 123, "rdm_model": 123, "rdm_v1": 123, "pop": 123, "_correlate_rdms_exercis": 123, "55": [123, 144, 145, 146, 147, 161, 162, 169, 188, 189, 195, 198], "plot_resp_lowd": 123, "resp_lowd": 123, "twilight": 123, "_vizualizing_reduced_dimensionality_representations_discuss": 123, "fourier": 123, "convfc": [123, 124], "lfloor": 123, "rfloor": 123, "convpoolfc": 123, "neighbor": 123, "leftrightarrow": [123, 195], "gd": [123, 124], "gather": [123, 136, 179], "z_i": 123, "z_n": 123, "ddot": 123, "w1d5_t4_bonu": 124, "plot_decoded_result": 124, "test_loss": 124, "test_label": 124, "predicted_test_label": 124, "n_class": 124, "class_bin": 124, "visualize_weight": 124, "w_in_sort": 124, "w_out": 124, "visualize_hidden_unit": 124, "plot_tun": 124, "respi_train": 124, "respi_test": 124, "neuron_index": 124, "plot_predict": 124, "plot_training_curv": 124, "identitylin": 124, "lim": [124, 195, 196, 197], "minval": 124, "maxval": 124, "equal_lim": 124, "stimulus_class": 124, "accommod": 124, "regularized_mse_loss": 124, "l2_penalti": 124, "l1_penalti": 124, "scala": 124, "penalti": [124, 162], "cuda": 124, "is_avail": 124, "runtim": 124, "hardwar": 124, "12219": 124, "759": 124, "1672": 124, "731": 124, "548": 124, "097": 124, "235": [124, 153, 179], "619": [124, 135], "jump": [124, 135, 170, 188, 196], "obstacl": [124, 188], "23589": 124, "gaussian_filter1d": 124, "resp_smooth": 124, "preferred_orient": 124, "resort": 124, "isort": 124, "_visualizing_weights_exercis": 124, "b_in": 124, "_interpreting_weights_discuss": 124, "weren": 124, "axtick": 124, "_delving_into_error_problems_discuss": 124, "359": [124, 131], "2b": [124, 136, 171], "3b": 124, "p_c": 124, "softmax": 124, "troubl": 124, "logsoftmax": 124, "l_i": 124, "deepnetsoftmax": 124, "logprob": 124, "logp": 124, "nllloss": 124, "test_data": 124, "n_iter": [124, 180], "decode_orient": 124, "train_binned_label": 124, "test_binned_label": 124, "out_label": 124, "frac_correct": 124, "_a_new_loss_function_exercis": 124, "regularized_loss": 124, "_add_regularization_to_training_exercis": 124, "_convolutional_encoding_model_video": 124, "grating_stimuli": 124, "neuronsto": 124, "tmp": [124, 137, 138, 173], "ipykernel_5963": 124, "554819614": 124, "deprecationwarn": [124, 137, 138], "__array__": 124, "_number_of_units_and_weights_discuss": 124, "custom_loss": 124, "param_group": 124, "conv1d": 124, "normal_": 124, "_add_linear_layer_exercis": 124, "ineur": 124, "runtimeerror": 124, "125": [124, 154, 197], "124": [124, 154], "mat1": 124, "mat2": 124, "720x16": 124, "23589x20": 124, "1940": 124, "__getattr__": 124, "1938": 124, "1939": 124, "1941": 124, "__name__": 124, "1942": 124, "w2d1_daysummari": 126, "w2d1_intro": 127, "w2d1_outro": 128, "w2d1_t1": 129, "_introduction_to_tutorial_video": 129, "_asking_a_question_video": 129, "buili": 129, "_asking_your_own_question_discuss": 129, "_literature_review_and_background_knowledge_video": 129, "_literature_review_discuss": 129, "_submit_your_feedback_video": 129, "_determine_your_basic_ingredients_discuss": 129, "_formulating_your_hypothesis_video": 129, "_formulating_your_hypothesis_discuss": 129, "persist": 129, "solid": [129, 169, 199], "2002": [129, 149, 165], "03211v1": 129, "ekaterina": [130, 139, 148], "morozova": [130, 139, 148], "costa": 131, "aham": 131, "1501": [131, 191], "1510": 131, "1813476116": 131, "billeh": 131, "cai": 131, "gratii": 131, "iyer": 131, "gouwen": 131, "arkhipov": 131, "106": [131, 154, 170, 175], "403": [131, 175], "040": 131, "botvinick": [131, 182], "brodi": 131, "6128": 131, "1233912": 131, "kutz": 131, "258": 131, "010": [131, 186], "gilson": 131, "burkitt": 131, "grayden": 131, "hemmen": 131, "plastic": [131, 142], "cybernet": [131, 140], "102": [131, 165, 170, 175], "0319": 131, "aravkin": 131, "autoregress": [131, 198], "siam": 131, "2335": 131, "2358": 131, "1137": 131, "20m1338058": 131, "08389": 131, "1952": [131, 140], "nerv": [131, 140], "117": [131, 140, 154], "544": [131, 175], "1113": [131, 140], "jphysiol": [131, 140], "sp004764": [131, 140], "hu": 131, "cain": 131, "mihala": 131, "shea": [131, 145], "motif": [131, 149], "062312": 131, "1103": [131, 191], "physrev": 131, "izhikevich": [131, 140], "burst": [131, 173], "blei": 131, "1610": 131, "08466": 131, "mant": 131, "sussillo": 131, "newsom": [131, 169], "prefront": [131, 182], "503": 131, "7474": 131, "nature12742": 131, "pmc4121670": 131, "morrison": 131, "curto": 131, "combinatori": 131, "241": 131, "277": [131, 175], "academ": [131, 157], "b978": 131, "814066": 131, "00008": 131, "1804": 131, "01487": 131, "ocker": 131, "litwin": 131, "doiron": [131, 145], "microcircuit": 131, "e1004458": 131, "1004458": 131, "josi\u0107": [131, 145], "buic": 131, "e1005583": 131, "1005583": 131, "seung": 131, "13339": 131, "13344": 131, "usher": 131, "mcclelland": [131, 186], "compet": 131, "108": [131, 154, 188], "550": 131, "1037": 131, "0033": 131, "295x": 131, "s41467": 131, "10772": 131, "kaufman": 131, "foster": 131, "nuyujukian": 131, "487": 131, "7405": 131, "nature11129": 131, "pmc3393826": 131, "gilja": 131, "pandarinath": 131, "blabe": 131, "simer": 131, "sarma": 131, "henderson": 131, "prosthesi": 131, "medicin": 131, "1142": 131, "1145": [131, 191], "nm": 131, "pmc4805425": 131, "kao": 131, "ncomms8759": 131, "935": 131, "945": 131, "tbme": 131, "2582691": 131, "nonhuman": 131, "jproc": 131, "2586967": 131, "pmc7970827": 131, "albit": 131, "sanabria": 131, "saab": 131, "jarosiewicz": 131, "tablet": 131, "paralysi": 131, "e0204566": 131, "pone": [131, 165], "0204566": 131, "jozefowicz": 131, "staviski": 131, "805": 131, "815": 131, "s41592": 131, "0109": 131, "pmc6380887": 131, "soric": 131, "willett": 131, "intracort": 131, "e18554": 131, "18554": 131, "santhanam": 131, "afshar": 131, "prosthes": 131, "1315": 131, "1330": 131, "00097": 131, "annual": [131, 191], "062111": 131, "150509": 131, "visuomotor": 131, "null": [131, 198], "208": [131, 149], "023": 131, "murphi": [131, 149], "rezaii": 131, "avansino": 131, "dorsal": 131, "speech": 131, "e46015": 131, "46015": 131, "trautmann": 131, "lahiri": 131, "103": [131, 170], "292": [131, 172], "308": 131, "vya": 131, "1177": 131, "1186": 131, "249": [131, 179], "092619": 131, "094115": 131, "pmc7402639": 131, "329": 131, "deo": 131, "hochberg": 131, "knob": 131, "premotor": 131, "bodi": 131, "181": 131, "396": 131, "409": 131, "043": 131, "william": [131, 186, 187, 188, 189], "discoveri": [131, 191], "demix": 131, "1099": 131, "015": 131, "nips2008": 131, "w2d2_daysummari": 132, "w2d2_intro": 133, "w2d2_outro": 134, "wen": [135, 136, 137, 138], "alic": [135, 137], "schwarz": [135, 137], "norma": [135, 136, 137, 138], "kuhn": [135, 136, 137, 138, 140, 146], "w2d2_t1": 135, "solve_ivp": 135, "plot_trajectori": 135, "initial_condit": 135, "portrait": 135, "figtitlt": 135, "t_span": 135, "t_eval": 135, "dense_output": 135, "timecolor": 135, "ah1": [135, 137], "ah2": [135, 137], "ah3": 135, "set_size_inch": 135, "bx": 135, "subplots_adjust": 135, "wspace": 135, "plot_streamplot": 135, "x1dot": 135, "x2dot": 135, "log1p": 135, "sca": 135, "streamplot": 135, "cividi": 135, "arrows": 135, "eigenvector1": [135, 136], "eigenvector2": [135, 136], "plot_specific_example_stream_plot": 135, "a_opt": 135, "eigstr": 135, "y_label": [135, 162], "righthand": 135, "hspace": [135, 147], "_linear_dynamical_systems_video": [135, 172], "serv": [135, 136, 137], "govern": [135, 136, 137, 153, 189], "t_i": [135, 173], "sudden": 135, "fine": 135, "1b": 135, "integrate_exponenti": 135, "xdot": 135, "_forward_euler_integration_exercis": 135, "\u03b1": [135, 162, 187], "readout_format": [135, 186], "plot_euler_integr": 135, "clunki": 135, "259": 135, "_forward_euler_integration_interactive_demo_discuss": 135, "imaginari": 135, "oscil": [135, 149, 151, 154], "hertz": 135, "0001": [135, 153, 186], "_oscillatory_dynamics_interactive_demo_discuss": 135, "_multidimensional_dynamics_video": 135, "bigg": [135, 154, 162], "1c": 135, "\ud835\udc651": 135, "\ud835\udc652": 135, "a00": 135, "a01": 135, "a10": 135, "a11": 135, "xdot1": 135, "xdot2": 135, "_ivp": 135, "ivp": 135, "621": 135, "618": 135, "tf": 135, "623": 135, "624": 135, "ts": [135, 173], "rk": 135, "rungekutta": 135, "t_bound": 135, "max_step": [135, 188, 189], "rtol": 135, "atol": 135, "first_step": 135, "extran": 135, "validate_max_step": 135, "validate_tol": 135, "h_ab": 135, "select_initial_step": 135, "error_estimator_ord": 135, "odesolv": 135, "fun_singl": 135, "check_argu": 135, "asarrai": [135, 161, 170, 179, 197], "593": 135, "592": [135, 149], "_sample_trajectories_in_2_dimensions_exercis": 135, "a_option_1": 135, "a_option_2": 135, "a_option_3": 135, "a_option_4": 135, "_varying_a_interactive_demo_discuss": 135, "x0_option_1": 135, "x0_option_2": 135, "x0_option_3": 135, "_varying_initial_conditions_interactive_demo_discuss": 135, "fortun": [135, 172, 180], "1_0": 135, "2_0": 135, "shrunk": 135, "_interpreting_eigenvalues_and_eigenvectors_discuss": 135, "elli": 136, "stradquist": 136, "markovian": [136, 186], "w2d2_t2": 136, "plot_switch_simul": 136, "plot_interswitch_interval_histogram": 136, "inter_switch_interv": 136, "plot_state_prob": 136, "prob": [136, 161, 170, 173, 179], "_markov_process_video": 136, "mu_": [136, 145, 162, 169, 170, 171], "c2o": 136, "o2c": 136, "req": [136, 144, 145, 154, 161, 162, 170, 199], "ion_channel_open": 136, "switch_tim": 136, "uniti": 136, "myrand": 136, "random_sampl": 136, "2a": [136, 171], "_computing_intervals_between_switches_exercis": 136, "return_count": 136, "undergon": 136, "adopt": 136, "plot_inter_switch_interv": 136, "_varying_transition_probability_values_and_t_interactive_demo_and_discuss": 136, "_k": 136, "x_kp1": 136, "plu": [136, 137, 161, 169, 198], "simulate_prob_prop": 136, "latest": [136, 171], "_probability_propagation_exercis": 136, "settl": [136, 137, 187], "relax": 136, "_continuous_vs_discrete_time_fromulation_video": 136, "eigendecomposit": 136, "988": 136, "98058068": 136, "19611614": 136, "70710678": 136, "_finding_a_stable_state_discuss": 136, "biraj": [137, 138], "pandei": [137, 138], "neither": 137, "face": [137, 162, 172, 187, 198], "w2d2_t3": 137, "plot_random_walk_sim": 137, "nsim": 137, "3a": 137, "plot_mean_var_by_timestep": 137, "plot_ddm": 137, "xinfti": [137, 138], "var_comparison_plot": 137, "plot_dynam": [137, 179], "_ecoli_and_random_walks_video": 137, "gander": 137, "wander": 137, "aimlessli": 137, "live": [137, 173], "bacterium": 137, "odor": 137, "substrat": [137, 182], "seek": [137, 179, 188], "dog": 137, "blindfold": 137, "flail": 137, "brownian": 137, "terminolog": 137, "microscop": 137, "protein": 137, "mintag": 137, "this_step": 137, "random_walk_simul": 137, "nxt": 137, "random_walk_simulator_funct": 137, "_random_walk_simulation_exercis": 137, "bacteria": 137, "2500": 137, "sig2": 137, "mytitl": [137, 138], "sharpli": 137, "_random_walk_and_variance_exercis": 137, "plot_gaussian": [137, 162], "_influence_of_parameter_choice_interactive_demo_and_discuss": 137, "_combining_deterministic_and_stochastic_processes_video": 137, "ddm": [137, 138], "hang": [137, 162], "imperfectli": 137, "land": [137, 188, 189], "simulate_ddm": 137, "_driftdiffusion_model_exercis": 137, "stimul": [137, 146, 153, 193], "_driftdiffusion_simulation_observations_discuss": 137, "_balance_of_variances_video": 137, "pull": [137, 172, 187], "restor": 137, "standard_norm": [137, 138], "ddm_eq_var": 137, "hack": 137, "sweep": 137, "empirical_vari": 137, "analytical_vari": 137, "ipykernel_6416": 137, "1365116358": 137, "convers": [137, 138], "_computing_the_variances_empirically_exercis": 137, "interplai": [137, 146], "w2d2_t4": 138, "plot_residual_histogram": 138, "4a": 138, "stdev": 138, "plot_training_fit": 138, "4b": 138, "build_time_delay_matric": 138, "xprime": 138, "roll": 138, "ar_predict": 138, "ar_model": 138, "error_r": 138, "mismatch": [138, 172], "count_nonzero": 138, "_autoregressive_models_video": 138, "ipykernel_6463": 138, "4059738216": 138, "bird": [138, 175], "reformul": 138, "rnk": 138, "lstsq": 138, "rcond": 138, "lam_hat": 138, "_residuals_of_the_autoregressive_model_exercis": 138, "_monkey_at_a_typewriter_video": 138, "alpha_0": 138, "alpha_1": 138, "alpha_2": 138, "alpha_3": 138, "alpha_": [138, 155], "jot": 138, "monkey_at_typewrit": 138, "1010101010101010101010101010101010101010101010101": 138, "100100100100100100100100100100100100100": 138, "char": 138, "char2arrai": 138, "_understanding_autoregressive_parameters_discuss": 138, "notori": 138, "terribl": 138, "yr": 138, "laptop": 138, "jab": 138, "10010101001101000111001010110001100101000101101001010010101010001101101001101000011110100011011010010011001101000011101001110000011111011101000011110000111101001010101000111100000011111000001010100110101001011010010100101101000110010001100011100011100011100010110010111000101": 138, "test_monkei": 138, "00100101100001101001100111100101011100101011101001010101000010110101001010100011110": 138, "randint": 138, "unpredict": 138, "jitter": 138, "_fitting_ar_models_exercis": 138, "x1_test": 138, "x2_test": 138, "err": 138, "rr": 138, "test_error": 138, "sweet": 138, "6th": 138, "gerstner": [140, 149], "kistler": [140, 149], "naud": [140, 142, 144, 145, 146, 147, 149], "katz": 140, "giant": 140, "loligo": 140, "424": 140, "sp004716": 140, "fitzhugh": 140, "nagumo": 140, "scholarpedia": 140, "1349": 140, "4249": 140, "1955": 140, "bulletin": 140, "257": 140, "278": [140, 172], "bf02477753": 140, "hakim": 140, "richardson": 140, "155": 140, "326": [140, 147], "5951": 140, "379": 140, "380": 140, "1181936": 140, "infosci": 140, "epfl": [140, 149], "142067": 140, "naud09": 140, "jolivet": 140, "kobayashi": 140, "rauch": 140, "shinomoto": 140, "417": [140, 149], "118680": 140, "jolivet08": 140, "lewi": 140, "959": 140, "976": 140, "00190": 140, "larkum": 140, "nevian": 140, "sandler": 140, "polski": 140, "schiller": 140, "tuft": 140, "dendrit": [140, 142], "pyramid": 140, "325": [140, 147], "5941": 140, "756": [140, 175], "760": 140, "1171958": 140, "poirazi": [140, 142], "brannon": 140, "mel": 140, "989": [140, 172], "s0896": 140, "6273": 140, "00149": 140, "aertsen": [140, 145, 146], "rotter": [140, 146], "2345": 140, "2356": 140, "3349": 140, "markram": 140, "tsodyk": [140, 149], "redistribut": 140, "efficaci": [140, 144, 146], "6594": 140, "807": 140, "810": 140, "382807a0": 140, "5323": 140, "5328": 140, "steven": 140, "1995": [140, 157, 175, 180], "depress": [140, 147], "795": 140, "802": [140, 145], "0896": 140, "90223": 140, "nelson": [140, 182], "tame": 140, "beast": 140, "1178": 140, "1183": 140, "81453": 140, "bi": [140, 145, 162], "poo": 140, "modif": [140, 147], "cultur": 140, "hippocamp": [140, 182], "10464": 140, "10472": 140, "song": 140, "competit": [140, 182], "hebbian": 140, "919": 140, "926": 140, "78829": 140, "w2d3_daysummari": 141, "upi": 142, "bhalla": 142, "irregular": [142, 145, 146, 149], "synchroni": 142, "yiota": 142, "morpholog": 142, "w3d5": [142, 151], "dysfunct": [142, 175], "w2d3_intro": 142, "w2d3_outro": 143, "qinglong": [144, 145, 146, 147, 153, 154, 155], "gu": [144, 145, 146, 147, 153, 154, 155], "songtin": [144, 145, 146, 147, 153, 154, 155], "lorenzo": [144, 145, 146, 147, 153, 154, 155], "fontolan": [144, 145, 146, 147, 153, 154, 155], "w2d3_t1": 144, "plot_volt_trac": [144, 146], "par": [144, 145, 146, 147, 153, 154, 155], "trajetori": [144, 146], "volt": [144, 146], "range_t": [144, 145, 146, 147, 153, 154, 155], "sp_num": [144, 146, 147], "nicer": [144, 146], "npotenti": 144, "plot_gwn": 144, "i_gwn": [144, 145, 146], "pa": [144, 145, 146], "my_hist": 144, "isi1": 144, "isi2": 144, "cv1": 144, "cv2": 144, "sigma1": [144, 162], "sigma2": [144, 162], "my_bin": [144, 145], "_lif_model_video": 144, "laurenc": 144, "eqn": 144, "mimick": [144, 145], "exceed": 144, "default_par": [144, 145, 146, 154, 155], "simulation_tim": 144, "time_step": [144, 153, 154, 155], "new_param": 144, "ns": [144, 145, 146], "v_init": [144, 145, 146, 147], "tref": [144, 145, 146, 147], "000e": 144, "997e": 144, "998e": [144, 197], "999e": 144, "run_lif": [144, 145], "iinj": [144, 145, 146], "puls": 144, "rec_v": [144, 145, 146, 147], "rec_sp": 144, "lt": [144, 145, 146, 147, 153, 154, 155, 180], "rec_spik": [144, 145, 146, 147], "tr": [144, 145, 146, 147], "counter": [144, 145], "_lif_model_exercis": 144, "_response_lif_model_video": 144, "cosmet": 144, "rheobas": 144, "i_dc": 144, "diff_dc": 144, "_parameter_exploration_of_dc_input_amplitude_interactive_demo_and_discuss": 144, "vivo": [144, 146, 186, 198], "mimic": 144, "my_gwn": [144, 145, 146], "myse": [144, 145, 146, 147, 153, 155], "amplitut": [144, 145, 146, 147, 153, 155], "mu_gwn": 144, "diff_gwn_to_lif": 144, "_gaussian_white_noise_interactive_demo_and_discuss": 144, "clock": [144, 145], "_analyzing_gwn_effects_on_spiking_discuss": 144, "textbf": 144, "clocklik": 144, "diff_std_affect_fi": 144, "spk_count": 144, "spk_count_dc": 144, "v_dc": 144, "rec_sp_dc": 144, "_f_i_explorer_interactive_demo_and_discuss": 144, "isi_cv_lif": 144, "spike_train": [144, 145, 147], "sig_gwn1": 144, "sig_gwn2": 144, "i_gwn1": 144, "sp1": [144, 145], "i_gwn2": 144, "sp2": [144, 145], "_compute_cv_isi_exercis": 144, "cv_isi": [144, 146], "_spike_irregularity_interactive_demo_and_discuss": 144, "shot": [144, 145], "my_ou": [144, 153, 155], "i_ou": [144, 153, 155], "tau_ou": [144, 153, 155], "sig_ou": [144, 153, 155], "mu_ou": 144, "190": 144, "220": 144, "lif_with_": 144, "_lif_explorer_with_ou_input_bonus_interactive_demo_and_discuss": 144, "_extension_to_integrate_and_fire_bonus_video": 144, "lif": [145, 153], "w2d3_t2": 145, "example_plot_mycc": 145, "50000": 145, "r12": 145, "i1gl": 145, "i2gl": 145, "correlate_input": 145, "my_cc": 145, "my_raster_poisson": 145, "ffunction": 145, "exce": [145, 147, 155], "rater": 145, "plot_c_r_lif": 145, "mycolor": [145, 154, 155], "mylabel": [145, 154, 155], "polyfit": 145, "c_rang": 145, "v_l": [145, 146, 147], "mebran": [145, 146, 147], "lif_output_cc": 145, "bin_siz": 145, "coe": 145, "sp_rate": 145, "i_trial": 145, "sp1_count": 145, "sp2_count": 145, "poisson_gener": [145, 146, 147], "coincid": 145, "uni": 145, "direction": 145, "gap": [145, 197], "junction": 145, "stronger": [145, 198], "forthcom": 145, "impair": 145, "_input_and_output_correlations_video": 145, "unconnect": 145, "i_i": [145, 155], "xi_i": 145, "xi_c": 145, "le": 145, "le1": 145, "whute": 145, "xi_1": 145, "xi_2": 145, "i_j": 145, "pearson": [145, 196], "rodger": 145, "nicewand": 145, "rij": 145, "rxy": 145, "tip1": 145, "a1": 145, "a2": 145, "a3": 145, "b1": 145, "b2": 145, "b3": 145, "tip2": 145, "tip3": 145, "var_i": 145, "var_j": 145, "_compute_the_correlation_exercis": 145, "\ud835\udc36\ud835\udc49isi": 145, "pre_spike_train": [145, 146, 147], "ith": [145, 146, 147], "u_rand": [145, 146, 147], "poisson_train": [145, 146, 147], "generate_corr_poisson": 145, "poi_rat": 145, "mother_r": 145, "mother_spike_train": 145, "sp_mother": 145, "l_sp_mother": 145, "sp_mother_id": 145, "l_sp_corr": 145, "corr_coeff_pair": 145, "r_12": 145, "diff_trial": 145, "simu": 145, "197": 145, "_measure_the_correlation_between_spike_trains_exercis": 145, "aforement": [145, 146], "gwn_mean": 145, "gwn_std": 145, "80000": 145, "starttim": [145, 147], "perf_count": [145, 147], "r12_ss": 145, "sp_ss": 145, "endtim": [145, 147], "timecost": [145, 147], "8000": 145, "140": 145, "138": 145, "ic": 145, "_input_output_correlation_discuss": 145, "r12_l": 145, "r12_sl": 145, "sp_l": 145, "sp_sl": 145, "_gwn_and_the_correlation_transfer_function_discuss": 145, "campbel": 145, "unphysiolog": 145, "ou": [145, 153, 155], "la": [145, 175], "rocha": 145, "rey": 145, "806": 145, "nature06028": 145, "bujan": 145, "af": 145, "evok": 145, "neocortex": 145, "8611": 145, "4536": 145, "_correlations_and_network_activity_discuss": 145, "correlogram": 145, "response_of_ensemble_of_neurons_to_time_varying_input_bonus_video": 145, "chemic": 146, "neurotransmitt": 146, "cleft": 146, "permeabl": 146, "partner": 146, "undergo": [146, 186], "w2d3_t3": 146, "my_illus_lifsyn": 146, "v_fmp": 146, "illustart": 146, "fmp": 146, "alongsid": 146, "pot": 146, "my_illus_std": 146, "tau_d": 146, "tau_f": 146, "plot_out": 146, "constantr": 146, "ot": 146, "t_simu": 146, "isi_num": 146, "1e3": 146, "dynamic_syn": 146, "g_bar": 146, "tau_syn": 146, "spt": [146, 147], "gwn": 146, "poissonian": 146, "_static_and_dynamic_synapses_video": 146, "depolar": 146, "hyperpolar": 146, "transient": [146, 155], "dg_": 146, "g_e": [146, 147], "g_i": [146, 147, 155], "e_i": 146, "inj": 146, "bombard": 146, "run_lif_cond": 146, "i_inj": 146, "pre_spike_train_ex": [146, 147], "pre_spike_train_in": 146, "gi": 146, "ge_bar": [146, 147], "gi_bar": 146, "vi": 146, "tau_syn_": [146, 147], "tau_syn_i": 146, "pre_spike_train_ex_tot": 146, "pre_spike_train_in_tot": 146, "cv_": 146, "descriptor": 146, "_measure_the_mean_free_membrane_potential_exercis": 146, "ei_isi_regular": 146, "lip": [146, 165], "211": [146, 147, 154, 155], "fontweight": [146, 147, 155], "spk": 146, "_lif_explorer_interactive_demo_and_discuss": 146, "_excitatory_inhibitory_balance_discuss": 146, "vesicl": 146, "termin": [146, 186], "fashion": 146, "influx": 146, "du_e": 146, "u_": 146, "u_0": 146, "5mm": [146, 147], "dg_e": 146, "_e": [146, 154, 155], "spiketim": 146, "ur": 146, "gg": 146, "incur": [146, 188, 189], "phenomenolog": [146, 147], "kinet": 146, "dg": [146, 155], "regularli": 146, "uncheck": 146, "my_std_diff_r": 146, "_std_explorer_with_input_rate_interactive_demo_and_discuss": 146, "her": [146, 198], "10th": 146, "input_r": 146, "g_1": 146, "g_2": 146, "st": 146, "_stf_explorer_with_input_rate_interactive_demo_and_discuss": 146, "therebi": [146, 189], "imping": 146, "run_lif_cond_stp": 146, "u0_": 146, "tau_d_": 146, "tau_f_": 146, "u0i": 146, "tau_di": 146, "tau_fi": 146, "u0_i": 146, "tau_d_i": 146, "tau_f_i": 146, "ne": 146, "ni": 146, "ue": 146, "ge_tot": 146, "ui": 146, "ri": [146, 154, 155], "gi_tot": 146, "tau_ratio": 146, "lif_stp": 146, "t_plot_rang": 146, "400m": 146, "onward": 146, "_lif_with_stp_bonus_interactive_demo": 146, "w2d3_t4_bonu": 147, "my_raster_plot": 147, "raster_plot": 147, "my_example_p": 147, "ltp": 147, "rastert": 147, "color_set": 147, "cyan": 147, "212": [147, 154, 155], "mystdp_plot": 147, "a_plu": 147, "a_minu": 147, "tau_stdp": 147, "time_diff": 147, "biphas": 147, "default_pars_stdp": 147, "ltd": 147, "_stdp_video": 147, "weaken": 147, "latenc": 147, "delta_w": 147, "pre_spik": 147, "post_spik": 147, "_compute_stdp_changes_exercis": 147, "dm": 147, "displaystyl": [147, 153], "sp_or_not": 147, "generate_p": 147, "_compute_dp_exercis": 147, "foral": 147, "run_lif_cond_stdp": 147, "ge_init": 147, "ge_bar_upd": 147, "id_temp": 147, "epsp": 147, "322": 147, "323": 147, "324": 147, "_analyzing_synaptic_strength_discuss": 147, "depotenti": 147, "example_lif_stdp": 147, "inputr": 147, "tsim": 147, "120000": 147, "intputr": 147, "014": 147, "gbar_norm": 147, "620px": 147, "sample_tim": 147, "my_visual_stdp_distribut": 147, "g_di": 147, "_lif_and_stdp_interactive_demo_and_discuss": 147, "example_lif_stdp_corrinput": 147, "i_pr": 147, "figtemp": 147, "iput": 147, "get_text": [147, 179], "legend_handl": 147, "g_dis_cc": 147, "g_dis_dp": 147, "unaffect": [147, 198], "_lif_plasticity_correlated_inputs_interactive_demo_and_discuss": 147, "loooong": 147, "neuronaldynam": 149, "ch4": 149, "cowan": [149, 151], "1972": [149, 154, 155], "s0006": [149, 154, 155], "3495": [149, 154, 155], "86068": [149, 154, 155], "635": 149, "648": 149, "ozeki": 149, "finn": 149, "schaffer": 149, "ferster": 149, "028": 149, "sanzeni": 149, "akitak": 149, "goldbach": 149, "leedi": 149, "widespread": 149, "e54875": 149, "54875": 149, "skagg": 149, "mcnaughton": 149, "1997": [149, 182], "interneuron": 149, "4388": 149, "04382": 149, "rubin": [149, 157, 191, 195], "1994": 149, "2037": 149, "neco_a_00472": 149, "pmc4026108": 149, "1202": 149, "6670": 149, "cerebr": 149, "109": 149, "3373": 149, "3391": 149, "031": [149, 165], "1908": 149, "10101": 149, "hennequin": 149, "lengyel": 149, "attractor": [149, 151], "846": 149, "860": [149, 182], "017": 149, "875534": 149, "hooser": 149, "402": 149, "026": [149, 172], "vreeswijk": 149, "sompolinski": 149, "274": 149, "5293": 149, "1724": 149, "1023": 149, "1008925309027": 149, "01095": 149, "w2d4_daysummari": 150, "_daysummari": [150, 158, 166, 172, 192], "nicola": 151, "juliana": 151, "georgieva": 151, "ken": 151, "expos": [151, 199], "amplif": 151, "supra": 151, "w2d3": 151, "manifest": 151, "oscillatori": [151, 154, 155, 172], "w2d4_intro": 151, "w2d4_outro": 152, "julijana": [153, 154, 155], "gjorgjieva": [153, 154, 155], "mainli": 153, "signatur": [153, 172, 189], "diseas": [153, 175], "epilepsi": 153, "parkinson": 153, "homogen": 153, "w2d4_t1": 153, "plot_fi": 153, "plot_dr_r": 153, "drdt": 153, "x_fp": [153, 154, 155], "plot_dfdt": 153, "dfdt": 153, "_dynamic_networks_video": 153, "feed": 153, "ext": [153, 154, 155], "default_pars_singl": 153, "i_ext": 153, "r_init": 153, "t_sim": [153, 154, 155], "new_para": [153, 154, 155], "my_func": 153, "hyperbol": 153, "tangent": [153, 154], "_implement_fi_curve_exercis": 153, "interactive_plot_fi": 153, "expecxt": 153, "_parameter_exploration_of_fi_curve_interactive_demo_and_discuss": 153, "simulate_singl": 153, "ana": 153, "myplot_e_diffi_difftau": 153, "r_ana": 153, "_parameter_exploration_of_single_population_dynamics_interactive_demo_and_discuss": 153, "_finite_activities_discuss": 153, "_finding_fixed_points_video": 153, "deduc": 153, "compute_drdt": 153, "other_par": [153, 154, 155], "unus": 153, "_visualization_of_the_fixed_points_exercis": 153, "my_fp_singl": 153, "r_guess": 153, "check_fp_singl": 153, "fp": [153, 155], "my_fp_find": 153, "r_guess_vector": 153, "my_wcr": [153, 155], "mytol": [153, 155], "toler": [153, 155, 197], "correct_fp": 153, "student_exercis": 153, "_numerical_calculation_of_fixed_points_exercis": 153, "plot_intersection_singl": 153, "r_init_vector": 153, "_fixed_points_inputs_interactive_demo_and_discuss": 153, "_root": 153, "236": 153, "233": 153, "fatol": 153, "hybr": 153, "sol": 153, "_root_hybr": 153, "237": [153, 179], "238": [153, 179], "_root_leastsq": 153, "_minpack_pi": 153, "232": 153, "col_deriv": 153, "xtol": 153, "maxfev": 153, "230": 153, "231": 153, "_check_func": 153, "fsolv": [153, 161], "epsfcn": 153, "234": [153, 179], "checker": 153, "argnam": 153, "thefunc": 153, "numinput": 153, "output_shap": 153, "plot_single_diffeinit": 153, "_dynamics_initial_value_interactive_demo_and_discuss": 153, "800x500": 153, "_stable_vs_unstable_fixed_points_discuss": 153, "_inhibitory_populations_discuss": 153, "_stability_of_fixed_points_bonus_video": 153, "perturb": [153, 155, 193, 196, 197, 198], "wf": 153, "dfdx": [153, 154, 155], "eig_singl": 153, "r_fp": 153, "eig_fp": 153, "point1": [153, 154, 155], "583": 153, "point2": 153, "447": 153, "498": 153, "point3": 153, "900": 153, "626": 153, "_compute_eigenvalues_bonus_exercis": 153, "ornstein": [153, 155], "uhlenbeck": [153, 155], "uhlenback": 153, "becam": 154, "w2d4_t2": 154, "plot_fi_invers": [154, 155], "f_inv": [154, 155], "plot_fi_ei": [154, 155], "fi_exc": [154, 155], "fi_inh": [154, 155], "my_test_plot": [154, 155], "re1": [154, 155], "ri1": [154, 155], "re2": [154, 155], "ri2": [154, 155], "plot_nullclin": [154, 155], "exc_null_r": [154, 155], "exc_null_ri": [154, 155], "inh_null_r": [154, 155], "inh_null_ri": [154, 155], "my_plot_nullclin": [154, 155], "get_e_nullclin": [154, 155], "get_i_nullclin": [154, 155], "my_plot_vector": [154, 155], "my_n_skip": [154, 155], "myscal": [154, 155], "ei_grid": [154, 155], "dredt": [154, 155], "dridt": [154, 155], "eideriv": [154, 155], "n_skip": [154, 155], "my_plot_trajectori": [154, 155], "x_init": [154, 155], "re_init": [154, 155], "ri_init": [154, 155], "re_tj": [154, 155], "ri_tj": [154, 155], "simulate_wc": [154, 155], "e_grid": [154, 155], "trjectori": [154, 155], "plot_complete_analysi": [154, 155], "nfor": [154, 155], "nlow": [154, 155], "nhigh": [154, 155], "plot_fp": [154, 155], "wee": 154, "wie": [154, 155], "wii": [154, 155], "i_ext_": [154, 155], "i_ext_i": [154, 155], "_phase_analysis_video": 154, "subtyp": 154, "f_e": [154, 155], "f_i": [154, 155], "ae": 154, "ai": 154, "_plot_fi_exercis": 154, "_numerical_integration_of_we_model_exercis": 154, "plot_ei_diffiniti": 154, "_population_trajectories_with_different_initial_values_interactive_demo_and_discuss": 154, "_nullclines_and_vector_fields_video": 154, "n_t": [154, 187], "plot_activity_phas": 154, "_time_plane_to_phase_plane_interactive_demo_and_discuss": 154, "1mm": [154, 155], "shere": 154, "ln": [154, 155], "f_invers": [154, 155], "finvers": [154, 155], "_compute_the_nullclines_we_exercis": 154, "travers": 154, "119": [154, 175], "104": [154, 170], "770x600": 154, "_compute_the_vector_field_exercis": 154, "_analyzing_the_vector_field_discuss": 154, "w2d4_t3_bonu": 155, "_fixed_points_and_stability_video": 155, "my_fp": 155, "check_fp": 155, "vicin": 155, "x_fp_1": 155, "x_fp_2": 155, "x_fp_3": 155, "_find_the_fixed_points_of_we_exercis": 155, "attract": 155, "yield": 155, "get_eig_jacobian": 155, "eig_1": 155, "eig_2": 155, "eig_3": 155, "_compute_the_jacobian_exercis": 155, "pitchfork": 155, "bifurc": 155, "plot_nullcline_diffwe": 155, "clip_on": 155, "_effect_of_wee_interactive_demo_and_discuss": 155, "time_constant_effect": 155, "ei_grid_": 155, "ei_grid_i": 155, "_limit_cycle_and_oscillations_interactive_demo": 155, "subpopul": 155, "alpha_i": 155, "noninhibit": 155, "get_dgd": 155, "dgde": 155, "dgdre": 155, "dgdre1": 155, "dgdre2": 155, "dgdre3": 155, "fp1": 155, "fp2": 155, "fp3": 155, "x_fp_lc": 155, "dgdre_lc": 155, "fp_lc": 155, "650": 155, "519": [155, 198], "706": 155, "837": 155, "_compute_dgdre_exercis": 155, "iff": 155, "det": 155, "fw": 155, "steeper": 155, "isn_i_perturb": 155, "_nullclines_of_isn_and_nonisn_interactive_demo_and_discuss": 155, "20201": 155, "20202": 155, "se": [155, 198], "outlast": 155, "my_inject": 155, "t_start": 155, "t_lag": 155, "n_start": 155, "n_lag": 155, "i_puls": 155, "l_puls": 155, "wc_with_puls": 155, "2022": [155, 157, 191], "_persistent_activity_interactive_demo_and_discuss": 155, "treatment": [157, 191, 193, 197, 198], "goldreich": 157, "cn": 157, "nyu": 157, "malab": 157, "bayesianbook": 157, "gelman": 157, "carlin": 157, "stern": 157, "crc": 157, "mcelreath": 157, "rethink": 157, "stan": 157, "stuff": 157, "downei": 157, "reilli": 157, "media": 157, "inc": 157, "kruschk": 157, "jag": 157, "knill": 157, "propel": 157, "welchman": 157, "trommershaus": 157, "landi": 157, "cue": [157, 186], "kass": [157, 191], "w3d1_daysummari": 158, "fish": [159, 162, 167, 169, 170, 177], "astrocat": [159, 167, 177, 180], "rl": [159, 184, 186], "w3d1_intro": 159, "w3d1_outro": 160, "xaq": [161, 162, 169, 170, 171, 172, 179, 180], "pitkow": [161, 162, 169, 170, 171, 172, 179, 180], "w3d1_t1": 161, "namedtupl": [161, 170, 171, 173, 180], "gridspeclayout": 161, "togglebutton": [161, 179], "interactive_output": [161, 162], "clear_output": [161, 162], "filterwarn": [161, 162], "plot_joint_prob": 161, "marginal_i": 161, "marginal_x": 161, "joint_prob": 161, "rect_histx": 161, "rect_histi": 161, "rect_x_cmap": 161, "rect_y_cmap": 161, "matshow": 161, "barh": 161, "ind": 161, "tick_bottom": 161, "tick_left": 161, "silver": [161, 182], "plot_prior_likelihood_posterior": 161, "small_width": 161, "left_spac": 161, "added_spac": 161, "rect_prior": 161, "rect_likelihood": 161, "rect_posterior": 161, "ax_prior": 161, "ax_likelihood": 161, "ax_posterior": 161, "rect_colormap": 161, "tick_right": 161, "set_ticks_posit": 161, "plot_prior_likelihood": 161, "p_a_s1": 161, "p_a_s0": 161, "small_pad": 161, "prior_colormap": 161, "posterior_colormap": 161, "plot_util": 161, "rect_util": 161, "rect_expect": 161, "ax_util": 161, "ax_expect": 161, "plot_prior_likelihood_util": 161, "expected_colormap": 161, "compute_margin": 161, "cor": 161, "p11": 161, "p01": 161, "p10": 161, "p00": 161, "compute_cor_rang": 161, "cmax": 161, "cmin": 161, "_introduction_to_bayesian_statistics_and_decisions_video": 161, "_gone_fishin_video": 161, "losss": 161, "_utility_video": 161, "submarin": 161, "sunburn": 161, "afternoon": 161, "dock": 161, "weigh": [161, 162], "correspondingli": [161, 172], "ps_widget": 161, "make_utility_plot": 161, "_exploring_the_decision_interactive_demo_and_discuss": 161, "_utility_demo_discussion_video": 161, "_likelihood_video": 161, "fisher": 161, "_guessing_the_location_of_the_fish_discuss": 161, "knew": [161, 169], "_correlation_and_marginalization_video": [161, 162], "golden": 161, "cor_widget": 161, "\u03c1": [161, 162, 180], "px_widget": 161, "py_widget": 161, "make_corr_plot": 161, "_covarying_probability_distributions_discuss": 161, "journei": 161, "irrelev": 161, "njoint": 161, "n1": 161, "n2": 161, "n3": 161, "_computing_marginal_probabilities_math_exercis": 161, "caught": [161, 170, 179], "nprior": 161, "nlikelihood": 161, "_computing_marginal_likelihood_math_exercis": 161, "_posterior_beliefs_video": [161, 162], "propto": [161, 162, 163, 170], "intract": 161, "whfere": 161, "bother": 161, "unnorm": 161, "_calculating_a_posterior_probability_math_exercis": 161, "compute_posterior": 161, "p_m": 161, "_computing_posteriors_exercis": 161, "incorrect": [161, 169], "exert": 161, "p_a_s1_widget": 161, "370px": 161, "p_a_s0_widget": 161, "observed_widget": 161, "button_styl": [161, 179], "flex": [161, 162], "widget_ui": [161, 162], "widget_out": [161, 162], "_what_affects_the_posterior_interactive_demo_and_discuss": 161, "_posterior_beliefs_exercises_discussion_video": 161, "_bayesian_decisions_video": [161, 162], "econom": [161, 175, 184, 186], "ecolog": 161, "300px": 161, "_probabilities_vs_utilities_interactive_demo_and_discuss": 161, "_bayesian_decisions_demo_discussion_video": 161, "rho_": [161, 162], "w3d1_t2": 162, "gamma_distribut": 162, "affine2d": 162, "plot_mixture_prior": 162, "gaussian1": 162, "gaussian2": 162, "plot_loss": 162, "mse_loss": 162, "abs_loss": 162, "zero_one_loss": 162, "ax_gau": 162, "ax_error": 162, "gaussian_mixtur": 162, "mu1": [162, 169], "mu2": 162, "deepskyblu": 162, "aquamarin": 162, "plot_utility_mixture_dist": 162, "mu_g": 162, "sigma_g": 162, "mu_loc": 162, "mu_dist": 162, "plot_utility_row": 162, "mu_post": 162, "sigma_post": 162, "product_guassian": 162, "sigma_mix": 162, "mu_mix1": 162, "mu_mix2": 162, "gaus_mix1": 162, "gaus_mix2": 162, "plot_bayes_utility_row": 162, "plot_bayes_row": 162, "plot_mvn2d": 162, "cov12": 162, "mvn2d": 162, "contourf": 162, "plot_margin": 162, "c_x": 162, "c_y": 162, "p_x": 162, "p_y": 162, "mu_x_i": 162, "mu_y_x": 162, "sigma_x_i": 162, "sigma_y_x": 162, "p_x_y": 162, "p_y_x": 162, "p_c_y": 162, "p_c_x": 162, "rect_z": 162, "rect_x": 162, "rect_i": 162, "ax_z": 162, "set_axis_off": 162, "plot_bay": 162, "plot_inform": 162, "mu3": 162, "sigma3": 162, "satellit": 162, "plot_information_glob": 162, "reverse_product": 162, "plot_loss_utility_gaussian": 162, "loss_f": 162, "mu_tru": 162, "plot_loss_util": 162, "plot_loss_utility_mixtur": 162, "calc_mean_mode_median": 162, "calc_loss_func": 162, "calc_expected_loss": 162, "min_expected_loss": 162, "dashdot": 162, "plot_loss_utility_bay": 162, "plot_simple_utility_gaussian": 162, "mu_c": 162, "sigma_c": 162, "plot_utility_gaussian": 162, "plot_utility_mixtur": 162, "mu_m1": 162, "mu_m2": 162, "sigma_m1": 162, "sigma_m2": 162, "plot_utility_uniform": 162, "plot_utility_gamma": 162, "gamma_pdf": 162, "max_util": 162, "plot_bayes_loss_utility_gaussian": 162, "plot_bayes_loss_util": 162, "plot_bayes_loss_utility_uniform": 162, "plot_bayes_loss_utility_gamma": 162, "plot_bayes_loss_utility_mixtur": 162, "expected_loss": 162, "global_loss_plot_switch": 162, "loss_plot_switch": 162, "what_to_plot": 162, "loss_f_opt": 162, "mu_slid": 162, "\u00b5_estim": 162, "continuous_upd": [162, 197], "sigma_slid": 162, "\u03c3_estim": 162, "mu_true_slid": 162, "\u00b5_true": 162, "mu1_slid": 162, "\u00b5_est_p": 162, "mu2_slid": 162, "\u00b5_est_q": 162, "sigma1_slid": 162, "\u03c3_est_p": 162, "sigma2_slid": 162, "\u03c3_est_q": 162, "factor_slid": 162, "\u03c0": 162, "global_plot_prior_switch": 162, "plot_prior_switch": 162, "\u00b5_prior": 162, "\u00b5_likelihood": 162, "\u03c3_prior": 162, "\u03c3_likelihood": 162, "alpha_slid": 162, "\u03b1_prior": 162, "beta_slid": 162, "\u03b2_prior": 162, "offset_slid": 162, "gaus_label": 162, "justify_cont": 162, "gamma_label": 162, "mu_m1_slid": 162, "\u00b5_mix_p": 162, "mu_m2_slid": 162, "\u00b5_mix_q": 162, "sigma_m1_slid": 162, "\u03c3_mix_p": 162, "sigma_m2_slid": 162, "\u03c3_mix_q": 162, "global_plot_bayes_loss_utility_switch": 162, "plot_bayes_loss_utility_switch": 162, "empty_label": 162, "\u03bc": 162, "\u03b2": 162, "mvn": 162, "dstack": 162, "j_1": 162, "j_2": 162, "j_3": 162, "mu_prod": 162, "sigma_prod": 162, "calc": [162, 163], "cdf": 162, "_introduction_video": [162, 170, 172, 173, 186], "astronaut": 162, "jetpack": [162, 177, 180], "thumb": 162, "jet": [162, 180], "pack": [162, 180], "earth": [162, 180], "glimps": 162, "_astrocat_video": 162, "remot": 162, "tenni": 162, "_the_gaussian_distribution_video": 162, "ormal": 162, "clarif": 162, "\u00b5": 162, "_exploring_gaussian_parameters_interactive_demo_and_discuss": 162, "mu_3": 162, "sigma_3": 162, "_multiplying_gaussians_video": 162, "\u00b5_1": 162, "\u00b5_2": 162, "\u03c3_1": 162, "\u03c3_2": 162, "distro_1_label": 162, "distro_2_label": 162, "_multiplying_gaussians_interactive_demo_and_discuss": 162, "multimod": 162, "_mixtures_of_gaussians_video": 162, "\u00b5_p": 162, "\u00b5_q": 162, "\u03c3_p": 162, "\u03c3_q": 162, "mixture_label": 162, "_exploring_gaussian_mixtures_interactive_demo_and_discuss": 162, "_utility_loss_estimators_video": 162, "_exploring_loss_with_different_distributions_interactive_demo_and_discuss": 162, "fairli": [162, 198], "safe": [162, 187], "eu": 162, "mu_g_slid": 162, "\u00b5_gain": 162, "mu_c_slid": 162, "\u00b5_cost": 162, "sigma_g_slid": 162, "\u03c3_gain": 162, "sigma_c_slid": 162, "\u03c3_cost": 162, "distro_label": 162, "gain_label": 162, "loss_label": 162, "_complicated_cat_costs_interactive_demo_and_discuss": 162, "mu_x": 162, "sigma_x": 162, "anticorrel": 162, "\u00b5_x": 162, "\u00b5_y": 162, "\u03c3_x": 162, "\u03c3_y": 162, "corr_slid": 162, "distro1_label": 162, "distro2_label": 162, "corr_label": 162, "_covarying_2d_gaussian_interactive_demo_and_discuss": 162, "c_x_slider": 162, "cx": 162, "c_y_slid": 162, "cy": 162, "_marginalization_and_information_interactive_demo_and_discuss": 162, "2_": [162, 170], "_prior_exploration_interactive_demo_and_discuss": 162, "modal": 162, "_standard_loss_functions_with_various_priors_interactive_demo_and_discuss": 162, "dist_label": 162, "\u00b51_c": 162, "\u00b52_c": 162, "loc_label": 162, "mu_dist_slid": 162, "mu_loc_slid": 162, "_complicated_cat_costs_with_various_priors_interactive_demo_and_discuss": 162, "vincent": 163, "valton": 163, "jess": [163, 169, 170, 172, 173], "livezei": [163, 169, 170, 172, 173], "revis": [163, 172, 173], "outdat": 163, "w3d1_t3_bonu": 163, "plot_myarrai": 163, "plot_my_bayes_model": 163, "ex": 163, "alpha_tri": 163, "nll": 163, "i_tri": 163, "p_independ": 163, "ix": 163, "plot_simulated_behavior": 163, "true_stim": 163, "moments_myfunc": 163, "cdf_function": 163, "noisili": 163, "puppet": 163, "curtain": 163, "speaker": 163, "distant": 163, "hypothetical_stim": 163, "compute_likelihood_arrai": 163, "stim_arrai": 163, "likelihood_arrai": 163, "_auditory_likelihood_exercis": 163, "_prior_array_video": 163, "peakier": 163, "calculate_prior_arrai": 163, "p_indep": 163, "prior_mean_common": 163, "prior_sigma_common": 163, "prior_mean_indep": 163, "prior_sigma_indep": 163, "indep": 163, "prior_common": 163, "prior_indep": 163, "prior_mix": 163, "prior_arrai": 163, "fcn": 163, "_implement_prior_array_exercis": 163, "_posterior_array_video": 163, "calculate_posterior_arrai": 163, "posterior_arrai": 163, "_calculate_posterior_exercis": 163, "_binary_decision_matrix_video": 163, "unobserv": [163, 170, 173, 197, 198], "scan": [163, 172], "x_column": 163, "calculate_binary_decision_arrai": 163, "binary_decision_arrai": 163, "docstr": [163, 179], "_calculate_estimated_response_exercis": 163, "_input_array_video": 163, "generate_input_arrai": 163, "input_arrai": 163, "_generate_input_array_exercis": 163, "_marginalization_video": 163, "snippet": 163, "artifact": 163, "my_margin": 163, "marginalization_arrai": 163, "_implement_marginalization_matrix_exercis": 163, "recoveri": 163, "gone": 163, "x_stim": 163, "x_hat": [163, 198], "prior_mean": [163, 171], "prior_sigma1": 163, "prior_sigma2": 163, "prior1": 163, "prior2": 163, "prior_combin": 163, "i_stim": 163, "likelihood_mean": 163, "likelihood_sigma": 163, "_loglikelihood_video": 163, "my_bayes_model_ms": 163, "recomput": [163, 187], "trial_ll": 163, "marginal_nonzero": 163, "neg_ll": 163, "_fitting_a_model_to_generated_data_exercis": 163, "went": [163, 188, 189], "katahira": 165, "suzuki": 165, "okanoya": 165, "okada": 165, "birdsong": 165, "e24516": 165, "0024516": 165, "hmm": [165, 167, 171, 172, 179], "serruya": 165, "shaikhouni": 165, "bienenstock": 165, "cursor": 165, "169779d3852b32ce8b1a1724dbf5217d": 165, "kf": [165, 172, 180], "mormann": 165, "malmaud": 165, "huth": 165, "rangel": 165, "pressur": 165, "449": 165, "2139": 165, "ssrn": 165, "1901533": 165, "zoltowski": 165, "yate": 165, "1249": 165, "1258": 165, "demystifi": 165, "vannevar": 165, "ec": 165, "uw": 165, "techsit": 165, "uweetr": 165, "0002": 165, "w3d2_daysummari": 166, "recreat": [167, 186], "plenti": 167, "lesson": [167, 171, 177, 179], "pervas": 167, "fluoresc": 167, "w3d2_intro": 167, "w3d2_outro": 168, "yicheng": [169, 170, 173], "fei": [169, 170, 173], "melvin": 169, "selim": 169, "atai": 169, "posterior": [169, 170, 171, 172, 177, 179, 180], "w3d2_t1": 169, "erf": 169, "plot_accuracy_vs_stoptim": 169, "stop_time_list": 169, "accuracy_analytical_list": 169, "accuracy_list": 169, "stop_time_list_plot": 169, "sigma_st_max": 169, "stop_tim": 169, "ins": 169, "inset_ax": 169, "mu_st": 169, "sigma_st": 169, "lbl": [169, 170], "crimson": [169, 170, 171, 179], "domain0": 169, "simulate_and_plot_sprt_fixedtim": 169, "evidence_history_list": 169, "ttotal_evid": 169, "tdecis": 169, "evidence_histori": 169, "mvec": 169, "simulate_sprt_fixedtim": 169, "maxlen_evid": 169, "simulate_and_plot_sprt_fixedthreshold": 169, "threshold_from_errorr": 169, "ttime": 169, "taccumul": 169, "simulate_sprt_threshold": 169, "simulate_and_plot_accuracy_vs_threshold": 169, "threshold_list": 169, "alpha_list": 169, "decision_spe": 169, "simulate_accuracy_vs_threshold": 169, "amin": 169, "amax": 169, "_overview_of_tutorials_video": 169, "iid": 169, "l_t": [169, 180], "m_t": [169, 170, 171, 172, 180], "tp": 169, "delta_t": 169, "l_": 169, "epsilon_t": [169, 195, 197, 198], "_sequential_probability_ratio_test_video": 169, "m_i": 169, "rewritten": [169, 172], "bt": 169, "log_likelihood_ratio": 169, "logpdf": 169, "llvec": 169, "true_dist": 169, "mu_po": 169, "mu_neg": 169, "p_po": 169, "p_neg": 169, "ll_ratio_vec": 169, "total_evid": 169, "_simulating_an_sprt_model_exercis": 169, "_trajectories_under_the_fixed_time_stop": 169, "rule_interactive_demo_and_discuss": 169, "_section_1_exercises_discussion_video": [169, 170], "_speed_vs_accuracy_tradeoff_video": 169, "buri": 169, "simulate_accuracy_vs_stoptim": 169, "no_numer": 169, "stop_list_list": 169, "flag": [169, 172], "decisions_list": 169, "tracker": [169, 172], "accuracies_analyt": 169, "i_stop_tim": 169, "sigma_sum_gaussian": 169, "_speed_vs_accuracy_tradeoff_exercis": 169, "inset": 169, "_speed_vs_accuracy_tradeoff_interactive_demo_and_discuss": 169, "_section_2_exercises_discussion_video": 169, "kinematogram": 169, "britten": 169, "movshon": 169, "rightward": 169, "leftward": 169, "shadlen": 169, "pamela": 169, "reinagl": 169, "youtu": [169, 172, 173], "odxcytn": 169, "0o": 169, "learnt": 169, "_fixed_threshold_on_confidence_bonus_video": 169, "variant": [169, 171], "th_1": 169, "th_0": 169, "th_": 169, "pl": 169, "mul": 169, "has_enough_data": 169, "data_histori": 169, "current_evid": 169, "ll_ratio": 169, "chunk": 169, "log10_alpha": 169, "log10": 169, "_simulating_the_ddm_with_fixed_confidence_thresholds_bonus_exercis": 169, "_ddm_with_fixed_confidence_threshold_bonus_interactive_demo": 169, "ant": 169, "bee": 169, "rodent": 169, "incentiv": 169, "suppli": 169, "decision_speed_list": 169, "decision_time_list": 169, "decision_list": 169, "decision_tim": 169, "decision_length": 169, "decision_accuraci": 169, "86": [169, 189], "_speed_vs_accuracy_tradeoff_revisited_bonus_exercis": 169, "_speed_vs_accuracy_with_a_threshold_rule_bonus_interactive_demo": 169, "meenakshi": [170, 173], "sleep": [170, 197], "wake": 170, "indirectli": 170, "s_t": [170, 171, 172, 179, 180, 186, 188], "emiss": [170, 173], "w3d2_t2": 170, "linear_sum_assign": [170, 173], "plot_hmm1": 170, "flag_m": [170, 171], "hmmlearn": 170, "nstep": [170, 186], "aspect_ratio": 170, "states_forplot": 170, "twinx": [170, 171, 179], "maroon": 170, "fill_betweenx": [170, 171], "plot_marginal_seq": 170, "predictive_prob": 170, "switch_prob": 170, "prob_neg": 170, "p_vec": 170, "prob_po": 170, "boxstyl": 170, "wheat": 170, "plot_evidence_vs_noevid": 170, "posterior_matrix": 170, "nsampl": 170, "posterior_mean": [170, 171], "plot_forward_infer": 170, "states_inf": 170, "posterior_prob": 170, "flag_d": 170, "flag_pr": 170, "flag_lik": 170, "flag_post": 170, "gaussianhmm": 170, "states_interpol": 170, "borderaxespad": 170, "bar_scal": 170, "dodgerblu": [170, 171], "keepdim": 170, "wholli": 170, "s_": [170, 171, 172, 180, 186, 188], "d_": 170, "p_t": [170, 172], "_binary_hmm_with_gaussian_measurements_video": 170, "noise_level": 170, "create_hmm": 170, "transmat_": 170, "gaussianhmm1d": [170, 173], "startprob": [170, 173], "startprob_vec": 170, "transmat": [170, 173], "transmat_mat": 170, "means_vec": 170, "vars_vec": 170, "transition_vector": 170, "09355908": 170, "58552915": 170, "93502804": 170, "98819072": 170, "32506947": 170, "_simulating_binary_hmm_with_gaussian_measurements_exercis": 170, "plot_samples_widget": 170, "log10_noise_level": 170, "_binary_hmm_interactive_demo_and_discuss": 170, "_forgetting_in_a_changing_world_video": 170, "s_0": [170, 172], "simulate_prediction_onli": 170, "prob_switch": 170, "entropy_list": 170, "_forgetting_in_a_changing_world_interactive_demo_and_discuss": 170, "_section_2_exercise_discussion_video": 170, "_forward_inference_in_an_hmm_video": 170, "markov_forward": 170, "one_step_upd": 170, "compute_likelihood": 170, "simulate_forward_infer": 170, "rv0": 170, "rv1": 170, "predictive_state1": 170, "posterior_state1": 170, "hte": 170, "posterior_tm1": 170, "posterior_t": 170, "_forward_inference_of_hmm_exercis": 170, "log_10_noise_level": 170, "plot_forward_inference_widget": 170, "_forward_inference_of_hmm_interactive_demo": 170, "_section_3_exercise_discussion_video": 170, "rowei": [171, 172], "ghahramani": [171, 172], "mission": [171, 180], "w3d2_t3": 171, "visualize_astrocat": 171, "plot_measur": [171, 179], "y1": 171, "y2": 171, "y3": 171, "y4": 171, "y5": 171, "y6": 171, "process_nois": 171, "measurement_nois": 171, "todays_prior": 171, "info_prior": 171, "info_likelihood": 171, "info_posterior": 171, "prior_weight": 171, "likelihood_weight": 171, "posterior_cov": 171, "todays_posterior": 171, "predicted_estim": [171, 180], "predicted_covari": [171, 180], "innovation_estim": [171, 180], "innovation_covari": [171, 180], "updated_mean": [171, 180], "updated_cov": [171, 180], "paintmyfilt": 171, "initial_guess": 171, "cov_": 171, "filter_s_": 171, "filter_cov_": 171, "process_noise_std": 171, "measurement_noise_std": 171, "smin": 171, "smax": 171, "pscale": 171, "lightgrai": 171, "_astrocat_through_time_video": 171, "_quantifying_astrocat_dynamics_video": 171, "ds_": [171, 172], "w_t": [171, 172, 180], "sigma_p": 171, "actuat": 171, "propuls": 171, "tau_min": 171, "tau_max": 171, "process_noise_min": 171, "process_noise_max": 171, "measurement_noise_min": 171, "measurement_noise_max": 171, "unit_process_nois": 171, "unit_measurement_nois": 171, "s0": 171, "_simulating_astrocats_movements_exercis": 171, "_playing_with_astrocat_movement_interactive_demo_and_discuss": 171, "_exercise_1": 171, "1_discussion_video": 171, "_measuring_astrocats_movements_video": 171, "sigma_measur": 171, "read_collar": 171, "_reading_measurements_from_astrocats_collar_exercis": 171, "_comparing_true_states_to_measured_states_video": 171, "catastroph": 171, "sbound": 171, "_compare_true_states_to_measured_states_exercis": 171, "2_discussion_video": 171, "_the_kalman_filter_video": 171, "15ex": [171, 179, 180], "flag_": 171, "flag_s_": 171, "flag_err_": 171, "stochastic_system": 171, "process_noise_cov": 171, "measurement_noise_cov": 171, "prior_cov": 171, "captured_prior": 171, "captured_likelihood": 171, "captured_posterior": 171, "onfilt": 171, "show_pdf": 171, "pdf_likelihood": 171, "pdf_post": 171, "pdf_prior": 171, "_the_kalman_filter_in_action_interactive_demo": 171, "_interactive_demo_2": 171, "_implementing_a_kalman_filter_video": 171, "recip": 171, "broaden": 171, "sigma_w": 171, "sigma_m": 171, "textit": 171, "congrat": 171, "partwai": 171, "_implement_your_own_kalman_filter_exercis": 171, "_exercise_2": 171, "_compare_states_estimates_and_measurements_video": 171, "errorbar": 171, "yerr": 171, "mfc": 171, "mec": 171, "axhist": 171, "pdf_g": 171, "_compare_states_estimates_and_measurements_interactive_demo": 171, "_how_long_does_it_take_to_find_astrocat_video": 171, "hone": 171, "snr": 171, "decibel": 171, "equilibr": 171, "snrdb": 171, "pcov": 171, "equilibrium_posterior_var": 171, "equilibrium_process_var": 171, "labelcolor": 171, "set_major_formatt": 171, "funcformatt": 171, "format_func": 171, "nprocess": 171, "_how_long_does_it_take_to_find_astrocat_interactive_demo": 171, "3_discussion_video": 171, "carolin": 172, "haimerl": 172, "cristina": 172, "w3d2_t4_bonu": 172, "sy": 172, "set_printopt": [172, 187], "plot_kalman": 172, "plot_gaze_data": 172, "plot_kf_stat": 172, "mu_0": 172, "n_dim_stat": 172, "initial_state_mean": [172, 180], "w2d3_mit_eyetracking_2009": 172, "jfk8w": 172, "20c7bc4a6f61f49450997e381cf5e0dd": 172, "load_eyetracking_data": 172, "imread": 172, "jpg": 172, "6f_51l3i5aq": 172, "2swh639ygeg": 172, "condition": 172, "hs_": 172, "eta_t": 172, "sigma_0": 172, "tractabl": 172, "apolog": 172, "timecours": 172, "n_dim_ob": 172, "sample_ld": 172, "n_timestep": 172, "ob": 172, "_sampling_from_a_linear_dynamical_system_exercis": 172, "explore_dynam": 172, "_adjusting_system_dynamics_interactive_demo": 172, "vbozov9qmoi": 172, "_kalman_filtering_video": 172, "m_1": 172, "sigma_t": 172, "mathsf": 172, "newest": 172, "k_t": 172, "k_th": 172, "hdz_": 172, "kalman_filt": 172, "mu_pr": 172, "sigma_pr": 172, "filtered_state_mean": 172, "filtered_state_covari": 172, "_implement_kalman_filtering_exercis": 172, "m7ouxmvwhgi": 172, "_fitting_eye_gaze_data_video": 172, "devic": 172, "calibr": 172, "ambient": 172, "eyetrack": 172, "databas": 172, "judd": 172, "fixat": 172, "subject_id": 172, "image_id": 172, "plot_subject_trac": 172, "_tracking_eye_gaze_interactive_demo": 172, "influenti": 172, "texttt": 172, "transition_matric": 172, "transition_covari": [172, 180], "observation_matric": 172, "observation_covari": [172, 180], "initial_state_covari": [172, 180], "kalmanfilt": [172, 180], "em_var": 172, "016": 172, "219": 172, "774": 172, "596": 172, "magenta": 172, "triangl": 172, "plot_smoothed_trac": 172, "decent": 172, "nonetheless": 172, "kf_state": 172, "kf_data": 172, "environment": [172, 175, 189], "mitig": 172, "delet": 172, "arbitrarili": 172, "cb": 172, "4ar2myz1nm": 172, "_kalman_smoothing_and_the_em_algorithm_bonus_video": 172, "j_t": 172, "z_t": 172, "kalman_smooth": 172, "mu_hat": 172, "sigma_hat": 172, "smoothed_state_mean": 172, "smoothed_state_covari": 172, "_implement_kalman_smoothing_bonus_exercis": 172, "dz": 172, "kl": 172, "kept": 172, "s_ts_": 172, "j_": [172, 180, 195], "q_0": 172, "s_0s_0": 172, "s_ts_t": 172, "ny_ty_t": 172, "sean": 173, "escola": 173, "w3d2_t5_bonu": 173, "plot_spike_train": 173, "hot": 173, "trial_t": 173, "rect": 173, "add_patch": 173, "plot_ll": 173, "plot_lls_ecl": 173, "plot_epoch": 173, "save_v": 173, "minll": 173, "maxll": 173, "bs": 173, "lls_for_plot": 173, "eclls_for_plot": 173, "ecll": 173, "framealpha": 173, "plot_learnt_vs_tru": 173, "l_true": 173, "a_tru": 173, "run_em": 173, "psi": 173, "flot": 173, "e_step": 173, "print_everi": 173, "psi_new": 173, "a_new": 173, "l_new": 173, "m_step": 173, "interpol": [173, 188, 189], "extrapol": 173, "b_min": 173, "b_max": 173, "b_lim": 173, "num_plot_v": 173, "logpmf": 173, "diff_ll": 173, "ceqxn0ouafo": 173, "wb8mf5chmyi": 173, "_hmm_for_poisson_spiking_neurons_video": 173, "thalam": 173, "relai": 173, "tonic": 173, "rapid": 173, "receptor": 173, "molecular": 173, "n_frozen_tri": 173, "max_firing_r": 173, "max_transition_r": 173, "expens": 173, "craft": 173, "psi_tru": 173, "xf": 173, "yf": 173, "one_hot": 173, "umu4wuwlkvg": 173, "_em_tutorial_video": 173, "b_i": 173, "pairwis": 173, "gamma_": 173, "xi_": 173, "sum_j": 173, "ji": 173, "a_j": 173, "b_j": 173, "b_": 173, "psi_i": 173, "gamma_i": 173, "compact": 173, "o_j": 173, "o_": 173, "lj": 173, "l1j": 173, "node": [173, 196], "log_a": 173, "log_ob": 173, "maxtmp": 173, "h4ggtg_9bae": 173, "_implement_the_m_step_video": 173, "swapax": 173, "_implement_m_step_exercis": 173, "6utsxxe3hg0": 173, "_running_and_plotting_em_video": 173, "\ud835\udf03": [173, 179], "8684143040628": 173, "481": [173, 175], "5065734432824": 173, "cost_mat": 173, "true_ind": 173, "est_ind": 173, "bertseka": [175, 180], "bellman": 175, "1966": 175, "3731": 175, "charnov": 175, "forag": 175, "136": 175, "doyl": 175, "1978": 175, "lqg": 175, "757": 175, "tac": 175, "1101812": 175, "kalman": 175, "1960": 175, "boletin": 175, "sociedad": 175, "matematica": 175, "mexicana": 175, "kappen": 175, "g\u00f3mez": 175, "opper": 175, "159": 175, "182": 175, "s10994": 175, "5278": 175, "todorov": 175, "11478": 175, "11483": 175, "0710743106": 175, "pmc2705278": 175, "castro": 175, "hadjiosif": 175, "hemphil": 175, "1050": 175, "1061": 175, "cub": 175, "049": 175, "brandt": 175, "shadmehr": 175, "disord": 175, "huntington": 175, "6769": 175, "549": 175, "35000576": 175, "harvard": 175, "motorlab": 175, "reprint": 175, "nature00": 175, "sing": 175, "joiner": 175, "nanayakkara": 175, "brayanov": 175, "primit": 175, "575": 175, "589": 175, "wagner": 175, "10663": 175, "10673": 175, "5479": 175, "bautista": 175, "tinbergen": 175, "kacelnik": 175, "fly": 175, "1094": 175, "pmc14713": 175, "ralston": 175, "1958": 175, "international": 175, "zeitschrift": 175, "f\u00fcr": 175, "angewandt": 175, "physiologi": 175, "einschliesslich": 175, "arbeitsphysiologi": 175, "bf00698754": 175, "ahm": 175, "vigor": 175, "neuroeconom": 175, "zee": 175, "saccad": 175, "196": [175, 182], "475": 175, "s00221": 175, "1879": 175, "pmc2771693": 175, "yoon": 175, "geari": 175, "e10476": 175, "e10485": 175, "1812979115": 175, "pmc6217431": 175, "jaleel": 175, "2161": 175, "00700": 175, "w3d3_daysummari": 176, "w3d3_intro": 177, "w3d3_outro": 178, "zhengwei": [179, 180], "shreya": [179, 180], "saxena": [179, 180], "melisa": 179, "maidana": 179, "capitan": 179, "pomdp": 179, "agent": [179, 184, 186, 187, 188, 189], "greatest": 179, "w3d3_t1": 179, "isclos": [179, 180], "plot_fish": 179, "fish_stat": 179, "cornflowerblu": 179, "rel_po": 179, "red_i": 179, "blue_i": 179, "royalblu": 179, "plot_act_loc": 179, "ax_loc": 179, "act_down": 179, "act_up": 179, "plot_belief": 179, "choose_polici": 179, "midnightblu": 179, "get_yticklabel": 179, "time_rang": 179, "mea": 179, "ax0": [179, 180], "ax_bel": 179, "belief_histogram": 179, "plot_value_threshold": 179, "threshold_arrai": 179, "value_arrai": 179, "yrang": 179, "star_loc": 179, "fig_": 179, "cost_sw": 179, "fist": 179, "init_t": 179, "rnd_tele": 179, "rnd_high_rwd": 179, "rnd_low_rwd": 179, "get_random": 179, "binomial_tel": 179, "getrandom": 179, "excerciseerror": 179, "assertionerror": [179, 180], "binaryhmm": 179, "fish_initi": 179, "loc_initi": 179, "fish_dynam": 179, "telegraph": 179, "p_stai": 179, "tele_oper": 179, "generate_process_lazi": 179, "rwd": 179, "p_low_rwd": 179, "p_high_rwd": 179, "p_rwd_vector": 179, "binaryhmm_belief": 179, "generate_process": 179, "low_rew_p": 179, "high_rew_p": 179, "rew_prob": 179, "belief_0": 179, "belief_upd": 179, "lazi": 179, "policy_threshold": 179, "policy_lazi": 179, "belief_past": 179, "rew_prob_matrix": 179, "belief_1": 179, "test_policy_threshold": 179, "well_don": 179, "test_value_funct": 179, "get_valu": 179, "value_funct": 179, "_gone_fishing_video": 179, "secretli": 179, "sw": 179, "q_": [179, 187], "price": 179, "prescrib": 179, "b_t": 179, "stay_prob": 179, "update_ex_1": 179, "swim": 179, "binaryhmm_test": 179, "_examining_fish_dynamics_interactive_demo_and_discuss": 179, "_catch_some_fish_video": 179, "seren": 179, "high_rew_prob": 179, "low_rew_prob": 179, "radiobutton": [179, 180], "update_ex_2": 179, "agent_initi": 179, "_examining_the_reward_function_interactive_demo_and_discuss": 179, "_where_are_the_fish_video": 179, "_examining_the_beliefs_interactive_demo_and_discuss": 179, "_how_should_you_act_video": 179, "239": 179, "_dynamics_threshold_based_policy_exercis": 179, "new_se": 179, "update_ex_4": 179, "_dynamics_with_different_thresholds_interactive_demo_and_discuss": 179, "_evaluate_policy_video": 179, "a_t": [179, 180, 188], "paid": 179, "actions_int": 179, "247": 179, "248": 179, "251": 179, "252": 179, "_implementing_a_value_function_exercis": 179, "brute": 179, "get_optimal_threshold": 179, "large_time_horizon": 179, "run_polici": 179, "_run_the_policy_exercise_and_discuss": 179, "mdp": 179, "illumin": 179, "_from_discrete_to_continuous_control_video": 179, "_sensitivity_of_optimal_policy_bonus_video": 179, "high_rwd": 179, "low_rwd": 179, "rarer": 179, "coars": 179, "update_ex_bonu": 179, "_explore_task_parameters_bonus_interactive_demo_and_discuss": 179, "w3d3_t2": 180, "plot_vs_tim": 180, "slabel": 180, "plot_kf_state_vs_tim": 180, "latent_st": 180, "standard_normal_nois": 180, "standard_normal_noise_mea": 180, "exerciseerror": 180, "test_lds_class": 180, "lds_class": 180, "ldsy": 180, "ini_st": 180, "noise_var": 180, "dynamics_openloop": 180, "dynamics_closedloop": 180, "test_lqr_class": 180, "lqr_class": 180, "lqreg": 180, "calculate_j_st": 180, "calculate_j_control": 180, "_flying_through_space_video": 180, "corros": 180, "unintend": 180, "ba_t": 180, "ds_t": 180, "neq": [180, 196, 197], "polici": [180, 186, 187, 189], "static_nois": 180, "_implement_state_evolution_equations_exercis": 180, "fare": 180, "simulate_ld": 180, "s_no_control": 180, "s_open_loop": 180, "s_closed_loop": 180, "a_closed_loop": 180, "_no_control_closed_lopp_open_loop_interactive_demo_and_discuss": 180, "optimum": 180, "ls_t": 180, "bl": 180, "calculate_plot_ms": 180, "num_iter": 180, "num_candid": 180, "control_gain_arrai": 180, "mse_arrai": 180, "ambiti": 180, "051": 180, "simulate_l": 180, "s_closed_loop_choic": 180, "l_theori": 180, "s_closed_loop_theoret": 180, "_closed_loop_exploration_interactive_demo_and_discuss": 180, "_lqr_video": 180, "fuel": 180, "certainli": 180, "riccati": 180, "dimitri": 180, "belmont": 180, "control_gain_lqr": 180, "p_t_1": 180, "j_state": 180, "j_control": 180, "_implement_the_cost_function_exercis": 180, "simulate_rho": 180, "s_lqr": 180, "a_lqr": 180, "_lqr_to_the_origin_interactive_demo_and_discuss": 180, "calculate_plot_cost": 180, "rho_arrai": 180, "_tracking_a_moving_goal_video": 180, "bounc": 180, "g_t": 180, "lqr_track": 180, "dynamics_track": 180, "a_bar": 180, "react": 180, "goal_func": 180, "simulate_track": 180, "lqr_time": 180, "s_lqr_time": 180, "a_lqr_tim": 180, "a_bar_lqr_tim": 180, "lqr_control_to_desired_time_varying_goal_interactive_demo_and_discuss": 180, "_lqg_video": 180, "radar": 180, "proc_nois": 180, "meas_nois": 180, "get_estim": 180, "observation_matrix": 180, "innov": 180, "ntrial": 180, "get_control_gain_infinit": 180, "control_policy_lqg": 180, "control_gain": 180, "estimated_st": 180, "current_act": [180, 196], "simulate_kf_no_control": 180, "ini_state_mean": 180, "ini_state_cov": 180, "_lqg_control_interactive_demo_and_discuss": 180, "simulate_kf_with_control": 180, "_lqc_controller_varying_gains_interactive_demo": 180, "simulate_kf_with_lqg": 180, "_lqc_controller_varying_weight_interactive_demo": 180, "lqg_slider": 180, "_process_noise_measurements_noise_interactive_demo": 180, "transit_matrix_slid": 180, "n_op": 180, "process_noise_var": 180, "measurement_noise_var": 180, "mse_array_n_mea": 180, "mse_array_n_proc": 180, "jcontrol_array_n_mea": 180, "jcontrol_array_n_proc": 180, "meas_noise_arrai": 180, "proc_noise_arrai": 180, "proc": 180, "mse_array_proc": 180, "jcontrol_array_proc": 180, "control_gain_lqg": 180, "filtered_state_means_impl": 180, "filtered_state_covariances_impl": 180, "action_cost": 180, "state_cost": 180, "mse_array_mea": 180, "jcontrol_array_mea": 180, "mse_array_proc_mean": 180, "mse_array_proc_std": 180, "mse_array_meas_mean": 180, "mse_array_meas_std": 180, "jcontrol_array_proc_mean": 180, "jcontrol_array_proc_std": 180, "jcontrol_array_meas_mean": 180, "jcontrol_array_meas_std": 180, "quantif": 180, "_noise_effects_on_the_lqg_discuss": 180, "sutton": 182, "barto": 182, "schultz": 182, "montagu": 182, "5306": 182, "1593": 182, "1599": 182, "utexa": 182, "dana": 182, "daw": 182, "dorsolater": 182, "striatal": 182, "1704": 182, "1711": 182, "nn1560": 182, "185": 182, "kurth": 182, "kumaran": 182, "tirumala": 182, "soyer": 182, "leibo": 182, "868": 182, "0147": 182, "295964": 182, "mattar": [182, 186, 187, 188, 189], "replai": 182, "1609": 182, "1617": 182, "0232": 182, "pmc6203620": 182, "dabnei": 182, "uchida": 182, "starkweath": 182, "hassabi": 182, "muno": 182, "dopamin": [182, 186], "577": 182, "7792": 182, "671": 182, "675": 182, "1924": 182, "pmc7476215": 182, "mnih": 182, "kavukcuoglu": 182, "rusu": 182, "veness": 182, "bellemar": 182, "518": 182, "7540": 182, "529": 182, "533": 182, "nature14236": 182, "huang": 182, "maddison": 182, "guez": 182, "sifr": 182, "driessch": 182, "game": 182, "7587": 182, "484": 182, "489": 182, "nature16961": 182, "w3d4_daysummari": 183, "exploit": [184, 187, 188], "dilemma": [184, 187], "w3d4_intro": 184, "w3d4_outro": 185, "marcelo": [186, 187, 188, 189], "sargent": [186, 187, 188, 189], "sowmya": [186, 187, 188, 189], "parthiban": [186, 187, 188, 189], "feryal": [186, 187, 188, 189], "behbahani": [186, 187, 188, 189], "jane": [186, 187, 188, 189], "ezekiel": [186, 187, 188, 189], "mehul": [186, 187, 188, 189], "rastogi": [186, 187, 188, 189], "roberto": [186, 187, 188, 189], "guidotti": [186, 187, 188, 189], "arush": [186, 187, 188, 189], "tagad": [186, 187, 188, 189], "kelson": [186, 187, 188, 189], "shill": [186, 187, 188, 189], "scrivo": [186, 187, 188, 189], "uncondit": 186, "conting": 186, "rpe": 186, "tap": 186, "w3d4_t1": 186, "plot_value_funct": 186, "plot_tde_trac": 186, "tde": 186, "fixedloc": 186, "learning_summary_plot": 186, "ex1": 186, "reward_guesser_title_hint": 186, "r1": 186, "r2": 186, "mildli": 186, "obfusc": 186, "spoil": 186, "classicalcondit": 186, "reward_magnitud": 186, "reward_tim": 186, "n_action": [186, 188, 189], "cs_time": 186, "reward_st": 186, "reward_prob": 186, "set_reward": 186, "_create_state_dictionari": 186, "get_outcom": [186, 188, 189], "current_st": 186, "next_stat": [186, 188, 189], "episod": [186, 187, 188, 189], "is_delai": 186, "t_in_delai": 186, "multirewardcc": 186, "deliv": 186, "probabilisticcc": 186, "p_reward": 186, "iti": 186, "quarter": 186, "rumelhart": 186, "pdplab": 186, "pdphandbook": 186, "handbookch10": 186, "limits_": 186, "sum_a": 186, "proxi": [186, 193], "delta_": [186, 195], "discrep": 186, "tl": 186, "td_learner": 186, "env": [186, 188, 189], "_td_learning_exercis": 186, "saliv": 186, "smell": 186, "tasti": 186, "pavlov": 186, "ring": 186, "inconsist": 186, "plot_tde_by_tri": 186, "basefmt": 186, "linefmt": 186, "markerfmt": 186, "c1d": 186, "c0o": 186, "_us_to_cs_transfer_interactive_demo": 186, "plot_summary_alpha_gamma": 186, "980": 186, "\u03b3": 186, "v_param": 186, "tde_param": 186, "_learning_rates_and_discount_factors_interactive_demo_and_discuss": 186, "learner": 186, "dispens": 186, "rng_state": 186, "get_stat": 186, "v_multi": 186, "tde_multi": 186, "reward_guesser_interact": 186, "inttext": 186, "env2": 186, "v_guess": 186, "yo": 186, "set_markers": 186, "set_markerfacecolor": 186, "rx": 186, "_examining_the_td_error_discuss": 186, "intermitt": 186, "set_stat": 186, "resynchron": 186, "v_stochast": 186, "tde_stochast": 186, "_probabilistic_rewards_discuss": 186, "bewar": 186, "_removing_the_cs_bonus_discuss": 186, "w3d4_t2": 187, "plot_choic": 187, "choice_fn": 187, "rng_seed": 187, "plot_multi_armed_bandit_result": 187, "qs": 187, "plot_parameter_perform": 187, "trial_reward": 187, "trial_optim": 187, "_multiarmed_bandits_video": 187, "colloqui": 187, "lever": 187, "rig": 187, "monei": 187, "payout": 187, "r_t": [187, 188], "fatal": 187, "flaw": 187, "trap": 187, "bet": 187, "regret": 187, "stumbl": 187, "epsilon_greedi": [187, 188, 189], "be_greedi": [187, 189], "_implement_epsilon_greedy_exercis": 187, "amongst": 187, "\u03b5": 187, "explore_epilson_valu": 187, "_changing_epsilon_interactive_demo_and_discuss": 187, "q_t": 187, "update_action_valu": 187, "_updating_action_values_exercis": 187, "multi_armed_bandit": 187, "n_arm": 187, "all_reward": 187, "optimal_act": 187, "alright": 187, "explore_bandit_paramet": 187, "worst": 187, "_changing_epsilon_and_alpha_interactive_demo": 187, "bandit": [188, 189], "w3d4_t3": 188, "plot_state_action_valu": [188, 189], "n_state": [188, 189], "plot_quiver_max_act": [188, 189], "cheese_world": [188, 189], "dim_x": [188, 189], "dim_i": [188, 189], "which_max": [188, 189], "minor": [188, 189], "plot_heatmap_max_v": [188, 189], "value_max": [188, 189], "afmhot": [188, 189], "windy_cliff_grid": [188, 189], "plot_reward": [188, 189], "n_episod": [188, 189], "average_rang": [188, 189], "smoothed_reward": [188, 189], "plot_perform": [188, 189], "reward_sum": [188, 189], "_mdps_and_q_learning_video": 188, "overcom": 188, "cliff": [188, 189], "4x10": 188, "td": 188, "watkin": 188, "max_": [188, 189], "discount": [188, 189], "greedi": [188, 189], "learn_environ": [188, 189], "lifecycl": 188, "cliffworld": 188, "border": [188, 189], "cliff_world": 188, "init_st": [188, 189], "get_all_outcom": [188, 189], "learning_rul": 188, "q_learn": [188, 189], "max_next_q": 188, "td_error": 188, "value_qlearn": 188, "reward_sums_qlearn": 188, "110": 188, "113": 188, "_implement_q_learning_algorithm_exercis": 188, "notabl": 188, "steadili": 188, "policy_next_q": 188, "policy_act": 188, "value_sarsa": 188, "reward_sums_sarsa": 188, "_implement_the_sarsa_algorithm_bonus_exercis": 188, "skittish": 188, "standpoint": 188, "skirt": 188, "wall": [188, 189], "rout": 188, "w3d4_t4": 189, "prev_valu": 189, "isnan": [189, 196, 197], "max_valu": 189, "model_updat": 189, "shortcut_episod": 189, "episode_step": 189, "toggle_shortcut": 189, "quentinsworld": 189, "quentin": 189, "shortcut_st": 189, "_modelbased_rl_video": 189, "costli": 189, "fuller": 189, "assimil": 189, "10x10": 189, "trivial": 189, "tabular": 189, "forev": 189, "nontermin": 189, "dyna_q_model_upd": 189, "_dynaq_model_update_exercis": 189, "dyna_q_plan": 189, "nx2": 189, "_dynaq_planning_exercis": 189, "n_experi": 189, "planning_step": 189, "steps_per_episod": 189, "warm": 189, "upward": 189, "consolid": 189, "hernan": [191, 195], "robin": 191, "readabl": 191, "charit": 191, "dag": 191, "angrist": [191, 195], "pischk": [191, 195], "princeton": 191, "harmless": [191, 195], "imben": [191, 195], "aschengrau": 191, "seag": 191, "health": 191, "jone": 191, "bartlett": 191, "dominik": 191, "bernhard": 191, "cooper": 191, "herskovit": 191, "1992": 191, "induct": 191, "309": 191, "bf00994110": 191, "amari": 191, "arai": 191, "diekman": 191, "diesmann": 191, "kramer": 191, "041715": 191, "033733": 191, "126718": 191, "annrev2017fin": 191, "marinescu": 191, "lawlor": 191, "quasi": 191, "891": 191, "898": 191, "s41562": 191, "0466": 191, "econ": 191, "quasiexperiment": 191, "mooij": 191, "janz": 191, "zscheischler": 191, "sch\u00f6lkopf": 191, "1204": 191, "acm": 191, "5555": 191, "2946645": 191, "2946677": 191, "b\u00fchlmann": 191, "meinshausen": 191, "identif": 191, "royal": 191, "947": 191, "1012": 191, "1111": 191, "rssb": 191, "12167": 191, "01332": 191, "scholkopf": 191, "judea": [191, 193], "765": 191, "804": 191, "3501714": 191, "3501755": 191, "1911": 191, "10500": 191, "shimizu": 191, "hoyer": 191, "hyv\u00e4rinen": 191, "kerminen": 191, "jordan": 191, "acycl": 191, "jmlr": 191, "v7": 191, "shimizu06a": 191, "spirt": 191, "glymour": 191, "schein": 191, "heckerman": 191, "causat": [191, 197, 198], "triantafil": 191, "tsamardino": 191, "2147": 191, "2205": 191, "v16": 191, "triantafillou15a": 191, "w3d5_daysummari": 192, "drug": [193, 195], "mislead": 193, "unmeasur": 193, "unavoid": 193, "w3d1": 193, "bedrock": 193, "heart": 193, "w3d5_intro": 193, "w3d5_outro": 194, "toni": [195, 196, 197, 198], "mike": [195, 196, 197, 198], "cohen": [195, 196, 197, 198], "yoni": [195, 196, 197, 198], "pproduct": 195, "w3d5_t1": 195, "see_neuron": [195, 196, 197, 198], "renorm": 195, "plot_connectivity_matrix": [195, 196, 197], "set_siz": [195, 196], "plot_connectivity_graph_matrix": 195, "plot_neural_act": [195, 198], "cax1": [195, 198], "plot_true_vs_estimated_connect": [195, 196], "estimated_connect": [195, 196, 197, 198], "true_connect": [195, 196], "selected_neuron": [195, 196, 198], "_defining_causality_video": 195, "rct": 195, "placebo": 195, "neuron_b": 195, "activity_of_a": 195, "diff_in_mean": 195, "9907195190159408": 195, "_randomized_controlled_trial_for_two_neurons_exercis": 195, "_simulated_neural_system_model_video": 195, "nonlinearli": 195, "i_n": 195, "create_connect": [195, 196, 197, 198], "nxn": [195, 196, 197, 198], "s_val": [195, 196, 197, 198], "s_val_test": [195, 198], "singular": [195, 198], "simulate_neuron": [195, 196, 197, 198], "timetep": [195, 196, 197, 198], "___t____t": 195, "1___": 195, "___1____0_____": 195, "_system_simulation_exercis": 195, "_perturbing_systems_video": 195, "frac1n": 195, "substack": 195, "interven": 195, "simulate_neurons_perturb": 195, "seriou": 195, "huh": 195, "x_perturb": 195, "boilerpl": 195, "cax0": 195, "_calculating_causality_video": 195, "start_index": 195, "end_index": 195, "count_bi": 195, "get_perturbed_connectivity_from_single_neuron": 195, "perturbed_x": 195, "neuron_perturb": 195, "all_neuron_output": 195, "this_neuron_output": 195, "one_idx": 195, "zero_idx": 195, "get_perturbed_connectivity_single_neuron": 195, "difference_in_mean": 195, "_perturbed_dynamics_to_recover_connectivity_exercis": 195, "strictli": [195, 196], "get_perturbed_connectivity_all_neuron": 195, "2n": 195, "987593404378358": 195, "econometr": 195, "proportion": 195, "w3d5_t2": 196, "plot_estimation_quality_vs_n_neuron": 196, "number_of_neuron": 196, "corr_func": 196, "corr_data": [196, 197, 198], "get_sys_corr": [196, 197, 198], "corr_mean": [196, 197, 198], "corr_std": [196, 197, 198], "correlation_for_all_neuron": [196, 197, 198], "_correlation_vs_causation_video": 196, "compute_connectivity_from_single_neuron": 196, "next_act": 196, "this_output_act": 196, "_approximate_causation_with_correlation_exercis": 196, "5f": 196, "95967": 196, "_correlation_causation_for_small_systems_video": 196, "_correlation_causation_in_large_systems_video": 196, "plot_corr": 196, "_function_base_impl": [196, 197], "2922": [196, 197], "runtimewarn": [196, 197], "invalid": [196, 197], "stddev": [196, 197], "2923": [196, 197], "_connectivity_estimation_as_a_function_of_number_of_neurons_interactive_demo": 196, "rightli": 196, "wonder": [196, 197, 198], "_connectivity_estimation_as_a_function_of_the_sparsity_a_interactive_demo": 196, "phrase": 196, "filler": 196, "mediat": 196, "promot": 196, "_reflecting_on_causality_discuss": 196, "spearman": 196, "dichotom": 196, "concord": 196, "kappa": 196, "braini": 196, "coarse_x": 196, "get_coarse_corr": 196, "n_group": 196, "coarse_a": 196, "_compute_average_activity_bonus_exercis": 196, "neffect": 196, "controversi": 197, "w3d5_t3": 197, "multioutput": [197, 198], "multioutputregressor": [197, 198], "ratio_observ": 197, "_regression_approach_video": 197, "confound": [197, 198], "homework": 197, "grade": 197, "confond": 197, "collid": 197, "counterintuit": 197, "_fitting_a_glm_video": 197, "logit": [197, 198], "l_1": 197, "fit_intercept": [197, 198], "get_regression_estim": [197, 198], "865": 197, "703": 197, "_linear_regression_with_lasso_to_estimate_causal_connectivities_exercis": 197, "_omitted_variable_bias_video": 197, "sel_idx": [197, 198], "set_text": [197, 198], "046": [197, 198], "get_regression_estimate_full_connect": [197, 198], "get_regression_corr_full_connect": [197, 198], "reg": [197, 198], "n_job": [197, 198], "estimators_": [197, 198], "observed_ratio": [197, 198], "regression_arg": [197, 198], "sel_x": [197, 198], "sel_a": [197, 198], "sel_v": [197, 198], "4000": 197, "reg_arg": [197, 198], "n_observ": [197, 198], "to_neuron": 197, "big_r": [197, 198], "nanmean": 197, "nanstd": 197, "_coordinate_desc": 197, "695": 197, "convergencewarn": 197, "dualiti": 197, "194e": 197, "991e": 197, "cd_fast": 197, "enet_coordinate_desc": 197, "035e": 197, "170e": 197, "444e": 197, "037e": 197, "527e": 197, "297e": 197, "612e": 197, "502e": 197, "267e": 197, "659e": 197, "571e": 197, "069e": 197, "205e": 197, "716e": 197, "784e": 197, "325e": 197, "105e": 197, "815e": 197, "791e": 197, "903e": 197, "111e": 197, "913e": 197, "089e": 197, "599e": 197, "302e": 197, "114e": 197, "078e": 197, "658e": 197, "171e": 197, "299e": 197, "018e": 197, "731e": 197, "472e": 197, "109e": 197, "636e": 197, "693e": 197, "060e": 197, "243e": 197, "154e": 197, "479e": 197, "467e": 197, "440e": 197, "260e": 197, "721e": 197, "617e": 197, "637e": 197, "640e": 197, "633e": 197, "605e": 197, "259e": 197, "183e": 197, "021e": 197, "204e": 197, "223e": 197, "172e": 197, "555e": 197, "058e": 197, "365e": 197, "163e": 197, "059e": 197, "291e": 197, "818e": 197, "122e": 197, "162e": 197, "352e": 197, "268e": 197, "813e": 197, "262e": 197, "152e": 197, "719e": 197, "390e": 197, "202e": 197, "340e": 197, "522e": 197, "547e": 197, "700e": 197, "904e": 197, "419e": 197, "428e": 197, "013e": 197, "687e": 197, "523e": 197, "683e": 197, "236e": 197, "665e": 197, "632e": 197, "873e": 197, "514e": 197, "002e": 197, "649e": 197, "361e": 197, "023e": 197, "741e": 197, "238e": 197, "406e": 197, "129e": 197, "656e": 197, "778e": 197, "394e": 197, "720e": 197, "902e": 197, "908e": 197, "739e": 197, "495e": 197, "708e": 197, "896e": 197, "932e": 197, "575e": 197, "446e": 197, "790e": 197, "209e": 197, "333e": 197, "165e": 197, "312e": 197, "862e": 197, "702e": 197, "094e": 197, "758e": 197, "478e": 197, "846e": 197, "533e": 197, "073e": 197, "124e": 197, "149e": 197, "776e": 197, "977e": 197, "159e": 197, "217e": 197, "102e": 197, "723e": 197, "001e": 197, "556e": 197, "173e": 197, "535e": 197, "413e": 197, "232e": 197, "339e": 197, "226e": 197, "151e": 197, "598e": 197, "910e": 197, "253e": 197, "940e": 197, "304e": 197, "768e": 197, "679e": 197, "676e": 197, "265e": 197, "043e": 197, "539e": 197, "512e": 197, "272e": 197, "578e": 197, "448e": 197, "497e": 197, "507e": 197, "355e": 197, "221e": 197, "344e": 197, "328e": 197, "883e": 197, "189e": 197, "865e": 197, "500e": 197, "317e": 197, "905e": 197, "096e": 197, "462e": 197, "751e": 197, "015e": 197, "284e": 197, "263e": 197, "797e": 197, "577e": 197, "916e": 197, "120e": 197, "435e": 197, "973e": 197, "764e": 197, "278e": 197, "878e": 197, "432e": 197, "042e": 197, "395e": 197, "049e": 197, "468e": 197, "178e": 197, "255e": 197, "364e": 197, "252e": 197, "674e": 197, "965e": 197, "029e": 197, "834e": 197, "714e": 197, "032e": 197, "837e": 197, "367e": 197, "713e": 197, "303e": 197, "863e": 197, "476e": 197, "466e": 197, "737e": 197, "684e": 197, "224e": 197, "130e": 197, "415e": 197, "_regression_performance_as_a_function_of_the_number_of_observed_neurons_interactive_demo": 197, "_summari": 197, "w3d5_t4": 198, "linearregress": 198, "compare_granger_connect": 198, "reject_nul": 198, "selecte_neuron": 198, "plot_performance_vs_eta": 198, "matri": 198, "print_corr": 198, "idx_dict": 198, "text_dict": 198, "tax": 198, "cigarett": 198, "statu": 198, "get_regression_corr": 198, "_instrumental_variables_video": 198, "wild": 198, "smoke": 198, "pregnant": 198, "wealth": 198, "tobacco": 198, "consumpt": 198, "z_": 198, "socioeconom": 198, "wealthier": 198, "birthweight": 198, "child": 198, "gram": 198, "3000": 198, "2t_": 198, "mother": 198, "babi": 198, "lighter": 198, "covar": 198, "483": 198, "740": 198, "unconfound": 198, "_stage_1_video": 198, "fit_first_stag": 198, "t_hat": 198, "stage1": 198, "t_c_corr": 198, "t_hat_c_corr": 198, "_compute_regression_stage_1_exercis": 198, "_stage_2_video": 198, "fit_second_stag": 198, "stage2": 198, "984": 198, "_compute_the_iv_estimate_exercis": 198, "ivs_in_simulated_neural_systems_video": 198, "wire": 198, "radio": 198, "simulate_neurons_iv": 198, "iv_on_this_timestep": 198, "_simulate_a_system_with_iv_exercis": 198, "get_iv_estimate_network": 198, "x_hati": 198, "corr_": 198, "_ivs_and_omitted_variable_bias_video": 198, "sel_z": 198, "iv_corr": 198, "big_v": 198, "reg_corr": 198, "compare_iv_estimate_to_regress": 198, "sel_reg_v": 198, "sel_iv_v": 198, "ncorrel": 198, "_estimating_connectivity_with_iv_vs_regression_interactive_demo": 198, "threat": 198, "discussion_questions_discuss": 198, "instrument_strength_effect": 198, "iv_v": 198, "_exploring_instrument_strength_bonus_exercis": 198, "h_a": 198, "retain": 198, "b_1": 198, "statsmodel": 198, "tsa": 198, "stattool": 198, "grangercausalitytest": 198, "get_granger_caus": 198, "bonferroni": 198, "p_val": 198, "max_lag": 198, "target_neuron": 198, "ts_data": 198, "pval": 198, "lrtest": 198, "_evaluate_granger_causality_bonus_exercis": 198, "advic": 199, "isabel": 199, "brush": 199}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"prerequisit": [0, 83, 92, 103, 159, 167], "preparatori": 0, "materi": 0, "nma": [0, 129], "comput": [0, 68, 73, 74, 79, 86, 87, 94, 97, 98, 99, 108, 123, 136, 137, 144, 145, 147, 153, 154, 155, 161, 195, 196, 198], "neurosci": [0, 73, 74, 90, 108, 131, 182], "prepar": [0, 31, 32, 33], "yourself": 0, "cours": [0, 19, 37], "program": 0, "math": [0, 61, 72, 73, 79, 161], "skill": 0, "overview": [1, 5, 20, 27, 29, 37, 61, 83, 92, 103, 110, 119, 127, 133, 142, 151, 159, 167, 169, 175, 177, 182, 184, 193, 199], "video": [1, 5, 20, 21, 22, 27, 29, 30, 31, 32, 33, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 83, 84, 85, 86, 87, 92, 93, 94, 95, 96, 97, 98, 99, 103, 104, 105, 106, 110, 111, 112, 113, 114, 115, 119, 120, 121, 122, 123, 124, 128, 129, 133, 134, 135, 136, 137, 138, 142, 143, 144, 145, 146, 147, 151, 152, 153, 154, 155, 159, 160, 161, 162, 163, 167, 168, 169, 170, 171, 172, 173, 177, 178, 179, 180, 184, 185, 186, 187, 188, 189, 193, 194, 195, 196, 197, 198, 199], "ted": 1, "talk": 1, "kai": [1, 16, 19, 20], "miller": 1, "watch": 1, "until": 1, "15": [1, 171], "45": 1, "guid": [2, 4, 12, 19, 25, 26], "choos": [2, 4, 19, 26, 31, 106, 187], "an": [2, 19, 61, 69, 74, 85, 112, 144, 147, 163, 169, 170, 180, 187, 198], "eeg": [2, 15, 57], "ecog": [2, 6], "lfp": [2, 56], "dataset": [2, 4, 8, 13, 16, 19, 20, 26, 27, 31, 32, 33, 85, 96, 117], "refer": [2, 19, 26, 73, 74], "face": [2, 13], "hous": 2, "fingerflex": 2, "joystick": 2, "track": [2, 147, 172, 180], "memori": [2, 4, 13, 155], "nback": 2, "direct": [2, 144], "see": [2, 37], "motor": [2, 4, 13], "imageri": 2, "explor": [2, 13, 85, 94, 95, 113, 144, 146, 153, 161, 162, 179, 180, 198], "ajile12": [2, 13], "project": [3, 4, 11, 12, 13, 16, 21, 23, 24, 37, 112, 113, 129], "behavior": [4, 5, 7, 13, 14, 53, 73], "caltech": [4, 5], "ibl": [4, 5], "laquitain": 4, "gardner": 4, "neuron": [4, 10, 17, 26, 51, 61, 63, 72, 85, 86, 87, 139, 140, 144, 145, 146, 147, 149, 153, 173, 195, 196, 197, 198], "2017": 4, "theori": [4, 7, 18, 79], "work": [4, 13, 37, 108, 155, 198], "rnn": [4, 13], "databas": 4, "model": [4, 12, 13, 21, 22, 23, 24, 25, 33, 37, 61, 67, 73, 74, 78, 80, 85, 86, 87, 88, 89, 90, 95, 97, 98, 99, 100, 105, 106, 117, 123, 124, 125, 131, 137, 138, 139, 140, 144, 146, 147, 149, 153, 154, 155, 157, 163, 165, 169, 170, 173, 189, 195, 197], "addit": 4, "resourc": 4, "mous": [5, 13], "social": [5, 13], "bay": [5, 79, 161, 162, 163], "heurist": 5, "fmri": [9, 13, 16, 19, 20, 58], "2020": 11, "daili": [12, 37, 66, 77], "summari": [12, 21, 23, 24, 31, 32, 33, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 85, 86, 87, 91, 94, 95, 96, 97, 98, 99, 102, 105, 106, 109, 112, 113, 114, 115, 118, 121, 122, 123, 126, 129, 132, 135, 136, 137, 138, 141, 144, 145, 146, 147, 150, 153, 154, 158, 161, 162, 163, 166, 169, 170, 171, 176, 179, 180, 183, 186, 187, 188, 189, 192, 195, 196, 197, 198], "submiss": 12, "link": [12, 13, 43, 73, 74, 182], "templat": [12, 13], "ta": 12, "mentor": 12, "week": 12, "1": [12, 21, 24, 31, 32, 33, 60, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 117, 120, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "get": [12, 85], "start": [12, 74], "w1d1": 12, "w1d2": 12, "w1d3": 12, "w1d5": 12, "look": [12, 33, 69], "ahead": 12, "first": 12, "dai": [12, 37, 65, 71, 73, 74, 76, 82, 91, 102, 109, 118, 126, 132, 141, 150, 158, 166, 176, 183, 192], "w2d1": [12, 37], "2": [12, 21, 24, 31, 32, 33, 61, 62, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 105, 106, 112, 113, 114, 115, 117, 120, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "read": [12, 21, 22, 26, 73, 74, 81, 90, 101, 108, 117, 129, 131, 140, 149, 157, 165, 171, 175, 182, 191], "write": [12, 22, 37], "data": [12, 21, 23, 85, 87, 98, 105, 106, 112, 113, 114, 121, 122, 123, 124, 129, 138, 157, 163, 172, 173], "analysi": [12, 31, 108, 113, 149, 153, 154, 155, 157], "half": [12, 37], "tutori": [12, 21, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 117, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "block": 12, "task": [12, 13, 19, 20, 121, 123, 179], "w2d2": 12, "w2d5": [12, 37], "abstract": [12, 22, 24, 37], "WITH": 12, "your": [12, 21, 29, 30, 31, 32, 33, 37, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "group": [12, 196], "pod": 12, "back": 12, "IN": 12, "bonu": [12, 31, 32, 67, 69, 72, 74, 79, 86, 87, 94, 95, 98, 99, 105, 106, 113, 114, 121, 122, 123, 124, 144, 145, 146, 147, 153, 155, 161, 163, 169, 172, 173, 179, 186, 188, 195, 196, 198], "w3": 12, "time": [12, 37, 61, 136, 140, 144, 145, 147, 154, 169, 171, 180], "w3d5": [12, 37], "final": [12, 23, 24, 37], "present": 12, "schedul": [12, 37, 38], "logist": [12, 106], "content": 12, "question": [12, 21, 23, 24, 129, 172, 198], "flow": 13, "inform": [13, 87, 99, 162], "through": [13, 67, 171, 180, 195], "brain": [13, 55, 56, 57, 58, 59, 74, 79, 108, 117], "dure": [13, 173], "sensorimotor": 13, "effect": [13, 73, 106, 112, 144, 145, 147, 155, 180], "stimulu": [13, 49, 163], "context": 13, "state": [13, 21, 129, 136, 153, 161, 162, 171, 179, 180, 182], "visual": [13, 31, 32, 72, 85, 114, 115, 121, 122, 123, 124, 147, 153], "represent": [13, 31, 49, 123], "cortex": 13, "map": [13, 199], "activ": [13, 31, 55, 69, 74, 85, 105, 121, 122, 123, 145, 153, 154, 155, 196], "retinotop": 13, "navig": 13, "afford": 13, "scene": 13, "select": [13, 22, 23, 24, 90, 98, 99, 106], "respons": [13, 121, 144, 145, 163], "differ": [13, 33, 87, 97, 106, 114, 115, 144, 146, 154, 162, 179, 186], "region": 13, "depend": [13, 23, 32, 67, 72, 140, 147, 172, 179], "decis": [13, 24, 156, 161, 162, 163, 165, 188], "make": [13, 63, 161, 165], "mice": 13, "perform": [13, 113, 114, 124, 197], "2afc": 13, "The": [13, 31, 61, 67, 73, 74, 86, 87, 106, 129, 137, 144, 162, 169, 171, 172, 180], "capac": 13, "recurr": [13, 153], "neural": [13, 67, 68, 69, 72, 74, 106, 121, 122, 123, 124, 153, 157, 195, 198], "network": [13, 117, 121, 122, 123, 124, 145, 148, 149, 153, 155, 173, 190, 196], "attractor": 13, "doe": [13, 171, 179, 180], "reflect": [13, 85, 86, 87, 196], "percept": 13, "structur": [13, 97], "probe": 13, "dynam": [13, 34, 69, 131, 135, 140, 146, 148, 153, 164, 169, 171, 172, 179, 180, 195], "human": [13, 16, 52], "estim": [13, 79, 94, 95, 96, 97, 162, 163, 171, 195, 196, 197, 198], "error": [13, 74, 94, 98, 124, 186], "bayesian": [13, 79, 156, 161, 162], "framework": 13, "function": [13, 21, 23, 31, 32, 33, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "learn": [13, 35, 106, 116, 117, 122, 173, 181, 186, 187, 188, 189, 191], "connectom": 16, "stringer": [17, 26, 27], "steinmetz": [17, 26, 27, 85], "hcp": [19, 20], "fsl": 19, "retinotopi": [19, 20], "natur": 19, "imag": [19, 33, 59], "bonner": [19, 20], "algonaut": [19, 20], "cichi": [19, 20], "gallant": 20, "2021": 20, "fslcours": 20, "step": [21, 22, 25, 45, 72, 74, 129, 172, 173], "4": [21, 31, 32, 33, 61, 63, 67, 68, 72, 73, 74, 78, 79, 85, 87, 88, 95, 97, 106, 112, 114, 115, 129, 135, 138, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 187, 189, 195, 196, 197, 198], "object": [21, 22, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "demo": [21, 63, 67, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 106, 112, 113, 114, 129, 135, 136, 137, 144, 146, 147, 153, 154, 155, 161, 162, 169, 170, 171, 172, 179, 180, 186, 187, 196, 197, 198], "introduct": [21, 31, 32, 33, 67, 72, 73, 96, 121, 122, 129, 161, 162, 163, 170, 172, 173, 186, 199], "setup": [21, 23, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "plot": [21, 23, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "gener": [21, 24, 37, 69, 78, 79, 90, 100, 105, 112, 124, 129, 140, 144, 163, 173], "find": [21, 79, 95, 112, 129, 136, 153, 155, 171], "phenomenon": [21, 23, 24, 129], "ask": [21, 129], "about": [21, 26, 67, 72, 73, 106, 129, 198], "exampl": [21, 23, 24, 67, 73, 79, 90, 129, 147, 155, 162, 198], "think": [21, 67, 68, 73, 74, 78, 79, 85, 86, 87, 88, 115, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 161, 186, 196, 198], "own": [21, 171], "understand": [21, 68, 69, 72, 74, 122, 123, 129, 138], "art": [21, 129, 182], "background": [21, 23, 24, 129], "3": [21, 24, 31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 95, 96, 97, 106, 112, 114, 121, 122, 123, 124, 129, 135, 136, 137, 144, 145, 146, 147, 153, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "literatur": [21, 129], "review": [21, 117, 129, 172], "knowledg": [21, 83, 92, 103, 129], "determin": [21, 123, 129, 137], "basic": [21, 61, 79, 129], "ingredi": [21, 23, 24, 129], "formul": [21, 129, 136], "specif": [21, 37, 129], "mathemat": [21, 113, 129, 154], "defin": [21, 61, 67, 69, 112, 129, 173, 195], "hypothes": [21, 23, 24, 129], "5": [21, 22, 32, 61, 63, 67, 68, 72, 73, 74, 78, 79, 85, 87, 98, 106, 129, 161, 162, 163, 169, 170, 171, 172, 173, 179, 195, 198], "hypothesi": [21, 129], "next": 21, "10": [22, 61, 63, 161, 171], "toolkit": [22, 23, 24], "6": [22, 33, 61, 63, 67, 72, 74, 79, 99, 129, 161, 162, 163, 169, 170, 171, 179, 198], "plan": [22, 189], "draft": [22, 23, 24], "7": [22, 61, 63, 67, 79, 161, 162, 163, 170, 171, 179], "implement": [22, 23, 24, 69, 99, 106, 113, 147, 153, 163, 171, 172, 173, 179, 180, 187, 188], "8": [22, 61, 63, 161, 162, 163, 171], "complet": [22, 23, 24], "9": [22, 61, 63, 161, 162, 171], "test": [22, 23, 24, 98, 124, 169], "evalu": [22, 23, 24, 97, 106, 123, 124, 179, 198], "publish": 22, "11": [22, 61, 63, 171], "paper": [22, 117, 191], "guidanc": 22, "suggest": [22, 81, 90, 101, 108, 117, 131, 140, 149, 157, 165, 175, 182, 191, 198], "train": [23, 24, 31, 32, 33, 85, 98, 106, 124, 145, 173], "illus": [23, 24], "instal": [23, 29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "helper": [23, 31, 32, 33, 63, 69, 73, 74, 98, 99, 106, 113, 114, 121, 122, 123, 124, 138, 145, 146, 147, 154, 155, 161, 162, 163, 169, 171, 173, 179, 180, 186, 189, 196, 197, 198], "thought": [23, 24], "vestibular": 24, "signal": [24, 55, 56, 57, 58, 59, 86], "integr": [24, 61, 72, 73, 74, 86, 135, 144, 154], "ddm": [24, 169], "mechan": 24, "threshold": [24, 169, 179], "assembl": 24, "allen": [26, 27], "institut": [26, 27], "you": [26, 179], "can": [26, 106], "more": [26, 74, 106, 161, 162], "scientif": 26, "discoveri": 26, "relat": 26, "thi": [26, 163], "our": [26, 37, 195, 198], "preprint": 26, "autoencod": [28, 31, 32, 33], "intro": [29, 31, 48, 61, 67, 68, 74, 78, 83, 92, 103, 110, 113, 114, 115, 117, 119, 127, 133, 142, 151, 159, 163, 167, 175, 177, 184, 193], "import": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "feedback": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "gadget": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "slide": [29, 30, 83, 84, 92, 93, 103, 104, 110, 111, 119, 120, 133, 134, 142, 143, 151, 152, 159, 160, 167, 168, 177, 178, 183, 184, 185, 193, 194], "submit": [29, 30, 31, 32, 33, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 65, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 133, 134, 135, 136, 137, 138, 141, 142, 143, 144, 145, 146, 147, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 176, 177, 178, 179, 180, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198], "outro": [30, 66, 77, 84, 90, 93, 104, 108, 111, 117, 120, 128, 131, 134, 143, 152, 160, 163, 168, 175, 178, 185, 194], "intern": [31, 74], "figur": [31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "set": [31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 129, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "section": [31, 32, 33, 61, 63, 67, 68, 69, 72, 73, 74, 78, 79, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 162, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "0": [31, 32, 33, 67, 72, 73, 113, 114, 115, 121, 129, 146, 161, 162, 169, 170, 172, 173], "mnist": [31, 32, 33, 114, 115], "download": [31, 32, 33, 87], "sampl": [31, 61, 78, 106, 112, 113, 135, 172, 196], "latent": [31, 32, 33, 172], "space": [31, 32, 33, 67, 68, 180], "pca": [31, 108, 113, 114, 115], "code": [31, 32, 33, 61, 63, 67, 68, 69, 72, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "exercis": [31, 32, 33, 61, 63, 67, 68, 69, 72, 74, 78, 79, 85, 86, 87, 94, 95, 96, 97, 98, 99, 105, 106, 112, 113, 114, 115, 121, 122, 123, 124, 135, 136, 137, 138, 144, 145, 146, 147, 153, 154, 155, 161, 163, 169, 170, 171, 172, 173, 179, 180, 186, 187, 188, 189, 195, 196, 197, 198], "2d": [31, 32, 61, 72, 115, 122, 162], "qualit": [31, 123], "ann": [31, 33], "design": [31, 97, 105, 180], "32d": 31, "loss": [31, 121, 124, 162], "express": [31, 121], "power": 31, "wrap": [31, 32, 33, 34, 35, 36], "up": [31, 32, 33, 34, 35, 36, 85, 106, 123, 180], "failur": [31, 196], "mode": 31, "relu": 31, "unit": [31, 124], "weight": [31, 114, 122, 124, 147, 180], "initi": [31, 69, 73, 135, 153, 154, 173], "nmf": 31, "extens": [32, 144], "architectur": 32, "deeper": [32, 124], "build": [32, 123], "spheric": 32, "3d": 32, "deep": [32, 116, 117, 121, 122, 123], "surfac": 32, "s_2": 32, "thick": 32, "applic": [33, 72, 115, 147], "pre": [33, 147], "nois": [33, 95, 114, 144, 145, 180], "reconstruct": [33, 114], "befor": 33, "fine": 33, "tune": [33, 123, 124], "noisi": [33, 144, 153], "global": 33, "shift": 33, "occlus": 33, "after": [33, 37], "rotat": 33, "what": [33, 67, 72, 74, 85, 106, 122, 140, 145, 161], "would": 33, "digit": 33, "like": 33, "we": [33, 67, 72, 73, 106], "had": 33, "never": 33, "seen": 33, "remov": [33, 186], "most": 33, "domin": 33, "class": [33, 63, 186], "same": 33, "system": [34, 68, 69, 74, 108, 130, 131, 135, 153, 155, 172, 180, 195, 196, 197, 198], "podcast": [34, 35, 36, 73, 74], "panel": [34, 35, 36], "discuss": [34, 35, 36, 74, 88, 123, 161, 169, 170, 171, 172, 198], "machin": [35, 191], "stochast": [36, 78, 121, 137], "process": [36, 136, 137, 138, 144, 173, 180, 188], "For": [37, 61], "updat": [37, 187, 189], "annual": 37, "date": 37, "pleas": 37, "websit": 37, "coursework": 37, "slot": 37, "widget": [37, 40], "full": [37, 106], "convert": 37, "local": 37, "zone": 37, "chang": [37, 69, 72, 73, 74, 112, 147, 155, 170, 187, 189], "2025": 37, "all": [37, 74], "come": 37, "practic": [37, 125], "propos": 37, "share": 39, "calendar": 39, "timezon": 40, "us": [41, 42, 44, 45, 61, 63, 67, 69, 72, 74, 106, 114, 115, 117, 121, 171, 180, 186, 195, 197, 198], "discord": 41, "jupyterbook": 42, "quick": 43, "polici": [43, 179, 188], "googl": 44, "colab": 44, "advic": 44, "kaggl": 45, "technic": [46, 165], "help": 46, "neuro": [47, 198], "seri": 47, "neurotransmitt": 50, "conscious": 51, "psychophys": 52, "readout": 53, "live": 54, "lab": 54, "spike": [55, 61, 63, 73, 85, 86, 87, 105, 140, 144, 145, 147, 149, 173], "meg": 57, "calcium": 59, "python": [60, 61, 62, 72, 144], "workshop": [60, 62], "lif": [61, 63, 73, 74, 86, 144, 146, 147], "part": [61, 63, 74, 172], "i": [61, 144, 146, 153, 154, 155], "comment": 61, "nano": [61, 63], "recap": [61, 63], "string": 61, "paramet": [61, 73, 78, 79, 106, 137, 138, 144, 153, 155, 162, 173, 179], "oper": [61, 67, 72], "simul": [61, 137, 144, 146, 147, 153, 154, 169, 170, 171, 173, 195, 196, 198], "input": [61, 72, 73, 86, 144, 145, 146, 147, 153, 163, 180], "current": [61, 144], "print": 61, "format": [61, 106], "pretti": 61, "number": [61, 114, 124, 196, 197], "loop": [61, 180], "discret": [61, 69, 78, 136, 179], "membran": [61, 73, 146], "potenti": [61, 72, 73, 146], "random": [61, 63, 78, 137, 195], "synapt": [61, 140, 146, 147], "ad": [61, 63, 73, 74, 124], "list": [61, 73, 74], "ensembl": [61, 145], "statist": [61, 75, 79, 157, 161, 191], "store": 61, "mean": [61, 85, 94, 137, 145, 146], "standard": [61, 145, 162], "deviat": [61, 145], "numpi": 61, "rewrit": [61, 63], "12": [61, 63, 171], "enumer": 61, "index": [61, 63], "aggreg": 61, "13": [61, 63, 171], "arrai": [61, 163], "14": [61, 171], "ii": 63, "histogram": [63, 87], "dictionari": 63, "introduc": [63, 180], "boolean": 63, "binari": [63, 123, 149, 161, 163, 170], "raster": [63, 85], "refractori": 63, "period": 63, "investig": [63, 124, 145], "refactori": 63, "interact": [63, 67, 69, 72, 73, 74, 78, 79, 85, 86, 87, 94, 95, 106, 112, 113, 114, 135, 136, 137, 144, 146, 147, 153, 154, 155, 161, 162, 169, 170, 171, 172, 179, 180, 186, 187, 196, 197, 198], "last": 63, "concept": [63, 199], "linear": [64, 67, 68, 73, 86, 90, 94, 95, 97, 100, 105, 108, 124, 130, 131, 135, 153, 172, 180, 197], "algebra": [64, 67], "survei": [66, 77], "vector": [67, 112, 154], "why": [67, 72, 73, 86, 87, 106, 122], "do": [67, 72, 73, 86, 106, 145], "care": [67, 72, 73], "definit": [67, 172], "properti": [67, 113], "normal": [67, 163], "combin": [67, 137], "span": 67, "independ": 67, "determ": 67, "basi": [67, 112, 113], "out": [67, 154], "dot": 67, "product": [67, 72, 79], "lgn": 67, "fire": [67, 69, 73, 74, 86, 144, 147, 149], "geometri": 67, "polynomi": [67, 97], "proof": [67, 98], "equival": 67, "matric": 68, "solv": [68, 94, 180, 187], "equat": [68, 73, 74, 121, 135, 154, 180], "transform": [68, 147], "creat": [68, 78, 105, 124], "rank": 68, "null": 68, "eigenvalu": [68, 69, 135, 153, 155], "eigenvector": [68, 69, 113, 135], "eigenstuff": [68, 69], "identifi": 68, "from": [68, 78, 87, 112, 121, 122, 131, 154, 171, 172, 179, 187, 195], "matrix": [68, 97, 105, 113, 114, 123, 155, 163, 195], "multipl": [68, 72, 97], "corner": 68, "circuit": 69, "A": [69, 72, 74, 79, 123, 124, 135, 162, 191, 196, 198], "rate": [69, 73, 144, 146, 147, 149, 153, 186], "along": 69, "both": 69, "complex": [69, 122, 162, 196], "calculu": [70, 72], "differenti": [72, 73, 74, 135], "geometr": [72, 112], "interpret": [72, 73, 124, 135], "analyt": [72, 79], "numer": [72, 74, 153, 154], "rule": [72, 161, 163, 169], "deriv": [72, 74, 94], "postsynapt": [72, 147], "alpha": [72, 187], "chain": [72, 79], "sympi": 72, "sine": 72, "transfer": [72, 145, 186], "gain": [72, 180], "calcul": [72, 87, 113, 114, 153, 161, 163, 195], "variabl": [72, 197, 198], "partial": [72, 155, 180, 197], "demonstr": 72, "riemann": 72, "sum": 72, "vs": [72, 98, 121, 136, 146, 153, 169, 173, 180, 188, 196, 198], "size": [72, 106, 196], "charg": 72, "excitatori": [72, 146, 147, 153, 154], "filter": [72, 122, 165, 171, 172, 180], "popul": [73, 74, 153, 154], "exact": 73, "solut": [73, 74, 79, 123, 135], "condit": [73, 79, 135, 172], "leaki": [73, 74, 144], "without": 73, "v": 73, "v_": 73, "reset": 73, "impact": 73, "one": 73, "thing": 73, "matter": 73, "neuromatch": [73, 74], "bibliographi": [73, 74], "supplement": [73, 74], "popular": [73, 74], "method": [74, 90, 115], "euler": [74, 135], "slope": 74, "line": 74, "approxim": [74, 196], "singl": [74, 85, 153], "take": [74, 171], "simpl": 74, "wilson": [74, 154, 155], "cowan": [74, 154, 155], "phase": [74, 149, 154, 155], "plane": [74, 149, 154, 155], "nullclin": [74, 154, 155], "connect": [74, 123, 124, 147, 195, 196, 197, 198], "oscil": [74, 155], "small": [74, 196, 198], "everyth": 74, "4th": 74, "order": [74, 97, 138], "rung": 74, "kutta": 74, "ar": [74, 138, 179], "toward": 74, "rather": 74, "than": [74, 106], "end": 74, "Not": 74, "alik": 74, "stuart": 74, "landau": 74, "probabl": [78, 79, 87, 136, 161, 162, 163, 169], "distribut": [78, 79, 85, 87, 95, 112, 136, 147, 161, 162, 163, 172, 179], "world": [78, 170, 189], "uniform": 78, "walk": [78, 137], "vari": [78, 106, 135, 136, 145, 180, 186], "binomi": 78, "poisson": [78, 105, 173], "continu": [78, 136, 162, 179, 180], "gaussian": [78, 79, 95, 105, 144, 145, 162, 163, 170, 172, 180], "1a": [78, 137, 145, 147], "infer": [79, 162, 170, 175], "b": 79, "joint": [79, 172], "c": [79, 106], "d": 79, "margin": [79, 161, 162, 163, 172], "markov": [79, 136, 165, 170, 188], "likelihood": [79, 95, 161, 163], "maximum": [79, 95], "search": [79, 171], "best": 79, "optim": [79, 87, 90, 94, 105, 121, 174, 179, 180], "conjug": 79, "prior": [79, 162, 163], "posterior": [79, 161, 162, 163], "computation": 79, "net": 79, "causal": [79, 163, 190, 195, 196, 197, 198], "type": [80, 87, 144], "further": [81, 90, 101, 108, 117, 123, 131, 140, 149, 157, 165, 175, 180, 182, 191], "retriev": [85, 105, 106, 121, 122, 123, 124, 172], "warm": 85, "spike_tim": 85, "warmer": 85, "count": [85, 105], "total": 85, "compar": [85, 97, 98, 117, 171, 196], "median": 85, "subset": [85, 198], "inter": 85, "interv": [85, 96, 136], "isi": [85, 87, 144], "form": 85, "fit": [85, 89, 90, 97, 105, 106, 138, 163, 172, 197], "hand": 85, "how": [86, 140, 145, 171, 179, 180, 189, 198], "dv_m": 86, "IF": 86, "inhibitori": [86, 146, 153, 154], "inhibit": [86, 149, 155], "notat": [86, 87, 94, 95, 96, 97, 105, 106, 112, 113, 114], "entropi": 87, "mass": 87, "pmf": 87, "foundat": [87, 175], "tip": 90, "On": [90, 188], "regress": [90, 94, 95, 97, 105, 106, 197, 198], "llh": 90, "maxim": [90, 172, 173], "mse": [90, 94, 97], "minim": 90, "research": 90, "develop": 90, "squar": [94, 97, 198], "least": [94, 97, 198], "mle": 95, "probabilist": [95, 186], "confid": [96, 169], "bootstrap": 96, "resampl": 96, "replac": 96, "ordinari": 97, "qualiti": 97, "bia": [98, 197, 198], "varianc": [98, 114, 137], "trade": 98, "off": [98, 188], "tradeoff": [98, 169, 180], "decomposit": 98, "cross": [99, 106], "valid": [99, 106], "akaik": 99, "s": [99, 122, 123, 171], "criterion": 99, "aic": 99, "glm": [105, 197], "encod": [105, 117, 123, 124, 163], "load": [105, 106, 121, 122, 123, 124, 172], "retin": 105, "ganglion": 105, "cell": [105, 122, 163], "predict": [105, 170, 186], "challeng": 105, "nonlinear": [105, 108, 115, 121], "scipi": 105, "classifi": 106, "regular": [106, 124], "sigmoid": 106, "scikit": 106, "decod": [106, 121, 124], "accuraci": [106, 169, 171], "featur": 106, "lead": 106, "overfit": 106, "l_2": 106, "l_1": 106, "kei": 106, "between": [106, 136, 145, 153, 180], "sparsiti": [106, 196], "penalti": 106, "detail": 106, "dimension": [107, 108, 114, 115, 123, 135], "reduct": [107, 108, 114, 115, 123], "princip": [108, 113], "compon": [108, 113, 114], "other": 108, "interfac": 108, "shown": 108, "view": 112, "correl": [112, 113, 123, 145, 147, 161, 162, 196], "multivari": 112, "draw": 112, "new": [112, 124], "orthonorm": 112, "base": [112, 146, 149, 179, 189], "onto": [112, 113], "plai": [112, 171], "covari": [113, 161, 162], "coeffici": 113, "scree": 114, "explain": 114, "pc": 114, "examin": [114, 179, 186], "denois": 114, "add": [114, 124], "t": [115, 136], "sne": 115, "appli": 115, "run": [115, 163, 173, 179], "perplex": 115, "pytorch": [117, 121, 122, 123], "recommend": 117, "feed": 121, "forward": [121, 135, 170, 173], "split": 121, "gradient": 121, "descent": 121, "depth": 121, "width": 121, "sgd": 121, "gd": 121, "convolut": [122, 123, 124], "output": [122, 145, 180], "shape": 122, "layer": [122, 123, 124], "cnn": [122, 123], "norm": [123, 157], "orient": [123, 199], "discrimin": 123, "quantit": 123, "comparison": 123, "dissimilar": 123, "rdm": 123, "similar": [123, 196], "curv": [123, 124, 153, 154], "reduc": [123, 144], "fulli": [123, 124], "max": 123, "pool": 123, "classif": 123, "problem": [123, 124, 179], "z": 123, "score": 123, "explan": 123, "dive": 124, "devic": 124, "gpu": 124, "cpu": 124, "execut": 124, "set_devic": 124, "peer": 124, "insid": 124, "improv": 124, "critic": 124, "delv": 124, "frame": 129, "planner": 129, "lectur": 131, "One": 135, "oscillatori": 135, "determinist": [135, 137], "two": [135, 153, 195, 198], "dimens": 135, "multi": [135, 187], "trajectori": [135, 153, 154, 169], "3a": [135, 144], "3b": [135, 144], "stream": 135, "telegraph": 136, "switch": 136, "transit": [136, 153], "valu": [136, 144, 153, 154, 155, 179, 186, 187], "perspect": 136, "propag": 136, "equilibrium": 136, "stabl": [136, 153], "e": [137, 146, 153, 154, 155, 173], "coli": 137, "1b": [137, 145, 147], "influenc": [137, 180], "choic": 137, "ornstein": [137, 144], "uhlenbeck": [137, 144], "ou": [137, 138, 144], "drift": [137, 169], "diffus": [137, 169], "observ": [137, 180, 197, 198], "balanc": [137, 146, 149], "empir": 137, "autoregress": 138, "residu": 138, "higher": 138, "monkei": 138, "typewrit": 138, "biolog": 139, "text": 140, "book": 140, "hodgkin": 140, "huxlei": 140, "But": 140, "point": [140, 153, 155], "extend": [140, 155], "simplifi": 140, "synaps": [140, 146, 147], "short": [140, 146, 155], "term": [140, 146], "plastic": [140, 146, 147], "dc": 144, "amplitud": 144, "white": [144, 145], "gwn": [144, 145], "analyz": [144, 147, 154, 169, 179], "irregular": 144, "f": [144, 153, 154], "sig_gwn": 144, "cv_": 144, "synchroni": 145, "origin": [145, 180], "synchron": 145, "implic": 145, "measur": [145, 146, 170, 171, 180], "affect": [145, 161], "rational": 145, "behind": 145, "mu": 145, "sigma": 145, "transmiss": 146, "static": 146, "conduct": [146, 147], "free": 146, "depress": 146, "std": 146, "facilit": 146, "stf": 146, "stp": 146, "stdp": 147, "delta": 147, "w": 147, "keep": 147, "p": 147, "dp": 147, "show": 147, "evolut": [147, 180], "2a": 147, "strength": [147, 198], "2b": 147, "increas": 147, "presynapt": 147, "receiv": 147, "amplif": 149, "stabil": [149, 153, 155], "supralinear": 149, "scheme": [153, 154], "finit": 153, "fix": [153, 155, 169], "extern": 153, "relationship": 153, "unstabl": 153, "via": 153, "drive": 153, "descript": 154, "wc": 154, "field": 154, "r_i": 154, "r_e": [154, 155], "displaystyl": [154, 155], "big": 154, "frac": [154, 155], "dr_e": 154, "dt": 154, "dr_i": 154, "limit": 155, "cycl": 155, "jacobian": 155, "wee": 155, "posit": [155, 163], "isn": 155, "g_e": 155, "non": [155, 198], "puls": 155, "induc": 155, "persist": 155, "hidden": [161, 162, 164, 165, 169, 170], "gone": [161, 179], "fishin": 161, "decid": 161, "where": [161, 179], "fish": [161, 179], "util": [161, 162], "being": 161, "either": 161, "side": 161, "guess": 161, "locat": [161, 162], "belief": [161, 162, 179], "formula": 161, "astrocat": [162, 171], "multipli": 162, "mixtur": [162, 163], "complic": 162, "cat": 162, "cost": [162, 180], "theorem": 162, "variou": 162, "auditori": 163, "true": [163, 171, 173], "hypothet": 163, "x": 163, "hat": 163, "stimuli": 163, "expect": [163, 172, 173], "some": [163, 179], "generate_data": 163, "log": 163, "kalman": [165, 171, 172, 180], "aspect": 165, "sequenti": 169, "ratio": 169, "sprt": 169, "under": 169, "stop": 169, "speed": 169, "versu": 169, "revisit": 169, "hmm": [170, 173], "futur": 170, "forget": 170, "quantifi": 171, "movement": 171, "collar": 171, "action": [171, 180, 187], "long": 171, "ld": [172, 180], "adjust": 172, "ey": 172, "gaze": 172, "pykalman": 172, "handl": 172, "blink": 172, "smooth": 172, "em": [172, 173], "algorithm": [172, 173, 188], "m": [172, 173], "case": 173, "studi": 173, "frozen": 173, "sequenc": 173, "backward": 173, "learnt": 173, "progress": 173, "control": [174, 175, 179, 180, 195], "catch": 179, "reward": [179, 186, 187], "should": 179, "act": [179, 187, 188], "follow": 179, "sensit": 179, "open": 180, "close": 180, "fly": 180, "quadrat": 180, "regul": 180, "lqr": 180, "constraint": 180, "goal": 180, "move": 180, "desir": 180, "lqg": 180, "conjunct": 180, "effort": 180, "reinforc": [181, 189], "tempor": 186, "td": 186, "guarante": 186, "cs": 186, "discount": 186, "factor": 186, "magnitud": 186, "match": 186, "arm": 187, "bandit": 187, "epsilon": 187, "greedi": 187, "q": [188, 189], "mdp": 188, "sarsa": 188, "rl": 189, "dyna": 189, "much": 189, "when": 189, "econometr": 191, "epidemiolog": 191, "broad": 191, "rang": 191, "relev": 191, "intervent": 195, "trial": 195, "recov": [195, 197], "perturb": 195, "causat": 196, "try": 196, "larg": [196, 198], "metric": 196, "low": 196, "resolut": 196, "coars": 196, "averag": 196, "across": 196, "result": 196, "truth": 196, "simultan": 197, "approach": 197, "plu": 197, "lasso": 197, "omit": [197, 198], "instrument": 198, "iv": 198, "high": 198, "level": 198, "stage": 198, "granger": 198, "curriculum": 199}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx": 56}})