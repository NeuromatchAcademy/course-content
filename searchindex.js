Search.setIndex({"docnames": ["prereqs/ComputationalNeuroscience", "projects/ECoG/ECoG_videos", "projects/ECoG/README", "projects/README", "projects/behavior/README", "projects/behavior/behavior_videos", "projects/docs/ECoG", "projects/docs/behavior", "projects/docs/datasets_overview", "projects/docs/fMRI", "projects/docs/neurons", "projects/docs/project_2020_highlights", "projects/docs/project_guidance", "projects/docs/project_templates", "projects/docs/projects_2020/behavior", "projects/docs/projects_2020/eeg", "projects/docs/projects_2020/fMRI", "projects/docs/projects_2020/neurons", "projects/docs/projects_2020/theory", "projects/docs/theory", "projects/fMRI/README", "projects/fMRI/fMRI_videos", "projects/modelingsteps/ModelingSteps_1through4", "projects/modelingsteps/ModelingSteps_5through10", "projects/modelingsteps/TrainIllusionDataProject", "projects/modelingsteps/TrainIllusionModel", "projects/modelingsteps/intro", "projects/neurons/README", "projects/neurons/neurons_videos", "projects/theory/README", "tutorials/Bonus_Autoencoders/chapter_title", "tutorials/Bonus_Autoencoders/student/Bonus_Intro", "tutorials/Bonus_Autoencoders/student/Bonus_Outro", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial1", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial2", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial3", "tutorials/Module_WrapUps/DynamicalSystems", "tutorials/Module_WrapUps/MachineLearning", "tutorials/Module_WrapUps/StochasticProcesses", "tutorials/Schedule/daily_schedules", "tutorials/Schedule/schedule_intro", "tutorials/Schedule/shared_calendars", "tutorials/Schedule/timezone_widget", "tutorials/TechnicalHelp/Discord", "tutorials/TechnicalHelp/Jupyterbook", "tutorials/TechnicalHelp/Links_Policy", "tutorials/TechnicalHelp/Tutorial_colab", "tutorials/TechnicalHelp/Tutorial_kaggle", "tutorials/TechnicalHelp/tech_intro", "tutorials/W0D0_NeuroVideoSeries/chapter_title", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial1", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial10", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial11", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial12", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial2", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial3", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial4", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial5", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial6", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial7", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial8", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial9", "tutorials/W0D1_PythonWorkshop1/chapter_title", "tutorials/W0D1_PythonWorkshop1/student/W0D1_Tutorial1", "tutorials/W0D2_PythonWorkshop2/chapter_title", "tutorials/W0D2_PythonWorkshop2/student/W0D2_Tutorial1", "tutorials/W0D3_LinearAlgebra/chapter_title", "tutorials/W0D3_LinearAlgebra/student/W0D3_DaySummary", "tutorials/W0D3_LinearAlgebra/student/W0D3_Outro", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial1", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial2", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial3", "tutorials/W0D4_Calculus/chapter_title", "tutorials/W0D4_Calculus/student/W0D4_DaySummary", "tutorials/W0D4_Calculus/student/W0D4_Tutorial1", "tutorials/W0D4_Calculus/student/W0D4_Tutorial2", "tutorials/W0D4_Calculus/student/W0D4_Tutorial3", "tutorials/W0D5_Statistics/chapter_title", "tutorials/W0D5_Statistics/student/W0D5_DaySummary", "tutorials/W0D5_Statistics/student/W0D5_Outro", "tutorials/W0D5_Statistics/student/W0D5_Tutorial1", "tutorials/W0D5_Statistics/student/W0D5_Tutorial2", "tutorials/W1D1_ModelTypes/chapter_title", "tutorials/W1D1_ModelTypes/further_reading", "tutorials/W1D1_ModelTypes/student/W1D1_DaySummary", "tutorials/W1D1_ModelTypes/student/W1D1_Intro", "tutorials/W1D1_ModelTypes/student/W1D1_Outro", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial1", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial2", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial3", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial4", "tutorials/W1D2_ModelFitting/chapter_title", "tutorials/W1D2_ModelFitting/further_reading", "tutorials/W1D2_ModelFitting/student/W1D2_DaySummary", "tutorials/W1D2_ModelFitting/student/W1D2_Intro", "tutorials/W1D2_ModelFitting/student/W1D2_Outro", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial1", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial2", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial3", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial4", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial5", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial6", "tutorials/W1D3_GeneralizedLinearModels/chapter_title", "tutorials/W1D3_GeneralizedLinearModels/further_reading", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_DaySummary", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Intro", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Outro", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Tutorial1", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Tutorial2", "tutorials/W1D4_DimensionalityReduction/chapter_title", "tutorials/W1D4_DimensionalityReduction/further_reading", "tutorials/W1D4_DimensionalityReduction/student/W1D4_DaySummary", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Intro", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Outro", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial1", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial2", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial3", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial4", "tutorials/W1D5_DeepLearning/chapter_title", "tutorials/W1D5_DeepLearning/further_reading", "tutorials/W1D5_DeepLearning/student/W1D5_DaySummary", "tutorials/W1D5_DeepLearning/student/W1D5_Intro", "tutorials/W1D5_DeepLearning/student/W1D5_Outro", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial1", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial2", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial3", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial4", "tutorials/W2D1_ModelingPractice/chapter_title", "tutorials/W2D1_ModelingPractice/student/W2D1_DaySummary", "tutorials/W2D1_ModelingPractice/student/W2D1_Intro", "tutorials/W2D1_ModelingPractice/student/W2D1_Outro", "tutorials/W2D1_ModelingPractice/student/W2D1_Tutorial1", "tutorials/W2D2_LinearSystems/chapter_title", "tutorials/W2D2_LinearSystems/further_reading", "tutorials/W2D2_LinearSystems/student/W2D2_DaySummary", "tutorials/W2D2_LinearSystems/student/W2D2_Intro", "tutorials/W2D2_LinearSystems/student/W2D2_Outro", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial1", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial2", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial3", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial4", "tutorials/W2D3_BiologicalNeuronModels/chapter_title", "tutorials/W2D3_BiologicalNeuronModels/further_reading", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_DaySummary", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Intro", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Outro", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial1", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial2", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial3", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial4", "tutorials/W2D4_DynamicNetworks/chapter_title", "tutorials/W2D4_DynamicNetworks/further_reading", "tutorials/W2D4_DynamicNetworks/student/W2D4_DaySummary", "tutorials/W2D4_DynamicNetworks/student/W2D4_Intro", "tutorials/W2D4_DynamicNetworks/student/W2D4_Outro", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial1", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial2", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial3", "tutorials/W3D1_BayesianDecisions/chapter_title", "tutorials/W3D1_BayesianDecisions/further_reading", "tutorials/W3D1_BayesianDecisions/student/W3D1_DaySummary", "tutorials/W3D1_BayesianDecisions/student/W3D1_Intro", "tutorials/W3D1_BayesianDecisions/student/W3D1_Outro", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial1", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial2", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial3", "tutorials/W3D2_HiddenDynamics/chapter_title", "tutorials/W3D2_HiddenDynamics/further_reading", "tutorials/W3D2_HiddenDynamics/student/W3D2_DaySummary", "tutorials/W3D2_HiddenDynamics/student/W3D2_Intro", "tutorials/W3D2_HiddenDynamics/student/W3D2_Outro", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial1", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial2", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial3", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial4", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial5", "tutorials/W3D3_OptimalControl/chapter_title", "tutorials/W3D3_OptimalControl/further_reading", "tutorials/W3D3_OptimalControl/student/W3D3_DaySummary", "tutorials/W3D3_OptimalControl/student/W3D3_Intro", "tutorials/W3D3_OptimalControl/student/W3D3_Outro", "tutorials/W3D3_OptimalControl/student/W3D3_Tutorial1", "tutorials/W3D3_OptimalControl/student/W3D3_Tutorial2", "tutorials/W3D4_ReinforcementLearning/chapter_title", "tutorials/W3D4_ReinforcementLearning/further_reading", "tutorials/W3D4_ReinforcementLearning/student/W3D4_DaySummary", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Intro", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Outro", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial1", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial2", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial3", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial4", "tutorials/W3D5_NetworkCausality/chapter_title", "tutorials/W3D5_NetworkCausality/further_reading", "tutorials/W3D5_NetworkCausality/student/W3D5_DaySummary", "tutorials/W3D5_NetworkCausality/student/W3D5_Intro", "tutorials/W3D5_NetworkCausality/student/W3D5_Outro", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial1", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial2", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial3", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial4", "tutorials/intro"], "filenames": ["prereqs/ComputationalNeuroscience.md", "projects/ECoG/ECoG_videos.ipynb", "projects/ECoG/README.md", "projects/README.md", "projects/behavior/README.md", "projects/behavior/behavior_videos.ipynb", "projects/docs/ECoG.md", "projects/docs/behavior.md", "projects/docs/datasets_overview.md", "projects/docs/fMRI.md", "projects/docs/neurons.md", "projects/docs/project_2020_highlights.md", "projects/docs/project_guidance.md", "projects/docs/project_templates.md", "projects/docs/projects_2020/behavior.md", "projects/docs/projects_2020/eeg.md", "projects/docs/projects_2020/fMRI.md", "projects/docs/projects_2020/neurons.md", "projects/docs/projects_2020/theory.md", "projects/docs/theory.md", "projects/fMRI/README.md", "projects/fMRI/fMRI_videos.ipynb", "projects/modelingsteps/ModelingSteps_1through4.ipynb", "projects/modelingsteps/ModelingSteps_5through10.ipynb", "projects/modelingsteps/TrainIllusionDataProject.ipynb", "projects/modelingsteps/TrainIllusionModel.ipynb", "projects/modelingsteps/intro.md", "projects/neurons/README.md", "projects/neurons/neurons_videos.ipynb", "projects/theory/README.md", "tutorials/Bonus_Autoencoders/chapter_title.md", "tutorials/Bonus_Autoencoders/student/Bonus_Intro.ipynb", "tutorials/Bonus_Autoencoders/student/Bonus_Outro.ipynb", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial1.ipynb", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial2.ipynb", "tutorials/Bonus_Autoencoders/student/Bonus_Tutorial3.ipynb", "tutorials/Module_WrapUps/DynamicalSystems.ipynb", "tutorials/Module_WrapUps/MachineLearning.ipynb", "tutorials/Module_WrapUps/StochasticProcesses.ipynb", "tutorials/Schedule/daily_schedules.md", "tutorials/Schedule/schedule_intro.md", "tutorials/Schedule/shared_calendars.md", "tutorials/Schedule/timezone_widget.md", "tutorials/TechnicalHelp/Discord.md", "tutorials/TechnicalHelp/Jupyterbook.md", "tutorials/TechnicalHelp/Links_Policy.md", "tutorials/TechnicalHelp/Tutorial_colab.md", "tutorials/TechnicalHelp/Tutorial_kaggle.md", "tutorials/TechnicalHelp/tech_intro.md", "tutorials/W0D0_NeuroVideoSeries/chapter_title.md", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial1.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial10.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial11.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial12.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial2.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial3.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial4.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial5.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial6.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial7.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial8.ipynb", "tutorials/W0D0_NeuroVideoSeries/student/W0D0_Tutorial9.ipynb", "tutorials/W0D1_PythonWorkshop1/chapter_title.md", "tutorials/W0D1_PythonWorkshop1/student/W0D1_Tutorial1.ipynb", "tutorials/W0D2_PythonWorkshop2/chapter_title.md", "tutorials/W0D2_PythonWorkshop2/student/W0D2_Tutorial1.ipynb", "tutorials/W0D3_LinearAlgebra/chapter_title.md", "tutorials/W0D3_LinearAlgebra/student/W0D3_DaySummary.ipynb", "tutorials/W0D3_LinearAlgebra/student/W0D3_Outro.ipynb", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial1.ipynb", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial2.ipynb", "tutorials/W0D3_LinearAlgebra/student/W0D3_Tutorial3.ipynb", "tutorials/W0D4_Calculus/chapter_title.md", "tutorials/W0D4_Calculus/student/W0D4_DaySummary.ipynb", "tutorials/W0D4_Calculus/student/W0D4_Tutorial1.ipynb", "tutorials/W0D4_Calculus/student/W0D4_Tutorial2.ipynb", "tutorials/W0D4_Calculus/student/W0D4_Tutorial3.ipynb", "tutorials/W0D5_Statistics/chapter_title.md", "tutorials/W0D5_Statistics/student/W0D5_DaySummary.ipynb", "tutorials/W0D5_Statistics/student/W0D5_Outro.ipynb", "tutorials/W0D5_Statistics/student/W0D5_Tutorial1.ipynb", "tutorials/W0D5_Statistics/student/W0D5_Tutorial2.ipynb", "tutorials/W1D1_ModelTypes/chapter_title.md", "tutorials/W1D1_ModelTypes/further_reading.md", "tutorials/W1D1_ModelTypes/student/W1D1_DaySummary.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Intro.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Outro.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial1.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial2.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial3.ipynb", "tutorials/W1D1_ModelTypes/student/W1D1_Tutorial4.ipynb", "tutorials/W1D2_ModelFitting/chapter_title.md", "tutorials/W1D2_ModelFitting/further_reading.md", "tutorials/W1D2_ModelFitting/student/W1D2_DaySummary.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Intro.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Outro.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial1.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial2.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial3.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial4.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial5.ipynb", "tutorials/W1D2_ModelFitting/student/W1D2_Tutorial6.ipynb", "tutorials/W1D3_GeneralizedLinearModels/chapter_title.md", "tutorials/W1D3_GeneralizedLinearModels/further_reading.md", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_DaySummary.ipynb", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Intro.ipynb", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Outro.ipynb", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Tutorial1.ipynb", "tutorials/W1D3_GeneralizedLinearModels/student/W1D3_Tutorial2.ipynb", "tutorials/W1D4_DimensionalityReduction/chapter_title.md", "tutorials/W1D4_DimensionalityReduction/further_reading.md", "tutorials/W1D4_DimensionalityReduction/student/W1D4_DaySummary.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Intro.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Outro.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial1.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial2.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial3.ipynb", "tutorials/W1D4_DimensionalityReduction/student/W1D4_Tutorial4.ipynb", "tutorials/W1D5_DeepLearning/chapter_title.md", "tutorials/W1D5_DeepLearning/further_reading.md", "tutorials/W1D5_DeepLearning/student/W1D5_DaySummary.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Intro.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Outro.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial1.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial2.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial3.ipynb", "tutorials/W1D5_DeepLearning/student/W1D5_Tutorial4.ipynb", "tutorials/W2D1_ModelingPractice/chapter_title.md", "tutorials/W2D1_ModelingPractice/student/W2D1_DaySummary.ipynb", "tutorials/W2D1_ModelingPractice/student/W2D1_Intro.ipynb", "tutorials/W2D1_ModelingPractice/student/W2D1_Outro.ipynb", "tutorials/W2D1_ModelingPractice/student/W2D1_Tutorial1.ipynb", "tutorials/W2D2_LinearSystems/chapter_title.md", "tutorials/W2D2_LinearSystems/further_reading.md", "tutorials/W2D2_LinearSystems/student/W2D2_DaySummary.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Intro.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Outro.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial1.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial2.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial3.ipynb", "tutorials/W2D2_LinearSystems/student/W2D2_Tutorial4.ipynb", "tutorials/W2D3_BiologicalNeuronModels/chapter_title.md", "tutorials/W2D3_BiologicalNeuronModels/further_reading.md", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_DaySummary.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Intro.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Outro.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial1.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial2.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial3.ipynb", "tutorials/W2D3_BiologicalNeuronModels/student/W2D3_Tutorial4.ipynb", "tutorials/W2D4_DynamicNetworks/chapter_title.md", "tutorials/W2D4_DynamicNetworks/further_reading.md", "tutorials/W2D4_DynamicNetworks/student/W2D4_DaySummary.ipynb", "tutorials/W2D4_DynamicNetworks/student/W2D4_Intro.ipynb", "tutorials/W2D4_DynamicNetworks/student/W2D4_Outro.ipynb", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial1.ipynb", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial2.ipynb", "tutorials/W2D4_DynamicNetworks/student/W2D4_Tutorial3.ipynb", "tutorials/W3D1_BayesianDecisions/chapter_title.md", "tutorials/W3D1_BayesianDecisions/further_reading.md", "tutorials/W3D1_BayesianDecisions/student/W3D1_DaySummary.ipynb", "tutorials/W3D1_BayesianDecisions/student/W3D1_Intro.ipynb", "tutorials/W3D1_BayesianDecisions/student/W3D1_Outro.ipynb", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial1.ipynb", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial2.ipynb", "tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial3.ipynb", "tutorials/W3D2_HiddenDynamics/chapter_title.md", "tutorials/W3D2_HiddenDynamics/further_reading.md", "tutorials/W3D2_HiddenDynamics/student/W3D2_DaySummary.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Intro.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Outro.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial1.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial2.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial3.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial4.ipynb", "tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial5.ipynb", "tutorials/W3D3_OptimalControl/chapter_title.md", "tutorials/W3D3_OptimalControl/further_reading.md", "tutorials/W3D3_OptimalControl/student/W3D3_DaySummary.ipynb", "tutorials/W3D3_OptimalControl/student/W3D3_Intro.ipynb", "tutorials/W3D3_OptimalControl/student/W3D3_Outro.ipynb", "tutorials/W3D3_OptimalControl/student/W3D3_Tutorial1.ipynb", "tutorials/W3D3_OptimalControl/student/W3D3_Tutorial2.ipynb", "tutorials/W3D4_ReinforcementLearning/chapter_title.md", "tutorials/W3D4_ReinforcementLearning/further_reading.md", "tutorials/W3D4_ReinforcementLearning/student/W3D4_DaySummary.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Intro.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Outro.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial1.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial2.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial3.ipynb", "tutorials/W3D4_ReinforcementLearning/student/W3D4_Tutorial4.ipynb", "tutorials/W3D5_NetworkCausality/chapter_title.md", "tutorials/W3D5_NetworkCausality/further_reading.md", "tutorials/W3D5_NetworkCausality/student/W3D5_DaySummary.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Intro.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Outro.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial1.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial2.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial3.ipynb", "tutorials/W3D5_NetworkCausality/student/W3D5_Tutorial4.ipynb", "tutorials/intro.ipynb"], "titles": ["Prerequisites and preparatory materials for NMA Computational Neuroscience", "Overview videos", "Guide to choosing an EEG/ECoG/LFP dataset", "Projects", "Guide to choosing a Behavior dataset", "Overview videos", "ECoG", "Behavior", "Datasets", "fMRI", "Neurons", "Projects 2020", "Daily guide for projects", "Project Templates", "Behavior", "EEG", "fMRI", "Neurons", "Theory", "Theory", "Guide to choosing an FMRI dataset", "Overview videos", "Modeling Steps 1 - 4", "Modeling Steps 5 - 10", "Example Data Project: the Train Illusion", "Example Model Project: the Train Illusion", "Modeling Step-by-Step Guide", "Guide to choosing a Neurons dataset", "Overview videos", "Guide to choosing a Theory project", "Autoencoders", "Intro", "Outro", "Tutorial 1: Intro to Autoencoders", "Tutorial 2: Autoencoder extensions", "Tutorial 3: Autoencoders applications", "Dynamical Systems Wrap-Up", "Machine Learning Wrap-Up", "Stochastic Processes Wrap-Up", "General schedule", "Schedule", "Shared calendars", "Timezone widget", "Using discord", "Using jupyterbook", "Quick links and policies", "Using Google Colab", "Using Kaggle", "Technical Help", "Neuro Video Series", "Intro", "Stimulus Representation", "Neurotransmitters", "Neurons to Consciousness", "Human Psychophysics", "Behavioral Readout", "Live in Lab", "Brain Signals: Spiking Activity", "Brain Signals: LFP", "Brain Signals: EEG &amp; MEG", "Brain Signals: fMRI", "Brain Signals: Calcium Imaging", "Python Workshop 1", "Tutorial: LIF Neuron Part I", "Python Workshop 2", "Tutorial 1: LIF Neuron Part II", "Linear Algebra", "Day Summary", "Outro", "Tutorial 1: Vectors", "Tutorial 2: Matrices", "Bonus Tutorial: Discrete Dynamical Systems", "Calculus", "Day Summary", "Tutorial 1: Differentiation and Integration", "Tutorial 2: Differential Equations", "Tutorial 3: Numerical Methods", "Statistics", "Day Summary", "Outro", "Tutorial 1: Probability Distributions", "Tutorial 2: Statistical Inference", "Model Types", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: \u201cWhat\u201d models", "Tutorial 2: \u201cHow\u201d models", "Tutorial 3: \u201cWhy\u201d models", "Tutorial 4: Model Discussions", "Model Fitting", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Linear regression with MSE", "Tutorial 2: Linear regression with MLE", "Tutorial 3: Confidence intervals and bootstrapping", "Tutorial 4: Multiple linear regression and polynomial regression", "Tutorial 5: Model Selection: Bias-variance trade-off", "Tutorial 6: Model Selection: Cross-validation", "Generalized Linear Models", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: GLMs for Encoding", "Tutorial 2: Classifiers and regularizers", "Dimensionality Reduction", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Geometric view of data", "Tutorial 2: Principal Component Analysis", "Tutorial 3: Dimensionality Reduction &amp; Reconstruction", "Tutorial 4:  Nonlinear Dimensionality Reduction", "Deep Learning", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Decoding Neural Responses", "Tutorial 2: Convolutional Neural Networks", "Tutorial 3: Building and Evaluating Normative Encoding Models", "Bonus Tutorial: Diving Deeper into Decoding &amp; Encoding", "Modeling Practice", "Day Summary", "Intro", "Outro", "Tutorial 1: Framing the Question", "Linear Systems", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Linear dynamical systems", "Tutorial 2: Markov Processes", "Tutorial 3: Combining determinism and stochasticity", "Tutorial 4: Autoregressive models", "Biological Neuron Models", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model", "Tutorial 2: Effects of Input Correlation", "Tutorial 3: Synaptic transmission - Models of static and dynamic synapses", "Bonus Tutorial: Spike-timing dependent plasticity (STDP)", "Dynamic Networks", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Neural Rate Models", "Tutorial 2: Wilson-Cowan Model", "Bonus Tutorial: Extending the Wilson-Cowan Model", "Bayesian Decisions", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Bayes with a binary hidden state", "Tutorial 2: Bayesian inference and decisions with continuous hidden state", "Bonus Tutorial: Fitting to data", "Hidden Dynamics", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Sequential Probability Ratio Test", "Tutorial 2: Hidden Markov Model", "Tutorial 3: The Kalman Filter", "Bonus Tutorial 4: The Kalman Filter, part 2", "Bonus Tutorial 5: Expectation Maximization for spiking neurons", "Optimal Control", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Optimal Control for Discrete States", "Tutorial 2: Optimal Control for Continuous State", "Reinforcement Learning", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Learning to Predict", "Tutorial 2: Learning to Act: Multi-Armed Bandits", "Tutorial 3: Learning to Act: Q-Learning", "Tutorial 4: Model-Based Reinforcement Learning", "Network Causality", "Suggested further readings", "Day Summary", "Intro", "Outro", "Tutorial 1: Interventions", "Tutorial 2: Correlations", "Tutorial 3: Simultaneous fitting/regression", "Tutorial 4: Instrumental Variables", "Introduction"], "terms": {"welcom": [0, 105, 201], "neuromatch": [0, 12, 22, 33, 34, 35, 36, 37, 38, 45, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 78, 80, 81, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 105, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200, 201], "academi": [0, 2, 20, 22, 33, 34, 35, 36, 37, 38, 45, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 119, 123, 124, 125, 126, 131, 133, 137, 138, 139, 140, 142, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 177, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "we": [0, 2, 4, 12, 22, 23, 24, 25, 29, 33, 34, 39, 41, 47, 63, 65, 70, 71, 76, 80, 81, 85, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 105, 107, 112, 114, 115, 116, 117, 121, 123, 124, 125, 126, 129, 131, 135, 137, 138, 139, 140, 144, 146, 147, 148, 149, 153, 155, 156, 157, 161, 163, 164, 165, 169, 171, 172, 173, 174, 175, 179, 181, 182, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201], "re": [0, 12, 22, 23, 25, 35, 47, 63, 65, 69, 70, 74, 75, 76, 81, 87, 94, 99, 101, 107, 108, 112, 114, 115, 117, 123, 124, 125, 126, 129, 131, 138, 140, 148, 155, 156, 157, 164, 172, 173, 175, 181, 188, 197, 198, 200], "realli": [0, 12, 22, 23, 25, 69, 81, 94, 98, 105, 108, 119, 123, 125, 131, 140, 163, 164, 167, 201], "excit": [0, 12, 27, 69, 74, 76, 85, 88, 119, 133, 137, 142, 148, 151, 157, 191], "bring": [0, 24, 29, 163, 186, 188], "wide": [0, 2, 80, 98, 105, 121, 123, 161, 171, 175, 186], "vari": [0, 4, 25, 39, 69, 81, 87, 88, 89, 94, 97, 99, 100, 114, 123, 133, 146, 148, 149, 155, 157, 163, 165, 171, 174, 189, 198], "audienc": [0, 12, 23], "an": [0, 12, 22, 23, 24, 25, 29, 33, 35, 44, 45, 46, 47, 65, 69, 70, 74, 75, 80, 81, 85, 88, 89, 94, 96, 97, 98, 99, 100, 101, 105, 107, 108, 112, 115, 116, 117, 119, 121, 123, 124, 125, 126, 129, 131, 133, 137, 138, 139, 140, 144, 147, 148, 153, 155, 156, 157, 163, 164, 167, 169, 173, 174, 175, 179, 181, 184, 186, 188, 190, 191, 195, 197, 198, 199, 201], "amaz": 0, "set": [0, 2, 4, 12, 22, 23, 24, 25, 47, 112, 129, 169, 193], "lectur": [0, 39, 115, 116, 126, 138, 144, 146, 147, 153, 159, 175, 182], "tutori": [0, 12, 39, 42, 47, 85, 94, 105, 110, 112, 121, 129, 144, 153, 159, 161, 167, 169, 179, 186, 195], "you": [0, 2, 12, 22, 23, 24, 25, 29, 31, 33, 34, 35, 39, 41, 44, 46, 47, 63, 65, 68, 69, 70, 71, 74, 75, 76, 79, 80, 81, 85, 86, 87, 88, 89, 90, 94, 95, 96, 97, 98, 99, 100, 101, 105, 106, 107, 108, 112, 113, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 129, 130, 131, 136, 137, 138, 139, 140, 144, 145, 146, 147, 148, 149, 153, 154, 155, 156, 157, 161, 162, 163, 164, 165, 169, 170, 171, 172, 173, 174, 175, 179, 180, 182, 186, 187, 188, 189, 190, 191, 196, 197, 198, 199, 200, 201], "peopl": [0, 12, 22, 24, 25, 92, 101, 131, 133, 188, 197, 199], "ar": [0, 2, 4, 11, 12, 20, 22, 23, 24, 25, 27, 29, 31, 33, 34, 35, 39, 45, 47, 63, 65, 69, 70, 71, 74, 75, 80, 81, 83, 85, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 105, 107, 108, 114, 115, 116, 117, 121, 123, 124, 125, 126, 131, 137, 138, 139, 142, 144, 146, 147, 148, 149, 153, 155, 156, 157, 159, 161, 163, 164, 165, 167, 171, 172, 173, 174, 175, 179, 182, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201], "come": [0, 12, 22, 23, 24, 27, 63, 70, 74, 76, 80, 81, 87, 99, 101, 108, 123, 131, 148, 159, 163, 164, 165, 171, 172, 175, 188, 189, 190, 191, 195], "thi": [0, 2, 11, 12, 20, 22, 23, 24, 25, 29, 31, 33, 34, 35, 36, 37, 38, 39, 42, 44, 45, 46, 47, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 85, 87, 88, 89, 90, 94, 96, 97, 98, 99, 100, 101, 105, 107, 108, 112, 114, 115, 116, 117, 121, 123, 124, 125, 126, 129, 131, 137, 138, 139, 140, 144, 146, 147, 148, 149, 153, 155, 156, 157, 159, 161, 163, 164, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201], "from": [0, 2, 4, 11, 12, 20, 22, 23, 24, 25, 27, 31, 32, 33, 34, 35, 36, 37, 38, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 71, 73, 74, 75, 76, 78, 81, 83, 84, 85, 86, 87, 88, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 111, 112, 113, 115, 116, 117, 119, 120, 121, 122, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 157, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 175, 178, 179, 180, 182, 185, 186, 187, 188, 190, 191, 193, 194, 195, 196, 198, 199, 200, 201], "rang": [0, 12, 22, 23, 24, 25, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 96, 98, 99, 100, 101, 105, 107, 108, 114, 116, 117, 121, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "disciplin": [0, 33], "level": [0, 2, 12, 20, 22, 23, 25, 33, 34, 75, 81, 87, 108, 121, 123, 124, 125, 126, 131, 146, 155, 171, 172, 173, 177, 182, 184, 189, 198, 199], "background": [0, 20, 23], "want": [0, 12, 22, 23, 24, 25, 29, 46, 47, 63, 70, 75, 76, 80, 81, 85, 87, 97, 99, 100, 101, 105, 107, 108, 123, 124, 126, 131, 137, 138, 146, 147, 148, 155, 161, 163, 164, 165, 171, 174, 175, 182, 189, 191, 197, 198, 199, 200], "make": [0, 4, 12, 20, 22, 23, 24, 25, 33, 45, 46, 47, 63, 69, 71, 74, 75, 76, 80, 81, 85, 87, 88, 89, 96, 97, 99, 100, 101, 103, 105, 107, 108, 114, 115, 116, 117, 121, 123, 124, 125, 126, 129, 131, 133, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 161, 164, 165, 171, 172, 173, 174, 175, 177, 181, 182, 186, 188, 189, 190, 191, 195, 197, 198, 199, 200, 201], "sure": [0, 12, 22, 23, 25, 47, 69, 71, 75, 76, 80, 81, 87, 89, 96, 97, 107, 114, 115, 116, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 171, 172, 174, 175, 181, 182, 188, 189, 198, 200], "everybodi": 0, "abl": [0, 12, 25, 69, 70, 74, 75, 80, 81, 87, 88, 94, 114, 116, 117, 123, 140, 153, 163, 164, 165, 171, 172, 174, 182, 189, 191, 195, 200], "follow": [0, 12, 22, 23, 24, 25, 31, 33, 34, 35, 39, 47, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 90, 97, 99, 100, 101, 105, 107, 108, 114, 115, 116, 117, 123, 124, 125, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 182, 186, 188, 189, 190, 191, 197, 198, 199, 200], "enjoi": [0, 22, 35, 105, 131, 147], "school": [0, 163, 172, 181, 199], "dai": [0, 22, 24, 31, 33, 34, 35, 45, 63, 65, 69, 70, 71, 74, 80, 81, 85, 87, 88, 89, 90, 94, 96, 97, 98, 99, 100, 101, 105, 107, 108, 112, 114, 115, 116, 117, 121, 123, 124, 125, 126, 129, 131, 133, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 161, 163, 164, 165, 169, 171, 172, 173, 174, 175, 179, 181, 182, 188, 189, 190, 191, 195, 197, 198, 199, 200, 201], "1": [0, 2, 23, 24, 29, 31, 32, 39, 41, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 67, 73, 78, 83, 84, 85, 86, 92, 93, 94, 95, 103, 104, 105, 106, 111, 112, 113, 120, 121, 128, 129, 130, 133, 134, 135, 136, 142, 143, 144, 145, 151, 152, 153, 154, 160, 161, 162, 168, 169, 170, 177, 178, 179, 180, 185, 186, 187, 193, 194, 195, 196], "mean": [0, 12, 22, 23, 24, 25, 33, 34, 35, 39, 65, 69, 71, 74, 75, 76, 80, 81, 88, 89, 97, 98, 99, 100, 101, 105, 107, 108, 112, 114, 115, 116, 121, 123, 124, 125, 126, 129, 131, 137, 138, 140, 144, 146, 149, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 189, 191, 197, 198, 199, 200], "need": [0, 12, 22, 23, 24, 25, 39, 47, 63, 65, 69, 70, 74, 75, 80, 81, 87, 88, 89, 94, 98, 99, 100, 101, 105, 107, 108, 112, 114, 116, 117, 121, 123, 124, 125, 126, 129, 131, 137, 138, 139, 146, 147, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 195, 199, 200, 201], "know": [0, 12, 22, 23, 33, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 98, 101, 105, 107, 108, 124, 125, 129, 131, 137, 139, 146, 148, 149, 163, 164, 165, 172, 174, 175, 179, 182, 186, 189, 190, 197, 198], "basic": [0, 23, 24, 33, 46, 65, 69, 70, 71, 74, 80, 83, 85, 87, 88, 94, 99, 105, 108, 121, 124, 139, 146, 163, 164, 190, 193, 195, 201], "python": [0, 12, 22, 24, 65, 69, 70, 75, 76, 80, 81, 87, 105, 107, 123, 125, 126, 131, 137, 139, 155, 159, 174, 198, 199, 201], "some": [0, 12, 22, 23, 24, 25, 33, 35, 39, 69, 70, 71, 74, 75, 80, 81, 85, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 105, 107, 108, 116, 117, 119, 121, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 156, 157, 163, 164, 171, 173, 174, 182, 186, 188, 189, 190, 191, 197, 198, 199, 200], "core": [0, 22, 69, 112, 131, 163, 169, 173, 179, 181, 186], "concept": [0, 12, 22, 23, 29, 35, 63, 71, 74, 76, 80, 89, 94, 100, 105, 108, 114, 115, 131, 140, 144, 147, 148, 149, 155, 156, 161, 163, 164, 169, 181, 182, 186, 188, 190, 195], "exposur": [0, 81], "below": [0, 12, 13, 23, 24, 33, 34, 35, 36, 37, 38, 41, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 97, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 138, 139, 140, 146, 147, 148, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 181, 182, 188, 189, 191, 197, 198, 199, 200], "provid": [0, 2, 12, 22, 23, 27, 29, 33, 35, 63, 65, 69, 70, 81, 85, 88, 89, 92, 94, 97, 105, 107, 114, 115, 123, 124, 125, 126, 129, 131, 139, 144, 147, 148, 153, 155, 157, 161, 164, 165, 169, 171, 172, 173, 174, 175, 179, 181, 182, 186, 188, 197, 198, 199, 200], "more": [0, 2, 12, 22, 23, 24, 25, 29, 33, 34, 35, 39, 45, 63, 65, 69, 70, 71, 74, 75, 80, 81, 85, 87, 88, 89, 94, 96, 98, 99, 100, 101, 105, 107, 112, 115, 116, 117, 121, 123, 124, 125, 126, 131, 137, 140, 144, 146, 148, 155, 156, 161, 165, 167, 171, 172, 173, 174, 175, 181, 182, 186, 188, 189, 190, 191, 197, 198, 199, 200, 201], "detail": [0, 12, 22, 23, 24, 33, 63, 65, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 105, 123, 124, 125, 131, 142, 146, 163, 173, 182, 191], "run": [0, 2, 4, 12, 20, 22, 23, 24, 25, 27, 29, 33, 35, 44, 46, 47, 63, 65, 70, 71, 74, 76, 80, 87, 88, 89, 98, 105, 107, 108, 114, 115, 116, 123, 124, 125, 126, 131, 137, 138, 139, 146, 147, 148, 149, 155, 169, 171, 174, 179, 182, 188, 189, 190, 191, 195, 197, 198, 199, 200], "us": [0, 2, 4, 11, 12, 20, 22, 23, 24, 25, 27, 29, 31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 67, 70, 73, 75, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 110, 111, 112, 113, 114, 115, 120, 121, 122, 124, 125, 126, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 174, 175, 178, 179, 180, 181, 185, 186, 187, 189, 190, 191, 193, 194, 195, 196, 198, 201], "If": [0, 12, 22, 23, 24, 25, 29, 35, 41, 45, 46, 47, 63, 69, 70, 71, 74, 75, 80, 81, 87, 88, 89, 96, 99, 101, 108, 114, 115, 117, 123, 124, 125, 126, 131, 137, 138, 140, 146, 147, 148, 149, 155, 156, 163, 164, 171, 172, 174, 181, 189, 190, 191, 193, 197, 198, 199, 200], "ve": [0, 12, 23, 35, 65, 69, 71, 81, 87, 89, 108, 112, 115, 116, 117, 125, 126, 138, 139, 140, 146, 148, 149, 155, 157, 163, 165, 169, 171, 174, 181, 189, 191, 198, 199, 200], "never": [0, 12, 20, 23, 107, 108, 123, 140, 149, 156, 174, 188, 189, 198], "now": [0, 12, 22, 23, 24, 25, 34, 35, 65, 69, 71, 74, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 105, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 129, 131, 137, 138, 139, 140, 146, 147, 148, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 179, 181, 182, 189, 190, 191, 197, 198, 199, 200, 201], "good": [0, 12, 22, 23, 24, 25, 33, 63, 70, 75, 81, 89, 96, 97, 98, 100, 101, 105, 107, 108, 115, 123, 125, 126, 129, 131, 139, 140, 142, 153, 159, 164, 171, 174, 175, 179, 181, 182, 184, 188, 189, 195, 197, 198, 200], "time": [0, 2, 4, 20, 22, 23, 24, 25, 33, 34, 41, 42, 47, 65, 69, 70, 71, 74, 75, 76, 80, 81, 85, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 107, 108, 112, 114, 115, 116, 117, 123, 124, 125, 126, 129, 131, 133, 137, 139, 140, 144, 148, 155, 157, 163, 164, 165, 167, 169, 172, 174, 175, 181, 188, 189, 190, 191, 195, 197, 198, 199, 200, 201], "start": [0, 22, 23, 24, 33, 34, 35, 39, 47, 63, 65, 69, 70, 71, 74, 75, 80, 81, 85, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 121, 123, 124, 125, 129, 131, 137, 138, 139, 140, 144, 146, 147, 148, 153, 155, 156, 157, 159, 163, 164, 169, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200, 201], "practic": [0, 12, 24, 33, 63, 65, 74, 80, 81, 92, 96, 97, 98, 99, 107, 108, 123, 125, 126, 129, 131, 163, 175, 182, 189, 191, 193, 199, 200, 201], "expect": [0, 22, 23, 24, 25, 35, 65, 74, 76, 80, 81, 87, 89, 107, 108, 123, 124, 125, 126, 131, 139, 140, 146, 147, 149, 155, 156, 157, 163, 164, 167, 179, 181, 188, 189, 190, 191, 197, 198, 199], "student": [0, 2, 11, 12, 29, 33, 34, 39, 45, 63, 65, 69, 71, 74, 76, 80, 81, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 108, 114, 115, 116, 117, 123, 124, 125, 126, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 165, 171, 173, 174, 181, 188, 189, 190, 191, 197, 198, 200], "familiar": [0, 2, 12, 27, 74, 81, 139, 156, 199], "variabl": [0, 2, 4, 12, 22, 23, 24, 27, 33, 34, 35, 63, 65, 76, 80, 81, 87, 88, 89, 94, 96, 97, 98, 99, 100, 107, 108, 114, 115, 116, 121, 123, 124, 125, 126, 131, 137, 138, 139, 140, 147, 148, 149, 151, 156, 157, 163, 164, 165, 169, 171, 172, 173, 174, 175, 179, 181, 182, 188, 189, 193, 195, 197, 198], "list": [0, 12, 22, 24, 25, 29, 33, 34, 35, 65, 69, 70, 71, 74, 81, 87, 99, 100, 101, 108, 117, 119, 123, 125, 126, 131, 137, 138, 165, 171, 172, 175, 188, 197, 198, 200], "dict": [0, 25, 87, 99, 100, 101, 107, 108, 123, 124, 125, 126, 172, 174, 189, 190, 191, 199, 200], "numpi": [0, 22, 24, 25, 33, 34, 35, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "scipi": [0, 22, 24, 25, 35, 74, 80, 81, 88, 89, 97, 125, 126, 131, 137, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 190, 191], "librari": [0, 12, 22, 74, 87, 105, 108, 119, 123, 131, 149, 174, 200], "well": [0, 2, 4, 12, 22, 23, 24, 25, 27, 33, 34, 35, 65, 75, 76, 80, 81, 87, 88, 89, 98, 99, 100, 101, 108, 114, 115, 119, 123, 124, 125, 126, 131, 137, 139, 140, 148, 161, 163, 164, 165, 173, 174, 181, 182, 188, 189, 190, 191, 199, 200], "plot": [0, 12, 25, 33, 34, 35], "matplotlib": [0, 22, 24, 25, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "littl": [0, 12, 24, 25, 27, 33, 35, 69, 71, 74, 80, 81, 87, 126, 139, 140, 163, 171, 173, 182, 188, 198], "bit": [0, 22, 24, 33, 74, 75, 76, 80, 81, 87, 88, 89, 107, 126, 131, 137, 163, 164, 189, 191, 198], "everi": [0, 12, 23, 29, 47, 69, 70, 74, 80, 81, 85, 87, 89, 90, 107, 108, 123, 124, 138, 139, 140, 146, 148, 159, 165, 175, 181, 188, 189, 190, 197, 198, 199], "ll": [0, 12, 22, 23, 24, 33, 34, 63, 65, 69, 70, 71, 74, 75, 80, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 112, 114, 115, 116, 117, 123, 124, 125, 126, 131, 135, 148, 155, 157, 163, 164, 165, 169, 171, 172, 175, 179, 181, 188, 197, 198, 199, 200, 201], "great": [0, 12, 20, 23, 27, 33, 75, 76, 81, 85, 88, 97, 105, 107, 159, 189], "shape": [0, 22, 24, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 85, 87, 88, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 125, 126, 131, 138, 144, 147, 148, 149, 153, 155, 156, 157, 164, 165, 171, 172, 174, 175, 181, 182, 188, 190, 191, 197, 198, 199, 200], "class": [0, 24, 33, 34, 45, 69, 70, 87, 88, 96, 107, 108, 123, 124, 125, 126, 174, 181, 182, 190, 191], "have": [0, 2, 4, 12, 22, 23, 24, 25, 27, 29, 31, 33, 34, 35, 39, 41, 44, 46, 47, 63, 69, 70, 71, 74, 75, 76, 80, 81, 85, 87, 88, 89, 96, 97, 98, 99, 100, 101, 105, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 129, 131, 137, 138, 139, 140, 144, 146, 147, 148, 149, 153, 155, 156, 157, 161, 163, 164, 165, 167, 171, 172, 174, 175, 179, 181, 182, 186, 188, 189, 190, 191, 197, 198, 199, 200, 201], "workshop": [0, 12, 39, 63, 65], "w0d1": [0, 75], "w0d2": [0, 75], "here": [0, 12, 22, 23, 24, 25, 29, 33, 35, 36, 37, 38, 39, 43, 47, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 85, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 169, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "should": [0, 2, 4, 12, 22, 23, 24, 25, 27, 29, 41, 47, 63, 65, 70, 71, 74, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 101, 107, 108, 114, 115, 116, 123, 125, 126, 129, 131, 137, 138, 139, 140, 144, 146, 147, 148, 149, 153, 161, 163, 164, 169, 171, 172, 174, 179, 182, 188, 189, 190, 191, 195, 197, 198, 199, 200, 201], "go": [0, 12, 20, 22, 23, 24, 25, 29, 34, 47, 70, 74, 76, 80, 81, 87, 96, 99, 100, 105, 107, 108, 123, 124, 126, 129, 131, 139, 140, 146, 147, 155, 163, 164, 174, 175, 181, 184, 189, 190, 191, 197, 198, 201], "through": [0, 12, 22, 23, 24, 25, 33, 70, 71, 74, 81, 85, 87, 99, 100, 101, 105, 108, 112, 123, 124, 125, 126, 129, 131, 133, 137, 138, 139, 140, 142, 155, 161, 163, 164, 165, 169, 171, 172, 175, 184, 188, 189, 190, 198, 200, 201], "made": [0, 12, 23, 87, 97, 123, 124, 126, 164, 165, 171, 174, 190, 200, 201], "content": [0, 2, 22, 23, 27, 33, 34, 35, 36, 37, 38, 39, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 68, 69, 70, 71, 74, 75, 76, 79, 80, 81, 85, 86, 87, 88, 89, 90, 94, 95, 96, 97, 98, 99, 100, 101, 106, 107, 108, 113, 114, 115, 116, 117, 119, 122, 123, 124, 125, 126, 130, 131, 136, 137, 138, 139, 140, 144, 145, 146, 147, 148, 149, 153, 154, 155, 156, 157, 161, 162, 163, 164, 165, 169, 170, 171, 172, 173, 174, 175, 180, 181, 182, 187, 188, 189, 190, 191, 196, 197, 198, 199, 200], "your": [0, 12, 23, 24, 25, 29, 39, 41, 42, 46, 47, 68, 79, 201], "own": [0, 12, 23, 24, 25, 80, 85, 108, 124, 129, 147, 148, 149, 164, 175, 191, 199, 201], "pace": 0, "befor": [0, 12, 22, 23, 24, 33, 39, 63, 65, 68, 70, 71, 74, 76, 79, 80, 81, 85, 86, 87, 88, 89, 95, 96, 97, 100, 101, 106, 107, 108, 113, 115, 117, 122, 123, 126, 130, 131, 136, 139, 140, 145, 146, 148, 149, 154, 155, 156, 162, 163, 170, 171, 173, 174, 175, 179, 180, 181, 182, 187, 188, 189, 190, 191, 196, 199], "besid": [0, 33, 173], "recommend": [0, 12, 47, 117, 126, 163, 193], "softwar": [0, 29, 70, 107], "carpentri": 0, "free": [0, 12, 22, 25, 29, 35, 80, 117, 123, 125, 131, 159, 163, 173, 181, 188, 190, 191], "edx": 0, "research": [0, 2, 12, 22, 23, 24, 25, 29, 33, 35, 46, 85, 94, 121, 123, 131, 177, 191, 193, 198], "For": [0, 2, 12, 22, 23, 25, 27, 33, 34, 35, 39, 65, 69, 70, 71, 74, 76, 80, 81, 88, 89, 90, 96, 98, 99, 101, 107, 108, 112, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 144, 146, 147, 148, 149, 155, 157, 163, 164, 165, 169, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 195, 200], "depth": [0, 33, 34, 92, 115, 125, 159, 164], "intro": [0, 12, 22, 23, 25, 39, 46, 124, 131, 172, 175, 193, 201], "see": [0, 3, 12, 13, 22, 23, 24, 25, 33, 35, 39, 41, 44, 45, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 85, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 107, 108, 112, 114, 115, 116, 117, 123, 124, 125, 126, 129, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 157, 163, 164, 165, 169, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 195, 197, 198, 199, 200], "note": [0, 12, 22, 23, 24, 25, 39, 45, 46, 47, 63, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 103, 107, 108, 114, 115, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 159, 163, 164, 165, 171, 172, 173, 174, 175, 177, 181, 182, 188, 193, 197, 198, 199, 200], "final": [0, 23, 33, 34, 35, 47, 69, 81, 85, 96, 98, 99, 101, 105, 107, 108, 112, 114, 115, 121, 125, 144, 147, 148, 149, 153, 156, 163, 164, 171, 174, 175, 181, 182, 186, 188, 191, 200, 201], "can": [0, 2, 12, 20, 22, 23, 24, 25, 29, 33, 34, 35, 39, 44, 45, 46, 47, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 85, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 105, 107, 112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 126, 129, 131, 133, 137, 138, 139, 140, 144, 146, 147, 148, 149, 153, 155, 156, 157, 163, 164, 165, 167, 171, 172, 173, 174, 175, 181, 182, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201], "data": [0, 2, 4, 12, 20, 23, 25, 27, 29, 33, 34, 35, 63, 65, 69, 70, 74, 80, 81, 83, 85, 88, 92, 94, 96, 97, 98, 99, 101, 105, 112, 117, 121, 129, 133, 139, 147, 153, 163, 169, 171, 172, 173, 193, 195, 197, 198, 199, 200, 201], "scienc": [0, 2, 12, 20, 22, 23, 24, 27, 75, 76, 83, 92, 96, 98, 119, 131, 133, 142, 151, 173, 174, 177, 184, 186, 188, 193, 195, 197, 201], "handbook": [0, 83, 188], "which": [0, 2, 4, 12, 20, 22, 23, 24, 25, 27, 31, 33, 34, 35, 39, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 85, 87, 88, 89, 90, 94, 96, 97, 98, 99, 101, 105, 107, 108, 114, 115, 116, 117, 119, 121, 123, 124, 125, 126, 131, 137, 138, 139, 144, 146, 147, 148, 149, 155, 156, 157, 159, 161, 163, 164, 165, 169, 171, 172, 173, 174, 175, 179, 181, 182, 186, 188, 189, 190, 191, 197, 198, 199, 200, 201], "also": [0, 2, 11, 12, 22, 23, 24, 25, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 85, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 105, 107, 108, 112, 114, 115, 116, 117, 123, 124, 125, 126, 129, 131, 138, 139, 140, 144, 146, 147, 148, 149, 153, 155, 156, 157, 159, 163, 164, 165, 169, 171, 172, 173, 174, 175, 179, 181, 182, 188, 189, 190, 191, 195, 198, 199, 200], "ha": [0, 2, 4, 12, 20, 22, 23, 24, 25, 33, 34, 35, 36, 37, 38, 46, 47, 69, 71, 74, 75, 76, 80, 81, 85, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 172, 173, 174, 175, 181, 182, 186, 188, 189, 190, 191, 197, 198, 199, 200], "print": [0, 22, 24, 25, 33, 34, 35, 65, 70, 74, 80, 81, 87, 89, 96, 97, 98, 99, 107, 108, 115, 123, 124, 125, 126, 131, 138, 140, 146, 147, 148, 149, 155, 156, 157, 165, 171, 172, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "edit": [0, 12, 39, 46, 75, 76, 165], "matlab": [0, 92, 107], "quickli": [0, 12, 33, 87, 88, 96, 115, 148, 155, 172, 182, 188, 189, 191], "get": [0, 11, 22, 23, 24, 25, 33, 45, 47, 63, 69, 70, 71, 74, 75, 76, 80, 81, 88, 89, 96, 97, 98, 99, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 129, 131, 137, 139, 140, 146, 147, 148, 149, 155, 156, 157, 159, 163, 164, 165, 171, 172, 173, 174, 175, 179, 181, 182, 188, 189, 190, 191, 193, 197, 198, 199, 200], "up": [0, 12, 22, 23, 24, 25, 29, 63, 69, 70, 71, 74, 75, 76, 80, 81, 89, 97, 98, 99, 101, 107, 112, 114, 116, 123, 124, 126, 129, 131, 140, 146, 148, 155, 163, 164, 165, 169, 171, 172, 173, 174, 181, 188, 189, 190, 191, 197, 198, 199, 200, 201], "speed": [0, 24, 63, 88, 107, 119, 126, 173, 177, 188, 189, 191], "cheatsheet": 0, "mai": [0, 12, 23, 24, 25, 33, 34, 35, 39, 45, 47, 63, 65, 69, 70, 74, 75, 76, 80, 81, 87, 88, 89, 98, 99, 101, 108, 116, 117, 119, 123, 124, 125, 126, 137, 138, 139, 144, 146, 147, 148, 149, 153, 163, 164, 165, 171, 172, 174, 181, 182, 188, 189, 190, 191, 195, 198, 199, 200], "paperback": 0, "neural": [0, 2, 12, 20, 24, 29, 31, 33, 75, 80, 81, 83, 87, 88, 89, 92, 94, 103, 105, 107, 110, 112, 116, 119, 121, 133, 142, 144, 147, 148, 151, 161, 167, 169, 171, 172, 173, 175, 177, 184, 193, 198, 201], "both": [0, 22, 24, 25, 33, 34, 35, 39, 69, 74, 75, 80, 81, 88, 99, 100, 101, 108, 114, 115, 116, 124, 126, 129, 131, 137, 138, 139, 144, 146, 147, 148, 156, 157, 163, 164, 169, 172, 174, 181, 182, 188, 189, 190, 197, 199, 200, 201], "version": [0, 12, 13, 33, 34, 35, 46, 63, 69, 76, 81, 107, 112, 114, 125, 139, 165, 169, 173, 175, 195], "analysi": [0, 2, 12, 20, 22, 23, 24, 74, 81, 83, 85, 94, 98, 103, 105, 107, 112, 119, 121, 123, 125, 129, 131, 133, 138, 153, 165, 169, 173, 193, 198, 200], "reli": [0, 12, 23, 24, 25, 94, 96, 98, 163, 164, 174, 199], "linear": [0, 12, 22, 24, 25, 33, 34, 35, 39, 71, 74, 76, 80, 81, 85, 87, 89, 94, 98, 100, 101, 103, 105, 108, 112, 117, 121, 123, 124, 125, 131, 135, 138, 139, 140, 144, 146, 147, 153, 156, 157, 169, 172, 173, 181, 193, 200, 201], "algebra": [0, 63, 70, 71, 81, 96, 99, 112, 133, 137, 174, 201], "probabl": [0, 12, 22, 23, 24, 25, 33, 41, 85, 87, 88, 94, 97, 101, 105, 107, 108, 125, 126, 131, 139, 147, 148, 149, 161, 169, 172, 173, 174, 175, 181, 186, 188, 189, 190, 191, 195, 199, 201], "statist": [0, 23, 29, 65, 80, 92, 94, 98, 100, 103, 107, 124, 138, 144, 146, 147, 149, 153, 155, 161, 164, 167, 169, 172, 173, 175, 181, 182, 195, 197, 201], "calculu": [0, 75, 76, 96, 137, 146, 156, 201], "deriv": [0, 23, 33, 63, 75, 81, 85, 89, 92, 97, 98, 101, 108, 121, 123, 137, 138, 155, 156, 157, 164, 171, 174, 186, 188, 189], "od": [0, 63, 137, 148], "highli": [0, 23, 100, 123, 149, 155, 193], "our": [0, 12, 22, 23, 24, 25, 33, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 85, 87, 88, 89, 96, 97, 98, 99, 100, 101, 105, 107, 108, 114, 116, 117, 123, 124, 125, 126, 129, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 161, 163, 164, 165, 169, 171, 172, 173, 174, 175, 179, 181, 182, 186, 188, 189, 190, 191, 198, 199], "refresh": [0, 71, 107, 114, 115, 116, 164, 165, 181, 182, 201], "w0d3": [0, 81, 94, 105], "w0d4": [0, 85], "w0d5": [0, 85, 94, 105, 161, 164], "ask": [0, 12, 24, 25, 27, 35, 39, 75, 80, 85, 87, 101, 108, 140, 148, 164, 195, 197, 198, 199, 201], "question": [0, 23, 27, 33, 35, 69, 70, 71, 75, 76, 80, 81, 85, 87, 88, 89, 90, 94, 98, 105, 116, 121, 123, 125, 126, 129, 144, 146, 147, 148, 153, 155, 163, 164, 172, 173, 181, 195, 197, 198, 201], "discord": [0, 12, 39], "grasp": 0, "along": [0, 12, 22, 69, 70, 74, 87, 96, 98, 114, 115, 123, 124, 131, 156, 157, 164, 165, 189], "crucial": [0, 12, 22, 23, 35, 94, 126, 131, 155, 179], "almost": [0, 22, 80, 81, 94, 108, 123, 131, 139, 149, 163, 190, 191, 197], "anyth": [0, 12, 24, 46, 75, 123, 126, 129, 140, 148, 165, 174, 188, 189], "quantit": [0, 22, 23, 107, 124, 131, 133, 142, 155, 174], "involv": [0, 23, 74, 81, 107, 121, 123, 125, 138, 164, 181, 191], "than": [0, 12, 22, 23, 24, 27, 33, 35, 45, 63, 65, 71, 74, 75, 80, 81, 87, 89, 96, 97, 99, 100, 101, 107, 116, 117, 123, 124, 125, 126, 131, 137, 138, 140, 146, 147, 148, 149, 157, 161, 163, 164, 165, 171, 173, 174, 175, 181, 182, 188, 189, 190, 191, 193, 198, 199, 200], "one": [0, 2, 4, 12, 20, 22, 23, 24, 25, 27, 33, 34, 39, 46, 47, 65, 69, 70, 71, 74, 76, 80, 81, 85, 87, 88, 89, 90, 94, 96, 97, 98, 99, 100, 101, 105, 107, 108, 114, 115, 121, 123, 124, 125, 126, 129, 131, 133, 137, 138, 139, 140, 146, 148, 149, 155, 156, 157, 163, 164, 165, 167, 171, 172, 173, 174, 175, 181, 182, 186, 188, 189, 190, 191, 195, 197, 198, 200, 201], "number": [0, 22, 24, 33, 34, 35, 47, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 101, 107, 108, 112, 114, 115, 117, 123, 124, 125, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 159, 163, 164, 171, 172, 173, 174, 175, 181, 182, 188, 189, 191, 193, 197, 200], "vector": [0, 24, 25, 33, 34, 35, 70, 71, 74, 81, 87, 94, 96, 97, 98, 99, 100, 101, 105, 107, 108, 115, 116, 117, 123, 124, 125, 126, 137, 138, 140, 146, 147, 148, 149, 155, 157, 164, 165, 171, 172, 173, 175, 181, 197, 198], "matrix": [0, 22, 24, 33, 71, 74, 75, 81, 100, 101, 105, 108, 110, 114, 117, 123, 124, 126, 131, 137, 138, 139, 147, 148, 149, 156, 163, 172, 173, 174, 175, 182, 191, 198, 199, 200], "addit": [0, 4, 12, 20, 22, 23, 27, 33, 34, 35, 39, 63, 65, 69, 76, 80, 88, 99, 100, 105, 107, 108, 124, 131, 137, 146, 147, 157, 164, 173, 174, 175, 182, 190, 191, 200], "multipl": [0, 12, 27, 63, 65, 69, 71, 80, 81, 87, 96, 97, 98, 100, 101, 105, 114, 123, 124, 125, 129, 133, 137, 140, 147, 148, 153, 164, 165, 171, 175, 189, 190, 191, 193, 199, 200], "rank": [0, 115, 123, 133, 198], "base": [0, 2, 12, 22, 23, 24, 29, 33, 39, 69, 70, 71, 74, 76, 80, 81, 89, 97, 98, 99, 101, 103, 107, 112, 115, 116, 119, 123, 129, 131, 137, 138, 140, 149, 153, 155, 156, 163, 164, 167, 171, 172, 173, 174, 175, 182, 184, 188, 189, 190, 193, 195, 201], "determin": [0, 12, 23, 24, 25, 33, 34, 35, 69, 74, 80, 85, 101, 108, 116, 117, 121, 123, 124, 126, 129, 137, 138, 146, 148, 149, 151, 153, 155, 156, 157, 163, 164, 171, 172, 173, 177, 181, 182, 188, 189, 197, 198, 199, 200, 201], "invers": [0, 69, 70, 87, 89, 99, 108, 146, 156, 157, 164, 165, 171, 173, 199, 200], "eigenvalu": [0, 115, 116, 138], "decomposit": [0, 33, 117, 125, 133], "In": [0, 12, 22, 23, 24, 25, 33, 34, 35, 39, 47, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 83, 85, 87, 88, 89, 90, 94, 96, 97, 98, 99, 100, 101, 103, 105, 107, 108, 112, 114, 115, 116, 117, 119, 121, 123, 124, 125, 126, 131, 133, 137, 138, 139, 140, 142, 144, 146, 147, 148, 149, 153, 155, 156, 157, 161, 163, 164, 165, 167, 169, 171, 172, 173, 174, 175, 179, 181, 182, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201], "beauti": [0, 33, 75, 76, 83, 147, 159, 193], "seri": [0, 12, 25, 33, 36, 37, 38, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 74, 75, 76, 81, 85, 87, 88, 89, 96, 97, 98, 99, 100, 101, 105, 107, 108, 140, 144, 146, 147, 171, 172, 174, 191, 193, 200, 201], "anoth": [0, 12, 20, 22, 24, 25, 33, 34, 35, 46, 47, 65, 69, 70, 74, 75, 76, 81, 87, 88, 89, 96, 99, 101, 107, 116, 123, 124, 126, 131, 138, 139, 146, 147, 163, 164, 165, 174, 182, 188, 193, 195, 198, 200], "resourc": [0, 74, 75, 80, 81, 88, 148, 159], "khan": 0, "exercis": [0, 22, 23, 75, 131, 164], "understand": [0, 12, 23, 24, 33, 34, 35, 63, 69, 75, 80, 81, 83, 87, 88, 89, 99, 100, 107, 108, 110, 114, 115, 121, 123, 126, 129, 137, 138, 144, 147, 148, 153, 155, 156, 157, 163, 164, 167, 169, 172, 173, 174, 175, 179, 182, 188, 189, 191, 195, 197, 198, 199, 200], "import": [0, 12, 22, 23, 24, 25, 36, 37, 38, 47, 78, 92, 201], "comfort": [0, 33, 161], "varianc": [0, 63, 80, 81, 96, 97, 98, 99, 101, 108, 114, 115, 147, 164, 171, 172, 173, 182, 189, 197], "normal": [0, 12, 22, 24, 25, 33, 34, 35, 39, 65, 71, 74, 75, 76, 80, 81, 87, 89, 96, 97, 98, 100, 101, 107, 108, 114, 115, 116, 119, 123, 124, 125, 126, 131, 139, 140, 163, 164, 171, 172, 173, 175, 189, 197, 198], "distribut": [0, 4, 12, 22, 24, 27, 33, 34, 35, 63, 65, 85, 88, 94, 96, 98, 100, 101, 105, 107, 108, 124, 125, 131, 139, 140, 144, 146, 147, 148, 161, 169, 171, 172, 173, 175, 184, 188, 189, 198], "select": [0, 2, 12, 29, 33, 34, 35, 47, 65, 80, 81, 87, 94, 96, 97, 98, 99, 116, 123, 126, 133, 151, 163, 164, 179, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "read": [0, 12, 25, 33, 54, 63, 65, 80, 98, 99, 100, 164, 165, 171, 175, 189], "i": [0, 12, 22, 23, 24, 25, 27, 33, 34, 35, 39, 65, 69, 70, 71, 74, 75, 76, 80, 81, 83, 85, 87, 88, 89, 96, 97, 98, 99, 103, 105, 107, 108, 110, 114, 115, 116, 117, 119, 123, 124, 125, 126, 129, 131, 133, 137, 139, 140, 147, 149, 151, 153, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 193, 197, 198, 199, 200], "e": [0, 2, 12, 20, 22, 23, 24, 25, 27, 33, 34, 35, 46, 63, 65, 69, 70, 74, 75, 76, 80, 81, 83, 85, 87, 88, 89, 92, 94, 97, 98, 99, 100, 101, 103, 105, 108, 110, 114, 115, 116, 117, 119, 121, 123, 124, 125, 126, 129, 131, 133, 137, 142, 146, 147, 149, 151, 153, 159, 163, 164, 165, 167, 171, 172, 173, 174, 177, 181, 182, 188, 189, 190, 191, 193, 195, 197, 198, 199], "chapter": [0, 12, 92, 142, 151, 159, 174, 188], "6": [0, 12, 20, 22, 24, 25, 33, 34, 39, 70, 71, 75, 80, 87, 89, 92, 94, 96, 97, 98, 99, 100, 107, 108, 115, 116, 117, 119, 123, 124, 125, 126, 129, 131, 133, 137, 138, 139, 140, 142, 146, 147, 148, 149, 155, 156, 157, 167, 174, 175, 177, 182, 184, 188, 189, 190, 191, 197, 198, 199], "7": [0, 20, 22, 24, 25, 31, 33, 39, 70, 71, 74, 75, 76, 80, 83, 87, 88, 96, 97, 98, 103, 107, 108, 115, 116, 117, 124, 125, 126, 131, 137, 138, 139, 140, 147, 148, 149, 155, 156, 157, 174, 175, 177, 182, 188, 189, 193, 197, 198, 199, 200], "russ": 0, "poldrack": 0, "s": [0, 2, 12, 20, 22, 23, 24, 25, 27, 29, 31, 33, 34, 35, 46, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 83, 85, 87, 88, 89, 92, 94, 96, 97, 98, 99, 103, 105, 107, 108, 110, 114, 115, 116, 119, 123, 126, 129, 131, 133, 137, 138, 139, 140, 142, 144, 146, 147, 148, 149, 151, 155, 156, 157, 159, 163, 164, 165, 169, 171, 172, 174, 175, 177, 179, 181, 182, 184, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201], "book": [0, 12, 83, 107, 146, 159, 175, 193], "think": [0, 12, 23, 24, 25, 63, 71, 74, 85, 99, 100, 101, 105, 108, 112, 116, 123, 129, 144, 159, 164, 171, 172, 173, 174, 181, 182, 190, 191, 197, 199], "21st": 0, "centuri": 0, "what": [0, 11, 12, 22, 23, 24, 25, 27, 33, 34, 63, 65, 70, 71, 75, 80, 81, 85, 88, 89, 90, 92, 96, 97, 99, 100, 101, 105, 107, 114, 115, 116, 117, 119, 121, 123, 125, 126, 129, 131, 137, 138, 139, 140, 146, 148, 149, 151, 153, 155, 156, 157, 161, 164, 165, 169, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201], "integr": [0, 12, 22, 24, 45, 65, 80, 81, 85, 124, 131, 133, 142, 144, 147, 148, 151, 159, 163, 164, 165, 171, 173, 174, 175, 201], "differenti": [0, 63, 101, 116, 119, 123, 126, 138, 139, 142, 148, 155, 156, 175], "equat": [0, 23, 25, 34, 63, 65, 69, 71, 74, 80, 81, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 124, 125, 126, 138, 139, 140, 146, 147, 148, 149, 155, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 188, 189, 190, 197, 199, 200], "memori": [0, 20, 70, 71, 123, 139, 156, 184, 191], "gilbert": 0, "strang": 0, "studi": [0, 12, 74, 75, 76, 87, 105, 123, 124, 125, 126, 138, 139, 146, 147, 148, 149, 155, 156, 157, 164, 186, 188, 191, 200], "0": [0, 2, 12, 22, 24, 25, 31, 39, 63, 65, 70, 71, 76, 80, 81, 83, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 119, 124, 125, 126, 133, 137, 138, 139, 140, 142, 146, 147, 149, 155, 156, 157, 165, 173, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "includ": [0, 4, 12, 23, 24, 25, 27, 29, 33, 63, 69, 70, 71, 75, 80, 81, 89, 99, 107, 108, 114, 115, 116, 121, 123, 126, 137, 139, 140, 144, 155, 156, 157, 161, 165, 171, 172, 174, 175, 181, 182, 188, 189, 197, 199, 200, 201], "jiri": 0, "lebl": 0, "engin": [0, 2, 23, 33, 75, 76, 119, 133, 167, 179, 182], "outsid": [0, 22, 24, 25, 97, 123, 131, 139, 149], "fundament": [0, 12, 35, 83, 98, 107, 108, 163, 164, 189, 200], "watch": [0, 2, 12, 39, 115, 146, 159, 163, 181, 201], "neuro": [0, 12, 20, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 71, 85, 105, 108, 119, 133, 201], "video": [0, 2, 12, 20, 25, 39, 44, 159], "w0d0": 0, "short": [0, 12, 23, 35, 63, 74, 81, 87, 115, 124, 137, 138, 139, 144, 147, 164, 182], "subject": [0, 4, 12, 20, 35, 94, 156, 163, 165, 171, 174, 177, 188], "brain": [0, 12, 20, 22, 24, 25, 27, 29, 35, 36, 37, 38, 74, 75, 83, 85, 87, 108, 112, 121, 123, 124, 125, 126, 131, 133, 144, 147, 148, 153, 155, 156, 163, 164, 165, 167, 169, 171, 172, 173, 174, 175, 177, 179, 181, 186, 188, 195, 197, 198, 199, 201], "fact": [0, 12, 22, 24, 69, 70, 80, 81, 97, 114, 116, 123, 124, 131, 139, 146, 147, 148, 149, 155, 156, 161, 163, 164, 171, 174, 189, 190, 191, 198, 200], "societi": [0, 193], "so": [0, 12, 22, 24, 25, 63, 69, 70, 71, 74, 75, 76, 80, 81, 85, 87, 88, 89, 90, 94, 96, 97, 98, 99, 100, 101, 105, 107, 108, 112, 114, 115, 116, 117, 123, 124, 125, 126, 129, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 193, 197, 198, 199, 200, 201], "look": [0, 12, 22, 24, 25, 29, 33, 69, 70, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 100, 105, 107, 108, 112, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 148, 157, 163, 164, 165, 171, 172, 174, 175, 181, 189, 190, 191, 197, 198, 200, 201], "forward": [0, 34, 35, 76, 124, 125, 126, 139, 155, 174], "meet": [0, 12, 23, 39, 107], "soon": [0, 24, 33], "The": [0, 2, 4, 12, 20, 22, 23, 24, 25, 27, 34, 35, 39, 47, 65, 70, 71, 74, 80, 81, 83, 85, 87, 92, 94, 96, 97, 98, 99, 100, 101, 103, 105, 107, 110, 114, 115, 116, 117, 121, 123, 124, 125, 126, 129, 131, 133, 137, 138, 140, 142, 144, 147, 148, 149, 151, 153, 155, 156, 157, 159, 161, 163, 165, 167, 169, 172, 175, 177, 179, 181, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201], "team": [0, 4, 12, 33, 34, 35, 63, 65, 89, 90, 140, 147, 148], "juli": [2, 4, 20, 27, 29, 39], "5": [2, 4, 12, 20, 24, 25, 27, 29, 31, 33, 35, 39, 41, 71, 83, 88, 96, 97, 98, 99, 101, 103, 107, 110, 114, 115, 116, 117, 119, 123, 124, 125, 126, 133, 137, 138, 139, 140, 142, 146, 147, 148, 149, 151, 155, 156, 157, 167, 177, 182, 188, 189, 190, 191, 193, 198, 199], "23": [2, 4, 20, 27, 29, 39, 65, 71, 76, 80, 83, 88, 89, 96, 97, 98, 99, 100, 107, 115, 119, 124, 125, 126, 133, 137, 138, 139, 140, 149, 155, 156, 165, 171, 172, 173, 175, 177, 182, 190, 191, 197, 199, 200], "2021": [2, 4, 11, 20, 27, 29, 75, 76, 119, 123, 124, 125, 133, 151, 157], "new": [2, 12, 23, 27, 29, 33, 35, 63, 65, 69, 71, 74, 81, 83, 92, 98, 101, 105, 108, 115, 116, 117, 123, 138, 139, 142, 146, 147, 148, 151, 155, 156, 157, 159, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 191, 193, 198], "youtub": [2, 4, 20, 27, 159], "kai": [2, 22, 83, 131], "miller": [2, 103, 133, 142, 151, 153], "rare": [2, 80, 96, 129, 200], "intracrani": 2, "electrocorticograph": 2, "record": [2, 4, 12, 22, 24, 27, 65, 69, 70, 75, 80, 81, 87, 88, 89, 94, 99, 103, 107, 108, 110, 114, 121, 123, 124, 125, 126, 131, 133, 142, 146, 147, 148, 149, 156, 173, 174, 175, 182, 189], "clinic": [2, 121, 133], "pleas": [2, 12, 22, 23, 33, 34, 35, 39, 42, 43, 45, 46, 47, 63, 65, 68, 70, 71, 79, 85, 86, 87, 88, 89, 90, 94, 95, 96, 100, 106, 107, 108, 113, 117, 122, 123, 124, 126, 130, 131, 136, 145, 154, 155, 157, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 180, 181, 182, 187, 188, 196, 197, 198, 199, 200], "ted": 2, "talk": [2, 12, 69, 89, 94, 97, 105, 124, 179, 195, 200], "yourself": [2, 12, 23, 70, 75, 80, 140, 146, 163, 164, 171, 173, 200], "type": [2, 22, 23, 24, 33, 39, 63, 69, 71, 74, 75, 76, 81, 87, 88, 90, 94, 99, 100, 105, 107, 108, 112, 117, 121, 123, 124, 125, 126, 129, 131, 133, 138, 139, 140, 142, 147, 148, 149, 153, 155, 157, 173, 175, 189, 191, 193, 198, 201], "less": [2, 12, 25, 35, 71, 74, 80, 81, 85, 87, 107, 108, 116, 123, 163, 172, 189, 190, 198, 200], "same": [2, 12, 22, 23, 24, 33, 34, 46, 63, 65, 69, 70, 71, 74, 76, 80, 81, 85, 87, 89, 90, 96, 97, 98, 99, 100, 107, 108, 117, 121, 123, 124, 125, 126, 131, 137, 138, 139, 142, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199], "difficulti": [2, 33], "all": [2, 12, 20, 22, 23, 24, 25, 27, 31, 33, 34, 35, 39, 63, 65, 69, 70, 71, 74, 80, 81, 85, 87, 88, 89, 92, 94, 97, 98, 99, 101, 105, 107, 108, 112, 114, 115, 116, 119, 123, 124, 125, 126, 129, 131, 137, 138, 139, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 188, 189, 190, 191, 195, 197, 198, 199, 200, 201], "group": [2, 12, 20, 22, 24, 27, 29, 46, 69, 70, 87, 88, 89, 90, 125, 126, 129, 131, 149, 181, 188, 195, 200], "method": [2, 12, 22, 23, 33, 63, 65, 69, 71, 74, 75, 81, 83, 85, 88, 89, 94, 96, 97, 98, 101, 105, 107, 108, 112, 123, 126, 131, 133, 137, 138, 142, 146, 147, 148, 155, 156, 157, 165, 171, 174, 179, 182, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201], "standard": [2, 22, 23, 25, 29, 69, 70, 74, 80, 81, 96, 97, 98, 100, 101, 107, 108, 123, 125, 131, 139, 140, 146, 148, 159, 165, 171, 172, 173, 174, 175, 188, 195, 197, 198, 200], "protocol": 2, "particular": [2, 12, 22, 24, 25, 70, 87, 89, 96, 101, 105, 108, 112, 114, 123, 124, 125, 126, 131, 137, 138, 140, 146, 147, 156, 161, 172, 190, 191, 197, 200], "interest": [2, 12, 20, 22, 23, 24, 25, 85, 87, 88, 89, 94, 107, 117, 124, 126, 131, 137, 139, 144, 147, 148, 153, 155, 163, 164, 165, 188, 190, 191, 197, 198, 200], "sensori": [2, 4, 12, 22, 24, 75, 103, 123, 124, 131, 151, 159, 164, 171, 172, 173, 174, 175], "bci": 2, "slightli": [2, 12, 63, 124, 139, 148, 157, 163, 165, 171, 173, 174, 189, 190], "advanc": [2, 20, 22, 27, 29, 70, 80, 81, 92, 101, 103, 119, 131, 133, 156, 161, 167, 173, 199], "definit": [2, 12, 23, 34, 65, 70, 74, 75, 76, 88, 89, 137, 138, 146, 148, 156, 157, 163, 164, 171, 177, 188, 195, 197, 198, 199, 200], "consid": [2, 4, 12, 23, 29, 69, 75, 76, 81, 87, 88, 89, 97, 99, 100, 108, 116, 123, 126, 137, 138, 139, 149, 155, 157, 163, 164, 165, 171, 173, 174, 175, 182, 188, 189, 190, 197, 198, 199, 200], "steinmetz": [2, 4, 89, 108], "much": [2, 12, 22, 23, 24, 25, 34, 63, 65, 71, 74, 75, 76, 80, 81, 88, 89, 96, 101, 105, 107, 108, 115, 116, 117, 121, 123, 124, 129, 131, 146, 148, 149, 163, 164, 165, 171, 174, 175, 182, 188, 189, 193, 198], "better": [2, 12, 22, 23, 24, 33, 34, 35, 63, 65, 69, 71, 74, 75, 81, 85, 94, 96, 97, 101, 107, 108, 112, 117, 123, 124, 125, 126, 129, 131, 137, 140, 147, 149, 153, 156, 163, 164, 171, 173, 174, 181, 182, 188, 189, 195, 198, 199, 200], "suit": [2, 12, 33, 101, 112, 123, 124, 125], "exploratori": [2, 12, 27], "analys": [2, 4, 12, 20, 23, 27, 29, 80, 123, 157, 165, 201], "divers": [2, 12, 23, 27, 83, 85, 119, 126, 155], "topic": [2, 12, 22, 69, 70, 80, 131, 139, 161, 171, 186, 188, 191, 201], "thei": [2, 12, 22, 23, 24, 25, 27, 39, 41, 45, 69, 70, 75, 76, 80, 81, 85, 87, 88, 89, 97, 98, 99, 100, 105, 107, 108, 112, 114, 115, 117, 121, 123, 124, 125, 126, 131, 137, 138, 139, 140, 147, 148, 149, 156, 163, 164, 165, 173, 174, 175, 181, 188, 189, 190, 191, 197, 198, 199, 200], "comput": [2, 12, 22, 23, 24, 25, 29, 33, 45, 47, 63, 65, 69, 71, 74, 80, 83, 87, 92, 94, 97, 98, 103, 107, 108, 112, 114, 116, 119, 123, 124, 126, 129, 131, 133, 137, 140, 142, 144, 148, 151, 153, 161, 164, 165, 167, 169, 171, 173, 174, 175, 177, 179, 181, 182, 186, 188, 189, 190, 193, 199, 201], "project": [2, 4, 20, 23, 27, 33, 34, 35, 42, 46, 47, 69, 70, 74, 99, 112, 116, 117, 129, 153, 174, 201], "becaus": [2, 12, 20, 22, 23, 24, 25, 27, 74, 75, 80, 81, 85, 87, 89, 97, 99, 101, 107, 108, 115, 116, 117, 123, 124, 125, 126, 129, 131, 139, 140, 146, 147, 148, 149, 153, 155, 163, 164, 165, 171, 173, 174, 179, 181, 189, 190, 197, 198, 199, 200], "high": [2, 12, 23, 27, 33, 34, 74, 100, 101, 112, 114, 115, 117, 119, 123, 125, 126, 133, 137, 140, 142, 146, 148, 155, 157, 163, 167, 171, 172, 181, 182, 188, 189, 198, 199], "dimension": [2, 12, 27, 31, 33, 35, 39, 69, 70, 74, 85, 99, 107, 112, 114, 115, 123, 126, 133, 139, 147, 155, 164, 172, 174, 181, 182, 195, 197, 198, 201], "lot": [2, 11, 12, 20, 22, 23, 24, 69, 71, 74, 80, 81, 98, 100, 101, 123, 125, 131, 139, 163, 164, 171, 198, 201], "neuron": [2, 12, 20, 22, 24, 35, 39, 69, 70, 71, 75, 76, 80, 81, 85, 94, 97, 103, 105, 107, 108, 114, 115, 119, 121, 123, 124, 125, 126, 131, 133, 137, 138, 144, 153, 156, 157, 164, 167, 171, 177, 179, 181, 188, 195, 201], "trial": [2, 4, 12, 22, 24, 25, 80, 108, 114, 124, 126, 131, 133, 146, 147, 148, 165, 171, 175, 188, 189, 190, 191, 198, 199, 200], "support": [2, 4, 27, 29, 63, 69, 75, 87, 89, 94, 108, 182, 198], "nma": [2, 11, 12, 24, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 85, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 129, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 159, 161, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 186, 188, 189, 190, 191, 197, 198, 199, 200], "been": [2, 12, 22, 23, 24, 25, 39, 46, 47, 69, 71, 75, 80, 81, 98, 100, 101, 105, 114, 115, 123, 124, 125, 126, 131, 139, 148, 149, 155, 156, 157, 163, 164, 165, 167, 174, 175, 181, 188, 191, 197, 198, 200], "curat": [2, 4, 20, 27, 201], "annot": [2, 20, 70, 108, 189], "gener": [2, 12, 23, 24, 33, 34, 35, 63, 65, 69, 74, 75, 76, 85, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 103, 105, 108, 115, 121, 123, 124, 125, 138, 139, 140, 144, 147, 148, 149, 155, 156, 157, 163, 164, 171, 172, 173, 174, 181, 188, 189, 190, 191, 197, 198, 199, 200, 201], "credit": [2, 4, 20, 27, 70], "mariu": [2, 20, 22, 23, 24, 25, 27, 131], "pachitariu": [2, 20, 22, 27, 119, 131], "ta": [2, 39, 76], "view": [2, 4, 20, 22, 23, 24, 25, 27, 29, 69, 74, 83, 87, 89, 97, 123, 124, 125, 126, 131, 155, 172, 174, 175], "faceshous": 2, "joysticktrack": 2, "memorynback": 2, "motorimageri": 2, "exploreajile12": 2, "k": [2, 12, 20, 22, 23, 25, 27, 63, 65, 69, 70, 71, 76, 80, 83, 92, 97, 99, 101, 103, 108, 110, 114, 115, 116, 117, 119, 124, 125, 126, 131, 133, 137, 138, 139, 140, 142, 146, 147, 148, 149, 151, 155, 156, 157, 159, 164, 165, 167, 173, 174, 175, 182, 184, 188, 189, 191, 193, 197, 198, 199, 200], "j": [2, 12, 20, 27, 33, 34, 35, 63, 65, 69, 70, 71, 74, 81, 83, 92, 99, 103, 107, 108, 110, 115, 119, 133, 142, 147, 151, 156, 157, 159, 163, 167, 172, 174, 175, 177, 182, 184, 188, 193, 197, 198, 199, 200], "herm": 2, "d": [2, 20, 22, 23, 24, 25, 27, 33, 63, 69, 70, 71, 74, 75, 76, 83, 92, 96, 99, 103, 107, 108, 110, 119, 125, 126, 131, 133, 139, 140, 142, 146, 151, 155, 156, 157, 159, 167, 172, 173, 174, 175, 177, 182, 184, 188, 190, 191, 193, 198], "pestilli": 2, "f": [2, 20, 22, 24, 25, 31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 147, 148, 149, 152, 153, 154, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200], "wig": 2, "g": [2, 12, 20, 22, 23, 24, 25, 46, 69, 70, 71, 74, 75, 76, 80, 81, 83, 87, 88, 89, 92, 94, 96, 97, 98, 99, 100, 101, 103, 105, 107, 116, 117, 119, 121, 123, 124, 125, 126, 131, 133, 137, 142, 146, 148, 149, 151, 153, 155, 164, 165, 171, 172, 173, 174, 177, 181, 182, 184, 188, 189, 190, 191, 193, 195, 198], "ojemann": [2, 133], "2017": [2, 20, 23, 83, 92, 103, 119, 133, 193], "percept": [2, 22, 24, 25, 83, 103, 131, 159, 165, 173, 181], "format": [2, 12, 25, 29, 69, 87, 115, 123, 139, 140, 147, 171, 172, 174, 175, 182, 200], "human": [2, 4, 20, 33, 35, 75, 80, 119, 121, 123, 124, 133, 139, 140, 163, 164, 171, 184, 186, 188, 193], "ventral": [2, 119], "tempor": [2, 23, 103, 107, 119, 133, 146, 147, 156, 173, 174, 190, 191, 200], "cortex": [2, 27, 81, 103, 108, 119, 121, 123, 124, 125, 126, 133, 151, 153, 175, 184], "journal": [2, 20, 23, 76, 83, 92, 103, 119, 133, 142, 147, 151, 156, 157, 167, 177, 193], "neurophysiolog": [2, 76, 92, 103, 133, 142, 151, 177], "118": [2, 119], "2614": 2, "2627": 2, "doi": [2, 20, 22, 23, 27, 75, 76, 83, 92, 103, 110, 119, 131, 133, 142, 147, 151, 156, 157, 167, 177, 184, 193], "10": [2, 12, 20, 22, 24, 25, 27, 33, 34, 35, 39, 69, 71, 74, 75, 76, 80, 81, 83, 87, 88, 89, 92, 96, 97, 98, 99, 100, 101, 103, 107, 108, 110, 115, 116, 117, 119, 123, 124, 125, 126, 129, 131, 133, 137, 139, 140, 142, 146, 147, 148, 149, 151, 155, 156, 157, 164, 165, 167, 171, 172, 175, 177, 181, 182, 184, 188, 189, 190, 191, 193, 197, 198, 199, 200], "1152": [2, 92, 103, 133, 142, 151, 177], "jn": [2, 92, 103, 133, 142, 151, 177], "00113": 2, "witthoft": 2, "n": [2, 20, 22, 24, 25, 27, 33, 34, 63, 65, 69, 71, 74, 75, 76, 80, 81, 83, 87, 89, 92, 96, 97, 98, 99, 100, 101, 103, 107, 108, 110, 114, 115, 116, 119, 123, 124, 125, 126, 131, 133, 137, 139, 140, 142, 146, 147, 148, 149, 151, 155, 156, 157, 159, 163, 164, 165, 171, 172, 173, 174, 175, 177, 181, 182, 184, 188, 189, 190, 191, 193, 197, 198, 199, 200], "rao": [2, 133], "r": [2, 20, 22, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 83, 87, 88, 89, 92, 96, 97, 98, 103, 107, 108, 110, 114, 115, 119, 123, 124, 125, 126, 131, 133, 137, 139, 140, 142, 146, 147, 148, 149, 151, 155, 156, 157, 159, 164, 165, 167, 171, 172, 174, 175, 177, 181, 182, 184, 188, 190, 191, 193, 197, 198, 199, 200], "p": [2, 20, 22, 27, 34, 35, 69, 70, 74, 75, 76, 80, 81, 83, 89, 92, 97, 99, 103, 107, 108, 110, 119, 123, 125, 126, 131, 133, 138, 140, 142, 147, 163, 164, 165, 171, 172, 173, 174, 175, 177, 181, 182, 184, 188, 189, 193, 197, 198, 199, 200], "2015": [2, 110, 119, 133, 147, 151, 184, 193], "physiolog": [2, 29, 74, 87, 88, 103, 133, 142], "lobe": 2, "special": [2, 69, 70, 71, 81, 105, 107, 108, 123, 125, 126, 137, 146, 148, 155, 164, 171, 191], "contextu": 2, "novelti": [2, 27], "114": [2, 20, 83, 190], "256": [2, 107, 198], "263": [2, 81], "2fjn": 2, "00131": 2, "schalk": 2, "2016": [2, 83, 103, 110, 117, 119, 133, 184, 193], "spontan": [2, 27, 75, 76, 123, 124, 125, 126], "decod": [2, 12, 24, 33, 34, 35, 70, 97, 103, 105, 112, 121, 124, 147, 159, 167, 201], "object": [2, 20, 24, 25, 81, 119, 121, 169, 179], "cortic": [2, 27, 119, 124, 133, 146, 148, 151, 159], "surfac": [2, 35, 74, 97], "reveal": [2, 119], "complementari": [2, 22, 23, 27, 81, 85, 131], "inform": [2, 12, 20, 22, 23, 24, 25, 29, 33, 35, 65, 70, 75, 80, 81, 85, 87, 88, 92, 103, 107, 108, 115, 116, 117, 119, 121, 123, 124, 125, 126, 131, 133, 138, 146, 148, 153, 155, 156, 159, 163, 165, 167, 171, 172, 173, 174, 175, 177, 181, 188, 189, 191], "event": [2, 39, 41, 70, 80, 81, 88, 89, 137, 138, 146, 147, 148, 149, 163, 164, 175], "relat": [2, 12, 20, 22, 23, 29, 33, 35, 69, 70, 74, 75, 76, 80, 87, 100, 103, 105, 108, 116, 125, 131, 133, 137, 138, 139, 142, 155, 156, 157, 163, 164, 171, 173, 177, 197, 199, 201], "potenti": [2, 12, 22, 65, 76, 80, 81, 85, 87, 88, 89, 98, 99, 101, 105, 107, 123, 125, 131, 144, 146, 147, 149, 163, 164, 165, 175, 189, 190, 191, 200], "broadband": 2, "spectral": [2, 12], "chang": [2, 12, 22, 23, 24, 27, 33, 34, 35, 46, 65, 69, 70, 80, 81, 88, 89, 94, 96, 97, 98, 99, 100, 107, 108, 112, 115, 117, 123, 126, 131, 137, 138, 139, 144, 146, 147, 148, 153, 155, 156, 163, 164, 165, 169, 171, 173, 174, 175, 181, 182, 188, 190, 197, 198, 199, 200, 201], "plo": [2, 23, 29, 76, 83, 103, 119, 133, 167], "biologi": [2, 29, 75, 76, 83, 103, 119, 133, 177, 201], "12": [2, 4, 24, 25, 33, 34, 35, 39, 69, 71, 74, 75, 76, 80, 81, 87, 88, 96, 97, 98, 99, 100, 101, 103, 107, 108, 110, 114, 119, 123, 124, 125, 126, 133, 137, 139, 140, 146, 147, 148, 149, 151, 155, 156, 157, 163, 164, 165, 171, 172, 175, 181, 182, 184, 188, 189, 190, 191, 193, 197, 198, 199, 200, 201], "e1004660": 2, "1371": [2, 23, 76, 83, 103, 119, 133, 167], "pcbi": [2, 23, 83, 103, 119, 133], "1004660": 2, "zano": 2, "fetz": 2, "den": [2, 184], "nij": 2, "m": [2, 12, 20, 22, 24, 27, 69, 76, 83, 88, 92, 97, 103, 108, 110, 119, 123, 125, 126, 131, 133, 140, 142, 148, 149, 151, 156, 157, 159, 163, 164, 167, 171, 172, 173, 177, 182, 184, 188, 193], "2009": [2, 20, 83, 92, 133, 142, 151, 174, 177, 193], "decoupl": 2, "power": [2, 12, 34, 80, 81, 96, 98, 99, 105, 117, 123, 156, 164, 165, 171, 175, 200], "spectrum": [2, 146, 148], "real": [2, 12, 22, 24, 35, 69, 71, 81, 85, 88, 89, 94, 96, 99, 108, 115, 116, 124, 126, 131, 137, 140, 146, 155, 157, 164, 171, 174, 182, 191, 193, 198, 199], "represent": [2, 20, 23, 29, 34, 35, 65, 70, 76, 83, 87, 97, 105, 107, 108, 112, 117, 119, 121, 123, 124, 126, 138, 155, 159, 164, 165, 175, 188, 190, 191], "individu": [2, 12, 20, 23, 39, 65, 69, 87, 116, 123, 125, 126, 144, 155, 156, 157, 163, 171, 190, 191, 200, 201], "finger": 2, "movement": [2, 22, 24, 25, 80, 131, 133, 164, 167, 177, 182, 190], "neurosci": [2, 12, 20, 22, 23, 24, 27, 29, 35, 45, 47, 63, 69, 70, 80, 83, 87, 94, 99, 101, 103, 105, 108, 112, 114, 119, 121, 125, 126, 129, 131, 137, 139, 142, 144, 146, 147, 151, 153, 161, 163, 164, 169, 171, 174, 177, 179, 186, 191, 193, 195, 197, 198, 201], "29": [2, 69, 76, 80, 87, 89, 96, 99, 100, 101, 103, 107, 116, 119, 123, 125, 126, 137, 138, 139, 147, 148, 149, 155, 156, 165, 171, 173, 174, 181, 182, 188, 189, 190, 191, 197, 198, 200], "3132": 2, "3137": 2, "1523": [2, 22, 23, 83, 103, 119, 131, 142, 147, 151, 177], "2fjneurosci": 2, "5506": 2, "08": [2, 12, 69, 71, 96, 107, 184], "honei": 2, "c": [2, 20, 22, 24, 25, 27, 69, 70, 71, 74, 83, 92, 96, 98, 103, 107, 110, 117, 119, 124, 125, 126, 131, 133, 138, 140, 142, 147, 148, 151, 156, 157, 159, 163, 164, 165, 167, 171, 172, 174, 175, 177, 181, 182, 184, 191, 193, 197, 198, 199, 200], "hebb": 2, "A": [2, 12, 20, 22, 23, 24, 25, 27, 29, 33, 35, 63, 65, 69, 70, 75, 80, 83, 87, 88, 89, 92, 94, 101, 103, 107, 108, 110, 119, 121, 123, 124, 131, 133, 138, 139, 142, 146, 147, 148, 149, 151, 155, 156, 159, 163, 167, 171, 173, 174, 175, 177, 181, 182, 184, 188, 189, 191, 197, 199], "o": [2, 63, 69, 74, 75, 76, 80, 96, 99, 103, 107, 108, 115, 116, 119, 123, 124, 125, 126, 133, 138, 147, 148, 156, 157, 159, 171, 173, 175, 190, 191, 193, 197], "ramsei": 2, "knight": 2, "t": [2, 12, 20, 22, 23, 24, 25, 27, 33, 34, 35, 47, 63, 65, 68, 69, 70, 71, 74, 75, 76, 79, 80, 81, 83, 86, 87, 88, 89, 95, 96, 98, 99, 100, 101, 103, 106, 107, 108, 110, 112, 113, 115, 116, 119, 122, 123, 124, 125, 126, 129, 130, 131, 133, 136, 137, 139, 140, 142, 145, 146, 147, 148, 149, 151, 154, 155, 156, 157, 159, 162, 163, 164, 165, 169, 170, 171, 172, 173, 174, 175, 177, 180, 181, 182, 187, 188, 189, 190, 191, 193, 196, 197, 198, 199, 200], "2012": [2, 83, 103, 133, 177], "activ": [2, 12, 20, 22, 24, 27, 34, 35, 69, 70, 74, 75, 81, 88, 89, 94, 103, 105, 108, 112, 114, 115, 121, 126, 131, 133, 142, 144, 146, 148, 151, 153, 167, 169, 172, 173, 175, 179, 191, 197, 199, 200], "phase": [2, 33, 100, 124, 125, 126, 137, 153, 155, 188, 191], "entrain": 2, "underli": [2, 24, 69, 70, 85, 96, 97, 108, 110, 112, 133, 140, 151, 153, 164, 167, 174, 175, 188, 198, 201], "rhythm": 2, "e1002655": 2, "1002655": 2, "kubanek": 2, "anderson": 2, "leuthardt": 2, "wolpaw": 2, "2007": [2, 75, 76, 103, 133, 142, 147], "two": [2, 12, 20, 22, 23, 24, 29, 33, 34, 35, 45, 65, 69, 70, 71, 74, 75, 76, 80, 81, 85, 87, 89, 94, 97, 99, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 129, 131, 138, 140, 142, 146, 147, 148, 149, 153, 156, 157, 161, 163, 164, 165, 169, 171, 172, 174, 175, 179, 181, 182, 188, 189, 190, 191, 198], "trajectori": [2, 71, 139, 140, 157, 172, 173, 174, 182], "signal": [2, 12, 22, 23, 24, 74, 76, 80, 97, 99, 103, 131, 133, 142, 171, 173, 186, 188, 189, 190, 191, 200], "4": [2, 12, 20, 23, 24, 25, 31, 39, 41, 47, 71, 83, 88, 92, 94, 96, 98, 100, 101, 103, 107, 110, 112, 115, 119, 123, 124, 125, 126, 129, 133, 138, 139, 142, 146, 147, 148, 149, 151, 155, 156, 177, 186, 188, 190, 193, 195], "3": [2, 12, 20, 23, 24, 31, 39, 41, 47, 83, 85, 92, 94, 96, 100, 101, 103, 105, 107, 110, 112, 115, 117, 119, 121, 133, 140, 142, 151, 156, 177, 186, 195], "264": 2, "275": [2, 119, 133, 184], "1088": [2, 103], "1741": 2, "2560": 2, "012": [2, 70, 177], "wilson": [2, 83, 92, 119, 133, 151, 153, 177], "smyth": 2, "2008": [2, 20, 92, 103, 119, 133, 142, 177, 184, 193], "control": [2, 12, 22, 39, 45, 46, 63, 76, 80, 81, 85, 88, 89, 94, 107, 110, 114, 123, 124, 125, 126, 131, 133, 147, 148, 153, 155, 156, 157, 161, 163, 164, 169, 171, 172, 173, 179, 184, 186, 188, 190, 191, 195, 199, 200, 201], "75": [2, 65, 70, 74, 75, 76, 96, 98, 124, 125, 126, 146, 147, 148, 149, 171, 172, 175, 188, 191, 199], "84": [2, 133, 171, 191], "008": [2, 63, 103, 149], "brouwer": 2, "hogervorst": 2, "van": [2, 20, 22, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 69, 70, 75, 76, 80, 81, 119, 131, 133, 142, 151, 171, 184], "erp": [2, 29], "b": [2, 12, 20, 22, 23, 24, 25, 27, 33, 34, 65, 69, 70, 71, 74, 76, 80, 83, 87, 88, 89, 90, 97, 98, 103, 107, 110, 114, 115, 119, 123, 126, 131, 133, 137, 138, 139, 140, 142, 146, 147, 148, 149, 151, 155, 156, 157, 159, 163, 164, 165, 171, 172, 173, 174, 175, 177, 181, 182, 188, 189, 191, 193, 197, 198, 199, 200], "heffelaar": 2, "zimmerman": 2, "h": [2, 33, 70, 74, 81, 83, 89, 103, 107, 108, 119, 123, 124, 125, 126, 133, 142, 151, 156, 157, 159, 174, 177, 184], "oostenveld": 2, "estim": [2, 4, 22, 25, 69, 70, 74, 75, 76, 80, 87, 88, 89, 90, 94, 100, 101, 103, 105, 107, 108, 114, 115, 116, 117, 121, 123, 124, 125, 126, 131, 133, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 163, 171, 172, 174, 175, 181, 182, 188, 189, 190, 191, 193, 195, 201], "workload": 2, "back": [2, 12, 22, 23, 24, 25, 33, 34, 75, 97, 99, 100, 107, 121, 123, 126, 131, 139, 140, 148, 157, 163, 164, 171, 173, 174, 175, 182, 190, 200], "task": [2, 4, 12, 27, 29, 33, 34, 35, 81, 85, 96, 98, 105, 107, 108, 121, 124, 133, 140, 171, 174, 182, 188, 189, 190, 191, 200, 201], "9": [2, 12, 24, 25, 33, 34, 39, 69, 71, 74, 75, 76, 80, 81, 83, 96, 98, 99, 103, 108, 116, 117, 119, 123, 125, 126, 133, 137, 138, 139, 140, 142, 146, 147, 148, 149, 151, 155, 156, 157, 165, 167, 174, 175, 177, 181, 182, 188, 189, 190, 191, 193, 197, 198, 199, 200], "045008": 2, "grissmann": 2, "faller": 2, "scharing": 2, "sp\u00fcler": 2, "gerjet": 2, "electroencephalographi": 2, "work": [2, 12, 20, 22, 23, 24, 25, 27, 33, 39, 45, 47, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 99, 100, 107, 116, 119, 123, 125, 126, 129, 131, 137, 140, 156, 161, 163, 164, 165, 171, 173, 174, 175, 179, 181, 182, 189, 191, 193, 195, 197, 198, 199], "load": [2, 12, 35, 87, 89, 115, 116, 117, 188], "affect": [2, 12, 35, 71, 74, 75, 76, 81, 97, 101, 108, 114, 116, 117, 123, 137, 139, 144, 146, 148, 155, 164, 171, 172, 173, 177, 182, 188, 189, 190, 191, 195, 197, 199, 200, 201], "valenc": 2, "emot": [2, 20], "stimuli": [2, 22, 24, 27, 81, 103, 121, 123, 124, 125, 126, 131, 174, 177], "frontier": [2, 20, 119, 191], "11": [2, 39, 71, 80, 81, 87, 96, 97, 98, 99, 101, 103, 107, 108, 110, 114, 115, 116, 117, 119, 123, 124, 125, 126, 133, 137, 139, 142, 146, 147, 148, 149, 151, 155, 156, 157, 164, 165, 172, 182, 184, 188, 189, 190, 191, 200], "616": [2, 110], "3389": [2, 20, 119], "2ffnhum": 2, "00616": 2, "2010": [2, 34, 92, 103, 167], "dure": [2, 12, 24, 27, 33, 34, 35, 39, 63, 65, 69, 70, 71, 74, 80, 81, 85, 94, 100, 101, 103, 121, 124, 129, 133, 138, 146, 163, 165, 167, 174, 177, 188, 191, 201], "execut": [2, 31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "onlin": [2, 74, 80, 83, 151, 159, 174], "feedback": [2, 12, 39, 133, 177], "proceed": [2, 20, 75, 76, 103, 119, 133, 142, 177], "nation": [2, 20, 75, 76, 119, 133, 142, 177], "107": [2, 156, 172], "4430": 2, "4435": 2, "1073": [2, 20, 75, 76, 119, 133, 142, 177], "pna": [2, 20, 75, 76, 119, 133, 142, 177], "0913697107": 2, "peterson": 2, "singh": [2, 55], "wang": [2, 70, 133, 142, 151, 184, 188, 189, 190, 191], "x": [2, 12, 22, 24, 25, 27, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 83, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 119, 123, 124, 125, 126, 131, 137, 138, 139, 140, 147, 148, 151, 155, 156, 157, 163, 164, 172, 173, 174, 175, 181, 182, 184, 188, 190, 191, 197, 198, 199, 200], "brunton": [2, 36, 133, 137, 138, 139, 140], "w": [2, 20, 33, 69, 70, 71, 74, 76, 81, 83, 92, 103, 108, 114, 115, 116, 119, 123, 124, 125, 126, 133, 142, 151, 155, 157, 159, 167, 172, 173, 177, 184, 193, 199, 200], "behavior": [2, 12, 20, 22, 23, 27, 33, 74, 76, 83, 85, 88, 89, 92, 94, 103, 105, 121, 125, 131, 137, 138, 139, 146, 149, 151, 155, 156, 157, 161, 163, 165, 171, 173, 175, 182, 184, 186, 188, 189, 190, 191, 195], "naturalist": [2, 125], "arm": [2, 80, 133, 165, 190, 191], "eneuro": [2, 22, 23, 83, 103, 131], "8": [2, 22, 24, 25, 33, 34, 35, 39, 70, 71, 74, 75, 76, 80, 81, 83, 87, 88, 89, 92, 97, 98, 99, 100, 101, 103, 107, 108, 114, 115, 116, 117, 119, 124, 125, 126, 131, 133, 137, 139, 147, 149, 151, 155, 156, 157, 171, 172, 174, 175, 181, 182, 184, 188, 189, 190, 191, 197, 199, 200], "0007": 2, "21": [2, 25, 65, 71, 76, 80, 81, 83, 88, 89, 92, 96, 97, 98, 99, 100, 101, 107, 108, 110, 114, 115, 119, 123, 126, 133, 137, 138, 139, 140, 146, 147, 149, 151, 155, 156, 157, 163, 165, 171, 172, 175, 181, 182, 184, 189, 190, 191, 197, 198, 199, 200], "mine": 2, "long": [2, 12, 34, 69, 71, 87, 123, 139, 146, 148, 149, 174, 181, 189, 200], "term": [2, 12, 23, 33, 34, 63, 69, 70, 74, 76, 80, 81, 87, 89, 99, 101, 107, 115, 123, 124, 125, 126, 137, 138, 139, 140, 144, 147, 149, 153, 155, 156, 157, 163, 171, 173, 182, 188, 190, 200], "358": 2, "109199": 2, "1016": [2, 12, 20, 27, 83, 92, 103, 110, 119, 133, 142, 151, 156, 157, 167, 177, 184], "jneumeth": [2, 133, 142], "daili": 3, "guid": [3, 22, 23, 39, 43, 70, 83, 85, 108, 126, 129, 131, 139, 164, 169, 201], "everyon": [4, 12, 75, 85, 188], "onli": [4, 12, 20, 22, 23, 24, 25, 33, 34, 35, 47, 63, 69, 70, 71, 74, 76, 80, 81, 87, 88, 89, 98, 99, 101, 107, 108, 115, 116, 117, 121, 123, 124, 125, 129, 131, 138, 140, 146, 147, 148, 149, 153, 155, 156, 157, 159, 163, 164, 165, 169, 171, 172, 173, 174, 181, 182, 186, 188, 189, 190, 191, 197, 198, 199, 200], "veri": [4, 12, 22, 23, 24, 25, 27, 33, 35, 63, 70, 71, 74, 75, 76, 80, 81, 87, 98, 99, 100, 101, 105, 107, 108, 123, 125, 126, 131, 137, 139, 144, 148, 149, 153, 157, 163, 164, 171, 175, 181, 182, 189, 190, 191, 193, 197, 198, 199, 200], "rich": [4, 34, 35, 156], "mani": [4, 12, 20, 22, 23, 24, 25, 27, 35, 69, 70, 74, 75, 76, 80, 81, 87, 88, 89, 98, 99, 105, 107, 108, 112, 114, 116, 123, 124, 125, 126, 131, 138, 147, 148, 149, 155, 156, 161, 163, 164, 165, 171, 173, 181, 182, 186, 188, 189, 190, 197, 199, 200], "pose": [4, 121, 201], "track": [4, 12, 33, 34, 35, 65, 71, 123, 125, 126, 138, 146, 169, 173, 188], "social": [4, 20, 193, 197], "interact": [4, 22, 44, 46, 47, 63, 70, 117, 131, 140, 147, 151, 153, 161, 169, 175, 190, 191, 197], "mice": [4, 27, 87, 108, 121, 123, 124, 125, 182], "code": [4, 12, 20, 22, 23, 24, 27, 29, 44, 45, 46, 47, 75, 85, 103, 110, 119, 129, 131, 159, 164, 184, 193, 201], "templat": [4, 20, 27, 29], "ann": [4, 34, 56, 119], "kennedi": 4, "loader": 4, "notebook": [4, 12, 22, 23, 27, 44, 46, 47, 63, 69, 70, 87, 101, 108, 114, 115, 116, 117, 124, 125, 126, 131, 163, 164, 165, 174, 188, 191, 197, 199, 200], "visual": [4, 12, 20, 22, 23, 24, 25, 27, 35, 63, 65, 69, 70, 71, 75, 76, 80, 81, 88, 89, 96, 97, 98, 99, 100, 101, 103, 107, 108, 112, 114, 115, 119, 121, 131, 133, 137, 138, 139, 140, 146, 147, 148, 151, 153, 156, 157, 163, 165, 169, 171, 172, 173, 174, 175, 177, 181, 182, 188, 189, 190, 197, 198, 199, 200, 201], "decis": [4, 22, 23, 24, 39, 75, 76, 80, 81, 83, 85, 94, 103, 105, 108, 123, 126, 131, 133, 139, 161, 171, 177, 181, 186, 188, 189, 201], "similar": [4, 20, 22, 24, 25, 33, 34, 35, 63, 65, 69, 74, 75, 81, 87, 88, 99, 100, 107, 114, 115, 119, 121, 123, 124, 126, 129, 131, 139, 147, 149, 155, 156, 157, 163, 165, 171, 172, 189, 190, 191, 199, 200], "eric": [4, 22, 131, 163, 164, 188, 189, 190, 191], "dewitt": [4, 22, 131, 163, 164, 188, 189, 190, 191], "explor": [4, 12, 24, 29, 33, 34, 76, 80, 81, 88, 89, 98, 99, 100, 101, 114, 117, 121, 123, 126, 137, 138, 139, 140, 144, 147, 157, 172, 174, 179, 186, 188, 189, 190, 198, 199], "psychometr": 4, "contain": [4, 11, 12, 22, 23, 24, 25, 27, 29, 33, 35, 47, 74, 80, 81, 87, 89, 96, 97, 98, 99, 107, 117, 121, 123, 124, 125, 126, 131, 147, 159, 174, 189, 190, 191, 197, 199], "collect": [4, 12, 22, 23, 24, 63, 65, 69, 75, 76, 80, 81, 98, 131, 163, 171, 172, 173, 174, 175, 182], "motion": [4, 22, 24, 25, 131, 139, 167, 171], "direct": [4, 23, 24, 25, 29, 33, 34, 69, 70, 74, 75, 76, 80, 89, 92, 98, 115, 119, 123, 126, 137, 138, 148, 156, 157, 164, 165, 171, 174, 190, 197, 198], "perform": [4, 12, 22, 23, 24, 25, 31, 33, 34, 35, 65, 69, 70, 74, 81, 96, 101, 107, 108, 112, 117, 119, 121, 123, 124, 125, 131, 133, 139, 140, 146, 148, 165, 171, 172, 174, 175, 182, 188, 189, 190, 191, 197, 198, 200], "reaction": [4, 167], "variou": [4, 69, 80, 81, 87, 88, 96, 97, 98, 99, 100, 101, 112, 124, 126, 146, 153, 163, 174, 181, 191, 199], "83": [4, 81, 171, 191], "214": [4, 83, 193], "author": [4, 25, 107, 108], "strength": [4, 22, 25, 69, 74, 75, 76, 81, 108, 124, 131, 142, 148, 155, 156, 157, 191, 197, 198, 199], "evid": [4, 12, 22, 24, 25, 75, 98, 108, 117, 131, 133, 140, 144, 148, 156, 157, 163, 171, 172, 173], "coher": [4, 133, 171], "prior": [4, 22, 23, 45, 80, 103, 107, 108, 131, 161, 163, 171, 172, 173, 175, 182], "compar": [4, 20, 22, 24, 33, 34, 35, 69, 74, 76, 80, 81, 88, 89, 94, 96, 97, 98, 101, 105, 107, 108, 114, 115, 116, 117, 121, 123, 124, 125, 131, 137, 138, 139, 140, 146, 148, 157, 163, 164, 171, 172, 174, 175, 181, 182, 189, 190, 191, 197, 200, 201], "predict": [4, 12, 22, 23, 24, 25, 33, 34, 35, 71, 74, 76, 80, 81, 89, 96, 99, 100, 101, 103, 105, 108, 119, 123, 124, 125, 126, 131, 133, 138, 139, 140, 171, 173, 174, 181, 182, 184, 190, 191, 193, 200], "bayesian": [4, 20, 39, 92, 103, 159, 161, 165, 172, 173, 174, 193, 195, 201], "observ": [4, 22, 24, 25, 33, 34, 35, 71, 74, 75, 80, 81, 85, 88, 89, 96, 97, 98, 100, 107, 124, 125, 126, 131, 137, 138, 140, 147, 148, 149, 155, 157, 161, 163, 164, 169, 171, 172, 173, 174, 175, 179, 181, 186, 188, 189, 190, 191, 193, 197, 198], "model": [4, 12, 20, 33, 34, 70, 71, 74, 81, 83, 85, 94, 96, 98, 103, 105, 112, 114, 117, 121, 123, 124, 129, 131, 137, 138, 144, 147, 153, 161, 163, 164, 169, 173, 174, 177, 179, 181, 182, 186, 188, 189, 190, 193, 195, 198, 200, 201], "page": [11, 44, 46, 47, 81, 108, 117], "exampl": [11, 12, 23, 29, 33, 34, 46, 63, 65, 70, 71, 74, 76, 80, 85, 87, 88, 89, 94, 96, 98, 99, 100, 101, 105, 107, 108, 112, 114, 115, 116, 117, 123, 124, 125, 126, 129, 137, 138, 139, 140, 144, 146, 147, 148, 155, 156, 159, 161, 163, 165, 169, 171, 172, 173, 174, 175, 179, 181, 182, 188, 189, 190, 191, 195, 197, 198, 199], "last": [11, 12, 22, 27, 33, 34, 35, 39, 46, 47, 63, 69, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 133, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "year": [11, 12, 27, 75, 76, 83, 163, 188], "sens": [11, 12, 22, 24, 25, 35, 75, 87, 99, 100, 116, 121, 126, 131, 140, 163, 169, 174, 181, 189, 191], "like": [11, 12, 22, 23, 24, 25, 27, 33, 34, 39, 65, 69, 70, 74, 75, 76, 80, 81, 85, 87, 88, 89, 90, 96, 97, 101, 105, 107, 108, 117, 119, 121, 123, 124, 125, 126, 129, 131, 138, 139, 140, 146, 148, 149, 155, 156, 161, 163, 164, 165, 169, 171, 172, 173, 174, 181, 182, 186, 188, 189, 190, 191, 197, 198, 200], "brainstorm": [11, 12, 22, 24, 25, 131], "idea": [11, 12, 22, 23, 24, 69, 71, 74, 80, 81, 87, 97, 98, 99, 105, 107, 125, 131, 146, 148, 149, 153, 161, 163, 164, 169, 171, 172, 173, 179, 182, 186, 188, 190, 193, 199], "plan": [12, 165, 179, 184, 188], "explicitli": [12, 24, 25, 80, 87, 94, 125, 129, 159, 161], "encourag": [12, 23, 25, 108, 190], "iter": [12, 33, 34, 35, 63, 65, 101, 123, 125, 126, 175, 182, 188, 199], "natur": [12, 27, 63, 71, 80, 83, 88, 99, 103, 110, 119, 124, 133, 142, 146, 147, 148, 161, 177, 184, 189, 193, 195, 200], "answer": [12, 22, 23, 24, 25, 35, 70, 75, 76, 85, 108, 121, 129, 131, 146, 148, 163, 181, 195, 197, 198, 199, 201], "gradual": [12, 33, 138, 148, 172, 181, 188], "refin": [12, 24], "hypothes": [12, 23, 85, 123, 129, 163, 165, 171, 188], "assign": [12, 33, 34, 35, 80, 87, 89, 96, 99, 100, 101, 107, 124, 125, 126, 165, 195], "pod": [12, 39], "broad": [12, 173, 186, 188, 195, 201], "fmri": [12, 80, 108, 195, 198], "ecog": 12, "theori": [12, 22, 70, 89, 92, 100, 108, 131, 159, 177, 181, 191], "each": [12, 13, 22, 23, 24, 25, 27, 33, 34, 35, 39, 41, 44, 46, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 85, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 121, 123, 124, 125, 126, 129, 131, 137, 138, 139, 140, 144, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "split": [12, 22, 24, 33, 34, 35, 89, 101, 108, 124, 125, 126, 131, 189], "goal": [12, 22, 23, 24, 25, 75, 83, 85, 99, 100, 107, 108, 115, 123, 125, 129, 131, 138, 139, 140, 148, 149, 164, 165, 181, 188, 189, 190, 191, 197], "balanc": [12, 85, 88, 89, 100, 153, 189, 190, 191], "There": [12, 22, 23, 24, 25, 33, 65, 74, 80, 81, 87, 88, 89, 101, 108, 121, 123, 124, 131, 147, 148, 156, 159, 163, 164, 169, 171, 173, 181, 182, 188, 191, 195, 200], "guidanc": [12, 129], "onc": [12, 22, 23, 24, 25, 47, 71, 76, 81, 87, 88, 98, 101, 105, 116, 117, 123, 125, 126, 131, 138, 148, 156, 174, 175, 182, 188, 189, 190, 191, 197, 200, 201], "search": [12, 22, 25, 29, 92, 96, 123, 131, 184, 191, 193, 200], "literatur": [12, 23, 24, 25, 29, 39, 129], "paper": [12, 20, 25, 70, 75, 76, 83, 89, 103, 117, 142, 146, 147, 156, 157, 163, 167, 198], "form": [12, 22, 24, 31, 33, 34, 35, 45, 63, 69, 71, 74, 75, 76, 80, 88, 89, 94, 96, 99, 107, 108, 112, 114, 115, 123, 125, 126, 131, 137, 139, 140, 147, 161, 163, 164, 165, 173, 174, 175, 182, 188, 189, 198, 199, 200], "rest": [12, 65, 75, 76, 81, 87, 88, 89, 99, 100, 101, 123, 126, 146, 148, 157, 197, 199, 201], "try": [12, 22, 25, 27, 33, 34, 47, 69, 70, 71, 74, 75, 80, 81, 87, 89, 96, 97, 98, 100, 107, 108, 116, 117, 123, 124, 125, 126, 131, 137, 138, 140, 146, 147, 148, 149, 156, 157, 163, 164, 165, 173, 174, 181, 182, 188, 189, 190, 191, 199, 200], "preliminari": [12, 22, 131, 182], "dataset": [12, 22, 24, 29, 81, 85, 89, 96, 97, 99, 107, 108, 116, 117, 121, 123, 124, 125, 131, 140, 165, 174, 175], "2": [12, 20, 23, 24, 31, 39, 41, 47, 83, 85, 92, 94, 101, 103, 105, 112, 121, 133, 142, 151, 177, 184, 186, 193, 195], "dedic": [12, 27], "teach": [12, 33, 45, 105, 173, 179, 195], "strategi": [12, 22, 71, 89, 131, 138, 139, 171, 181, 189, 190, 191, 195, 197], "approach": [12, 22, 23, 24, 25, 33, 74, 81, 96, 97, 98, 99, 101, 105, 108, 121, 125, 126, 129, 131, 140, 155, 156, 159, 161, 163, 164, 165, 174, 175, 181, 186, 188, 190, 193, 195], "step": [12, 24, 25, 33, 34, 35, 63, 65, 69, 70, 71, 75, 80, 81, 87, 88, 89, 96, 101, 107, 108, 114, 115, 116, 117, 123, 125, 126, 129, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 167, 169, 171, 172, 173, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200, 201], "appli": [12, 23, 24, 33, 34, 65, 71, 74, 76, 81, 87, 89, 94, 97, 99, 101, 107, 108, 116, 121, 123, 124, 125, 133, 147, 155, 157, 161, 164, 174, 182, 188, 190, 193, 197, 198, 199, 200, 201], "second": [12, 22, 24, 25, 33, 36, 63, 65, 69, 71, 74, 75, 76, 80, 81, 87, 88, 89, 105, 107, 108, 112, 114, 115, 116, 117, 121, 123, 124, 125, 126, 131, 137, 139, 140, 144, 147, 148, 153, 155, 156, 157, 163, 171, 173, 174, 175, 181, 182, 188, 191, 199, 200], "continu": [12, 22, 45, 63, 65, 71, 74, 76, 81, 87, 88, 89, 94, 101, 131, 139, 140, 147, 156, 161, 163, 169, 171, 173, 175, 179, 191], "analyz": [12, 24, 25, 27, 35, 117, 124, 125, 139, 165, 197, 201], "result": [12, 22, 23, 24, 25, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 83, 85, 87, 89, 96, 97, 99, 107, 114, 117, 123, 124, 125, 126, 131, 138, 139, 140, 146, 147, 148, 157, 164, 165, 171, 173, 174, 181, 182, 188, 189, 190, 191, 197, 199, 201], "least": [12, 25, 45, 69, 71, 81, 97, 98, 100, 101, 107, 123, 126, 139, 157, 174, 181, 198], "testabl": [12, 23], "hypothesi": [12, 23, 24, 25, 63, 87, 94, 98, 125, 200], "swap": [12, 33, 39, 63, 199], "cours": [12, 24, 25, 33, 34, 35, 45, 47, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 105, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 133, 137, 138, 139, 140, 146, 147, 148, 149, 153, 155, 156, 157, 159, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200, 201], "focu": [12, 23, 63, 69, 70, 71, 80, 81, 87, 88, 97, 99, 108, 114, 123, 125, 137, 146, 148, 149, 153, 163, 164, 174, 181, 191, 197, 198, 199, 200, 201], "against": [12, 23, 25, 94, 96, 105, 139, 140, 156, 182, 195, 200], "other": [12, 22, 23, 24, 25, 33, 35, 39, 46, 63, 69, 71, 74, 75, 76, 80, 81, 83, 87, 88, 89, 90, 97, 101, 105, 107, 108, 117, 121, 123, 124, 125, 126, 131, 138, 139, 140, 144, 146, 147, 148, 149, 155, 156, 157, 161, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200], "megapod": 12, "organ": [12, 33, 35, 63, 65, 87, 107, 119, 133], "lead": [12, 22, 25, 34, 65, 70, 75, 81, 97, 123, 125, 131, 147, 149, 153, 155, 157, 163, 171, 182, 188, 189, 190, 191], "tell": [12, 23, 70, 74, 81, 87, 94, 97, 101, 105, 108, 121, 123, 125, 126, 138, 155, 163, 164, 174, 182, 198], "them": [12, 22, 23, 24, 29, 33, 34, 35, 41, 63, 65, 69, 70, 74, 81, 85, 87, 88, 89, 101, 105, 108, 115, 116, 117, 121, 123, 124, 125, 126, 131, 139, 140, 148, 155, 161, 164, 165, 172, 174, 175, 181, 182, 186, 188, 191, 195, 197, 199, 200, 201], "stori": [12, 181], "low": [12, 33, 74, 87, 100, 108, 112, 116, 117, 125, 133, 146, 148, 163, 164, 167, 171, 172, 174, 181, 182, 188], "kei": [12, 23, 24, 25, 35, 65, 69, 96, 97, 99, 100, 101, 112, 114, 121, 123, 125, 164, 169, 191, 200, 201], "wai": [12, 22, 23, 24, 25, 33, 34, 63, 69, 70, 74, 75, 76, 80, 81, 85, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 105, 107, 112, 114, 116, 121, 123, 124, 125, 126, 129, 131, 133, 138, 139, 140, 147, 148, 149, 155, 161, 163, 164, 165, 174, 182, 189, 190, 191, 193, 195, 197, 198, 200], "meant": [12, 24, 25, 121, 123, 124], "product": [12, 22, 23, 25, 33, 34, 35, 63, 65, 70, 71, 75, 76, 80, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 191, 198, 199, 200], "valu": [12, 22, 23, 24, 25, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 80, 81, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 139, 140, 147, 148, 149, 153, 163, 164, 165, 167, 171, 172, 173, 174, 175, 177, 182, 184, 186, 190, 191, 197, 198, 199, 200], "airtabl": [12, 45], "develop": [12, 22, 23, 29, 87, 97, 100, 108, 115, 123, 124, 129, 131, 139, 140, 144, 147, 148, 153, 155, 159, 165, 174, 175, 188], "conjunct": 12, "varieti": [12, 22, 24, 69, 70, 121, 124, 131, 137], "starter": 12, "just": [12, 20, 22, 23, 25, 35, 39, 69, 70, 71, 74, 76, 80, 81, 87, 88, 89, 96, 97, 98, 100, 101, 105, 107, 108, 114, 116, 123, 124, 125, 126, 131, 137, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 189, 190, 191, 197, 198, 199, 200, 201], "keyword": [12, 33, 34, 107, 126, 165], "reus": [12, 65, 81, 90, 172, 181], "extens": [12, 33, 35, 80, 99, 108, 114, 164, 188, 189, 191], "don": [12, 22, 23, 25, 47, 68, 69, 75, 79, 81, 86, 87, 88, 89, 95, 99, 100, 101, 106, 107, 108, 113, 115, 116, 117, 122, 123, 126, 129, 130, 131, 136, 145, 147, 154, 162, 163, 164, 165, 170, 172, 173, 174, 175, 180, 181, 187, 188, 189, 196, 197, 198, 199, 200], "experi": [12, 22, 23, 24, 25, 27, 33, 34, 35, 45, 47, 75, 76, 80, 81, 87, 105, 107, 108, 116, 123, 131, 140, 157, 163, 164, 165, 171, 173, 174, 186, 188, 191, 195], "design": [12, 20, 22, 24, 27, 35, 65, 75, 76, 100, 101, 131, 174], "give": [12, 22, 23, 24, 25, 27, 63, 69, 74, 75, 76, 80, 81, 87, 88, 89, 105, 107, 108, 116, 123, 131, 140, 144, 146, 147, 148, 153, 155, 156, 157, 163, 164, 165, 171, 172, 174, 181, 188, 189, 191, 195, 197, 198], "enough": [12, 22, 23, 63, 87, 96, 100, 107, 123, 131, 164, 171, 181, 191, 198, 200], "structur": [12, 22, 23, 29, 33, 35, 39, 70, 71, 87, 88, 103, 105, 108, 112, 116, 117, 124, 125, 126, 131, 133, 140, 167, 172, 173, 174, 181, 200, 201], "option": [12, 22, 23, 24, 33, 34, 35, 39, 47, 63, 65, 70, 74, 80, 81, 108, 121, 123, 124, 126, 131, 137, 148, 155, 163, 164, 165, 171, 173, 174, 175, 181, 182, 189, 198, 199, 200, 201], "keep": [12, 22, 23, 33, 34, 35, 63, 65, 71, 74, 76, 87, 100, 108, 116, 125, 131, 133, 137, 138, 146, 148, 163, 164, 165, 171, 174, 175, 179, 181, 182, 188, 189], "stick": [12, 23, 189], "Or": [12, 22, 23, 125, 131], "first": [12, 22, 23, 24, 25, 33, 34, 35, 37, 39, 47, 63, 65, 69, 70, 74, 75, 76, 80, 81, 85, 87, 88, 89, 96, 98, 99, 100, 101, 105, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 129, 131, 137, 138, 139, 140, 144, 146, 147, 148, 149, 153, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 186, 188, 189, 191, 193, 197, 199, 200, 201], "diverg": [12, 155, 157], "test": [12, 22, 33, 34, 35, 63, 74, 80, 81, 85, 89, 94, 101, 107, 108, 114, 123, 124, 125, 131, 140, 142, 149, 165, 174, 181, 182, 188, 190, 191, 200], "flow": [12, 23, 63, 75, 148], "hesit": 12, "skip": [12, 63, 65, 117, 123, 124, 126, 171, 188], "complet": [12, 22, 33, 34, 35, 39, 45, 65, 68, 69, 70, 71, 74, 76, 79, 80, 81, 86, 87, 95, 100, 101, 103, 106, 107, 108, 113, 114, 115, 117, 119, 122, 123, 124, 125, 126, 130, 131, 133, 136, 137, 138, 139, 145, 146, 147, 148, 149, 154, 162, 163, 165, 170, 171, 172, 173, 175, 180, 181, 182, 187, 188, 191, 196, 197, 198, 199, 200, 201], "flexibl": [12, 23, 65, 97, 108, 119, 121, 123, 164], "friendli": [12, 27], "expert": [12, 201], "consult": [12, 22, 74, 75, 107, 131, 191, 197], "issu": [12, 24, 25, 33, 35, 76, 137, 163, 174], "help": [12, 22, 23, 27, 33, 34, 35, 41, 42, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 121, 123, 124, 125, 126, 129, 131, 140, 146, 147, 148, 149, 153, 155, 156, 157, 163, 164, 165, 169, 172, 174, 175, 181, 182, 186, 190, 191, 200, 201], "aspect": [12, 22, 23, 33, 34, 35, 63, 65, 74, 85, 87, 97, 123, 126, 131, 139, 151, 174, 190, 191, 200], "approxim": [12, 33, 63, 65, 74, 80, 81, 87, 116, 121, 123, 137, 142, 155, 157, 163, 164, 174, 199], "someth": [12, 22, 23, 24, 25, 63, 74, 75, 76, 87, 89, 90, 107, 108, 124, 125, 131, 147, 153, 163, 164, 165, 173, 188, 189, 201], "sinc": [12, 24, 25, 33, 34, 35, 46, 63, 65, 89, 97, 99, 100, 108, 114, 116, 121, 123, 124, 125, 126, 138, 140, 146, 147, 149, 157, 163, 164, 165, 171, 172, 175, 181, 182, 189, 191, 198, 199, 200], "arriv": [12, 71, 88, 89, 96, 97, 98, 148, 149, 163, 173], "unannounc": 12, "ani": [12, 22, 23, 24, 25, 29, 33, 34, 47, 63, 69, 70, 71, 74, 75, 80, 81, 85, 87, 89, 94, 97, 100, 101, 107, 108, 115, 116, 117, 119, 123, 124, 125, 126, 129, 131, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 174, 181, 182, 188, 189, 190, 198, 199, 200], "busi": [12, 70], "stop": [12, 22, 24, 63, 65, 107, 131, 146, 175, 189], "were": [12, 22, 23, 24, 33, 74, 81, 87, 88, 89, 101, 107, 121, 123, 124, 125, 126, 131, 140, 147, 148, 149, 163, 164, 171, 172, 174, 175, 181, 182, 186, 188, 198, 200, 201], "do": [12, 20, 22, 23, 24, 25, 27, 29, 33, 34, 35, 39, 46, 47, 63, 70, 71, 76, 80, 81, 85, 87, 89, 90, 94, 96, 97, 98, 99, 100, 101, 107, 114, 116, 117, 121, 123, 124, 125, 126, 129, 131, 137, 139, 140, 146, 148, 149, 153, 155, 156, 157, 159, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 193, 195, 197, 198, 199, 200, 201], "resum": 12, "when": [12, 22, 23, 24, 25, 33, 34, 35, 39, 47, 63, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 90, 94, 96, 97, 99, 100, 101, 105, 107, 108, 114, 116, 117, 123, 124, 125, 126, 129, 131, 137, 138, 139, 146, 147, 148, 149, 155, 156, 157, 163, 164, 171, 172, 173, 174, 181, 182, 186, 188, 190, 195, 197, 198, 199, 200, 201], "leav": [12, 69, 88, 98, 125, 147, 155, 163, 171], "sometim": [12, 23, 25, 33, 63, 69, 70, 74, 75, 80, 81, 101, 105, 115, 138, 139, 163, 164, 174, 188, 189, 191, 195, 198, 199], "might": [12, 20, 22, 23, 24, 25, 29, 70, 71, 75, 76, 81, 87, 88, 96, 105, 107, 108, 123, 124, 125, 126, 131, 140, 146, 147, 148, 163, 164, 167, 174, 190, 199, 200], "earlier": [12, 63, 70, 74, 107, 137, 139, 163, 188], "later": [12, 22, 25, 63, 70, 71, 74, 75, 76, 80, 81, 88, 114, 123, 124, 129, 131, 140, 147, 155, 163, 164, 169, 175, 179, 181, 182, 190, 197], "reach": [12, 24, 25, 34, 80, 87, 88, 97, 116, 129, 133, 139, 146, 148, 149, 155, 156, 157, 171, 182], "out": [12, 22, 23, 24, 25, 33, 34, 39, 42, 45, 46, 63, 65, 70, 71, 74, 75, 80, 81, 87, 88, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 123, 124, 125, 126, 131, 137, 138, 140, 146, 147, 148, 149, 153, 155, 157, 159, 163, 164, 165, 171, 173, 174, 175, 179, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200, 201], "extra": [12, 23, 81, 99, 123, 146, 157, 171, 175, 188, 191, 197], "whenev": [12, 65, 108, 125, 149, 181, 188, 191], "post": [12, 39, 71, 74, 87, 89, 90, 119, 140, 147, 148, 149], "channel": [12, 65, 75, 124, 125, 126, 138, 148, 172, 175], "depend": [12, 22, 23, 25, 31, 33, 35, 65, 71, 76, 80, 81, 85, 87, 88, 94, 96, 97, 98, 99, 100, 101, 107, 108, 117, 123, 124, 129, 131, 133, 138, 139, 140, 144, 146, 147, 148, 156, 157, 163, 164, 165, 171, 172, 173, 182, 188, 197], "slot": [12, 39, 41, 189], "regardless": [12, 89, 124, 163, 190], "whether": [12, 22, 24, 25, 33, 34, 35, 70, 71, 74, 76, 80, 81, 94, 107, 108, 112, 117, 123, 124, 125, 131, 144, 147, 148, 149, 155, 157, 163, 164, 181, 200], "spend": [12, 22, 81, 90, 131, 137, 163, 197], "session": [12, 35, 36, 37, 38, 39, 47, 87, 190, 191], "intention": [12, 189], "creat": [12, 22, 23, 24, 25, 33, 35, 47, 63, 65, 69, 74, 81, 87, 89, 96, 98, 99, 100, 101, 108, 121, 123, 124, 125, 131, 137, 147, 149, 156, 163, 164, 165, 172, 174, 175, 181, 188, 197, 199, 200], "skillset": 12, "who": [12, 23, 45, 199], "confid": [12, 96, 97, 99, 100, 101, 172, 173, 193], "those": [12, 22, 23, 24, 25, 33, 69, 74, 80, 81, 85, 96, 105, 108, 112, 123, 124, 125, 126, 129, 131, 138, 139, 148, 163, 164, 171, 174, 175, 181, 189, 191], "learn": [12, 22, 23, 24, 25, 27, 33, 34, 35, 39, 46, 47, 63, 65, 69, 70, 74, 75, 80, 85, 87, 88, 89, 92, 94, 96, 97, 98, 99, 100, 101, 103, 105, 107, 110, 112, 114, 115, 116, 117, 121, 123, 125, 126, 129, 131, 133, 137, 138, 140, 142, 144, 146, 147, 148, 149, 153, 155, 156, 157, 159, 161, 163, 164, 165, 169, 171, 172, 173, 174, 177, 179, 181, 182, 184, 186, 195, 197, 198, 199, 200, 201], "togeth": [12, 23, 24, 25, 39, 69, 70, 74, 81, 87, 97, 98, 100, 107, 117, 123, 124, 125, 126, 147, 149, 157, 163, 175, 190, 197], "strengthen": [12, 133, 149], "eachoth": 12, "skill": [12, 22, 81, 131], "member": 12, "chanc": [12, 22, 39, 80, 81, 131, 140, 149, 163, 181], "part": [12, 22, 23, 24, 25, 33, 35, 45, 74, 80, 87, 88, 89, 97, 99, 105, 107, 108, 123, 124, 125, 131, 137, 139, 140, 155, 156, 157, 163, 164, 175, 182, 189, 190, 191, 195, 197], "folk": [12, 105], "share": [12, 29, 33, 35, 39, 65, 69, 87, 89, 108, 124, 125, 147, 163, 164, 173, 177], "handoff": 12, "peer": [12, 23], "improv": [12, 23, 33, 34, 35, 63, 65, 76, 88, 119, 123, 124, 163, 173, 188, 191, 198], "introduct": [12, 23, 99, 137, 138, 184], "30": [12, 39, 65, 69, 71, 74, 75, 76, 81, 87, 92, 96, 97, 98, 99, 100, 101, 107, 108, 114, 116, 117, 123, 125, 126, 137, 138, 140, 146, 147, 148, 149, 155, 156, 157, 163, 165, 171, 173, 174, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "min": [12, 22, 24, 33, 34, 35, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "sai": [12, 23, 39, 69, 70, 74, 75, 80, 81, 89, 94, 97, 101, 125, 126, 137, 138, 163, 164, 171, 189, 197, 200], "few": [12, 24, 25, 33, 34, 35, 63, 65, 71, 75, 76, 81, 87, 107, 116, 117, 123, 124, 125, 126, 140, 144, 146, 147, 149, 161, 163, 173, 174, 188, 198, 199], "thing": [12, 22, 69, 71, 81, 97, 105, 126, 129, 131, 137, 139, 148, 167, 169, 174, 175, 189, 191, 198, 199, 200, 201], "about": [12, 23, 24, 25, 33, 35, 47, 63, 65, 70, 71, 76, 80, 81, 85, 87, 88, 89, 94, 97, 98, 100, 105, 107, 112, 115, 116, 121, 123, 124, 125, 126, 129, 137, 138, 139, 140, 144, 146, 147, 148, 149, 153, 155, 156, 157, 161, 163, 164, 165, 169, 171, 172, 173, 174, 179, 181, 182, 186, 188, 189, 190, 191, 193, 195, 197, 198, 199, 201], "area": [12, 20, 27, 33, 35, 65, 69, 71, 74, 80, 81, 85, 88, 89, 121, 123, 124, 125, 126, 133, 147, 148, 171, 186, 188, 191, 198, 201], "curiou": [12, 87, 148, 197], "listen": [12, 36, 37, 38, 75, 76], "carefulli": [12, 23, 137, 188, 197, 201], "brows": 12, "booklet": [12, 22, 23, 131], "skim": 12, "entir": [12, 27, 87, 98, 124, 138, 139, 140, 155, 156, 165, 174, 182, 190, 199], "slide": [12, 71, 124, 146], "doc": [12, 33, 46, 100], "further": [12, 23, 24, 33, 34, 74, 75, 76, 81, 96, 100, 101, 107, 112, 123, 124, 126, 137, 139, 163, 164, 171, 174, 189, 190, 191], "within": [12, 22, 23, 24, 25, 63, 69, 80, 87, 89, 98, 108, 123, 124, 125, 126, 131, 138, 149, 188, 190, 197, 198, 200, 201], "60": [12, 22, 24, 33, 74, 75, 81, 107, 123, 126, 131, 138, 147, 148, 149, 181, 190, 191], "choos": [12, 23, 35, 70, 74, 80, 81, 85, 89, 96, 97, 98, 99, 100, 101, 116, 123, 126, 137, 139, 148, 157, 163, 164, 171, 173, 174, 177, 179, 181, 190, 191, 201], "concret": [12, 22, 123, 125, 131, 138, 197], "either": [12, 24, 27, 33, 34, 35, 71, 74, 81, 87, 88, 89, 94, 98, 101, 138, 148, 155, 156, 164, 171, 172, 181, 190, 197], "yourselv": [12, 174], "directli": [12, 33, 46, 63, 87, 89, 97, 115, 124, 125, 126, 138, 164, 169, 172, 173, 174, 179, 181, 190, 197, 199, 201], "tip": [12, 23, 69, 97, 182, 189], "No": [12, 22, 31, 32, 33, 34, 35, 39, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "after": [12, 22, 23, 24, 33, 34, 39, 47, 63, 65, 68, 69, 70, 71, 79, 80, 81, 86, 87, 88, 89, 95, 96, 97, 99, 100, 105, 106, 113, 114, 115, 116, 119, 122, 123, 125, 126, 130, 131, 136, 138, 140, 145, 147, 148, 149, 154, 156, 157, 162, 164, 170, 171, 173, 175, 180, 181, 187, 188, 189, 190, 191, 196, 197, 198, 199, 200, 201], "feasibl": [12, 98, 123], "next": [12, 24, 33, 39, 63, 65, 69, 70, 71, 74, 75, 80, 81, 85, 87, 88, 89, 90, 99, 100, 101, 107, 108, 114, 115, 116, 117, 121, 123, 124, 125, 126, 138, 139, 140, 146, 147, 148, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 181, 182, 188, 190, 191, 197, 198, 199, 200, 201], "That": [12, 22, 23, 24, 33, 70, 71, 74, 87, 89, 107, 108, 123, 124, 129, 131, 140, 146, 149, 155, 156, 157, 163, 164, 165, 198], "how": [12, 22, 23, 24, 25, 29, 33, 34, 35, 47, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 83, 85, 87, 89, 90, 94, 96, 97, 98, 99, 100, 101, 105, 107, 108, 110, 112, 114, 115, 116, 117, 121, 123, 124, 125, 126, 129, 131, 133, 137, 138, 139, 140, 144, 146, 148, 149, 153, 155, 156, 157, 161, 163, 164, 165, 171, 172, 174, 175, 177, 179, 186, 188, 189, 190, 193, 195, 197, 198, 199, 201], "culmin": [12, 125], "propos": [12, 29, 75, 76, 85, 88, 98, 146], "peek": [12, 63, 139], "ahead": [12, 87, 172], "hand": [12, 22, 23, 24, 33, 70, 75, 76, 81, 89, 96, 123, 124, 131, 133, 137, 139, 148, 155, 157, 161, 165, 175, 190, 200], "dirti": 12, "interspers": 12, "among": [12, 34, 35, 89, 177, 189], "even": [12, 25, 33, 35, 63, 69, 70, 71, 75, 76, 80, 87, 89, 96, 105, 107, 108, 121, 123, 124, 125, 133, 138, 139, 148, 149, 156, 161, 164, 165, 171, 172, 174, 181, 189, 190, 191, 193, 197, 199, 200], "especi": [12, 23, 47, 70, 81, 96, 101, 124, 146, 163, 174, 201], "fine": [12, 137], "being": [12, 63, 71, 74, 80, 81, 89, 96, 108, 115, 123, 124, 125, 126, 138, 164, 165, 171, 174, 182], "pai": [12, 75, 76, 148, 181, 189, 190, 191], "attent": [12, 75, 76, 148, 151, 157, 182, 191], "access": [12, 22, 27, 29, 39, 46, 47, 80, 97, 107, 115, 123, 156, 172, 173, 182, 184, 199], "bin": [12, 22, 24, 33, 65, 71, 80, 81, 87, 88, 89, 98, 107, 123, 124, 125, 126, 131, 139, 146, 147, 149, 173, 175, 181], "align": [12, 22, 24, 25, 34, 63, 69, 70, 71, 74, 75, 76, 80, 81, 88, 89, 96, 97, 98, 99, 107, 108, 114, 115, 116, 123, 125, 126, 131, 146, 147, 155, 156, 157, 163, 164, 171, 172, 173, 174, 175, 182, 188, 199, 200], "element": [12, 23, 24, 33, 34, 35, 63, 65, 69, 70, 74, 75, 87, 88, 99, 100, 107, 108, 115, 116, 123, 125, 129, 137, 138, 139, 140, 157, 163, 165, 172, 174, 175, 181, 189, 193, 197, 198, 199, 200], "Be": [12, 22, 23, 69, 80, 87, 131, 200], "lookout": 12, "notic": [12, 22, 23, 24, 25, 33, 63, 74, 81, 105, 108, 123, 125, 131, 138, 139, 140, 146, 147, 149, 155, 157, 182, 188, 190, 191, 199], "unexpect": 12, "dig": [12, 22, 131], "deeper": [12, 22, 63, 105, 115, 123, 124, 131, 148, 157], "must": [12, 23, 70, 75, 81, 87, 88, 89, 101, 115, 117, 123, 126, 138, 163, 171, 172, 182, 189, 190, 191, 199, 200], "open": [12, 23, 29, 39, 41, 46, 98, 107, 108, 123, 124, 125, 126, 138, 148, 155, 172, 174, 191], "mind": [12, 22, 23, 33, 63, 75, 76, 100, 108, 131, 164], "trick": [12, 75, 81, 123, 125, 175], "hardest": [12, 22, 85, 131], "technic": [12, 34, 69, 70, 124, 181, 188], "challeng": [12, 20, 34, 35, 97, 123, 174, 175, 182, 189, 190], "wrestl": 12, "process": [12, 22, 23, 24, 25, 27, 29, 33, 35, 65, 70, 75, 76, 80, 81, 83, 85, 87, 88, 92, 98, 100, 101, 103, 107, 110, 119, 124, 125, 126, 129, 131, 133, 147, 148, 153, 155, 157, 165, 167, 169, 171, 172, 173, 174, 179, 181, 188, 200, 201], "easier": [12, 22, 23, 33, 63, 126, 129, 131, 140, 165, 173, 182], "equal": [12, 24, 33, 63, 69, 70, 71, 74, 76, 80, 81, 88, 89, 96, 97, 108, 114, 115, 117, 125, 139, 146, 155, 163, 164, 171, 173, 175, 181, 182, 188, 189, 197, 198, 199, 200], "network": [12, 20, 31, 33, 34, 35, 39, 75, 76, 81, 83, 85, 94, 103, 110, 112, 121, 133, 142, 144, 148, 149, 153, 156, 184, 193, 197, 199, 200, 201], "simul": [12, 22, 23, 24, 25, 65, 71, 75, 76, 80, 81, 83, 88, 94, 96, 97, 98, 99, 100, 101, 114, 131, 137, 138, 140, 147, 157, 165, 174, 181, 182, 188, 189, 191, 199], "still": [12, 22, 25, 27, 33, 34, 69, 71, 81, 87, 88, 96, 98, 99, 123, 124, 126, 131, 133, 138, 148, 155, 159, 181, 182, 189, 197, 199, 200], "becom": [12, 33, 35, 70, 71, 74, 75, 76, 81, 89, 139, 146, 148, 157, 172, 173, 175, 182, 198, 199, 200], "opposit": [12, 33, 69, 74, 123, 148, 171, 197, 198, 200], "happen": [12, 23, 46, 70, 71, 74, 75, 76, 80, 87, 88, 99, 107, 108, 114, 115, 126, 137, 146, 147, 148, 149, 153, 155, 156, 157, 163, 164, 171, 173, 181, 182, 188, 197, 198, 201], "find": [12, 23, 24, 25, 27, 29, 35, 42, 69, 70, 74, 75, 76, 96, 98, 99, 100, 101, 107, 108, 115, 116, 117, 123, 126, 137, 147, 149, 156, 163, 164, 165, 171, 174, 175, 181, 182, 188, 189, 190, 191, 198, 199, 200], "realiz": [12, 63, 65, 147, 148], "alwai": [12, 23, 24, 25, 33, 34, 69, 70, 71, 74, 76, 81, 87, 89, 96, 97, 98, 99, 105, 123, 125, 138, 147, 148, 149, 155, 156, 157, 161, 163, 172, 181, 189, 190, 191, 200], "bug": 12, "too": [12, 22, 23, 24, 25, 75, 80, 81, 87, 88, 100, 107, 108, 115, 123, 131, 164, 174, 182, 188, 189, 191, 198, 199], "true": [12, 22, 24, 25, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 171, 172, 174, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "train": [12, 22, 23, 101, 107, 117, 119, 121, 123, 124, 125, 129, 131, 140, 142, 146, 148, 149, 188], "simpl": [12, 23, 24, 25, 33, 34, 63, 69, 71, 74, 75, 80, 81, 83, 87, 88, 89, 92, 94, 96, 97, 98, 99, 100, 101, 105, 107, 108, 112, 114, 121, 123, 124, 125, 129, 137, 138, 140, 142, 144, 146, 147, 148, 149, 151, 156, 161, 163, 164, 165, 167, 169, 172, 181, 186, 188, 189, 190, 191, 197, 199, 200, 201], "where": [12, 22, 23, 24, 25, 33, 46, 47, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 99, 100, 101, 107, 108, 112, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 161, 164, 165, 169, 171, 172, 173, 174, 175, 179, 182, 186, 188, 189, 190, 191, 195, 197, 199, 200], "matter": [12, 22, 23, 25, 33, 65, 69, 81, 108, 123, 131, 148, 155, 157, 163, 164, 193, 200], "tune": [12, 103, 121, 123, 124, 151, 177], "curv": [12, 22, 24, 74, 75, 81, 87, 99, 103, 107, 108, 123, 124, 131, 146, 147, 157, 172, 173, 175, 182], "doe": [12, 22, 23, 24, 25, 27, 31, 35, 46, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 94, 97, 98, 107, 108, 114, 116, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 188, 189, 190, 191, 195, 197, 198, 199, 200], "rememb": [12, 22, 23, 69, 70, 71, 74, 80, 81, 89, 108, 115, 123, 126, 131, 137, 138, 140, 146, 147, 163, 164, 175, 181, 182, 189, 191, 197, 198, 200], "quick": [12, 89, 110, 164, 198], "survei": [12, 22, 39, 92, 131], "googl": [12, 29, 41, 47, 123, 124, 125, 126, 199], "thought": [12, 22, 33, 70, 74, 90, 124, 126, 129, 131, 161, 175, 188, 189, 193], "past": [12, 76, 107, 119, 140, 172, 173, 174, 175, 181, 191], "origin": [12, 23, 25, 33, 34, 35, 65, 69, 70, 71, 74, 75, 87, 96, 97, 98, 99, 114, 115, 116, 144, 157, 164, 165, 174, 175, 189, 199], "howev": [12, 24, 25, 29, 35, 63, 70, 74, 80, 81, 85, 87, 88, 89, 96, 98, 100, 105, 108, 115, 116, 117, 123, 125, 137, 138, 139, 140, 147, 148, 155, 157, 164, 165, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199], "situat": [12, 69, 74, 97, 99, 108, 124, 163, 164, 171, 181, 182, 188, 191, 198], "relev": [12, 23, 24, 29, 33, 34, 35, 65, 75, 76, 80, 92, 97, 99, 101, 108, 123, 124, 125, 126, 137, 155, 156, 159, 163, 164, 188], "hint": [12, 22, 74, 80, 81, 87, 89, 98, 99, 100, 107, 108, 115, 116, 123, 126, 131, 137, 138, 139, 146, 148, 155, 157, 163, 164, 165, 171, 172, 175, 181, 188, 200], "suggest": [12, 25, 65, 74, 87, 98, 99, 108, 116, 117, 165, 171, 175], "complex": [12, 23, 29, 35, 74, 75, 80, 81, 88, 94, 99, 100, 101, 107, 108, 119, 121, 123, 125, 133, 137, 144, 146, 155, 157, 163, 165, 167, 186, 188, 190, 191, 201], "could": [12, 22, 23, 24, 25, 33, 35, 39, 70, 71, 74, 75, 76, 80, 81, 83, 85, 87, 88, 89, 94, 99, 101, 107, 112, 114, 117, 123, 124, 125, 126, 131, 147, 149, 155, 161, 163, 164, 165, 172, 173, 174, 181, 182, 188, 189, 199, 200], "sever": [12, 24, 33, 34, 45, 65, 69, 70, 74, 80, 87, 96, 101, 105, 108, 112, 123, 124, 144, 148, 149, 153, 155, 157, 164, 175, 182, 188, 191, 201], "wrangl": 12, "simpli": [12, 22, 25, 71, 74, 76, 87, 89, 97, 108, 123, 125, 126, 131, 140, 146, 159, 174, 181, 189, 191, 200], "right": [12, 22, 23, 24, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 89, 96, 98, 100, 101, 107, 108, 123, 124, 125, 126, 131, 138, 139, 148, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 189, 190, 191, 197, 198, 199, 200], "psth": 12, "scatter": [12, 22, 24, 65, 71, 75, 76, 80, 96, 97, 98, 99, 108, 114, 115, 117, 125, 131, 137, 140, 165, 172, 173, 174, 197, 198, 199, 200], "differ": [12, 20, 22, 23, 24, 25, 33, 34, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 85, 87, 88, 94, 96, 97, 98, 100, 101, 105, 107, 114, 115, 123, 124, 125, 126, 129, 131, 137, 138, 139, 140, 147, 149, 155, 157, 159, 163, 165, 171, 172, 173, 174, 175, 182, 189, 190, 191, 193, 197, 198, 199, 200], "across": [12, 20, 22, 24, 25, 27, 63, 70, 75, 80, 85, 87, 88, 89, 96, 100, 108, 114, 115, 119, 123, 124, 125, 126, 131, 133, 148, 149, 163, 165, 171, 174, 175, 181, 188, 190, 191, 195], "most": [12, 20, 23, 27, 33, 63, 65, 69, 71, 74, 75, 76, 80, 81, 85, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 119, 121, 123, 124, 125, 126, 129, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 179, 181, 182, 186, 188, 189, 190, 191, 197, 198, 199, 200, 201], "pick": [12, 24, 74, 81, 96, 101, 108, 123, 125, 126, 181, 189, 201], "qualiti": [12, 35, 81, 98, 100, 101, 174, 181, 198, 200], "deep": [12, 20, 23, 31, 33, 35, 39, 47, 83, 85, 94, 105, 112, 121, 126, 184, 186, 188, 201], "stage": [12, 22, 129, 131], "often": [12, 22, 23, 24, 25, 33, 35, 70, 74, 80, 81, 85, 87, 89, 97, 99, 100, 101, 105, 116, 121, 123, 124, 126, 129, 131, 139, 148, 155, 157, 163, 164, 165, 169, 171, 172, 173, 174, 175, 181, 188, 189, 190, 193, 195, 198, 201], "popul": [12, 20, 24, 27, 69, 70, 74, 87, 94, 103, 105, 112, 114, 121, 123, 124, 125, 126, 133, 149, 151, 153, 157, 177, 197], "voxel": [12, 20, 108], "encod": [12, 33, 34, 35, 69, 103, 105, 108, 121, 123, 124, 133, 175, 198, 201], "certain": [12, 22, 24, 35, 74, 75, 76, 81, 88, 89, 108, 131, 138, 146, 147, 157, 164, 171, 172, 174, 181, 189, 190, 191, 198], "By": [12, 22, 23, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 69, 70, 71, 74, 75, 80, 81, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 161, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "far": [12, 22, 24, 71, 97, 99, 115, 123, 131, 137, 139, 149, 156, 164, 189], "regress": [12, 22, 24, 94, 98, 100, 101, 105, 112, 123, 125, 131, 140, 195, 197, 198], "pca": [12, 34, 35, 112, 114, 125], "cluster": [12, 33, 34, 87, 117], "binari": [12, 22, 25, 33, 34, 35, 80, 81, 94, 108, 124, 131, 140, 147, 148, 149, 161, 164, 169, 171, 175, 179, 181, 182, 198, 200], "categor": [12, 80, 81, 119, 125], "pipelin": [12, 22, 24, 129, 131, 165], "easi": [12, 23, 74, 75, 114, 123, 164, 189, 197, 198, 200], "switch": [12, 33, 69, 81, 123, 133, 172, 175, 181], "predictor": [12, 140], "scikit": [12, 24, 33, 101, 199, 200], "reduc": [12, 33, 34, 81, 89, 101, 108, 115, 116, 119, 123, 124, 157, 165, 174, 182, 188], "compon": [12, 22, 23, 24, 25, 29, 33, 35, 39, 69, 70, 74, 94, 97, 112, 117, 123, 124, 131, 133, 137, 139, 163, 164, 165, 172, 191, 200], "kind": [12, 20, 22, 24, 75, 80, 85, 90, 101, 107, 116, 123, 125, 129, 131, 137, 146, 148, 164, 182, 188, 189, 195], "pc": 12, "size": [12, 22, 25, 33, 34, 35, 65, 69, 70, 75, 76, 80, 81, 98, 101, 107, 114, 115, 116, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 171, 172, 175, 181, 188, 189, 197, 199, 200], "averag": [12, 20, 22, 24, 25, 74, 76, 80, 81, 87, 88, 96, 101, 105, 107, 108, 123, 124, 125, 126, 131, 138, 139, 146, 147, 148, 149, 153, 155, 156, 157, 163, 164, 171, 172, 173, 175, 181, 188, 189, 191, 197], "simplest": [12, 25, 88, 139, 146, 147, 148, 155, 189, 191], "complic": [12, 76, 88, 99, 105, 125, 163, 167, 188], "nonlinear": [12, 24, 31, 75, 76, 103, 133, 155, 167, 173, 197, 198, 199, 200], "fail": [12, 22, 23, 33, 35, 87, 107, 108, 123, 124, 125, 126, 131, 174, 175, 197, 198, 199, 200], "choic": [12, 20, 22, 24, 25, 27, 33, 34, 35, 80, 85, 89, 94, 96, 98, 101, 105, 107, 108, 114, 116, 117, 123, 125, 126, 129, 131, 133, 155, 161, 164, 167, 171, 172, 182, 188, 189, 190, 191, 197, 198, 199, 200], "fanci": [12, 74], "tsne": [12, 117, 125], "dead": 12, "end": [12, 22, 24, 25, 33, 34, 35, 39, 45, 63, 65, 69, 70, 71, 74, 75, 80, 81, 88, 89, 96, 97, 98, 99, 100, 101, 105, 107, 108, 114, 115, 116, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 161, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 199, 200, 201], "die": [12, 157], "progress": [12, 33, 75, 103, 123, 125, 126, 139, 148, 188, 190], "greatli": 12, "reason": [12, 45, 70, 75, 76, 80, 85, 88, 96, 99, 112, 123, 124, 146, 147, 148, 149, 155, 164, 165, 172, 181, 190, 191], "hard": [12, 22, 23, 24, 80, 131, 199, 201], "interpret": [12, 22, 23, 24, 35, 80, 105, 108, 117, 119, 123, 124, 125, 131, 138, 169, 171, 173, 174, 182, 197, 200], "function": [12, 20, 23, 25, 63, 85, 103, 105, 119, 121, 133, 144, 169, 179], "black": [12, 33, 63, 65, 75, 76, 124, 139, 147, 148, 149, 163, 167, 172, 173, 175], "box": [12, 23, 65, 69, 71, 80, 101, 148, 172, 181], "paramet": [12, 22, 23, 24, 25, 33, 34, 35, 65, 70, 74, 76, 87, 88, 94, 96, 97, 98, 99, 100, 101, 105, 107, 114, 115, 117, 123, 124, 125, 126, 131, 137, 138, 147, 148, 149, 156, 163, 165, 171, 172, 173, 174, 182, 188, 189, 190, 191, 197, 199, 200], "its": [12, 22, 23, 24, 33, 63, 69, 71, 74, 76, 80, 81, 87, 88, 89, 94, 96, 97, 101, 107, 108, 115, 116, 123, 124, 125, 126, 131, 133, 137, 138, 139, 142, 146, 148, 149, 155, 156, 157, 164, 165, 169, 173, 174, 175, 181, 182, 188, 189, 190, 191, 193, 198], "replac": [12, 33, 34, 35, 76, 80, 101, 116, 123, 125, 126, 148, 155, 182, 188, 189], "sne": [12, 110, 112, 125], "umap": [12, 110], "leiden": 12, "louvain": 12, "tool": [12, 23, 27, 29, 33, 34, 35, 85, 87, 94, 99, 112, 121, 129, 140, 148, 164, 175, 195], "unlik": [12, 33, 46, 81, 88, 107, 108, 117, 139, 181, 190], "noisi": [12, 22, 24, 25, 33, 81, 96, 98, 99, 100, 116, 131, 137, 157, 164, 165, 172, 173, 174, 175, 182, 189], "reduct": [12, 31, 33, 35, 39, 83, 85, 112, 114, 115, 124, 146, 147, 195, 201], "instead": [12, 65, 69, 70, 71, 74, 75, 76, 81, 87, 89, 96, 97, 98, 101, 107, 108, 112, 123, 125, 126, 139, 140, 147, 148, 155, 156, 157, 163, 164, 171, 172, 174, 181, 189, 190, 191, 198, 199, 200, 201], "valid": [12, 24, 75, 92, 94, 96, 97, 98, 99, 100, 105, 124, 126, 186, 188, 200], "simpler": [12, 100, 115, 121, 123, 124], "algorithm": [12, 22, 24, 33, 34, 74, 87, 92, 98, 105, 107, 108, 110, 116, 123, 125, 126, 131, 155, 156, 157, 159, 169, 172, 179, 186, 188, 189, 191, 193], "hdbscan": 12, "tend": [12, 23, 80, 87, 88, 99, 100, 116, 124, 126, 156, 188], "unstabl": [12, 97, 157, 182], "difficult": [12, 45, 47, 81, 100, 112, 125, 126, 200], "configur": 12, "specif": [12, 20, 23, 24, 25, 27, 29, 33, 69, 71, 74, 80, 81, 85, 87, 88, 89, 97, 107, 112, 114, 123, 124, 125, 138, 147, 148, 155, 163, 164, 171, 182, 188, 191, 199, 201], "resembl": [12, 33, 63, 124, 125, 164, 171, 188], "ramp": [12, 167, 182], "launch": [12, 44, 46, 47], "done": [12, 22, 23, 24, 25, 46, 74, 80, 81, 87, 88, 89, 94, 121, 123, 125, 126, 131, 137, 149, 181, 182, 191], "review": [12, 23, 33, 34, 35, 39, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 69, 70, 74, 75, 76, 80, 81, 83, 85, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 107, 108, 112, 114, 115, 116, 117, 123, 124, 125, 126, 129, 133, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 161, 163, 164, 165, 171, 172, 173, 175, 181, 182, 188, 189, 190, 191, 193, 197, 198, 199, 200], "2h": 12, "outro": [12, 35, 39, 94, 105, 112, 121, 144, 153, 179, 195], "yet": [12, 22, 25, 98, 101, 107, 123, 131, 149, 155, 156, 163, 164, 189, 191], "haven": [12, 98, 101], "walk": [12, 23, 125, 129, 137, 138, 140, 171, 174, 177], "four": [12, 34, 63, 69, 76, 129, 137, 157, 190], "translat": [12, 33, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 124, 133, 146, 164], "colab": [12, 22, 24, 47, 123, 124, 125, 126, 131], "readili": 12, "avail": [12, 23, 27, 33, 34, 39, 87, 92, 123, 126, 140, 148, 159, 171, 174, 175, 189, 200], "down": [12, 22, 23, 47, 74, 75, 76, 80, 88, 123, 125, 131, 140, 155, 175, 190, 191], "sentenc": [12, 23], "todai": [12, 22, 24, 69, 70, 74, 81, 83, 85, 94, 96, 99, 105, 108, 112, 123, 129, 131, 135, 137, 144, 153, 161, 163, 169, 171, 172, 173, 175, 179, 182, 195, 197, 198, 199, 200], "5h": 12, "identifi": [12, 20, 22, 23, 33, 34, 35, 65, 69, 101, 124, 126, 131, 140, 144, 146, 149, 153, 156, 182, 188, 189, 190, 191, 200], "context": [12, 33, 70, 74, 88, 97, 133, 147, 163, 164, 171, 175, 201], "acquir": [12, 22, 33, 69, 131, 190, 191], "30min": 12, "promis": 12, "ones": [12, 22, 23, 24, 63, 65, 69, 75, 76, 81, 89, 99, 100, 101, 108, 126, 131, 140, 146, 147, 148, 149, 155, 156, 157, 172, 174, 175, 181, 182, 188, 190, 191, 197], "10min": 12, "report": [12, 65, 81, 101, 119, 123, 124, 125, 126, 174, 189], "whole": [12, 23, 24, 81, 87, 94, 108, 116, 123, 125, 133, 137, 148, 164, 172, 190, 197, 200], "found": [12, 22, 47, 74, 80, 89, 97, 107, 108, 114, 116, 123, 131, 146, 155, 165, 174, 189, 200], "pool": [12, 124, 147, 148], "per": [12, 20, 22, 24, 33, 34, 35, 75, 80, 87, 88, 99, 117, 131, 138, 147, 171, 181, 190, 191, 198, 200], "person": [12, 46, 129, 163, 174], "1h": 12, "wa": [12, 20, 22, 23, 24, 25, 27, 33, 35, 63, 70, 75, 76, 80, 81, 87, 88, 89, 97, 98, 99, 100, 107, 108, 117, 121, 123, 124, 125, 126, 131, 138, 146, 148, 149, 163, 164, 165, 174, 175, 181, 188, 189, 200], "common": [12, 22, 71, 74, 80, 81, 87, 89, 101, 103, 105, 108, 116, 121, 123, 131, 137, 144, 147, 148, 163, 164, 165, 188, 190, 191, 195, 198, 199], "connect": [12, 20, 29, 33, 35, 47, 69, 71, 103, 105, 112, 119, 121, 123, 124, 137, 138, 147, 148, 151, 155, 156, 157, 161, 169, 172, 173, 179, 186, 188], "edu": [12, 20, 70, 83, 92, 107, 110, 159, 167, 177, 184, 188, 193], "domain": [12, 33, 34, 35, 171, 172, 173], "vpn": 12, "full": [12, 13, 23, 24, 25, 33, 34, 35, 71, 74, 75, 76, 80, 81, 88, 97, 98, 107, 115, 119, 123, 124, 125, 126, 159, 163, 171, 182, 190, 198, 199, 200], "preprint": [12, 83, 92, 103, 108, 110, 119, 123, 124, 125, 126, 133, 142, 151, 184, 193], "server": [12, 31], "arxiv": [12, 103, 108, 110, 119, 131, 133, 151, 193], "biorxiv": [12, 27, 92, 108, 119, 123, 124, 125, 126, 151, 184], "turn": [12, 33, 69, 71, 75, 76, 80, 81, 97, 99, 105, 108, 123, 124, 125, 126, 140, 146, 147, 155, 157, 173, 174, 182, 190, 191, 198], "someon": [12, 81, 163, 171, 174], "univers": [12, 41, 83, 92, 142, 151, 159, 174, 193], "understood": [12, 123, 137, 138, 146, 157], "section": [12, 22, 23, 45, 92, 131, 201], "block": [12, 63, 75, 105, 121, 124, 125, 138, 144, 153, 163, 197], "3h": 12, "text": [12, 25, 31, 32, 33, 34, 35, 39, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "wrote": [12, 123, 125, 126, 198], "worri": [12, 75, 87, 88, 200], "paragraph": [12, 24, 25], "word": [12, 22, 23, 69, 70, 71, 74, 75, 76, 80, 89, 121, 123, 131, 137, 139, 140, 148, 155, 156, 163, 164, 172, 182, 191, 198], "200": [12, 24, 25, 70, 87, 89, 107, 123, 126, 140, 146, 147, 148, 149, 171, 173, 174, 189, 191, 200], "300": [12, 80, 138, 139, 146, 148, 149, 175], "possibl": [12, 23, 24, 25, 33, 34, 63, 69, 70, 71, 74, 76, 80, 81, 87, 88, 89, 96, 105, 108, 112, 123, 126, 129, 138, 139, 147, 149, 155, 157, 163, 164, 165, 172, 173, 181, 182, 188, 189, 190, 191, 195, 197, 198, 199, 200], "properli": [12, 22, 87, 131], "scientif": [12, 22, 23, 24, 25, 63, 83, 87, 119, 131, 177, 182], "It": [12, 22, 23, 24, 25, 29, 47, 69, 70, 71, 75, 76, 80, 81, 85, 87, 96, 98, 107, 108, 114, 116, 123, 124, 125, 126, 131, 137, 139, 148, 155, 156, 157, 161, 163, 164, 165, 169, 171, 173, 174, 179, 181, 186, 189, 190, 197, 198, 199, 200], "readi": [12, 22, 23, 81, 87, 89, 131, 139, 148], "submit": 12, "mandatori": 12, "won": [12, 81, 108, 123, 125, 137, 164, 165, 190, 199], "evalu": [12, 22, 33, 34, 35, 65, 74, 80, 81, 85, 89, 96, 100, 101, 123, 129, 131, 137, 140, 164, 165, 189, 190, 191], "overal": [12, 20, 22, 23, 24, 33, 81, 101, 105, 117, 131, 148, 171, 195, 197], "vagu": 12, "would": [12, 22, 23, 24, 25, 27, 33, 63, 69, 70, 74, 75, 76, 80, 81, 87, 89, 90, 98, 99, 101, 107, 108, 116, 123, 124, 126, 129, 131, 138, 140, 147, 149, 155, 163, 164, 165, 171, 172, 173, 174, 182, 189, 190, 191, 197, 198, 200], "take": [12, 22, 23, 25, 31, 33, 34, 35, 46, 63, 70, 74, 75, 80, 81, 87, 88, 89, 96, 97, 101, 107, 108, 114, 116, 117, 123, 124, 125, 126, 129, 131, 137, 138, 139, 140, 147, 148, 149, 155, 157, 163, 164, 165, 171, 172, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200, 201], "let": [12, 22, 24, 25, 29, 33, 34, 35, 63, 69, 70, 71, 74, 75, 76, 80, 81, 87, 89, 96, 97, 98, 99, 101, 107, 108, 116, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 189, 190, 191, 197, 198, 199, 200], "explicit": [12, 22, 23, 101, 131, 156, 163], "One": [12, 34, 65, 69, 75, 88, 89, 98, 99, 100, 101, 108, 116, 123, 124, 125, 126, 139, 144, 156, 159, 164, 172, 174, 189, 190, 200], "best": [12, 22, 23, 24, 25, 33, 74, 76, 85, 87, 90, 94, 96, 97, 99, 100, 101, 108, 121, 123, 126, 129, 131, 139, 140, 146, 147, 148, 155, 156, 157, 159, 173, 181, 188, 189, 190], "earli": [12, 23, 39, 119, 124, 156, 188], "thesi": 12, "confer": [12, 119], "intermedi": [12, 20, 63, 108], "venu": 12, "wait": [12, 76, 87, 182], "requir": [12, 20, 22, 23, 24, 31, 33, 34, 35, 39, 47, 63, 70, 74, 80, 87, 89, 116, 119, 123, 124, 131, 155, 164, 174, 181, 189, 190, 191, 198, 200], "branch": [12, 20, 74, 119, 126], "pursu": [12, 23, 29], "knowledg": [12, 23, 33, 69, 70, 81, 87, 107, 112, 115, 126, 138, 139, 161, 163, 164, 165, 171, 179, 198, 201], "again": [12, 22, 34, 71, 74, 76, 80, 81, 87, 88, 94, 97, 98, 100, 101, 108, 112, 123, 125, 126, 131, 138, 140, 149, 156, 164, 174, 189, 190, 191, 197, 198, 200, 201], "necessari": [12, 22, 23, 45, 63, 69, 85, 89, 94, 108, 116, 126, 131, 161, 165], "lack": [12, 22, 23, 33, 131], "oomph": 12, "sound": [12, 80, 81, 108, 165], "check": [12, 22, 23, 24, 33, 34, 35, 39, 42, 46, 65, 68, 69, 70, 74, 79, 81, 86, 87, 88, 95, 98, 106, 107, 108, 113, 114, 115, 122, 124, 125, 130, 131, 136, 140, 145, 146, 147, 148, 154, 155, 156, 157, 162, 164, 165, 170, 171, 174, 180, 181, 182, 187, 188, 190, 196, 197, 199, 200], "facet": [12, 75, 85], "enjoy": 12, "big": [12, 39, 71, 74, 76, 80, 99, 123, 137, 155, 157, 164, 174, 190, 191, 197, 198, 200, 201], "point": [12, 22, 23, 24, 25, 33, 63, 69, 71, 74, 75, 76, 80, 81, 83, 87, 88, 89, 96, 97, 98, 99, 103, 107, 108, 114, 121, 123, 125, 131, 137, 138, 139, 140, 146, 147, 148, 149, 153, 156, 164, 165, 171, 172, 174, 175, 181, 182, 188, 190, 195, 197, 198], "show": [12, 22, 23, 24, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 105, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 153, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 193, 197, 198, 199, 200], "build": [12, 22, 23, 24, 25, 33, 35, 69, 75, 76, 81, 85, 88, 96, 97, 98, 99, 100, 101, 105, 107, 114, 116, 121, 123, 124, 126, 131, 139, 140, 144, 146, 149, 153, 155, 157, 161, 163, 165, 173, 181, 188, 191, 201], "begin": [12, 24, 25, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 123, 124, 125, 126, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 177, 181, 182, 188, 189, 190, 197, 199, 200], "pictur": [12, 69, 87, 124, 157], "With": [12, 71, 74, 75, 80, 99, 144, 157, 164, 171, 172, 188, 191], "abc": 12, "ten": [12, 23, 35, 83, 92, 188], "rule": [12, 23, 71, 81, 83, 92, 96, 121, 123, 137, 139, 149, 157, 161, 164, 167, 173, 188, 189, 190, 191, 197, 200], "close": [12, 23, 33, 39, 74, 75, 76, 80, 81, 87, 96, 105, 107, 123, 124, 125, 126, 138, 139, 140, 146, 147, 148, 149, 155, 163, 164, 172, 174, 175, 188, 197, 198, 199, 200], "figur": [12, 22, 23, 24, 25, 179], "specifi": [12, 22, 23, 24, 33, 34, 35, 63, 65, 71, 80, 81, 87, 88, 96, 114, 115, 123, 124, 125, 126, 131, 137, 155, 172, 174, 181, 188, 191, 197, 198, 199, 200], "refer": [12, 23, 24, 25, 33, 35, 39, 69, 71, 81, 88, 89, 99, 100, 101, 105, 107, 123, 124, 125, 126, 137, 138, 139, 140, 147, 148, 156, 157, 164, 165, 171, 172, 173, 174, 175, 182, 188, 189, 190, 191, 199], "principl": [12, 23, 81, 83, 85, 121, 123, 142, 165, 179, 182, 201], "order": [12, 22, 23, 24, 39, 44, 47, 65, 69, 75, 87, 89, 97, 100, 101, 108, 114, 115, 116, 123, 124, 125, 126, 131, 147, 148, 149, 155, 157, 165, 174, 175, 182, 188, 189, 190, 198, 200, 201], "problem": [12, 22, 23, 24, 70, 74, 76, 80, 81, 85, 88, 89, 92, 96, 97, 99, 101, 107, 108, 123, 124, 131, 140, 144, 153, 161, 163, 164, 171, 173, 175, 177, 182, 186, 188, 189, 190, 195, 199], "solut": [12, 23, 33, 34, 35, 63, 65, 69, 70, 71, 74, 80, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 126, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "break": [12, 39, 70, 74, 75, 76, 88, 190, 191], "At": [12, 65, 108, 123, 139, 148, 153, 163, 181, 188, 189, 190, 191, 200], "style": [12, 25, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 193, 197, 198, 199, 200], "scientist": [12, 99, 163, 164], "writer": [12, 23, 33], "importantli": [12, 22, 71, 85, 101, 105, 107, 124, 129, 131, 138, 139, 161, 163, 186, 201], "previou": [12, 22, 23, 24, 25, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 81, 88, 89, 97, 99, 108, 115, 116, 117, 123, 124, 125, 126, 131, 137, 139, 140, 146, 147, 148, 149, 155, 156, 157, 165, 171, 172, 173, 174, 175, 181, 188, 190, 191, 197, 198, 201], "left": [12, 22, 23, 24, 25, 33, 34, 35, 47, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 89, 96, 100, 101, 107, 108, 123, 124, 125, 126, 131, 137, 138, 139, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 189, 190, 191, 197], "jargon": 12, "without": [12, 22, 23, 33, 35, 63, 69, 80, 97, 101, 107, 115, 123, 126, 131, 133, 139, 165, 172, 174, 181, 182, 191, 197, 200], "defin": [12, 23, 25, 33, 34, 65, 70, 74, 76, 80, 81, 87, 88, 89, 96, 107, 108, 115, 116, 117, 123, 125, 126, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 161, 163, 164, 165, 171, 174, 181, 182, 186, 188, 189, 190, 191, 198, 199, 200], "cohes": 12, "copi": [12, 24, 33, 34, 35, 46, 81, 125, 126, 156, 157], "put": [12, 23, 24, 25, 76, 80, 99, 107, 114, 123, 138, 148, 157, 163, 164], "did": [12, 22, 23, 24, 25, 81, 87, 88, 90, 100, 126, 131, 138, 149, 155, 156, 163, 164, 181, 182, 188, 189, 190, 198, 199], "60min": 12, "mode": [12, 34, 133, 153, 164, 165, 175, 177, 190, 191, 199], "alreadi": [12, 20, 22, 25, 33, 35, 71, 74, 87, 89, 100, 101, 105, 112, 114, 115, 116, 125, 129, 131, 139, 146, 148, 149, 165, 172, 174, 179, 181, 182, 189, 190, 191, 198, 199, 200], "mayb": [12, 22, 23, 24, 25, 75, 81, 108, 131, 198, 199], "match": [12, 22, 35, 63, 70, 74, 80, 81, 87, 88, 108, 123, 124, 125, 126, 131, 138, 147, 163, 165, 173, 175], "mondai": 12, "timeslot": 12, "had": [12, 24, 25, 71, 75, 80, 81, 88, 89, 97, 108, 138, 139, 140, 147, 163, 164, 165, 171, 174, 182, 188], "reflect": [12, 24, 39, 68, 70, 74, 79, 81, 86, 90, 95, 106, 113, 116, 122, 130, 136, 145, 148, 154, 156, 162, 164, 170, 171, 177, 180, 187, 196], "inspir": [12, 36, 37, 38, 70, 88, 96, 107, 124, 193], "unknowingli": 12, "proven": 12, "steer": 12, "toward": [12, 71, 80, 87, 88, 138, 139, 148, 149, 155, 156, 163, 164, 171, 190, 191], "invalid": [12, 198, 199], "cover": [12, 22, 23, 33, 36, 37, 38, 69, 70, 71, 74, 75, 80, 81, 94, 96, 97, 99, 112, 121, 123, 124, 131, 137, 138, 148, 149, 155, 159, 163, 164, 165, 171, 174, 181, 186, 188, 198, 199, 200, 201], "materi": [12, 23, 45, 69, 70, 74, 75, 80, 85, 94, 112, 155, 156, 161, 165, 169, 171, 174, 175, 188, 195, 201], "afraid": [12, 23], "why": [12, 22, 23, 24, 33, 34, 35, 63, 65, 70, 76, 80, 81, 83, 85, 87, 90, 105, 110, 119, 123, 125, 126, 131, 137, 139, 146, 147, 148, 149, 155, 156, 163, 164, 171, 172, 173, 174, 181, 182, 188, 190, 191, 193, 197, 198, 199, 201], "sparsiti": [12, 103, 126], "These": [12, 20, 22, 27, 33, 34, 35, 39, 63, 65, 69, 71, 75, 76, 80, 81, 87, 100, 101, 107, 114, 123, 124, 125, 126, 131, 138, 140, 144, 148, 157, 163, 164, 165, 173, 174, 175, 181, 182, 188, 195, 199, 200, 201], "usual": [12, 22, 24, 25, 29, 39, 85, 107, 123, 131, 146, 155, 175, 188], "spark": 12, "discuss": [12, 22, 29, 39, 69, 70, 74, 75, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 112, 116, 123, 124, 126, 129, 131, 135, 146, 147, 155, 156, 157, 164, 190, 193, 197, 198], "mix": [12, 22, 24, 33, 81, 131, 164, 165], "respond": [12, 70, 74, 76, 81, 107, 123, 124, 146, 148, 155, 171, 191], "stimulu": [12, 24, 27, 76, 80, 81, 97, 105, 107, 108, 121, 123, 124, 125, 126, 151, 157, 174, 188, 195], "increas": [12, 24, 25, 33, 34, 74, 75, 76, 80, 81, 87, 88, 89, 97, 108, 114, 123, 124, 126, 137, 139, 146, 147, 148, 155, 157, 163, 164, 172, 174, 175, 182, 188, 190, 198, 199], "facilit": [12, 23, 142], "arbitrari": [12, 22, 25, 74, 89, 108, 114, 115, 123, 124, 125, 131, 164, 165, 182], "transform": [12, 22, 24, 33, 34, 35, 71, 81, 87, 97, 108, 112, 114, 115, 117, 121, 123, 124, 125, 126, 131, 147, 163, 164, 172, 173, 197, 198, 199, 200], "toi": [12, 24, 25, 71, 89, 123, 129, 182], "pure": [12, 29, 81, 139, 157, 175], "label": [12, 20, 22, 24, 25, 33, 34, 35, 63, 65, 69, 71, 74, 75, 76, 80, 81, 87, 89, 96, 97, 98, 100, 101, 107, 108, 114, 115, 117, 123, 124, 125, 126, 131, 138, 139, 140, 146, 147, 148, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199], "line": [12, 22, 24, 33, 34, 35, 63, 65, 69, 70, 71, 74, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "combin": [12, 24, 25, 71, 74, 76, 81, 89, 103, 126, 144, 147, 157, 159, 163, 164, 165, 169, 171, 172, 174, 175, 179, 181, 182, 188, 189, 190, 191, 193], "between": [12, 22, 24, 25, 33, 34, 35, 63, 69, 70, 74, 75, 76, 80, 81, 85, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 105, 107, 114, 116, 117, 123, 124, 125, 126, 129, 131, 137, 139, 140, 142, 146, 148, 149, 157, 163, 164, 171, 172, 173, 174, 175, 184, 188, 189, 190, 191, 195, 197, 198, 199, 200], "rather": [12, 22, 24, 33, 35, 63, 87, 89, 116, 123, 125, 126, 131, 138, 148, 164, 171, 174, 188, 190, 195, 197, 199], "input": [12, 22, 23, 24, 25, 33, 34, 35, 65, 69, 70, 71, 76, 81, 87, 89, 96, 97, 98, 99, 100, 101, 103, 107, 108, 114, 121, 123, 124, 125, 126, 131, 133, 137, 142, 144, 151, 153, 156, 157, 171, 173, 174, 181, 198, 199, 200], "effici": [12, 29, 33, 34, 65, 96, 99, 123, 124, 125, 139, 148, 175, 177, 186, 200], "dynam": [12, 22, 23, 29, 33, 39, 65, 74, 75, 76, 80, 81, 85, 88, 94, 103, 105, 119, 131, 138, 139, 140, 144, 146, 147, 149, 151, 153, 156, 157, 161, 163, 167, 169, 172, 175, 177, 179, 186, 188, 190, 198, 199, 200, 201], "fire": [12, 22, 24, 63, 65, 74, 80, 87, 89, 114, 123, 131, 142, 144, 147, 148, 153, 155, 156, 157, 175, 197, 201], "ch": [12, 142, 151], "dayan": [12, 75, 76, 83, 85, 142, 146, 184], "abbott": [12, 75, 76, 85, 142, 146], "theoret": [12, 75, 76, 83, 142, 146, 153, 177, 182, 201], "critic": [12, 23, 70, 80, 157, 189], "assumpt": [12, 22, 80, 81, 88, 97, 108, 124, 131, 148, 163, 165, 188, 189, 199, 200], "impli": [12, 70, 87, 99, 147, 198, 199], "region": [12, 20, 33, 35, 47, 74, 87, 124, 156, 164, 171, 191, 195], "transfer": [12, 75, 133, 144, 146, 155, 156, 157], "basi": [12, 70, 71, 74, 88, 89, 96, 116, 126, 147, 161], "dictionari": [12, 33, 34, 35, 99, 100, 101, 107, 146, 147, 148, 149, 155, 156, 157, 174, 188, 189, 190, 191, 199, 200], "featur": [12, 24, 36, 37, 38, 87, 99, 100, 101, 117, 119, 124, 126, 148, 157, 188, 199], "ensembl": [12, 103, 133], "syllabl": 12, "suffici": [12, 23, 63, 126, 139, 146, 157, 174, 182, 189], "band": [12, 76, 155], "alpha": [12, 33, 34, 35, 63, 65, 69, 70, 71, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 123, 139, 140, 146, 147, 148, 149, 155, 156, 157, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 190, 191, 197, 198, 199, 200], "associ": [12, 25, 34, 80, 81, 147, 189, 191, 197, 198], "gamma": [12, 76, 164, 175, 188, 190, 191], "etc": [12, 20, 23, 25, 33, 35, 45, 46, 69, 71, 85, 88, 99, 101, 107, 146, 153, 155, 163, 165, 186, 188, 195, 198, 199], "cell": [12, 27, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 103, 108, 114, 115, 116, 117, 119, 123, 125, 126, 133, 137, 138, 139, 140, 142, 146, 147, 148, 149, 155, 156, 157, 163, 164, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "1146": [12, 133, 193], "annurev": [12, 133, 193], "26": [12, 39, 63, 65, 69, 71, 76, 87, 89, 96, 98, 99, 100, 107, 108, 116, 123, 125, 126, 137, 138, 139, 147, 148, 149, 155, 156, 157, 165, 171, 173, 174, 175, 182, 188, 190, 191, 197, 198, 199, 200], "041002": 12, "131022": 12, "mcn": 12, "2006": [12, 92, 142, 173, 174, 193], "001": [12, 25, 63, 65, 69, 81, 123, 137, 138, 177, 188, 189, 199, 200], "narrow": [12, 123], "posit": [12, 22, 24, 33, 35, 63, 69, 70, 71, 74, 75, 76, 81, 87, 101, 107, 108, 116, 123, 124, 125, 126, 131, 137, 139, 140, 148, 149, 155, 156, 159, 161, 164, 171, 173, 174, 177, 181, 182, 188, 190, 191], "neg": [12, 33, 65, 69, 71, 74, 75, 76, 81, 87, 88, 89, 97, 103, 107, 108, 114, 116, 123, 124, 125, 126, 140, 148, 149, 155, 157, 163, 164, 165, 171, 173, 174, 190, 200], "actual": [12, 22, 23, 24, 25, 63, 74, 80, 81, 89, 98, 99, 101, 107, 123, 124, 125, 126, 131, 140, 164, 171, 173, 174, 181, 188, 189, 190, 198, 199, 200], "discourag": 12, "month": [12, 22, 131], "toolkit": [12, 22, 131, 201], "otherwis": [12, 22, 46, 63, 70, 81, 87, 101, 108, 117, 123, 126, 131, 147, 148, 149, 163, 164, 173, 181, 189, 190, 197, 198, 200], "implement": [12, 22, 33, 34, 35, 63, 65, 69, 70, 74, 76, 80, 89, 96, 97, 98, 99, 107, 114, 117, 123, 124, 125, 126, 131, 137, 138, 139, 146, 148, 156, 157, 163, 164, 169, 171, 172, 179, 188, 191, 198, 200], "scratch": [12, 35, 146, 201], "exist": [12, 25, 29, 69, 74, 80, 85, 87, 90, 99, 105, 112, 155, 198], "absolut": [12, 65, 71, 89, 101, 108, 126, 163, 164, 171], "ok": [12, 25, 107, 108, 123, 124, 125, 126, 174], "Then": [12, 22, 23, 70, 75, 87, 94, 99, 114, 115, 116, 123, 124, 125, 126, 131, 140, 144, 147, 155, 157, 163, 172, 200, 201], "initi": [12, 22, 34, 35, 63, 65, 69, 76, 80, 81, 88, 98, 101, 107, 108, 114, 117, 123, 124, 125, 126, 131, 133, 138, 139, 146, 147, 148, 149, 157, 163, 165, 172, 173, 174, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "limit": [12, 23, 24, 25, 33, 63, 70, 71, 74, 75, 80, 81, 85, 89, 97, 101, 105, 116, 126, 139, 148, 163, 164, 165, 173, 175, 182, 190, 191, 199, 200], "somebodi": 12, "somedai": 12, "shuffl": [12, 33, 34, 35, 147], "logic": [12, 22, 83, 123, 126, 131, 159, 181, 197], "accident": [12, 200], "sort": [12, 35, 69, 87, 99, 107, 114, 115, 116, 123, 126, 133, 147, 175, 197, 201], "peak": [12, 22, 24, 74, 87, 89, 126, 131, 139, 147, 149, 164], "respons": [12, 20, 63, 69, 70, 71, 74, 75, 76, 81, 88, 89, 96, 97, 98, 99, 103, 105, 107, 108, 119, 124, 125, 126, 153, 155, 156, 157, 164, 167, 171, 173, 188, 200], "sequenc": [12, 33, 63, 74, 87, 96, 97, 98, 99, 123, 124, 140, 146, 147, 148, 149, 167, 171, 172, 173, 174, 181, 182, 188, 190, 191], "circular": [12, 114, 126], "obviou": [12, 163, 189], "catch": [12, 163, 171, 179, 182], "experienc": [12, 22, 24, 25, 131, 190, 191], "off": [12, 33, 34, 35, 70, 81, 96, 97, 98, 99, 101, 107, 108, 114, 115, 124, 125, 126, 129, 163, 164, 171, 174, 175, 197, 198, 199, 200], "guard": 12, "calendar": 12, "http": [12, 22, 27, 31, 32, 33, 34, 35, 36, 37, 38, 42, 45, 46, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "compneuro": [12, 45], "io": [12, 22, 42, 45, 83, 87, 89, 107, 108, 110, 119, 123, 124, 125, 126, 131, 174], "daily_schedul": 12, "html": [12, 20, 42, 100, 101, 103, 108, 117, 119, 151, 167, 172, 173, 175, 181, 182, 188, 193, 200], "screen": [12, 107, 123, 174], "graphic": [12, 23, 80, 81, 100, 133, 155, 156, 165, 177], "told": [12, 74, 140, 165], "taught": [12, 129, 175], "via": [12, 74, 81, 96, 114, 119, 123, 125, 126, 133, 142, 147, 164, 172, 174, 182, 191, 199], "minut": [12, 39, 69, 70, 74, 75, 76, 81, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 138, 139, 140, 147, 155, 156, 163, 164, 171, 172, 173, 198, 200], "greet": 12, "round": [12, 74, 125, 139, 164, 172, 175], "call": [12, 22, 23, 24, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 105, 107, 108, 112, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "name": [12, 22, 29, 31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "zoom": [12, 39, 116, 138, 153], "themselv": [12, 23, 69, 70, 74, 147], "hi": [12, 89, 96, 105, 107, 144, 164, 188], "jonni": 12, "wiggli": 12, "caterpillar": 12, "am": [12, 39, 133, 200], "phd": 12, "notr": 12, "dame": 12, "pari": 12, "fli": [12, 139], "my": [12, 22, 23, 65, 85, 94, 105, 131, 140, 174], "bike": [12, 74], "ride": 12, "40": [12, 22, 24, 65, 71, 74, 76, 80, 81, 87, 88, 92, 99, 107, 108, 114, 115, 116, 123, 124, 126, 131, 139, 146, 148, 149, 155, 157, 163, 164, 171, 173, 175, 182, 188, 190, 191, 197, 198, 200], "speak": [12, 23, 24, 25, 163, 188, 197], "approx": [12, 33, 76, 89, 97, 107, 108, 155, 197], "wast": [12, 191], "join": [12, 35, 107, 137, 148], "appropri": [12, 20, 22, 23, 24, 107, 131, 163, 171, 182, 189, 200], "breakout": 12, "room": [12, 33, 88, 123], "20": [12, 25, 27, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 103, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 133, 137, 138, 139, 146, 147, 148, 149, 155, 156, 157, 163, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "miss": [12, 22, 23, 35, 45, 80, 81, 87, 88, 90, 96, 101, 107, 108, 123, 126, 129, 131, 174, 181, 188, 189], "anyon": [12, 35], "futur": [12, 23, 24, 25, 63, 65, 69, 70, 76, 119, 125, 139, 140, 147, 163, 174, 175, 186, 188, 190, 191], "perhap": [12, 35, 126, 182, 189, 197], "surpris": [12, 23, 89, 108, 174], "techniqu": [12, 33, 34, 35, 63, 65, 89, 94, 96, 112, 121, 123, 124, 125, 173, 190, 195, 199, 200], "immedi": [12, 22, 24, 76, 131, 190, 191], "current": [12, 23, 25, 31, 33, 65, 70, 74, 75, 76, 81, 88, 110, 121, 123, 126, 133, 142, 147, 148, 155, 156, 157, 171, 172, 173, 174, 175, 177, 181, 182, 184, 188, 189, 190, 191, 197, 198, 200], "subgroup": 12, "separ": [12, 23, 24, 27, 33, 34, 63, 74, 117, 124, 163, 164, 165, 171, 181, 182], "larg": [12, 34, 35, 71, 74, 76, 80, 81, 87, 107, 110, 116, 119, 121, 123, 124, 125, 126, 133, 137, 139, 147, 148, 153, 155, 157, 159, 163, 164, 173, 174, 181, 182, 186, 188, 191], "hour": [12, 39, 69, 70, 107, 108, 123, 125, 137, 146, 148, 155, 156, 163, 164, 172, 173, 188, 200], "00": [12, 39, 108, 110, 123, 140, 146, 199], "rel": [12, 22, 24, 25, 27, 29, 33, 35, 65, 81, 87, 89, 101, 123, 124, 125, 131, 138, 149, 163, 164, 173, 189, 191], "jupyterbook": [12, 22, 131], "cutoff": 12, "mark": [12, 165], "ensur": [12, 22, 23, 33, 65, 74, 80, 88, 96, 97, 98, 99, 107, 123, 125, 126, 129, 131, 139, 140, 148, 198], "powerpoint": 12, "primarili": [12, 174], "superpod": 12, "conclus": [12, 123, 157], "floor": [12, 71, 97, 125], "seem": [12, 22, 24, 25, 33, 71, 75, 76, 80, 87, 123, 124, 126, 131, 139, 149, 156, 157, 163, 164, 188, 189, 190, 195, 200], "imposs": [12, 22, 23, 24, 35, 108, 131, 164], "elev": 12, "pitch": 12, "poster": 12, "zuckerberg": 12, "secur": 12, "million": [12, 34, 75, 76], "dollar": 12, "fund": 12, "art": [12, 24, 25, 123], "act": [12, 69, 74, 89, 124, 126, 179, 186, 188, 191], "plai": [12, 22, 23, 33, 65, 69, 71, 74, 75, 81, 87, 88, 108, 116, 126, 131, 147, 163, 164, 171, 172, 181, 182, 188, 189], "music": [12, 75, 76], "instrument": [12, 195, 197, 198, 199], "rehears": 12, "doesn": [12, 20, 22, 23, 24, 25, 33, 71, 74, 75, 88, 89, 107, 108, 115, 123, 126, 131, 155, 169, 175, 181, 189, 191, 200], "WILL": 12, "annoi": 12, "tenth": [12, 148], "secret": 12, "professor": 12, "prepar": [12, 69, 81, 124, 133, 174], "small": [12, 22, 24, 63, 65, 68, 71, 74, 75, 79, 80, 81, 86, 87, 88, 95, 97, 106, 108, 113, 122, 123, 124, 125, 126, 130, 131, 136, 137, 139, 140, 145, 147, 148, 153, 154, 155, 162, 163, 170, 171, 174, 180, 182, 187, 188, 191, 196, 199], "anecdot": 12, "magic": 12, "engag": [12, 27], "As": [12, 22, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 96, 99, 100, 101, 108, 114, 115, 123, 124, 125, 126, 131, 138, 139, 140, 146, 148, 155, 157, 163, 164, 165, 171, 172, 173, 174, 188, 190, 191, 198, 199, 200], "passiv": 12, "bore": 12, "grab": 12, "smart": 12, "while": [12, 22, 24, 33, 34, 39, 44, 71, 74, 75, 76, 80, 81, 87, 96, 98, 108, 115, 117, 121, 123, 126, 131, 146, 147, 148, 149, 153, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 181, 182, 189, 190, 191, 195, 197, 199, 200], "main": [12, 22, 23, 24, 25, 27, 63, 65, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 107, 108, 112, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 171, 173, 174, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "anywai": [12, 45], "commun": [12, 23, 29, 45, 89, 126, 129, 133, 144, 159, 193], "bind": 12, "didn": [12, 22, 23, 74, 80, 87, 96, 125, 131], "hear": [12, 75, 76, 112, 138, 139], "furthermor": [12, 191], "clear": [12, 22, 81, 123, 125, 126, 131, 148, 157], "field": [12, 20, 22, 23, 87, 88, 89, 103, 105, 107, 124, 125, 126, 131, 155, 157, 159, 164, 191, 195, 200, 201], "got": [12, 33, 96, 140, 171, 189], "dream": [12, 191], "oppos": [12, 24, 74, 81, 98, 164, 165], "except": [12, 39, 45, 69, 71, 107, 108, 123, 124, 125, 126, 149, 173, 174, 188, 197, 200], "concis": [12, 29, 33], "rambl": 12, "avoid": [12, 22, 23, 33, 35, 63, 65, 89, 123, 125, 126, 131, 137, 164, 165, 188, 189, 190, 191], "life": [12, 99, 115, 139, 164], "given": [12, 22, 24, 63, 65, 69, 70, 71, 74, 76, 80, 81, 87, 88, 89, 96, 97, 99, 100, 101, 107, 108, 114, 115, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 200], "constraint": [12, 22, 33, 34, 81, 87, 110, 124, 131, 193], "click": [13, 22, 23, 33, 34, 35, 41, 43, 46, 47, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "imag": [13, 27, 33, 34, 65, 69, 71, 81, 97, 108, 112, 116, 117, 119, 121, 123, 124, 125, 126, 169, 174, 195, 197, 201], "browser": [13, 46, 75, 76], "2020": [20, 22, 23, 35, 63, 65, 75, 76, 83, 103, 114, 115, 116, 117, 119, 131, 133, 139, 140, 146, 147, 149, 151, 155, 157, 159, 165, 174, 175, 177, 184, 188], "gambl": 20, "languag": [20, 22, 23, 131, 198], "preprocess": [20, 101, 174], "john": [20, 67, 73, 74, 75, 76, 78, 84, 93, 104, 111, 114, 115, 116, 117, 120, 128, 134, 137, 138, 139, 140, 143, 146, 147, 148, 149, 152, 155, 156, 157, 160, 168, 171, 172, 175, 178, 185, 194, 201], "murrai": [20, 114, 115, 116, 117, 146, 147, 148, 149, 155, 156, 157], "saad": 20, "jbabdi": 20, "barch": 20, "burgess": [20, 83], "harm": 20, "petersen": 20, "schlaggar": 20, "l": [20, 33, 34, 63, 75, 76, 81, 92, 97, 101, 103, 108, 119, 123, 125, 126, 133, 142, 147, 149, 151, 164, 167, 171, 172, 174, 175, 177, 182, 184, 188, 190, 191], "corbetta": 20, "essen": 20, "2013": [20, 83, 103, 133, 151, 159, 193], "connectom": 20, "neuroimag": [20, 29, 80], "80": [20, 65, 70, 74, 146, 148, 171, 188], "169": [20, 69, 81, 142], "189": 20, "05": [20, 33, 34, 35, 63, 65, 69, 71, 74, 81, 89, 103, 116, 124, 125, 126, 133, 139, 146, 147, 149, 157, 163, 165, 171, 172, 175, 181, 182, 191, 199, 200], "033": 20, "complement": 20, "brainwid": [20, 27], "none": [20, 24, 33, 34, 35, 47, 65, 69, 70, 71, 74, 80, 81, 88, 97, 99, 100, 101, 107, 108, 117, 123, 124, 125, 126, 137, 140, 147, 148, 149, 155, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "summer": 20, "recept": [20, 103, 105, 107, 124, 164], "ml": [20, 105, 193], "savi": 20, "hierarchi": [20, 124], "benson": 20, "jamison": 20, "arcaro": 20, "vu": 20, "glasser": 20, "coalson": 20, "2018": [20, 33, 34, 35, 83, 103, 110, 119, 133, 151, 177, 184, 193], "tesla": 20, "descript": [20, 22, 27, 29, 63, 74, 83, 85, 94, 131, 133, 137, 142, 144, 163, 164, 171, 172, 173, 181, 182, 186, 188, 189], "vision": [20, 22, 24, 25, 33, 35, 119, 131], "18": [20, 39, 63, 65, 69, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 117, 123, 124, 125, 126, 137, 138, 139, 142, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 184, 189, 190, 191, 197, 198, 199, 200], "13": [20, 23, 31, 65, 69, 80, 81, 83, 87, 96, 98, 99, 100, 101, 107, 108, 110, 114, 115, 116, 119, 123, 124, 125, 126, 133, 137, 139, 147, 149, 151, 155, 156, 157, 163, 165, 172, 174, 181, 182, 188, 189, 191, 198, 199, 200], "1167": 20, "michael": [20, 33, 34, 35, 56, 63, 65, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 137, 138, 139, 140, 146, 147, 148, 155, 156, 157, 165, 171, 172, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "waskom": [20, 33, 34, 35, 63, 65, 87, 88, 89, 96, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 137, 138, 139, 140, 146, 147, 148, 155, 156, 157, 165, 171, 172, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "v1": [20, 27, 70, 108, 119, 123, 124, 125, 126, 200], "v2": [20, 200], "v3": 20, "v4": [20, 124], "naselari": 20, "prenger": 20, "gallant": 20, "452": 20, "7185": 20, "352": 20, "355": 20, "1038": [20, 27, 83, 103, 110, 119, 133, 142, 147, 177, 184, 193], "nature06713": 20, "oliv": 20, "reconstruct": [20, 33, 34, 117], "63": [20, 81, 126, 155, 181, 191], "902": 20, "915": 20, "09": [20, 92, 103], "006": [20, 63, 142], "di": [20, 74, 125, 156, 157], "static": [20, 71, 123, 182, 190], "navig": [20, 103, 123, 139, 164, 182, 190], "kshitij": [20, 33, 34, 35, 123, 124, 125, 126], "dwivedi": [20, 33, 34, 35, 123, 124, 125, 126], "anim": [20, 71, 76, 80, 81, 105, 108, 123, 126, 140, 163, 171, 179, 181, 186, 188, 195], "clip": [20, 35, 65, 173, 199, 200], "kriegeskort": [20, 119], "mur": [20, 119, 171], "bandettini": [20, 119], "system": [20, 22, 23, 25, 29, 33, 35, 39, 69, 74, 75, 80, 81, 83, 85, 89, 92, 103, 119, 124, 125, 126, 131, 135, 138, 139, 140, 142, 144, 146, 147, 153, 156, 164, 167, 172, 173, 181, 184, 195, 201], "06": [20, 63, 119, 155], "004": [20, 63, 119, 174], "epstein": 20, "afford": [20, 33, 99, 123], "4793": 20, "4798": 20, "1618228114": 20, "pantazi": [20, 119], "oliva": [20, 119, 121, 124], "2014": [20, 33, 34, 35, 75, 76, 103, 110, 119, 142, 151, 159, 177, 193], "resolv": [20, 22, 24, 25, 31, 87, 131], "recognit": [20, 92, 119, 121, 124, 125, 173, 174], "space": [20, 22, 71, 80, 87, 108, 112, 114, 116, 117, 124, 131, 133, 137, 148, 161, 163, 164, 174], "17": [20, 39, 65, 69, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 103, 107, 108, 110, 114, 115, 116, 123, 124, 125, 126, 137, 139, 142, 147, 149, 151, 155, 156, 157, 163, 165, 171, 172, 174, 175, 177, 181, 182, 189, 190, 191, 193, 198, 200], "455": [20, 175], "462": 20, "nn": [20, 33, 34, 35, 103, 110, 123, 124, 125, 126, 199], "3635": 20, "url": [20, 22, 27, 31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200], "csail": 20, "mit": [20, 83, 103, 133, 142, 159, 174, 177, 184, 188, 193], "creator": [22, 23, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 87, 88, 89, 90, 93, 96, 97, 98, 99, 100, 101, 104, 107, 108, 111, 114, 115, 116, 117, 120, 123, 124, 125, 126, 128, 131, 134, 137, 138, 139, 140, 143, 146, 147, 148, 149, 152, 155, 156, 157, 160, 163, 164, 165, 168, 171, 172, 173, 174, 175, 178, 181, 182, 185, 188, 189, 190, 191, 194, 197, 198, 199, 200], "hart": [22, 23, 24, 25, 131], "megan": [22, 23, 24, 25, 131], "peter": [22, 23, 24, 25, 131, 146, 193], "paul": [22, 23, 24, 25, 36, 37, 38, 131], "schrater": [22, 23, 24, 25, 83, 131], "gunnar": [22, 23, 24, 25, 37, 131], "blohm": [22, 23, 24, 25, 37, 83, 131], "tara": [22, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 131], "viegen": [22, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 131], "editor": [22, 23, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 146, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 191, 197, 198, 199, 200], "ella": [22, 23, 55, 60, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 155, 156, 157, 163, 164, 171, 172, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "batti": [22, 23, 55, 60, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 119, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 155, 156, 157, 163, 164, 171, 172, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "w1d2": 22, "eas": [22, 35, 156], "yesterdai": [22, 74, 108, 131, 146, 148, 155, 171, 172, 173, 182], "gain": [22, 23, 24, 25, 45, 71, 80, 88, 99, 114, 121, 131, 137, 139, 155, 156, 157, 163, 164, 172, 173, 174, 191], "bui": [22, 131], "But": [22, 24, 25, 74, 75, 76, 81, 85, 97, 101, 107, 116, 117, 123, 125, 131, 139, 140, 146, 147, 157, 163, 164, 167, 173, 189, 191, 198, 199, 200], "clarifi": [22, 131, 164], "assum": [22, 24, 71, 74, 80, 81, 88, 89, 97, 98, 107, 108, 114, 115, 131, 138, 139, 146, 148, 149, 155, 163, 164, 165, 171, 172, 174, 175, 179, 188, 191, 198, 199], "et": [22, 25, 27, 87, 89, 108, 117, 123, 124, 125, 126, 131, 174], "al": [22, 25, 27, 87, 89, 108, 117, 123, 124, 125, 126, 131, 174], "2019": [22, 23, 25, 27, 70, 83, 87, 89, 92, 103, 108, 119, 123, 124, 125, 126, 131, 133, 151, 167, 177, 193], "frame": [22, 23, 24, 25, 69, 70, 107, 129, 164], "remain": [22, 23, 35, 70, 89, 114, 129, 131, 138, 139, 148, 149, 155, 157, 165, 182, 188, 189], "throughout": [22, 71, 80, 94, 96, 114, 131, 138, 147, 149, 153, 155, 164, 182, 188, 198, 201], "revit": 22, "move": [22, 24, 25, 69, 71, 76, 80, 81, 87, 123, 124, 131, 139, 156, 157, 164, 165, 171, 172, 173, 179, 181, 188, 190, 191, 198, 199, 201], "maxim": [22, 33, 69, 74, 81, 89, 97, 98, 108, 115, 125, 126, 131, 163, 165, 167, 179, 181, 188, 189, 190], "succeed": [22, 126, 131], "tabl": [22, 74, 81, 131, 163, 190, 191], "side": [22, 33, 35, 63, 69, 75, 76, 88, 116, 124, 125, 126, 129, 131, 137, 146, 156, 164, 171, 181, 190, 197], "illus": [22, 129, 131], "introductori": [22, 131], "explain": [22, 23, 24, 25, 69, 70, 81, 87, 88, 89, 96, 97, 105, 114, 115, 119, 125, 126, 131, 138, 144, 147, 151, 156, 163, 164, 167, 171, 173, 181, 184, 191, 199], "roleplai": [22, 129, 131], "showcas": [22, 35, 131], "pitfal": [22, 23, 105, 129, 131], "around": [22, 24, 34, 69, 76, 80, 87, 88, 89, 96, 97, 98, 99, 100, 101, 115, 116, 131, 137, 139, 147, 151, 155, 157, 163, 164, 165, 172, 173, 174, 181, 182, 190, 198, 200], "appreci": [22, 23, 83, 85, 131, 144, 153], "np": [22, 24, 25, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "pyplot": [22, 24, 25, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "plt": [22, 24, 25, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "random": [22, 24, 25, 33, 34, 35, 74, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 123, 125, 126, 131, 138, 140, 146, 147, 148, 149, 155, 157, 163, 164, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 195, 198, 199, 200], "stat": [22, 24, 25, 80, 81, 88, 89, 97, 125, 131, 164, 171, 172, 173, 174, 175], "norm": [22, 24, 25, 33, 34, 69, 71, 80, 81, 97, 107, 124, 131, 156, 161, 163, 171, 172, 173], "poisson": [22, 24, 88, 103, 105, 108, 131, 138, 146, 147, 148, 149], "logist": [22, 24, 103, 105, 107, 125, 131], "sklearn": [22, 24, 33, 34, 35, 101, 105, 108, 116, 117, 125, 131, 199, 200], "linear_model": [22, 24, 108, 131, 199, 200], "logisticregress": [22, 24, 108, 131], "model_select": [22, 24, 101, 108, 131], "cross_val_scor": [22, 24, 108, 131], "titl": [22, 24, 31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "def": [22, 24, 25, 31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "rasterplot": [22, 24, 131], "spike": [22, 24, 33, 35, 74, 76, 80, 85, 94, 99, 103, 105, 108, 131, 133, 144, 148, 153, 155, 167, 195], "timepoint": [22, 24, 81, 107, 131], "trial_spik": [22, 24, 131], "trial_ev": [22, 24, 131], "nonzero": [22, 24, 108, 115, 131, 146, 175], "150": [22, 24, 36, 37, 38, 63, 69, 131, 171, 197, 198, 199, 200], "100": [22, 23, 24, 25, 36, 37, 38, 75, 76, 80, 81, 88, 97, 107, 108, 112, 116, 123, 125, 126, 131, 139, 140, 146, 147, 148, 155, 156, 157, 165, 171, 172, 174, 181, 182, 188, 190, 191, 197, 198, 199, 200], "dt": [22, 24, 25, 63, 65, 74, 75, 76, 88, 107, 131, 137, 138, 146, 147, 148, 149, 155, 157, 175], "eventplot": [22, 24, 87, 131], "linewidth": [22, 24, 65, 69, 70, 74, 80, 81, 97, 98, 99, 107, 114, 115, 126, 131, 137, 140, 164, 165, 172, 173, 174, 175, 181], "ylabel": [22, 24, 25, 33, 34, 35, 63, 65, 69, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 173, 174, 175, 182, 189, 190, 191, 197, 198, 199, 200], "xlabel": [22, 24, 25, 33, 34, 35, 63, 65, 69, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 173, 174, 175, 182, 189, 190, 191, 197, 198, 199, 200], "plotcrossvalaccuraci": [22, 24, 131], "accuraci": [22, 24, 76, 98, 119, 121, 126, 131, 142, 167, 174, 182, 189], "ax": [22, 24, 25, 33, 34, 35, 69, 70, 71, 74, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 107, 108, 116, 123, 124, 125, 126, 131, 137, 139, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "subplot": [22, 24, 25, 33, 34, 35, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 107, 108, 116, 123, 124, 125, 126, 131, 137, 139, 146, 148, 149, 156, 157, 164, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "figsiz": [22, 24, 25, 33, 34, 35, 65, 69, 70, 71, 74, 75, 76, 88, 89, 96, 97, 98, 107, 108, 114, 115, 123, 124, 125, 126, 131, 137, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 189, 190, 191, 197, 198, 199, 200], "boxplot": [22, 24, 101, 108, 131], "vert": [22, 24, 108, 131], "fals": [22, 23, 24, 33, 34, 35, 63, 65, 69, 70, 71, 74, 81, 88, 101, 105, 107, 108, 116, 117, 123, 124, 125, 126, 131, 137, 146, 147, 148, 149, 155, 157, 163, 164, 171, 172, 173, 174, 181, 182, 188, 190, 197, 198, 199, 200], "width": [22, 24, 36, 37, 38, 69, 70, 71, 74, 75, 76, 87, 100, 108, 124, 125, 126, 131, 137, 146, 148, 149, 163, 164, 172, 173, 181, 182, 197, 198, 199, 200], "ytick": [22, 24, 34, 35, 69, 70, 71, 74, 75, 76, 87, 108, 126, 131, 138, 148, 163, 164, 175], "spine": [22, 24, 69, 70, 71, 74, 107, 108, 124, 125, 131, 163, 171, 181], "set_vis": [22, 24, 69, 71, 108, 124, 125, 131, 149, 163, 171], "generatespiketrain": [22, 24, 131], "50": [22, 24, 25, 63, 65, 69, 75, 76, 81, 87, 89, 97, 98, 99, 100, 101, 107, 108, 114, 116, 117, 123, 125, 126, 131, 146, 147, 148, 149, 156, 157, 163, 165, 171, 172, 173, 174, 175, 182, 188, 198, 199, 200], "repetit": [22, 24, 25, 131], "800": [22, 24, 131], "seed": [22, 24, 33, 63, 65, 80, 81, 88, 96, 97, 98, 99, 100, 101, 108, 114, 115, 116, 123, 125, 126, 131, 138, 139, 140, 146, 147, 148, 149, 155, 157, 171, 172, 173, 174, 175, 181, 188, 189, 190, 191, 197, 198, 199, 200], "37": [22, 24, 71, 80, 81, 87, 88, 89, 98, 99, 101, 107, 108, 110, 114, 115, 126, 131, 139, 142, 146, 149, 155, 163, 171, 175, 177, 181, 182, 189, 191, 197, 198], "arang": [22, 24, 33, 34, 35, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 100, 101, 107, 108, 115, 116, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 175, 181, 182, 188, 190, 191], "interv": [22, 24, 65, 70, 71, 74, 76, 80, 85, 88, 89, 96, 97, 99, 100, 101, 131, 146, 147, 148, 149, 173, 175, 188, 193], "velocity_sigma": [22, 24, 131], "std": [22, 24, 63, 81, 98, 126, 131, 139, 140, 146, 165, 171, 182, 198, 200], "dev": [22, 24, 81, 131], "veloc": [22, 24, 25, 74, 131, 177], "profil": [22, 24, 131], "velocity_profil": [22, 24, 131], "pdf": [22, 24, 65, 80, 81, 83, 89, 97, 103, 110, 119, 131, 133, 142, 151, 164, 167, 171, 172, 173, 177, 184, 193], "gaussian": [22, 24, 33, 74, 98, 114, 115, 124, 125, 126, 131, 133, 139, 148, 161, 169, 171, 173, 179, 189, 193], "properti": [22, 23, 24, 63, 70, 74, 80, 81, 85, 98, 116, 123, 124, 125, 126, 131, 138, 139, 144, 147, 151, 153, 161, 163, 164, 171, 172, 173, 197], "rand": [22, 24, 96, 97, 98, 125, 131, 147, 148, 149, 175], "sensit": [22, 24, 74, 81, 117, 124, 131, 147], "fr": [22, 24, 96, 97, 131], "rate": [22, 24, 33, 34, 65, 69, 74, 76, 80, 87, 88, 89, 107, 108, 114, 123, 125, 126, 131, 137, 138, 139, 140, 147, 153, 156, 157, 171, 175, 177, 189, 190, 191], "output": [22, 23, 24, 25, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 125, 126, 131, 133, 137, 138, 139, 140, 144, 146, 148, 149, 155, 156, 157, 163, 165, 171, 172, 173, 174, 181, 188, 189, 190, 191, 197, 198, 200], "target_shap": [22, 24, 131], "len": [22, 24, 25, 33, 34, 35, 65, 70, 71, 74, 75, 76, 81, 87, 88, 89, 96, 97, 99, 101, 107, 108, 115, 116, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 156, 157, 165, 171, 172, 173, 174, 175, 181, 182, 189, 190, 191, 197, 198, 199, 200], "repeat": [22, 24, 63, 71, 81, 98, 101, 124, 131, 149, 156, 163, 165, 171, 172, 181, 191], "reshap": [22, 24, 33, 34, 35, 70, 99, 116, 131, 163, 165, 175, 190, 191, 198, 200], "axi": [22, 24, 33, 34, 35, 63, 65, 69, 70, 71, 74, 76, 80, 81, 88, 108, 114, 115, 116, 124, 125, 126, 131, 137, 139, 140, 148, 155, 156, 163, 164, 165, 171, 172, 173, 175, 181, 182, 189, 190, 191, 197, 198, 199, 200], "multipli": [22, 24, 69, 70, 71, 74, 75, 81, 97, 116, 123, 125, 126, 131, 147, 165, 173, 175, 182, 188], "s_gain": [22, 24, 131], "s_move": [22, 24, 131], "arrai": [22, 24, 25, 33, 34, 35, 65, 69, 70, 71, 74, 76, 80, 81, 87, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "top": [22, 24, 33, 35, 46, 47, 69, 70, 71, 74, 75, 76, 87, 94, 96, 99, 107, 108, 114, 115, 116, 117, 123, 125, 131, 139, 140, 149, 156, 171, 190, 191, 198, 199], "baselin": [22, 24, 35, 105, 131, 146, 147, 148], "s_fr": [22, 24, 131], "lower": [22, 24, 25, 33, 34, 35, 65, 69, 80, 81, 88, 97, 99, 100, 108, 112, 124, 126, 131, 156, 157, 163, 164, 171, 174, 175, 181, 182, 189, 190, 191, 198, 201], "correct": [22, 24, 63, 65, 71, 81, 89, 100, 107, 108, 126, 131, 133, 155, 157, 163, 164, 171, 172, 173, 174, 188, 195, 197, 198, 199, 200], "rv": [22, 24, 25, 88, 97, 131, 171, 172, 174, 175, 181], "return": [22, 24, 25, 31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "subsetpercept": [22, 24, 131], "400": [22, 24, 27, 131, 146, 147, 148, 149, 164, 188, 191], "subset": [22, 24, 65, 69, 89, 98, 101, 108, 123, 126, 131, 174, 199], "hwin": [22, 24, 131], "num_mov": [22, 24, 131], "zero": [22, 24, 33, 34, 35, 65, 69, 70, 71, 74, 76, 80, 81, 87, 88, 89, 96, 97, 98, 100, 101, 107, 108, 114, 115, 116, 124, 125, 126, 131, 137, 138, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "ground": [22, 24, 33, 34, 35, 98, 115, 131, 147, 164, 172, 197, 198, 201], "truth": [22, 24, 33, 34, 35, 83, 98, 115, 131, 147, 164, 172, 197, 200], "y_train": [22, 24, 33, 34, 35, 100, 101, 126, 131], "y_test": [22, 24, 33, 34, 35, 100, 101, 126, 131], "m_train": [22, 24, 131], "m_test": [22, 24, 131], "reproduc": [22, 23, 24, 33, 80, 87, 88, 99, 123, 125, 126, 131, 148, 174, 189, 190, 191, 197, 198, 199, 200], "w_idx": [22, 24, 131], "ab": [22, 24, 33, 34, 35, 69, 70, 71, 89, 124, 125, 126, 131, 155, 164, 165, 171, 173, 197, 198, 199], "w_0": [22, 24, 131], "w_1": [22, 24, 114, 131], "max": [22, 23, 24, 33, 34, 35, 63, 65, 69, 70, 71, 75, 76, 80, 81, 87, 88, 89, 96, 97, 99, 100, 101, 107, 108, 114, 123, 124, 126, 131, 137, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "total": [22, 24, 74, 89, 107, 108, 116, 123, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 171, 172, 173, 175, 181, 189, 190, 191, 198], "count": [22, 24, 33, 34, 35, 65, 75, 76, 80, 81, 88, 89, 94, 98, 108, 131, 138, 146, 147, 148, 175, 181, 189], "stationari": [22, 24, 25, 131, 148, 149], "spikes_stat": [22, 24, 131], "sum": [22, 24, 25, 63, 69, 71, 80, 81, 87, 89, 97, 99, 101, 107, 108, 116, 123, 124, 125, 126, 131, 137, 138, 139, 147, 148, 149, 157, 163, 164, 165, 171, 172, 173, 175, 181, 182, 188, 189, 190, 191, 197], "spikes_mov": [22, 24, 131], "train_spikes_stat": [22, 24, 131], "train_spikes_mov": [22, 24, 131], "test_spikes_stat": [22, 24, 131], "test_spikes_mov": [22, 24, 131], "y": [22, 24, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 96, 97, 98, 99, 100, 101, 103, 107, 108, 110, 114, 115, 116, 117, 119, 123, 124, 125, 126, 131, 133, 137, 139, 142, 147, 151, 155, 157, 163, 164, 165, 167, 173, 174, 175, 181, 182, 184, 188, 190, 191, 197, 198, 199, 200], "x_train": [22, 24, 33, 34, 35, 100, 101, 131], "concaten": [22, 24, 35, 87, 107, 124, 125, 126, 131, 171, 197, 198, 199, 200], "x_test": [22, 24, 33, 34, 35, 100, 101, 131, 140], "fit": [22, 23, 24, 25, 33, 39, 65, 70, 75, 81, 85, 94, 96, 97, 98, 100, 101, 105, 112, 117, 119, 121, 123, 124, 125, 126, 131, 153, 161, 163, 190, 195, 197, 198, 200, 201], "population_model": [22, 24, 131], "solver": [22, 24, 108, 131, 137], "liblinear": [22, 24, 131], "random_st": [22, 24, 117, 125, 131, 174, 197, 198, 199, 200], "newton": [22, 24, 131], "cg": [22, 24, 131], "lbfg": [22, 24, 131], "sag": [22, 24, 131], "saga": [22, 24, 108, 131], "coef_": [22, 24, 108, 131, 199, 200], "slope": [22, 24, 33, 74, 87, 96, 97, 98, 99, 123, 131, 147, 157], "intercept_": [22, 24, 131], "intercept": [22, 24, 87, 99, 107, 123, 131, 140, 199, 200], "ground_truth": [22, 24, 131], "getdata": [22, 24, 131], "ipywidget": [22, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 108, 114, 115, 116, 117, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 198, 199, 200], "widget": [22, 39, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 108, 114, 115, 116, 117, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 198, 199, 200], "ipython": [22, 36, 37, 38, 69, 75, 76, 108, 123, 124, 131, 163, 164, 172, 173, 175, 181, 182], "displai": [22, 23, 24, 33, 34, 35, 36, 37, 38, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 108, 114, 115, 116, 117, 123, 124, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 171, 172, 173, 174, 175, 181, 182, 188, 189, 197, 198, 199, 200], "markdown": [22, 24, 33, 36, 37, 38, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 108, 114, 115, 116, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 181, 182, 188, 189, 190, 197, 198, 199, 200], "markdown1": [22, 131], "br": [22, 131], "font": [22, 69, 70, 74, 81, 131], "3pt": [22, 131], "occur": [22, 24, 25, 39, 65, 69, 74, 80, 88, 89, 126, 131, 137, 138, 140, 149, 163, 188, 197, 200], "sit": [22, 24, 25, 89, 131, 140], "window": [22, 24, 25, 69, 107, 131, 138, 148], "suddenli": [22, 24, 25, 131], "wrong": [22, 23, 24, 25, 71, 76, 81, 89, 131, 163, 165, 171, 197, 198], "vice": [22, 24, 25, 33, 76, 125, 131, 156, 157], "versa": [22, 24, 25, 33, 76, 125, 131, 156, 157], "surround": [22, 24, 25, 124, 125, 126, 131, 151, 153], "disambigu": [22, 24, 25, 131], "strong": [22, 23, 24, 25, 65, 81, 108, 116, 131, 146, 148, 189, 193, 200], "vibrat": [22, 24, 25, 131], "indic": [22, 24, 25, 33, 69, 75, 76, 81, 98, 101, 108, 114, 115, 123, 125, 126, 131, 137, 156, 157, 171, 174, 188, 191], "inde": [22, 24, 25, 80, 81, 88, 94, 97, 107, 108, 124, 126, 131, 146, 147, 155], "vestibular": [22, 24, 131], "illusori": [22, 25, 131], "self": [22, 24, 25, 34, 35, 65, 69, 81, 89, 123, 124, 125, 126, 131, 133, 137, 140, 174, 181, 182, 188, 190, 191], "markdown2": [22, 131], "accumul": [22, 24, 25, 75, 80, 123, 131, 133, 165, 171, 190, 191], "case": [22, 23, 24, 25, 33, 39, 47, 63, 65, 69, 70, 71, 74, 80, 81, 87, 89, 96, 97, 99, 105, 107, 108, 123, 124, 125, 126, 131, 137, 146, 147, 148, 155, 157, 163, 164, 169, 171, 173, 174, 181, 182, 188, 189, 190, 191, 197], "pretend": [22, 24, 131, 174, 197], "hold": [22, 24, 25, 89, 99, 123, 124, 126, 131, 200], "condit": [22, 24, 25, 35, 63, 65, 71, 76, 85, 94, 114, 123, 131, 138, 139, 146, 147, 148, 155, 156, 157, 163, 164, 172, 173, 181, 182, 188, 190, 197, 199, 200], "slowli": [22, 24, 131, 182], "acceler": [22, 24, 25, 47, 119, 126, 131], "faster": [22, 24, 35, 107, 117, 125, 131, 157, 165, 171, 173, 181, 198], "correl": [22, 24, 25, 103, 107, 112, 131, 133, 146, 171, 174, 177, 195, 197, 199, 200, 201], "judgement": [22, 24, 131], "out2": [22, 131], "out1": [22, 131], "tab": [22, 23, 131, 182], "set_titl": [22, 25, 33, 34, 35, 70, 74, 89, 108, 124, 125, 126, 131, 149, 165, 171, 172, 181, 182, 188, 197, 198, 200], "25": [22, 35, 39, 63, 65, 69, 71, 76, 80, 81, 87, 88, 89, 99, 100, 101, 103, 107, 108, 115, 116, 123, 125, 126, 131, 137, 138, 139, 140, 142, 147, 149, 151, 155, 156, 157, 163, 164, 165, 171, 172, 173, 175, 182, 189, 190, 191, 197, 198, 199, 200], "write": [22, 24, 25, 35, 44, 46, 47, 63, 69, 70, 71, 75, 76, 81, 88, 89, 96, 97, 107, 108, 114, 115, 123, 124, 125, 126, 131, 137, 139, 140, 146, 147, 148, 155, 156, 163, 165, 171, 174, 175, 181, 188, 189, 190, 191, 197], "remind": [22, 80, 81, 96, 124, 131, 137], "exact": [22, 24, 71, 74, 76, 80, 85, 97, 100, 101, 117, 124, 126, 131, 138, 155, 164], "clearli": [22, 23, 24, 25, 87, 131, 139, 148, 174, 190], "precis": [22, 23, 27, 81, 87, 115, 119, 129, 131, 137, 171, 174, 189, 199], "lost": [22, 23, 101, 131, 174], "guarante": [22, 108, 131, 155, 171, 175, 177, 199], "everyth": [22, 29, 81, 87, 99, 107, 131, 163, 164, 174, 200], "address": [22, 23, 24, 25, 33, 35, 75, 85, 87, 94, 107, 126, 131, 153, 174, 181, 200], "comparison": [22, 23, 25, 33, 81, 94, 119, 121, 131, 173, 175, 198, 200], "essenti": [22, 23, 24, 25, 63, 69, 74, 80, 81, 100, 101, 123, 124, 126, 131, 144, 155, 163, 164, 182, 193], "interfac": [22, 23, 87, 107, 112, 131, 133, 167, 173, 174, 179], "phenomena": [22, 23, 24, 25, 80, 87, 108, 131, 142, 149, 153, 157, 172, 188, 191], "mechanist": [22, 25, 29, 131, 144, 181, 201], "investig": [22, 25, 35, 76, 87, 112, 125, 131, 139, 146, 148, 149, 155, 156, 157, 174, 182, 188, 191], "recap": [22, 23, 69, 70, 71, 74, 75, 76, 80, 81, 96, 97, 99, 100, 108, 114, 123, 124, 131, 137, 138, 146, 155, 156, 163, 164, 171, 197], "unclear": [22, 131], "meaning": [22, 131, 181], "chosen": [22, 74, 76, 81, 123, 131, 155, 156, 165, 181, 188, 189, 190, 191, 201], "prevent": [22, 23, 131, 148], "deepli": [22, 23, 131], "behind": [22, 71, 112, 123, 126, 131, 139, 163, 165, 171, 189, 201], "BUT": [22, 70, 131, 197], "anywher": [22, 69, 124, 131, 190, 191], "revisit": [22, 81, 97, 129, 131, 164], "frequent": [22, 25, 74, 131, 195], "necess": [22, 131], "feel": [22, 24, 25, 33, 75, 76, 80, 114, 125, 131, 161, 163, 173, 181, 190], "bad": [22, 23, 24, 81, 92, 123, 124, 126, 131, 140, 164, 173, 184, 190], "nest": [22, 81, 108], "known": [22, 24, 25, 35, 75, 76, 80, 81, 87, 89, 96, 99, 107, 129, 131, 137, 138, 139, 140, 148, 149, 171, 173, 174, 182, 188, 190, 191], "examin": [22, 24, 25, 71, 74, 80, 81, 85, 115, 126, 131, 137, 146, 155, 156, 157, 164, 172, 174, 182, 198, 199, 200], "attempt": [22, 25, 108, 131, 165, 188, 191, 198], "perceptu": [22, 25, 131, 133], "markdown21": [22, 131], "4d": [22, 24, 124, 131, 175], "integ": [22, 24, 33, 34, 35, 63, 70, 88, 94, 107, 125, 131, 139, 140], "2d": [22, 24, 35, 69, 70, 71, 107, 108, 115, 116, 123, 125, 131, 156, 165, 172, 175, 181, 190], "markdown22": [22, 131], "dimens": [22, 24, 33, 70, 74, 87, 88, 99, 100, 107, 112, 114, 116, 123, 124, 125, 126, 131, 133, 139, 140, 155, 156, 164, 173, 174, 175], "simultan": [22, 24, 27, 80, 103, 123, 129, 131, 133, 138, 147, 191, 195, 197, 198, 200], "third": [22, 24, 34, 38, 99, 116, 131, 137, 144, 155, 157], "ms": [22, 24, 65, 74, 75, 76, 87, 107, 131, 146, 147, 148, 149, 155, 156, 157], "fourth": [22, 24, 131, 156], "perfect": [22, 24, 25, 75, 131, 159, 197, 198, 200], "closer": [22, 24, 88, 96, 99, 116, 124, 125, 131, 139, 164], "mi": [22, 24, 131, 174], "markdown23": [22, 131], "blue": [22, 24, 63, 69, 74, 75, 76, 81, 99, 114, 115, 116, 123, 124, 131, 137, 139, 149, 155, 156, 163, 164, 171, 172, 188], "produc": [22, 23, 24, 33, 34, 65, 85, 88, 89, 96, 97, 98, 99, 101, 107, 108, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 157, 163, 164, 171, 175, 182, 188, 190, 195, 198], "flat": [22, 24, 81, 131, 164], "orang": [22, 24, 70, 74, 81, 87, 97, 131, 139, 149, 156, 157, 171, 172, 173, 174, 188], "green": [22, 24, 69, 70, 75, 76, 80, 124, 131, 163, 164, 172, 174, 182, 188, 191], "bell": [22, 24, 33, 131, 188], "correspond": [22, 24, 25, 33, 34, 63, 69, 70, 71, 74, 80, 81, 87, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 119, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 182, 189, 190, 191, 197, 198, 200], "consider": [22, 23, 24, 101, 131, 195], "nois": [22, 24, 25, 33, 74, 81, 96, 98, 99, 100, 101, 103, 107, 108, 117, 123, 126, 131, 140, 148, 149, 151, 155, 157, 165, 171, 172, 173, 174, 181, 197, 200], "exactli": [22, 24, 63, 75, 76, 80, 88, 89, 107, 123, 124, 125, 131, 139, 155, 157, 159, 164, 174, 188, 200], "singl": [22, 24, 33, 34, 35, 63, 65, 69, 71, 74, 75, 80, 81, 88, 89, 96, 97, 99, 103, 105, 107, 114, 116, 121, 123, 124, 125, 126, 131, 133, 137, 139, 140, 142, 146, 148, 149, 151, 156, 163, 164, 165, 171, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "markdown24": [22, 131], "abov": [22, 24, 35, 45, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 99, 100, 101, 108, 114, 115, 117, 123, 124, 125, 126, 131, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 171, 173, 174, 175, 181, 182, 188, 189, 190, 191, 195, 197, 198, 199, 200], "distinguish": [22, 24, 33, 80, 117, 131, 193], "ey": [22, 24, 107, 116, 131, 133, 137, 175, 197, 198, 199, 200], "ball": [22, 24, 131, 164], "seen": [22, 24, 65, 69, 71, 74, 75, 87, 88, 89, 98, 100, 101, 107, 108, 115, 116, 125, 126, 131, 138, 140, 146, 147, 148, 155, 156, 157, 161, 163, 164, 165, 172, 181, 182, 186, 188, 189, 190, 195, 200], "extract": [22, 24, 63, 85, 87, 107, 117, 125, 126, 131, 133, 139, 140, 197, 198, 199, 200], "move_no": [22, 24, 131], "legend": [22, 23, 24, 25, 33, 63, 65, 69, 71, 74, 75, 76, 80, 81, 87, 96, 97, 98, 99, 100, 107, 114, 115, 125, 126, 131, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 199, 200], "thorough": [22, 131], "week": [22, 39, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "exhaust": [22, 131, 200], "emit": [22, 81, 89, 107, 131, 172], "altern": [22, 25, 33, 35, 69, 74, 80, 94, 107, 116, 125, 131, 138, 140, 175, 190, 195, 198, 199, 200], "math": [22, 23, 70, 80, 88, 112, 123, 131, 140, 147, 155, 165, 171, 174, 181, 182], "v": [22, 25, 33, 34, 35, 63, 65, 69, 70, 71, 74, 76, 81, 88, 92, 103, 125, 131, 133, 137, 138, 142, 146, 147, 148, 149, 151, 163, 172, 173, 177, 181, 184, 188, 190, 191, 199, 200], "threshold": [22, 63, 65, 74, 75, 88, 116, 131, 142, 146, 147, 148, 149, 155, 156, 157], "\u03b8": [22, 131], "filter": [22, 25, 80, 107, 125, 126, 131, 146, 148], "mechan": [22, 23, 24, 35, 63, 85, 88, 89, 131, 151, 153, 175, 181, 182, 198, 200], "somehow": [22, 24, 131], "classic": [22, 24, 70, 81, 98, 116, 123, 125, 126, 131, 164, 171, 173, 188, 190, 200], "classif": [22, 24, 33, 105, 108, 124, 126, 131], "raw": [22, 24, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "pre": [22, 24, 63, 71, 75, 87, 88, 89, 107, 124, 131, 137, 138, 144, 146, 147, 148, 156, 163, 164, 165, 172, 201], "10m": [22, 24, 131], "sub": [22, 33, 74, 131, 189], "perceiv": [22, 24, 35, 80, 108, 131], "classifi": [22, 24, 85, 125, 126, 131, 201], "render": [22, 31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "allow": [22, 23, 24, 25, 45, 63, 69, 71, 76, 80, 81, 85, 87, 94, 96, 98, 99, 101, 105, 107, 108, 115, 121, 123, 124, 126, 131, 146, 148, 161, 163, 164, 165, 169, 171, 172, 173, 181, 186, 188, 191, 195, 199, 200], "constant": [22, 25, 63, 69, 74, 75, 76, 87, 88, 89, 99, 101, 107, 126, 131, 138, 146, 147, 148, 149, 155, 157, 163, 164, 165, 171, 173, 182, 188, 197], "over": [22, 24, 25, 63, 65, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 123, 124, 125, 126, 131, 137, 138, 139, 146, 147, 148, 149, 155, 157, 163, 164, 165, 169, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 193, 197, 198, 199, 200, 201], "omit": [22, 131, 188], "describ": [22, 23, 63, 69, 70, 75, 76, 80, 81, 85, 87, 88, 97, 98, 114, 115, 123, 126, 131, 137, 138, 139, 146, 147, 148, 149, 155, 156, 157, 161, 163, 164, 165, 169, 171, 172, 174, 179, 181, 188, 189, 190, 197], "measur": [22, 23, 33, 69, 74, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 115, 131, 138, 140, 142, 146, 157, 163, 164, 171, 174, 175, 181, 188, 197, 198, 199, 200, 201], "latent": [22, 94, 116, 131, 169, 171, 172, 173, 175, 181, 182, 189], "abstract": [22, 24, 71, 75, 103, 119, 123, 124, 125, 126, 131, 146, 167, 177, 191, 199], "instanti": [22, 123, 131, 173], "util": [22, 85, 131, 148, 161, 179, 181, 191], "uncertainti": [22, 89, 94, 97, 98, 131, 161, 164, 172, 173, 184], "cost": [22, 34, 87, 89, 96, 97, 105, 123, 131, 181, 189, 190, 191, 200], "salienc": [22, 131, 174], "plant": [22, 131], "intuit": [22, 23, 70, 71, 74, 75, 76, 80, 81, 85, 88, 108, 114, 115, 116, 123, 125, 131, 137, 139, 140, 146, 147, 157, 159, 161, 163, 164, 165, 169, 172, 173, 174, 175, 181, 182, 188, 195, 199], "inventori": [22, 131], "anymor": [22, 131, 155], "link": [22, 24, 29, 39, 41, 47, 69, 81, 101, 108, 126, 131, 133, 148, 157, 164, 165, 195], "Not": [22, 23, 89, 131, 140, 148, 159, 191, 193, 200], "latex": [22, 131], "relationship": [22, 23, 24, 25, 35, 69, 71, 75, 76, 81, 87, 97, 99, 108, 125, 131, 138, 140, 146, 147, 148, 157, 163, 164, 173, 197, 198, 199], "amplitud": [22, 25, 71, 74, 131, 147, 148, 157], "div": [22, 131], "center": [22, 33, 34, 35, 69, 70, 71, 74, 80, 81, 108, 115, 119, 124, 125, 126, 131, 139, 148, 156, 157, 163, 164, 165, 171, 172, 174, 181], "em": [22, 131, 167], "frequenc": [22, 25, 65, 74, 75, 76, 124, 125, 126, 131, 146, 148, 151, 155, 156, 157, 172], "deviat": [22, 25, 33, 74, 80, 81, 97, 125, 126, 131, 139, 140, 146, 148, 157, 164, 165, 171, 172, 173], "sup": [22, 131], "stand": [22, 25, 88, 131, 165, 175], "\u03c3": [22, 131, 164], "drive": [22, 24, 27, 46, 74, 88, 92, 131, 146, 148, 157, 174, 195], "strongest": [22, 24, 126, 131, 163], "decid": [22, 23, 24, 25, 100, 108, 123, 131, 164, 171, 174, 181, 189, 190], "period": [22, 23, 24, 35, 63, 76, 87, 89, 131, 138, 146, 148, 157, 188, 189], "ratio": [22, 24, 25, 34, 74, 87, 114, 131, 147, 148, 149, 163, 173, 174, 199, 200], "higher": [22, 24, 25, 74, 89, 99, 100, 116, 119, 123, 124, 131, 133, 148, 149, 163, 181, 182, 190, 200], "came": [22, 24, 25, 75, 131], "focuss": [22, 23, 24, 129, 131], "hyp": [22, 24, 131], "vs": [22, 23, 24, 25, 33, 70, 96, 97, 108, 117, 126, 131, 139, 140, 146, 147, 149, 156, 157, 163, 164, 165, 173, 174, 181, 189, 195, 197, 199, 201], "slower": [22, 24, 131, 146, 171, 173, 189], "simplic": [22, 24, 83, 97, 99, 107, 114, 117, 131, 140, 149, 182, 189, 191, 200], "accum": [22, 24, 131], "win": [22, 24, 29, 75, 131], "fast": [22, 24, 74, 123, 131, 151, 156, 174, 188, 190], "slow": [22, 24, 74, 107, 131, 175, 188], "denot": [22, 24, 63, 70, 76, 116, 123, 125, 126, 131, 148, 149, 155, 164, 172, 173, 174, 182, 189], "argument": [22, 24, 33, 34, 35, 63, 65, 69, 87, 88, 96, 107, 123, 124, 125, 126, 131, 155, 157, 165, 173, 190, 195, 199, 200], "outcom": [22, 23, 24, 25, 75, 80, 81, 108, 131, 138, 163, 171, 182, 190, 191, 197, 198, 199, 200], "consist": [22, 23, 69, 70, 71, 76, 80, 99, 116, 121, 123, 124, 131, 137, 138, 148, 156, 171, 174, 177, 191, 197], "consecut": [22, 87, 131], "influenc": [22, 23, 25, 88, 96, 101, 107, 108, 131, 146, 149, 155, 163, 188, 189, 195, 199], "express": [22, 23, 34, 35, 63, 70, 74, 89, 96, 99, 107, 108, 114, 115, 116, 125, 131, 137, 138, 149, 155, 156, 157, 173, 174, 175, 182, 188, 189, 190, 191], "z": [22, 25, 33, 34, 35, 69, 71, 74, 80, 108, 119, 123, 124, 126, 131, 147, 164, 173, 174, 184, 200], "captur": [22, 33, 34, 69, 74, 87, 88, 94, 99, 100, 103, 115, 116, 119, 125, 126, 131, 146, 149, 164, 198, 199, 200], "justifi": [22, 131], "loop": [22, 23, 34, 65, 71, 76, 88, 96, 98, 99, 100, 101, 108, 119, 123, 125, 126, 131, 138, 139, 146, 165, 171, 173, 181, 190, 191, 197, 198, 200], "clariti": [22, 23, 131, 195], "OR": [22, 70, 131, 138, 163], "kord": [22, 23, 38, 83, 87, 88, 89, 90, 92, 103, 119, 131, 159, 165, 193, 197, 198, 199, 200], "kp": [22, 23, 131], "pr": [22, 23, 81, 131, 171], "0352": [22, 23, 83, 131], "19": [22, 23, 39, 65, 69, 71, 76, 80, 81, 83, 88, 89, 96, 97, 98, 99, 100, 101, 103, 107, 114, 115, 123, 124, 126, 131, 137, 138, 139, 147, 149, 155, 156, 157, 163, 165, 171, 172, 173, 174, 175, 181, 182, 189, 190, 191, 198, 199, 200], "nbdt": [22, 131], "scholasticahq": [22, 131], "com": [22, 31, 32, 33, 34, 35, 36, 37, 38, 45, 46, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 159, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "articl": [22, 29, 33, 83, 103, 110, 119, 124, 131, 133, 151, 171, 177, 184], "16723": [22, 131], "mk": [22, 131], "osf": [22, 23, 83, 87, 89, 107, 108, 123, 124, 125, 126, 131, 174], "w56vt": [22, 83, 131], "jean": [23, 24], "lauren": [23, 24], "dive": [23, 34, 63, 70, 81, 85, 107, 123, 155, 157, 164, 165, 171, 201], "satisfact": 23, "mathemat": [23, 24, 25, 29, 63, 69, 74, 75, 76, 80, 83, 87, 92, 99, 105, 123, 137, 139, 142, 144, 146, 148, 155, 161, 164, 165, 171, 172, 173, 174, 181, 193, 197, 199], "empow": 23, "chose": [23, 25, 108], "physic": [23, 75, 76, 87, 88, 133, 148, 169, 181], "repres": [23, 25, 33, 65, 69, 70, 74, 75, 76, 80, 81, 87, 89, 112, 114, 115, 116, 121, 123, 124, 125, 126, 133, 137, 147, 148, 149, 155, 156, 157, 161, 163, 164, 165, 172, 174, 175, 181, 188, 189, 191, 197, 198, 199, 200], "ingredi": [23, 129], "granular": [23, 96], "scale": [23, 25, 33, 70, 74, 80, 87, 88, 89, 108, 110, 121, 123, 126, 133, 138, 139, 153, 156, 157, 164, 165, 171, 172, 173, 174, 175, 182, 197, 199], "stai": [23, 70, 121, 138, 139, 155, 157, 172, 181, 190, 191], "span": [23, 33, 34, 70, 156, 175, 201], "wider": [23, 100, 123, 124, 139], "behaviour": [23, 31, 80, 81, 105, 108, 165, 193], "lumpabl": 23, "solv": [23, 33, 69, 74, 75, 76, 81, 97, 98, 99, 107, 123, 124, 125, 126, 137, 140, 155, 156, 157, 173, 174, 181, 186, 188, 190, 191], "analyt": [23, 33, 75, 76, 80, 96, 97, 98, 99, 107, 129, 139, 155, 163, 164, 171, 174, 188], "numer": [23, 33, 34, 63, 69, 75, 80, 81, 85, 88, 96, 97, 99, 101, 107, 117, 137, 146, 149, 163, 165, 175, 182, 189], "spatial": [23, 119, 124, 125, 126, 133, 146, 190], "resolut": [23, 25, 124, 125, 126, 175], "regard": [23, 25, 105], "state": [23, 24, 25, 35, 65, 69, 76, 81, 88, 123, 133, 137, 148, 149, 153, 156, 157, 161, 169, 171, 172, 174, 175, 179, 186, 188, 189, 190, 191, 197, 198, 200, 201], "els": [23, 24, 33, 34, 35, 65, 69, 70, 71, 74, 75, 80, 81, 87, 88, 89, 98, 107, 108, 123, 124, 125, 126, 146, 147, 148, 149, 155, 156, 157, 163, 164, 171, 172, 173, 174, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "sake": [23, 165], "dl": [23, 123, 175, 193], "cool": [23, 29, 123, 139, 140, 163, 200], "Being": 23, "w1d1": [23, 39, 144], "meaningfulli": 23, "constrain": [23, 34, 89, 126], "add": [23, 25, 33, 34, 41, 63, 65, 69, 70, 74, 75, 76, 80, 81, 87, 88, 99, 100, 101, 107, 108, 123, 124, 125, 137, 139, 140, 146, 148, 149, 155, 156, 157, 163, 171, 172, 173, 174, 182, 189, 191], "needless": 23, "care": [23, 33, 80, 101, 108, 123, 163, 164, 195, 200], "highlight": [23, 25, 74, 80, 105, 191, 193], "outlin": [23, 76, 96, 125, 198, 199, 200], "draw": [23, 35, 63, 69, 70, 75, 80, 89, 96, 98, 99, 108, 123, 125, 126, 139, 146, 148, 165, 179, 181, 189], "diagram": [23, 101, 123, 138, 200], "sketch": 23, "formal": [23, 69, 74, 87, 125, 126, 163, 164, 179, 181, 186, 188, 190], "thu": [23, 39, 69, 74, 81, 85, 89, 99, 100, 101, 108, 123, 124, 125, 126, 146, 148, 149, 165, 171, 175, 182, 188, 190, 191], "huge": [23, 153, 191], "broken": 23, "portenti": 23, "ideal": [23, 88, 89, 100, 123, 126, 189], "hypothet": [23, 89], "arrow": [23, 69, 70, 71, 137, 156, 197, 198, 199, 200], "intern": [23, 34, 35, 65, 107, 112, 119, 121, 124, 125, 177, 182, 191], "place": [23, 70, 76, 80, 85, 107, 163, 164, 181, 182, 189, 190, 191], "explan": [23, 83, 115, 124, 148, 188, 197, 198], "rough": [23, 81], "forget": [23, 68, 69, 79, 81, 86, 95, 106, 107, 108, 113, 116, 117, 122, 130, 136, 145, 147, 154, 162, 165, 170, 173, 180, 182, 187, 196, 200], "recurs": [23, 171, 172, 173, 175, 188], "insid": [23, 63, 65, 80, 87, 123, 157], "icon": [23, 181], "unit": [23, 24, 25, 34, 35, 63, 69, 70, 80, 87, 88, 89, 97, 107, 114, 121, 123, 124, 125, 137, 140, 146, 147, 148, 171, 173, 181, 188, 189], "easiest": [23, 85, 163, 200], "ad": [23, 34, 35, 69, 74, 81, 87, 88, 97, 99, 107, 108, 123, 125, 137, 139, 140, 157, 164, 171, 173, 175, 182, 191, 197, 199], "accomplish": [23, 100, 200], "surprisingli": [23, 191], "remov": [23, 33, 34, 63, 65, 69, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 123, 125, 126, 137, 139, 146, 147, 148, 149, 155, 156, 163, 165, 171, 173, 174, 182, 189, 190, 191, 197, 198, 199, 200], "insight": [23, 25, 33, 76, 85, 112, 124, 144], "isn": [23, 70, 96, 126, 164, 181, 189], "stabil": [23, 74, 97, 137, 138, 153, 156, 175, 182, 188], "equilibrium": [23, 76, 139, 140, 157, 173], "asymptot": [23, 190], "isol": [23, 33, 63, 133, 137, 164], "mistak": [23, 172, 174], "debug": [23, 63, 165], "Is": [23, 74, 75, 76, 81, 87, 96, 107, 108, 117, 125, 147, 148, 188], "wore": 23, "nice": [23, 74, 75, 80, 124, 126, 164, 189, 197, 199], "useless": 23, "distract": 23, "reader": 23, "alreali": 23, "achiev": [23, 85, 88, 124, 171, 175, 190, 191], "determ": 23, "handi": [23, 63, 99, 182], "finish": [23, 35, 39, 81, 89, 96, 97, 98, 99, 100, 101, 107, 115, 148, 149, 155, 156, 171, 188, 198], "phenomenon": [23, 85, 87, 100, 129, 148, 171], "criterion": [23, 33, 34, 35, 98, 171], "satisfi": [23, 69, 89, 96, 114, 200], "criteria": [23, 89, 137, 200], "parametr": 23, "elimin": 23, "met": [23, 199], "board": 23, "endless": 23, "benchmark": [23, 116, 142, 179, 193], "neglect": 23, "warrant": 23, "cannot": [23, 74, 75, 76, 87, 126, 138, 164, 165, 172, 173, 182, 188, 189], "ultim": [23, 69, 85, 129, 165], "qualit": [23, 34, 76, 97, 99, 107, 124, 137, 146, 181, 198], "upfront": 23, "amount": [23, 34, 70, 74, 81, 87, 88, 101, 116, 126, 138, 140, 148, 149, 163, 164, 171, 173, 174, 181, 182, 188, 197, 200], "w1d3": [23, 105, 121, 123, 195], "breadth": 23, "bic": 23, "aic": 23, "fair": 23, "respect": [23, 33, 71, 74, 76, 80, 81, 88, 89, 96, 97, 101, 107, 116, 123, 124, 125, 126, 137, 148, 149, 155, 156, 157, 164, 172, 174, 181, 191], "subsumpt": 23, "uncov": [23, 27, 35, 96, 125, 201], "falsifi": 23, "demonstr": [23, 24, 25, 69, 71, 123, 129, 157, 191], "appar": [23, 33, 116], "alon": [23, 174], "leverl": 23, "avenu": 23, "experiment": [23, 25, 27, 76, 85, 88, 94, 126, 148, 165, 171, 174, 177, 188, 193, 198, 200], "target": [23, 33, 35, 71, 107, 108, 117, 123, 126, 133, 164, 179, 182, 188, 190], "messag": [23, 35, 81, 87], "experimentalist": [23, 148, 165], "analog": [23, 173, 198], "famou": [23, 75, 190], "worth": [23, 124, 174, 177, 181], "1000": [23, 25, 74, 75, 76, 80, 81, 87, 88, 97, 101, 112, 114, 115, 125, 126, 138, 139, 146, 147, 148, 149, 155, 164, 165, 175, 189, 190, 191, 198], "parallel": [23, 27, 70, 137, 188], "convinc": [23, 139, 140], "receiv": [23, 35, 65, 88, 124, 146, 147, 148, 155, 164, 181, 186, 188, 189, 190, 191, 197], "AND": [23, 70], "impact": [23, 76, 103, 147, 153, 172, 174, 189, 191, 200], "accept": [23, 33, 34, 35, 70, 81, 98, 126, 155, 156, 157, 182], "frget": 23, "spell": 23, "unreason": 23, "claim": [23, 171], "reject": [23, 98, 153, 200], "expeiment": 23, "mesi": 23, "rightfulli": 23, "cleanli": 23, "comment": [23, 35, 65, 81, 87, 88, 89, 107, 116, 117, 138, 153, 165, 181, 189, 190, 191], "stereotyp": 23, "piec": [23, 33, 107, 126, 164], "condens": [23, 99, 174], "To": [23, 24, 25, 33, 35, 46, 71, 74, 75, 76, 80, 81, 87, 88, 89, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 125, 126, 129, 137, 138, 139, 140, 146, 148, 149, 155, 157, 163, 164, 165, 171, 173, 174, 177, 181, 182, 188, 191, 197, 199], "summari": [23, 174], "summar": [23, 24, 25, 65, 70, 81, 101, 114, 137, 163, 172], "articul": [23, 24, 25], "tri": [23, 24, 25, 63, 96, 97, 108, 140, 163, 173, 190], "overview": [23, 24, 25, 114, 115, 116, 117, 137, 155, 193], "conclud": [23, 24, 25], "briefli": [23, 24, 25, 71, 112, 138, 174, 175], "argu": [23, 24, 25, 195], "plausibl": [23, 24, 25, 35, 76, 103, 121, 201], "instruct": [23, 33, 34, 35, 81, 96, 125, 181], "guidelin": [23, 24, 25], "effect": [23, 33, 34, 35, 65, 74, 76, 80, 81, 83, 88, 89, 94, 97, 99, 103, 110, 123, 124, 148, 151, 155, 165, 171, 172, 174, 188, 189, 191, 193, 195, 197, 198, 199, 200], "mensh": 23, "schedul": [23, 188], "schemat": [23, 108, 197], "convei": [23, 71], "necessarili": [23, 71, 100, 156, 164, 188], "upload": 23, "repositori": [23, 29, 119], "github": [23, 35, 42, 92, 108, 110, 117, 119, 123, 137, 174], "forc": [23, 34, 45, 69, 108, 123, 181, 197, 198], "succinctli": [23, 99], "commit": 23, "purpos": [23, 24, 25, 63, 70, 71, 74, 76, 81, 88, 96, 101, 107, 108, 123, 126, 140, 146, 165, 174], "biol": [23, 75, 76], "e1005619": 23, "1005619": 23, "disclaim": [24, 25, 70], "procedur": [24, 25, 92, 96, 98, 100, 108, 126, 147, 161, 200], "pip": [24, 25, 31, 34, 47, 74, 174, 200], "tqdm": 24, "quiet": [24, 25, 31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "matric": [24, 33, 69, 71, 94, 99, 100, 108, 116, 123, 125, 126, 137, 140, 172, 174, 182, 197, 198, 199, 200], "301": 24, "36": [24, 63, 80, 81, 98, 101, 107, 108, 114, 116, 123, 126, 133, 139, 149, 171, 173, 174, 175, 181, 191, 197, 198, 200], "7575": 24, "975": 24, "m_r": 24, "m_p": 24, "mathbb": [24, 70, 89, 100, 115, 146, 163, 164, 174, 188, 189, 197], "c_": [24, 25, 88, 107, 124, 200], "cdot": [24, 25, 69, 70, 74, 76, 80, 108, 114, 123, 125, 126, 147, 149, 155, 157, 164, 172, 175], "w1d4": [24, 195], "glm": [24, 85, 94, 105, 108, 121], "whiteboard": [24, 25], "convert": [24, 33, 34, 35, 89, 123, 124, 125, 126, 146, 147, 148, 171, 173, 175], "belong": [24, 87, 126], "half": [24, 34, 76, 98, 124, 139, 182], "halfwin": 24, "a_r": 24, "cross": [24, 33, 34, 35, 65, 76, 88, 92, 96, 97, 98, 99, 100, 105, 107, 125, 126, 137, 147, 155, 171], "getdesignmatrix": 24, "arg": [24, 25, 33, 34, 35, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 188, 189, 190, 191, 197, 198, 199, 200], "ndarrai": [24, 33, 34, 35, 69, 70, 71, 74, 80, 81, 87, 89, 96, 97, 98, 99, 100, 101, 117, 123, 125, 126, 137, 138, 139, 146, 163, 173, 174, 182, 188, 189, 190, 191, 197, 198, 199, 200], "three": [24, 33, 35, 63, 75, 76, 81, 85, 87, 89, 96, 107, 108, 121, 123, 125, 126, 153, 155, 156, 157, 164, 172, 174, 175, 181, 199, 200], "length": [24, 34, 35, 69, 70, 71, 74, 87, 99, 108, 114, 123, 138, 140, 147, 148, 171, 172, 175, 181, 182, 197, 200], "float": [24, 33, 34, 35, 63, 65, 71, 80, 81, 87, 88, 96, 97, 98, 108, 114, 115, 116, 117, 123, 124, 125, 126, 137, 139, 140, 146, 149, 155, 164, 165, 171, 172, 175, 181, 182, 188, 189, 190, 191, 198, 199, 200], "extent": [24, 35, 69, 97, 116, 165], "1d": [24, 69, 87, 88, 96, 97, 99, 107, 108, 123, 125, 126, 155, 157, 171, 172, 173, 182], "movstim": 24, "win_idx": 24, "desmat": 24, "mov": [24, 25], "76": [24, 65, 146, 148, 171, 172, 191], "33475": 24, "77": [24, 65, 75, 81, 171, 191], "53275": 24, "78": [24, 65, 133, 171, 182, 193], "61975": 24, "calcul": [24, 33, 34, 35, 70, 71, 75, 76, 80, 81, 87, 96, 97, 98, 99, 100, 101, 114, 123, 125, 137, 138, 139, 146, 147, 148, 149, 156, 157, 164, 171, 172, 173, 175, 181, 182, 188, 189, 190, 198, 199, 200], "correctli": [24, 34, 81, 99, 171, 181, 182, 197, 200], "saw": [24, 33, 35, 69, 70, 71, 74, 76, 87, 88, 101, 108, 115, 116, 123, 125, 138, 146, 148, 157, 163, 164, 165, 172, 173, 188, 189, 198, 200], "cv": [24, 108, 146, 148], "dot": [24, 25, 63, 65, 70, 75, 76, 80, 88, 89, 100, 101, 107, 108, 114, 115, 137, 138, 139, 140, 148, 164, 165, 171, 174, 197, 198, 199, 200], "graph": [24, 76, 100, 117, 126, 133, 138, 175, 182, 197, 198, 200], "56": [24, 107, 126, 133, 138, 146, 155, 156, 171, 190, 191, 197, 198], "72": [24, 27, 69, 81, 89, 123, 126, 133, 146, 151, 156, 157, 171, 172, 182, 191], "65": [24, 70, 81, 83, 126, 148, 149, 155, 157, 163, 164, 171, 181, 191], "median": [24, 98, 164, 165, 198], "accord": [24, 70, 74, 80, 85, 87, 97, 98, 99, 101, 114, 125, 149, 171, 173, 175, 181, 182, 188, 190, 197], "magnitud": [24, 108, 126, 137, 149, 173, 182, 198], "ignor": [24, 35, 81, 99, 107, 108, 117, 123, 125, 126, 156, 157, 163, 164, 165, 174, 195], "maximum": [24, 33, 34, 35, 71, 74, 80, 87, 96, 98, 99, 100, 101, 103, 105, 107, 108, 115, 125, 126, 148, 149, 155, 161, 163, 181, 182, 188, 189, 190, 191], "discrimin": [24, 116, 121, 123, 124], "classifymotionfromspik": 24, "750": [24, 101, 148], "int": [24, 25, 33, 34, 35, 63, 70, 71, 74, 80, 81, 87, 88, 98, 108, 116, 117, 123, 125, 126, 140, 146, 147, 148, 149, 155, 157, 171, 172, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "regular": [24, 63, 105, 123, 146, 148, 161, 191, 199], "intend": [24, 173, 198], "ye": [24, 25, 140, 146, 147, 181], "somewhat": [24, 81, 174], "contrast": [24, 74, 81, 99, 117, 172, 175, 179, 191, 201], "quit": [24, 96, 100, 107, 123, 165, 189, 191, 200], "presenc": [24, 155, 200], "And": [24, 25, 63, 69, 71, 74, 83, 107, 137, 146, 171, 173, 189, 197], "runanalysi": 24, "050": 24, "class_set": 24, "empti": [24, 69, 71, 80, 107, 146, 172, 181], "halfwin_no": 24, "lty": 24, "leg_hw": 24, "classes_no": 24, "leg_class": 24, "color": [24, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 87, 88, 96, 97, 98, 99, 107, 108, 114, 115, 117, 124, 125, 126, 137, 139, 140, 146, 147, 148, 149, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 191, 197, 198, 199, 200, 201], "purpl": [24, 70], "motions_no": 24, "cond_acc": 24, "m_acc": 24, "store": [24, 29, 33, 34, 35, 81, 87, 88, 108, 116, 117, 123, 125, 126, 138, 140, 146, 171, 181, 188, 198], "simplifi": [24, 63, 74, 76, 81, 88, 97, 100, 144, 149, 175], "plotaccuraci": 24, "accuarci": 24, "xlim": [24, 33, 34, 35, 69, 70, 71, 74, 75, 76, 80, 87, 88, 89, 97, 98, 116, 123, 126, 138, 139, 147, 148, 149, 157, 163, 174, 175, 190, 191, 199, 200], "ylim": [24, 33, 34, 35, 69, 70, 71, 74, 75, 76, 80, 87, 88, 89, 97, 98, 115, 116, 123, 126, 139, 146, 147, 148, 149, 155, 157, 163, 174, 175, 189, 190, 191], "proport": [24, 25, 81, 96, 108, 116, 139, 147, 163, 164, 171, 172, 174, 197, 199, 200], "xtick": [24, 34, 35, 65, 69, 70, 71, 74, 107, 108, 115, 126, 140, 163, 189], "tick": [24, 33, 116, 117, 125, 188, 197, 198], "loc": [24, 69, 70, 71, 74, 76, 99, 107, 125, 139, 146, 147, 148, 149, 155, 156, 157, 164, 171, 172, 173, 181, 182, 190, 191], "job": [24, 107, 123, 140, 171, 190, 197, 199], "dash": [24, 75, 76, 146, 147, 148, 155, 164, 165, 171, 172, 182], "wors": [24, 125, 164, 198], "longer": [24, 34, 81, 148, 149, 164, 188, 189, 191], "harder": [24, 75, 126, 171, 193, 199], "clearer": [24, 65], "judgment": [24, 25, 119, 121, 167], "sensor": [24, 173, 174], "notion": [24, 74, 108, 153, 163], "Of": [24, 81, 163, 198], "contribut": [24, 63, 74, 88, 90, 97, 99, 177, 190, 193], "On": [24, 33, 76, 81, 83, 94, 101, 108, 117, 148, 163, 171, 188, 189, 201], "adjac": [24, 25, 69, 74, 87, 140, 147, 175], "unknown": [24, 25, 74, 76, 96, 163, 164, 189], "effort": [24, 96, 174, 181], "cumul": [24, 74, 116, 138, 139, 171, 188, 190], "instantan": [24, 147, 149, 181, 190], "world": [24, 33, 34, 69, 75, 81, 97, 124, 139, 161, 163, 164, 169, 171, 173, 179, 181, 186, 188, 190, 193, 199, 201], "scenario": [24, 33, 63, 89, 99, 149, 163, 182, 188, 189], "causal": [24, 39, 87, 105, 133, 144, 153, 193, 195, 201], "letter": [24, 25, 75], "paraphras": [24, 25], "built": [24, 25, 29, 88, 123, 124, 125, 126, 137, 139, 146, 153, 181, 186, 188, 201], "extrem": [24, 25, 33, 71, 80, 81, 96, 107, 163, 181, 189], "artifici": [24, 25, 33, 83, 119, 121, 140, 148, 149, 165, 186, 188], "hopefulli": [24, 25, 33, 35, 63, 69, 80, 85, 124, 125, 139, 198], "hit": [24, 25, 146, 164, 190], "roadblock": [24, 25], "somewher": [24, 25, 107, 173, 181], "optim": [24, 33, 34, 35, 39, 74, 80, 85, 97, 98, 99, 100, 101, 105, 108, 116, 119, 121, 124, 125, 126, 133, 155, 156, 157, 161, 163, 164, 165, 169, 172, 175, 177, 179, 186, 188, 189, 190, 191, 201], "neuroscientist": [24, 80, 83, 112, 121, 155, 175], "weight": [24, 34, 35, 69, 70, 71, 76, 80, 89, 99, 100, 101, 107, 108, 115, 117, 123, 125, 144, 148, 155, 163, 164, 165, 173, 188, 197, 198, 199, 200], "role": [24, 33, 81, 103, 108, 114, 133, 147, 155, 188, 193], "demo": [25, 129, 161, 165], "theta": [25, 33, 34, 35, 69, 74, 81, 96, 97, 98, 99, 100, 101, 107, 108, 114, 124, 125, 126, 146, 155, 156, 157, 174, 175, 181, 197, 198, 199, 200], "mathbf": [25, 69, 70, 71, 81, 96, 97, 98, 99, 107, 115, 123, 125, 126, 137, 138, 140], "sigma": [25, 33, 63, 65, 74, 80, 81, 97, 100, 101, 108, 114, 115, 124, 125, 126, 139, 140, 146, 164, 165, 171, 172, 173, 174, 197, 199, 200], "drift": [25, 75, 76, 140, 167, 182], "diffus": [25, 75, 76, 140, 148, 167, 172], "establish": [25, 140], "framework": [25, 71, 81, 103, 105, 107, 108, 119, 140, 144, 161, 186, 188, 191, 198], "frac": [25, 34, 63, 69, 74, 75, 76, 80, 81, 88, 89, 96, 97, 99, 101, 107, 108, 114, 115, 116, 123, 125, 126, 137, 139, 146, 147, 148, 149, 155, 163, 164, 171, 173, 174, 175, 181, 182, 189, 199], "de": [25, 89, 147, 156, 157, 177], "leakag": [25, 88], "instal": [25, 47, 78], "panda": [25, 173], "dark_background": 25, "vestibular_sign": 25, "sig": [25, 139, 140, 146, 147, 148, 155, 157], "scalar": [25, 69, 70, 71, 74, 80, 81, 88, 99, 100, 101, 107, 108, 114, 115, 116, 123, 125, 126, 137, 138, 139, 140, 163, 164, 165, 171, 173, 182, 200], "sd": [25, 107], "white": [25, 33, 87, 97, 107, 116, 124, 148, 173], "1m": 25, "linspac": [25, 33, 34, 35, 63, 65, 70, 80, 81, 87, 89, 96, 97, 99, 107, 108, 123, 124, 125, 126, 140, 146, 149, 155, 156, 157, 164, 165, 171, 172, 173, 175, 182, 190, 191, 197, 198, 199, 200], "14": [25, 27, 69, 74, 76, 80, 81, 87, 88, 96, 97, 98, 99, 100, 101, 103, 107, 108, 115, 119, 123, 124, 125, 126, 137, 139, 142, 147, 148, 149, 155, 156, 157, 165, 172, 174, 182, 188, 189, 190, 191, 197, 198, 200], "1001": 25, "exp": [25, 74, 75, 76, 80, 81, 87, 97, 107, 108, 124, 125, 126, 137, 155, 156, 157, 164, 165, 171, 173, 175, 197, 198, 199, 200], "diff": [25, 74, 87, 88, 89, 138, 146, 148, 175], "u": [25, 33, 34, 35, 63, 69, 71, 74, 80, 103, 114, 115, 119, 123, 148, 155, 156, 157, 159, 163, 173, 182, 190, 191, 193], "leaki": [25, 63, 88, 89, 133, 144, 147, 201], "append": [25, 33, 34, 35, 75, 76, 87, 88, 99, 101, 108, 123, 125, 126, 138, 146, 147, 148, 149, 155, 156, 157, 171, 172, 175, 181, 182, 200], "thr": [25, 148], "run_model": 25, "selfmot": 25, "aris": [25, 70, 125, 146, 153, 157, 165, 199], "thrshold": 25, "fool": [25, 188], "conceptu": 25, "behav": [25, 88, 139, 148, 164, 173, 175, 188, 190, 200], "alter": [25, 70, 89, 155, 188], "regim": [25, 123, 142, 146, 148, 151, 157], "itertool": [25, 70], "automat": [25, 33, 65, 119, 123, 126, 177], "generat": 25, "param": [25, 34, 137, 140, 165, 173, 174, 181, 190, 191], "map": [25, 29, 33, 34, 35, 74, 108, 137, 138, 147, 156, 171, 172, 188, 190, 191], "zip": [25, 33, 34, 35, 69, 71, 89, 96, 97, 108, 124, 125, 149, 163, 174, 175], "temp": 25, "hypothsi": 25, "pd": [25, 173], "df": [25, 74, 155, 156, 157, 173], "datafram": [25, 173], "column": [25, 33, 63, 70, 74, 81, 99, 100, 101, 107, 114, 115, 116, 123, 124, 125, 126, 163, 165, 199], "multi": [25, 125, 133, 151, 188], "panel": [25, 47, 75, 76, 108], "layout": [25, 34, 74, 75, 76, 80, 81, 146, 147, 148, 149, 163, 164, 172, 173, 175, 181], "constrained_layout": 25, "absent": 25, "present": [25, 27, 33, 35, 39, 81, 99, 107, 119, 121, 123, 124, 125, 138, 155, 165, 174, 188, 197], "mov_": 25, "uniqu": [25, 69, 76, 89, 107, 123, 125, 126, 138], "thr_": 25, "sig_": 25, "thr_n": 25, "c_n": [25, 69], "subdf0": 25, "groupbi": 25, "subdf1": 25, "im0": [25, 197], "im1": [25, 197], "4f": [25, 33, 34, 35, 81, 126, 140, 155, 188], "set_ylim": [25, 70, 71, 89, 126, 139, 149, 157, 163, 164, 171, 172, 173, 175, 181], "set_xlim": [25, 70, 71, 89, 126, 149, 163, 164, 173, 175, 181], "450": 25, "set_xlabel": [25, 74, 80, 81, 89, 107, 123, 124, 125, 126, 137, 149, 156, 157, 163, 164, 165, 171, 172, 173, 181, 182, 188, 197, 199, 200], "set_ylabel": [25, 69, 74, 80, 81, 89, 107, 123, 124, 125, 126, 137, 149, 156, 157, 163, 164, 165, 171, 172, 173, 175, 181, 182, 188, 197, 198, 199, 200], "set_facecolor": [25, 165], "grei": [25, 65, 70, 75, 76, 163, 164, 165, 172, 174], "redund": 25, "sensibl": [25, 139], "0004": 25, "d0": 25, "d1": 25, "detect": [25, 27, 174], "31": [25, 71, 74, 76, 80, 101, 114, 116, 119, 123, 125, 126, 137, 139, 148, 149, 155, 157, 165, 171, 174, 181, 188, 189, 190, 191, 197, 200], "61": [25, 75, 126, 151, 155, 171, 190, 191, 198], "roughli": [25, 107, 117, 188, 198], "likelihood": [25, 80, 92, 94, 96, 98, 99, 100, 101, 103, 105, 107, 108, 125, 126, 161, 164, 169, 171, 172, 173, 175, 190], "201": 25, "monoton": [25, 74, 81, 87, 97, 126, 148, 155, 175], "satur": [25, 123, 155], "push": 25, "larger": [25, 74, 76, 107, 108, 115, 121, 123, 124, 126, 139, 140, 163, 188, 189, 195, 198, 199, 200], "linearli": [25, 69, 76, 139, 197], "error": [25, 33, 34, 35, 47, 69, 70, 87, 89, 92, 97, 98, 99, 101, 107, 108, 116, 123, 133, 139, 140, 155, 156, 157, 164, 171, 173, 174, 177, 182, 190, 191, 200], "construct": [25, 33, 87, 88, 89, 105, 107, 123, 125, 126, 139, 140, 165], "under": [25, 33, 34, 47, 70, 74, 101, 125, 126, 146, 147, 148, 156, 157, 167, 172, 181, 182, 188], "occurr": [25, 138, 149], "variat": [25, 76, 87, 88, 115, 138, 146, 188], "probabilist": [25, 80, 81, 103, 138, 163, 174, 193], "dokka": 25, "head": [25, 69, 70, 139, 189], "39": [27, 71, 81, 88, 107, 108, 114, 115, 123, 126, 139, 146, 148, 163, 171, 173, 175, 190, 191, 197, 198, 199, 200], "neuropixel": [27, 87, 108], "700": [27, 124], "mous": [27, 108, 112, 123, 124, 125, 126, 133, 164, 182], "superior": [27, 174], "colliculu": 27, "offer": [27, 29, 85, 108], "pathwai": [27, 133], "scott": [27, 100, 103], "linderman": [27, 133], "lfp": [27, 198], "waveform": 27, "zatka": 27, "haa": 27, "carandini": 27, "harri": [27, 133], "action": [27, 65, 85, 100, 144, 146, 149, 159, 163, 164, 165, 169, 175, 177, 179, 181, 186, 188, 190, 191, 201], "576": 27, "7786": 27, "266": [27, 69], "273": 27, "s41586": [27, 184], "019": [27, 119, 133, 184], "1787": 27, "neurostar": 27, "org": [27, 45, 69, 75, 76, 83, 92, 101, 103, 108, 110, 117, 119, 123, 124, 125, 126, 133, 151, 159, 177, 184, 193, 200], "14539": 27, "000": [27, 33, 63, 116, 117, 123, 124, 125, 126, 155, 165, 198], "grate": [27, 121, 123, 124, 125, 126], "whisk": 27, "snif": 27, "tast": [27, 65, 87], "orient": [27, 33, 35, 69, 80, 81, 99, 121, 123, 124, 126, 156, 164, 199], "reddi": 27, "multidimension": [27, 99], "364": 27, "6437": 27, "eaav7893": 27, "1126": [27, 83, 133, 142, 151, 174, 177, 184], "aav7893": 27, "michaelo": [27, 119], "tsyboulski": [27, 119], "lindo": [27, 119], "184": [27, 119], "2767": [27, 119], "2778": [27, 119], "03": [27, 76, 92, 103, 119, 125, 142, 151, 157, 164, 177], "042": [27, 119, 155], "beginn": [27, 33, 65, 159], "novel": [27, 80, 81], "excitatori": [27, 76, 88, 89, 151, 153, 157], "vip": 27, "sst": 27, "lm": [27, 155], "focus": [27, 69, 70, 81, 87, 101, 129, 146, 159, 193], "dataload": 27, "sdk": 27, "atla": 27, "swdb": 27, "databook": 27, "marina": 27, "garret": 27, "iryna": 27, "yavorska": 27, "doug": 27, "ollerenshaw": 27, "garrett": 27, "2023": 27, "circuit": [27, 69, 103, 124, 148, 151], "www": [27, 69, 75, 76, 92, 110, 119, 123, 124, 125, 126, 133, 159, 177, 200], "1101": [27, 92, 119, 123, 124, 125, 126, 151, 184], "02": [27, 63, 65, 74, 76, 108, 125, 133, 138, 139, 140, 146, 148, 151, 155, 156, 157, 163, 164, 172, 175], "528085v2": 27, "feulner": 29, "clopath": 29, "biomodel": 29, "biolog": [29, 35, 39, 71, 75, 76, 88, 119, 121, 124, 133, 142, 144, 146, 147, 148, 149, 153, 155, 188, 200, 201], "biomed": [29, 133, 193, 197], "host": [29, 36, 37, 38, 75, 76], "vast": 29, "pharmaceut": 29, "modeldb": 29, "locat": [29, 33, 35, 80, 81, 89, 97, 148, 155, 165, 173, 174, 175, 179, 181, 182, 190, 191], "retriev": [29, 33, 34, 35, 83, 146, 147, 148, 149, 155, 157], "entri": [29, 81, 87, 89, 107, 172, 199], "sourc": [29, 31, 35, 80, 81, 100, 139, 147, 164, 174, 182, 200], "citat": 29, "publish": [29, 75, 76, 193], "collabor": [29, 36, 37, 38, 46, 81], "crcn": 29, "websit": [29, 45, 124], "marketplac": 29, "forum": [29, 119], "eegbas": 29, "storag": [29, 63, 88], "manag": [29, 69, 149], "eeg": [29, 76, 80, 172, 173, 195, 198], "metadata": 29, "document": [29, 70, 108, 117, 123, 124, 125, 126, 164, 167], "electrophysiolog": [29, 146, 155], "incf": 29, "endors": 29, "nitrc": 29, "collaboratori": 29, "award": 29, "web": [29, 92, 188], "comprehens": [29, 63], "ever": [29, 47, 87, 88, 89, 90, 129, 149, 164, 174, 188, 189], "expand": [29, 33, 34, 87, 123, 144], "scope": 29, "neuroinformat": 29, "figshar": 29, "openli": 29, "neurovault": 29, "public": [29, 107, 129, 193], "unthreshold": 29, "parcel": 29, "atlas": 29, "mri": [29, 119], "pet": 29, "knowledgespac": 29, "global": [29, 76, 117, 164, 172, 181, 182, 188], "driven": [29, 74, 88, 133, 142, 146, 148, 149, 155, 201], "encyclopedia": 29, "bonu": [31, 35, 87, 112, 121, 140, 144, 156, 164, 169], "autoencod": [31, 112], "pip3": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "vibecheck": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "datatop": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "datatopscontentreviewcontain": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "content_review": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "notebook_sect": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "str": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "prompt": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "pmyvdlilci": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "api": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "east": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "amazonaw": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "klab": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "neuromatch_cn": [31, 32, 33, 34, 35, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "user_kei": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "y1x3mpx5": [31, 32, 33, 34, 35, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "feedback_prefix": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "bonus_autoencoders_intro": 31, "31merror": 31, "account": [31, 47, 75, 80, 81, 94, 101, 107, 139, 140, 149, 151, 163, 164, 167, 173, 174, 182], "packag": [31, 33, 63, 69, 81, 88, 123, 126, 137, 155, 174, 198, 199], "conflict": [31, 100], "jupyt": [31, 108, 117, 137], "client": 31, "incompat": 31, "0m": 31, "31m": 31, "_video": [31, 32, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 129, 130, 135, 136, 144, 145, 153, 154, 161, 162, 169, 170, 179, 180, 186, 187, 195, 196], "bonus_autoencoders_outro": 32, "marco": [33, 34, 35, 63, 65], "brigham": [33, 34, 35, 63, 65], "ccnss": [33, 34, 35, 63, 65], "itzel": [33, 34, 35, 173, 181], "olivo": [33, 34, 35, 173, 181], "karen": [33, 34, 35], "schroeder": [33, 34, 35], "karolina": [33, 34, 35, 63, 65, 137, 138, 165, 181, 182], "stosio": [33, 34, 35, 63, 65, 137, 138, 165, 181, 182], "spiro": [33, 34, 35, 63, 65, 74, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 191, 197, 198, 199, 200], "chavli": [33, 34, 35, 63, 65, 74, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 191, 197, 198, 199, 200], "robust": [33, 34, 35, 83, 117], "famili": [33, 70, 87], "auxiliari": [33, 173], "primari": [33, 81, 123, 125, 133], "compress": [33, 34, 35, 112], "throw": 33, "awai": [33, 35, 71, 81, 88, 139, 148, 163, 164, 174, 190, 199], "fictiti": 33, "cognit": [33, 34, 35, 83, 92, 103, 110, 119, 139, 142, 151, 174], "bundl": 33, "elabor": 33, "guess": [33, 80, 81, 98, 107, 140, 149, 155, 164, 171, 173, 174, 188, 190], "occlud": [33, 35], "recov": [33, 35, 70, 81, 148, 157, 165, 173, 175, 182, 189, 198, 200], "handwritten": [33, 116], "digit": [33, 34, 74, 97, 116, 117, 123, 125, 126, 140], "bottleneck": [33, 34, 35], "layer": [33, 34, 35, 107, 108, 121, 123, 142], "enforc": [33, 123, 126], "fewer": [33, 101, 116, 123, 124, 171, 200], "enabl": [33, 34, 47, 65, 69, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 108, 114, 115, 116, 123, 126, 137, 138, 139, 146, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 181, 182, 188, 189, 197, 198, 199, 200], "roadmap": 33, "typic": [33, 34, 85, 87, 94, 123, 124, 126, 129, 137, 146, 147, 148, 149, 163, 165, 174, 175, 188, 195], "architectur": [33, 35, 121, 123, 124, 125, 191], "extend": [33, 35, 71, 74, 75, 76, 99, 107, 123, 148, 153, 155, 156, 163, 164, 171, 182, 201], "acquaint": 33, "princip": [33, 112, 116, 117, 137], "non": [33, 34, 35, 70, 76, 87, 88, 89, 108, 112, 121, 123, 124, 125, 137, 148, 153, 155, 164, 173, 182, 193], "factor": [33, 71, 74, 75, 76, 87, 88, 89, 97, 110, 126, 133, 137, 147, 155, 164, 173, 190, 191], "hidden": [33, 34, 39, 65, 80, 81, 87, 103, 108, 123, 125, 126, 133, 161, 165, 169, 173, 174, 175, 179, 181, 186, 188, 199, 201], "inspect": [33, 34, 35, 47, 71, 99, 156, 181, 182, 199], "bonus_autoencoders_t1": 33, "torch": [33, 34, 35, 123, 124, 125, 126], "fetch_openml": [33, 34, 35, 116, 117], "log": [33, 34, 35, 47, 63, 65, 68, 70, 71, 74, 75, 76, 79, 80, 81, 86, 87, 88, 89, 92, 95, 96, 97, 98, 99, 100, 101, 106, 107, 108, 113, 114, 115, 116, 117, 122, 123, 124, 125, 126, 130, 131, 136, 137, 138, 139, 140, 145, 146, 147, 148, 149, 154, 155, 156, 157, 162, 163, 164, 170, 171, 172, 173, 174, 175, 180, 181, 182, 187, 188, 189, 190, 191, 196, 197, 198, 199, 200], "getlogg": [33, 34, 35, 63, 65, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "font_manag": [33, 34, 35, 63, 65, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "disabl": [33, 34, 35, 63, 65, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "config": [33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "inlinebackend": [33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "figure_format": [33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "retina": [33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "githubusercont": [33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "neuromatchacademi": [33, 34, 35, 42, 45, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "nma2020": [33, 34, 35, 165, 171, 172, 175], "mplstyle": [33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "fig_w": [33, 65, 74], "fig_h": [33, 65, 74], "rcparam": [33, 65, 70, 71, 74, 81], "downloadmnist": [33, 34, 35], "tensor": [33, 34, 35, 123, 124, 125, 126, 133, 175], "60000": [33, 34, 35], "28": [33, 34, 35, 63, 69, 71, 76, 89, 92, 96, 98, 107, 114, 116, 119, 123, 124, 125, 126, 137, 138, 139, 147, 148, 149, 155, 156, 157, 165, 171, 173, 174, 177, 181, 182, 188, 189, 191, 197, 198, 199, 200], "10000": [33, 34, 35, 65, 71, 87, 138, 139, 147, 181, 198, 199, 200], "mnist_784": [33, 34, 35, 116, 117], "return_x_i": [33, 34, 35], "as_fram": [33, 34, 35, 116, 117], "trunk": [33, 34, 35], "n_train": [33, 34, 35, 123, 125, 126], "n_test": [33, 34, 35, 126], "train_idx": [33, 34, 35], "test_idx": [33, 34, 35], "from_numpi": [33, 34, 35, 124, 125, 126], "astyp": [33, 34, 35, 71, 124, 125, 126, 146, 148, 149, 164, 181], "float32": [33, 34, 35, 87, 123, 124, 125, 126], "init_weights_kaiming_uniform": [33, 34, 35], "pytorch": [33, 34, 35, 121, 126], "kaim": [33, 34, 35], "uniform": [33, 34, 35, 63, 74, 81, 89, 96, 97, 98, 99, 100, 101, 116, 164, 174, 181, 188, 190, 191], "modul": [33, 34, 35, 36, 37, 38, 47, 65, 87, 101, 107, 114, 115, 116, 117, 123, 124, 125, 126, 140, 146, 147, 148, 149, 151, 155, 156, 157, 172, 198, 201], "noth": [33, 34, 35, 65, 80, 81, 114, 115, 116, 117, 123, 125, 126, 137, 148, 164, 182, 197, 198, 199, 200], "isinst": [33, 34, 35, 69, 155], "init": [33, 34, 35, 123, 126, 155, 156, 157, 182], "kaiming_uniform_": [33, 34, 35], "init_weights_kaiming_norm": [33, 34, 35], "kaiming_normal_": [33, 34, 35], "get_layer_weight": [33, 34, 35], "learnabl": [33, 34, 35], "item": [33, 34, 35, 87, 107, 108, 123, 125, 126, 149, 155, 175, 181], "detach": [33, 34, 35, 124, 125, 126], "eval_ms": [33, 34, 35], "y_pred": [33, 34, 35, 108, 126], "y_true": [33, 34, 35, 98], "squar": [33, 34, 35, 63, 69, 70, 80, 97, 98, 100, 101, 107, 114, 115, 117, 123, 126, 147, 163, 164, 174, 191], "mse": [33, 34, 35, 97, 98, 100, 101, 123, 126, 164, 174, 182], "no_grad": [33, 34, 35], "mseloss": [33, 34, 35, 123, 126], "eval_bc": [33, 34, 35], "entropi": [33, 34, 35, 125, 126], "bce": [33, 34, 35], "bceloss": [33, 34, 35, 125], "plot_weights_ab": 33, "encoder_w_a": 33, "encoder_w_b": 33, "decoder_w_a": 33, "decoder_w_b": 33, "label_a": 33, "label_b": 33, "bins_encod": 33, "bins_decod": 33, "row": [33, 34, 35, 63, 65, 70, 74, 81, 87, 99, 107, 116, 117, 123, 124, 125, 126, 139, 147, 148, 149, 163, 165, 172, 175, 181, 191, 199], "histogram": [33, 80, 81, 87, 88, 97, 139, 140, 146, 147, 149, 173, 181], "checkpoint": [33, 35], "string": [33, 34, 35, 107, 108, 125, 137, 165, 181, 188], "num": [33, 63, 190, 191], "32": [33, 34, 35, 65, 69, 87, 99, 100, 101, 107, 108, 116, 119, 123, 125, 126, 137, 148, 155, 156, 157, 163, 165, 171, 174, 175, 181, 188, 189, 190, 191, 197, 200], "221": [33, 148], "hist": [33, 65, 80, 81, 87, 89, 97, 98, 138, 139, 140, 146, 151, 173, 181], "flatten": [33, 99, 125, 126, 163, 172, 175, 197, 198, 199, 200], "222": [33, 157], "223": [33, 148], "224": [33, 148, 157], "tight_layout": [33, 34, 35, 65, 99, 107, 108, 116, 123, 125, 126, 146, 148, 149, 156, 157, 173, 181, 182, 188, 198, 199], "plot_row": [33, 34, 35], "show_n": [33, 34, 35], "image_shap": [33, 34, 35], "randomli": [33, 34, 35, 80, 81, 98, 107, 116, 123, 126, 139, 140, 172, 175, 188, 189, 190, 191, 195, 197], "tupl": [33, 34, 35, 87, 108, 125, 126, 137, 155, 165, 200], "items_idx": [33, 34, 35], "enumer": [33, 34, 35, 65, 69, 70, 75, 96, 97, 98, 101, 107, 124, 125, 126, 137, 139, 140, 171, 174, 175, 181, 189, 191, 198, 199, 200], "ndim": [33, 34, 35, 99, 100, 101, 124, 139, 140, 174, 190, 191], "expand_dim": [33, 34, 35, 197, 198], "image_idx": [33, 34, 35], "imshow": [33, 34, 35, 65, 69, 81, 97, 108, 116, 123, 124, 125, 126, 165, 174, 188, 190, 191, 197, 198, 199, 200], "cmap": [33, 34, 35, 65, 69, 71, 74, 97, 99, 107, 116, 117, 123, 124, 125, 126, 137, 163, 164, 190, 191, 197, 198, 199, 200], "grai": [33, 34, 35, 124, 156, 157, 173, 182, 191], "vmin": [33, 34, 35, 69, 71, 97, 116, 123, 124, 125, 126, 163, 197, 198, 199, 200], "vmax": [33, 34, 35, 69, 71, 97, 116, 123, 124, 125, 126, 163, 197, 198, 199, 200], "xy_lim": [33, 34, 35], "minimum": [33, 34, 35, 69, 74, 87, 96, 107, 108, 123, 146, 155, 163, 182], "x_min": [33, 34, 35], "x_max": [33, 34, 35], "finfo": [33, 34, 35, 155, 165], "ep": [33, 34, 35, 81, 155, 165, 198, 199], "plot_gen": [33, 34, 35], "decoder_fn": [33, 34, 35], "n_row": [33, 34, 35], "16": [33, 34, 35, 63, 65, 69, 70, 74, 76, 80, 81, 87, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 119, 123, 124, 125, 126, 137, 138, 139, 147, 148, 149, 155, 156, 157, 163, 165, 171, 172, 174, 175, 181, 182, 188, 189, 190, 191, 193, 198, 200], "grid": [33, 34, 35, 65, 69, 70, 71, 74, 81, 96, 99, 108, 124, 125, 126, 137, 139, 146, 156, 190, 191], "coordin": [33, 34, 35, 41, 65, 69, 70, 80, 137, 156, 157, 164, 174], "dx": [33, 34, 35, 70, 74, 76, 137, 155, 156, 157, 164], "canva": [33, 34, 35, 69], "get_cmap": [33, 34, 35, 97, 99, 175], "latent_i": [33, 34, 35], "latent_x": [33, 34, 35], "dtype": [33, 34, 35, 81, 87, 108, 123, 124, 125, 126, 137, 155, 172, 174, 175, 181], "x_decod": [33, 34, 35], "plot_lat": [33, 34, 35], "500": [33, 34, 35, 65, 80, 101, 126, 133, 138, 139, 140, 142, 146, 148, 171, 173, 190, 191], "fontdict": [33, 34, 35], "xy_label": [33, 34, 35], "bold": [33, 34, 35, 80, 94, 148, 149, 157, 197, 198, 199, 200], "tab10": [33, 34, 35, 117, 175], "my_x": [33, 34, 35], "my_i": [33, 34, 35], "horizontalalign": [33, 34, 35, 71, 148, 156, 157], "verticalalign": [33, 34, 35, 71, 148, 156, 157], "z_1": [33, 34, 35, 125], "z_2": [33, 34, 35, 125], "plot_latent_gen": [33, 34, 35], "horizont": [33, 34, 35, 70, 74, 76, 80, 81, 87, 108, 114, 124, 140], "lsit": 33, "fig": [33, 34, 35, 69, 70, 71, 74, 75, 76, 80, 81, 88, 89, 96, 97, 98, 99, 100, 108, 114, 115, 116, 123, 124, 125, 126, 137, 139, 140, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "suptitl": [33, 34, 35, 70, 80, 81, 123, 124, 125, 126, 137, 182, 197, 198, 199, 200], "add_subplot": [33, 34, 35, 69, 74, 114, 115, 165, 173], "121": [33, 34, 35, 96, 97, 98, 99, 103, 116, 126, 146, 148, 156, 157, 175], "122": [33, 34, 35, 116, 126, 146, 148, 149, 156, 157, 175], "plot_latent_ab": [33, 35], "x1": [33, 35, 74, 99, 137, 140], "x2": [33, 35, 99, 137, 140], "selected_idx": [33, 34, 35], "title_a": [33, 35], "title_b": [33, 35], "index": [33, 35, 81, 87, 89, 107, 115, 116, 124, 125, 126, 140, 175, 191, 197, 198, 199, 200], "s2": [33, 34, 35], "boolean": [33, 34, 35, 107, 116, 123, 124, 125, 126, 137, 146, 147, 148, 149, 155, 157, 174, 188, 189], "3d": [33, 35, 69, 70, 71, 74, 99, 117, 175], "spheric": [33, 35], "phi": [33, 34, 35, 123, 124, 125, 126], "runsgd": [33, 34, 35], "net": [33, 34, 35, 105, 119, 123, 125, 126, 171], "input_train": [33, 34, 35], "input_test": [33, 34, 35], "n_epoch": [33, 34, 35, 123, 125, 126], "batch_siz": [33, 34, 35, 125], "verbos": [33, 34, 35, 171], "stochast": [33, 34, 35, 63, 94, 103, 125, 138, 146, 173, 174, 181, 182, 188, 189, 201], "gradient": [33, 34, 35, 81, 119, 124, 125, 126, 139], "descent": [33, 34, 35, 81, 100, 125, 126], "adam": [33, 34, 35, 133], "opoch": [33, 34, 35], "minibatch": [33, 34, 35, 125], "mini": [33, 34, 35, 123, 125], "batch": [33, 34, 35, 119, 123, 125, 126, 172, 174], "loss_fn": [33, 34, 35, 123, 125, 126], "elif": [33, 34, 35, 70, 71, 74, 81, 83, 92, 103, 107, 108, 123, 124, 125, 126, 133, 138, 146, 147, 148, 149, 151, 155, 164, 171, 174, 181, 182, 190, 191], "sgd": [33, 34, 35, 125, 126], "placehold": [33, 34, 35, 123, 125, 126], "track_loss": [33, 34, 35, 125], "epoch": [33, 34, 35, 123, 125, 126, 175], "shuffle_idx": [33, 34, 35], "permut": [33, 34, 35], "output_train": [33, 34, 35], "zero_grad": [33, 34, 35, 123, 125, 126], "backward": [33, 34, 35, 123, 125, 126, 174, 188], "loss_epoch": [33, 34, 35], "loss_train": [33, 34, 35], "output_test": [33, 34, 35], "loss_test": [33, 34, 35, 126], "loss_ms": [33, 34, 35], "nmse": [33, 34, 35], "loss_bc": [33, 34, 35], "ceil": [33, 34, 35, 70, 97, 175], "x_rang": [33, 34, 35, 89], "c0": [33, 34, 35, 63, 65, 81, 99, 188], "_intro_video": [33, 85, 94, 165], "_autoencoders_video": 33, "introduc": [33, 34, 35, 63, 71, 74, 75, 76, 81, 89, 105, 108, 112, 121, 129, 138, 144, 146, 147, 148, 149, 153, 155, 156, 161, 163, 164, 171, 174, 175, 181, 191, 195, 197, 199, 200], "decompress": [33, 34, 35], "character": [33, 103, 155, 156, 181], "trigger": [33, 103, 105, 107], "backpropag": [33, 119, 123], "adjust": [33, 34, 35, 63, 65, 69, 71, 80, 87, 108, 137, 173, 181, 188, 200], "unseen": [33, 35, 108, 126], "fulli": [33, 34, 35, 69, 70, 81, 99, 103, 121, 124, 157, 163, 181, 191, 198], "aan": 33, "due": [33, 34, 45, 65, 69, 75, 87, 88, 123, 133, 144, 148, 165, 174, 188, 189, 198, 200], "stretch": [33, 137], "28x28": [33, 116], "pixel": [33, 35, 69, 112, 116, 124, 125, 126, 174], "grayscal": [33, 116, 124, 125], "uncom": [33, 34, 35, 70, 81, 124, 140, 190], "255": [33, 34, 35, 116], "rescal": [33, 138, 174], "favor": [33, 171], "input_s": [33, 34, 35], "prod": [33, 34, 35, 125, 126], "test_selected_idx": [33, 34, 35], "train_selected_idx": [33, 34, 35], "bottom": [33, 35, 41, 69, 70, 71, 74, 75, 76, 81, 116, 124, 125, 148, 149, 156, 157, 163, 164, 171, 181, 182, 190, 191, 197, 198, 201], "w1d5": [33, 125, 195], "overlaid": 33, "overlai": [33, 69, 174, 175], "pca1": 33, "pca2": 33, "Their": [33, 197], "usag": [33, 148, 198], "straightforward": [33, 140, 148], "shown": [33, 65, 74, 81, 107, 123, 124, 138, 146, 149, 157, 171, 181, 182, 188, 197, 198], "truncat": [33, 116, 117], "svd": [33, 197, 198, 199, 200], "truncatedsvd": 33, "n_compon": [33, 117, 125, 172, 175], "svd_latent_train": 33, "svd_latent_test": 33, "svd_reconstruction_train": 33, "inverse_transform": 33, "svd_reconstruction_test": 33, "obtain": [33, 35, 63, 74, 80, 87, 96, 99, 107, 108, 123, 146, 147, 148, 155, 157, 164, 174, 181, 182, 188, 190, 191, 197, 199, 200], "todo": [33, 34, 63, 65, 69, 71, 74, 76, 80, 81, 87, 96, 97, 98, 99, 100, 101, 108, 114, 115, 116, 117, 124, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 171, 174, 188, 189, 190, 191, 197, 198, 199, 200], "rais": [33, 34, 35, 63, 65, 69, 71, 74, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "notimplementederror": [33, 34, 35, 63, 65, 69, 71, 74, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "make_design_matrix": [33, 99, 100, 101, 107], "pca_latent_test": 33, "_visualize_pca_latent_space_exercis": 33, "similarli": [33, 35, 70, 74, 125, 148, 149, 157, 172, 182], "recogniz": 33, "components_": 33, "colormap": [33, 137, 165], "sign": [33, 47, 70, 74, 107, 115, 124, 140, 155, 157, 171], "thick": [33, 155], "thin": 33, "indistinguish": [33, 190], "confus": [33, 108, 148, 164, 174], "pca_compon": 33, "pca_output_test": 33, "shallow": [33, 34, 119, 123], "program": [33, 35, 177, 182, 188], "oop": [33, 35], "w3d4": [33, 35, 121, 144], "equival": [33, 63, 70, 74, 80, 87, 89, 107, 123, 163, 164, 165, 171], "deepnetrelu": [33, 123, 126], "sequenti": [33, 34, 35, 133, 190], "n_input": [33, 123, 126], "n_hidden": [33, 123, 126], "n_output": 33, "hyper": 33, "nielsen": [33, 119], "excel": [33, 115, 124], "ian": 33, "goodfellow": 33, "yoshua": 33, "bengio": [33, 119], "aaron": 33, "courvil": 33, "coverag": 33, "momentum": [33, 119, 123, 125, 126], "decai": [33, 71, 76, 87, 139, 148, 149, 155, 157, 188], "smith": [33, 177], "rectifi": [33, 123, 124, 155], "encoding_dim": 33, "sigmoid": [33, 34, 35, 74, 123, 125, 155, 156, 197, 198, 199, 200], "compat": 33, "Such": [33, 35, 74, 85, 124, 125, 137, 139, 148, 153, 157], "finit": [33, 74, 80, 87, 98, 182], "addition": [33, 114, 124, 126, 140, 147, 164, 197], "greater": [33, 71, 80, 123, 163], "input_shap": 33, "encoding_s": [33, 34, 35], "insert": [33, 65, 81, 88, 89, 117, 138, 139, 140, 165, 171, 172, 175, 182, 197, 198, 199, 200], "in_featur": 33, "784": [33, 34, 35, 116], "out_featur": 33, "bia": [33, 35, 81, 96, 97, 98, 99, 101, 107, 108, 123, 124, 125, 126], "_design_ann_autoencoder_exercis": 33, "illustr": [33, 35, 71, 74, 75, 76, 89, 94, 96, 100, 115, 124, 126, 146, 148, 159, 171, 190], "hat": [33, 81, 96, 97, 98, 99, 100, 101, 107, 108, 115, 116, 164, 173, 174, 182, 200], "64": [33, 34, 63, 81, 89, 124, 125, 126, 133, 155, 177, 181, 182, 190, 191], "middl": [33, 35, 75, 76, 89, 124, 156, 163, 164, 191], "priorit": [33, 184], "penal": 33, "gentl": 33, "quadrat": [33, 96], "rise": [33, 81, 88, 89, 147], "dramat": [33, 157], "dark": [33, 81, 164], "wherea": [33, 108, 124, 140, 148, 149, 174], "verifi": [33, 35, 47, 89, 155, 157], "subtl": [33, 123, 181], "converg": [33, 108, 123, 139, 155, 156, 157, 173, 188, 199], "retrain": [33, 101, 108], "accentu": 33, "opt": [33, 69, 74, 81, 123, 126, 137, 155, 156, 157, 174, 182, 198, 199], "prelu": [33, 34, 35], "wiggl": 33, "latent_test": [33, 34, 35], "wise": [33, 69, 87, 165, 175, 181, 197, 198, 199, 200], "capac": [33, 34], "oper": [33, 34, 70, 123, 124, 125, 126, 139, 140, 165, 181, 190, 193], "successfulli": [33, 34, 148, 175], "despit": [33, 45, 71, 174, 189, 197], "charact": 33, "advantag": [33, 34, 81, 101, 124, 191], "pattern": [33, 34, 75, 88, 92, 94, 99, 100, 108, 119, 123, 133, 140, 144, 146, 148, 149, 151, 163, 171, 173, 174, 179, 189, 197], "richer": [33, 137, 199], "tackl": [33, 69, 105, 175, 190], "_wrapup_video": [33, 34, 35], "default": [33, 63, 70, 71, 80, 81, 87, 108, 123, 124, 125, 126, 146, 148, 155, 156, 157, 173, 174, 190, 191], "rng": [33, 63, 81, 174], "manual_se": [33, 123, 125, 126], "afterward": [33, 63, 165, 188], "success": [33, 96, 175, 181, 188], "rai": 33, "recal": [33, 80, 81, 89, 97, 99, 108, 114, 116, 124, 126, 157, 171, 174, 188, 189, 190, 191, 197, 199], "sqrt": [33, 34, 35, 63, 69, 80, 97, 114, 115, 116, 125, 137, 146, 147, 148, 155, 157, 163, 164, 171, 172, 173, 182], "fan_in": 33, "increment": [33, 63, 65, 146, 147, 148, 149, 156, 157], "central": [33, 80, 142, 164, 195], "theorem": [33, 76, 80, 147, 171, 177], "clt": 33, "independ": [33, 74, 81, 88, 96, 97, 98, 99, 101, 108, 110, 124, 138, 139, 147, 148, 163, 164, 165, 171, 172, 174, 175], "inter": [33, 85, 88, 89, 138, 146, 147, 148, 188], "collaps": [33, 34, 87], "unchang": [33, 74, 114, 163], "bias": [33, 81, 101, 123, 125, 126, 171, 195], "torch_se": 33, "reset": [33, 35, 63, 65, 76, 88, 146, 147, 148, 149, 188], "encoder_w_init": 33, "encoder_b_init": 33, "decoder_w_init": 33, "decoder_b_init": 33, "encoder_w_train": 33, "encoder_b_train": 33, "decoder_w_train": 33, "decoder_b_train": 33, "popular": [33, 88, 108, 139, 189], "mathcal": [33, 63, 65, 74, 76, 80, 81, 97, 101, 108, 114, 126, 164, 171, 172, 173, 174, 197], "fan": 33, "_in": 33, "mu": [33, 65, 80, 81, 97, 125, 138, 139, 146, 148, 164, 165, 171, 172, 173, 174, 189], "backprop": 33, "feedforward": [33, 155, 177], "delv": [33, 71, 74, 75, 105], "surpass": 33, "imagenet": [33, 124], "_choosing_weight_initialization_bonus_exercis": 33, "proce": [33, 35, 188], "sk": 33, "furthest": 33, "apart": [33, 164], "shift": [33, 74, 119, 124, 125, 126, 140, 157, 173, 188], "nmf_latent_test": 33, "nmf_compon": 33, "nmf_output_test": 33, "sphere": [34, 35], "geometri": [34, 114, 115, 133], "degre": [34, 35, 69, 80, 81, 99, 100, 101, 114, 123, 124, 125, 126, 139, 140, 142, 147, 164], "freedom": 34, "plotli": 34, "bonus_autoencoders_t2": 34, "graph_object": 34, "print_parameter_count": 34, "params_n": 34, "layer_idx": 34, "params_layer_n": 34, "ntotal": 34, "sampl": [34, 35, 65, 74, 81, 88, 89, 96, 97, 98, 99, 100, 101, 116, 117, 123, 124, 125, 126, 139, 140, 147, 149, 155, 156, 157, 164, 165, 171, 172, 173, 175, 189, 190, 191, 193, 200], "loss": [34, 35, 70, 119, 125, 163], "to_s2": [34, 35], "pi": [34, 35, 63, 70, 74, 76, 80, 81, 97, 101, 114, 115, 116, 124, 125, 126, 164, 171, 173, 174, 182, 188, 189, 197, 198, 199, 200], "speric": [34, 35], "arcco": [34, 35, 115, 116], "arctan2": [34, 35], "to_u3": [34, 35], "sin": [34, 35, 63, 70, 74, 76, 124, 125, 126, 173, 182, 197, 198, 199, 200], "co": [34, 35, 69, 70, 74, 76, 107, 124, 125, 126, 197, 198, 199, 200], "varphi": [34, 35], "plot_latent_3d": 34, "show_text": 34, "marker": [34, 63, 65, 75, 76, 107, 108, 171, 173, 174, 175, 190, 191], "margin": [34, 70, 108, 114, 172, 175, 177], "scene": [34, 119, 123, 124, 126], "xaxi": [34, 69, 70, 163, 181, 188, 197, 198], "showspik": 34, "z1": 34, "yaxi": [34, 69, 70, 107, 163, 173, 197, 198], "z2": 34, "zaxi": 34, "z3": 34, "t10": 34, "idx": [34, 35, 87, 126, 146, 164, 165, 181, 191, 198, 199, 200], "trace": [34, 63, 74, 88, 171, 174], "scatter3d": 34, "textfont": 34, "hovermod": 34, "hoverinfo": 34, "opac": 34, "normalizelay": 34, "l2": [34, 35, 105, 108, 126], "inherit": [34, 35], "__init__": [34, 35, 65, 69, 81, 123, 124, 125, 126, 137, 181, 182, 188, 190, 191], "super": [34, 35, 69, 123, 124, 125, 126, 182, 188, 193], "dim": [34, 35, 125, 126, 174], "_extensions_video": 34, "leverag": [34, 47, 190, 200], "capabl": [34, 35, 80, 89, 123, 125, 139, 189], "layerwis": 34, "depthwis": 34, "392": 34, "aim": [34, 83, 96, 126, 189], "trainabl": 34, "doubl": [34, 65, 69, 87, 100], "halv": 34, "667k": 34, "333k": 34, "diminish": [34, 149, 188], "2x": [34, 74, 96], "3x": 34, "particularli": [34, 81, 105, 123, 124, 164], "drove": 34, "revolut": 34, "n_l": 34, "fill": [34, 35, 39, 45, 63, 65, 69, 71, 80, 81, 87, 88, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 125, 126, 137, 146, 147, 149, 155, 163, 165, 171, 173, 174, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "_build_deeper_autoencoder_exercis": 34, "128": [34, 35, 198], "skew": [34, 164], "lean": 34, "recogn": [34, 125], "spread": [34, 80, 98, 114, 139, 164], "z_3": 34, "indefinit": [34, 74], "eventu": [34, 89, 155, 156, 171, 182, 189], "divid": [34, 63, 69, 74, 76, 101, 123, 140, 146, 147, 148, 156, 163, 171, 182, 197, 198, 199, 200], "l_2": 34, "longmapsto": 34, "s_1": [34, 172], "s_3": 34, "_2": [34, 69, 71, 123, 137, 140], "radiu": 34, "custom": [34, 126, 200], "_deep_autoencoder_with_latent_spherical_space_exercis": 34, "arctan": 34, "angl": [34, 69, 70, 114, 123, 124, 125, 126, 156, 157], "un": [34, 89, 172], "unfold": 34, "deal": [34, 63, 65, 75, 76, 94, 96, 97, 163, 164], "sophist": [34, 123, 189, 197, 199, 200], "8m": [34, 107], "equip": [35, 149], "encount": [35, 69, 70, 71, 74, 80, 99, 129, 153, 161, 163, 175, 198, 199], "evolv": [35, 65, 71, 129, 137, 139, 140, 149, 155, 156, 157, 172, 174, 182, 188], "bonus_autoencoders_t3": 35, "os": [35, 107, 108, 123, 124, 125, 126, 174], "ndimag": [35, 126], "s_2": 35, "out_train": 35, "out_test": [35, 126], "different_output": 35, "batches_out": 35, "batch_idx": 35, "image_occlus": 35, "quadrant": [35, 76, 115, 116], "image_rot": 35, "deg": [35, 139, 147], "my_deg": 35, "prefilt": 35, "autoencoderclass": 35, "activatino": 35, "enc1": 35, "enc1_f": 35, "enc2": 35, "enc2_f": 35, "enc3": 35, "enc3_f": 35, "dec1": 35, "dec1_f": 35, "dec2": 35, "dec2_f": 35, "dec3": 35, "dec3_f": 35, "pass": [35, 69, 74, 107, 108, 123, 125, 126, 146, 148, 155, 156, 157, 174, 175, 181, 182, 191, 197, 200], "save_checkpoint": 35, "filenam": [35, 69, 124, 126], "save": [35, 46, 88, 99, 107, 117, 123, 125, 126, 175, 188, 191], "model_state_dict": 35, "state_dict": [35, 188], "optimizer_state_dict": 35, "pt": [35, 125, 139], "load_checkpoint": 35, "local": [35, 41, 46, 69, 74, 76, 81, 87, 88, 103, 107, 117, 123, 124, 125, 126, 133, 137, 151, 155, 156, 157, 189], "file": [35, 69, 81, 107, 123, 126, 137, 142, 155, 174], "path": [35, 107, 108, 123, 124, 125, 126, 174, 193], "isfil": [35, 107, 108, 123, 124, 125, 126, 174], "wget": 35, "reset_checkpoint": 35, "load_state_dict": 35, "_applications_video": 35, "test_subset_idx": 35, "onto": [35, 70, 112, 116, 125, 126, 131, 138, 189], "lengthi": 35, "ident": [35, 70, 81, 116, 126, 148, 149, 157, 165, 171, 174, 188], "filename_path": 35, "eval": [35, 74, 108, 115, 116, 157], "repo": 35, "3rd": 35, "bellow": 35, "root": [35, 69, 74, 97, 147, 155, 156, 157, 201], "mpbrigham": 35, "colaboratori": 35, "master": [35, 63, 69, 184, 193, 197, 198, 199, 200], "ae_6h_prelu_bce_adam_25e_32b": 35, "_s2": 35, "abil": [35, 81, 89, 107, 121, 124, 172, 190, 191, 198], "invari": [35, 89, 124, 182, 193], "latent_test_ref": 35, "clean": [35, 63, 114, 174, 188], "noise_factor": 35, "input_train_noisi": 35, "input_test_noisi": 35, "output_test_noisi": 35, "latent_test_noisi": 35, "signific": [35, 116, 198, 200], "regener": 35, "denois": 35, "caus": [35, 70, 83, 108, 144, 148, 153, 165, 173, 182, 188, 193, 197, 199, 200], "compos": [35, 81, 87, 89, 155, 156, 188], "characterist": [35, 87], "adapt": [35, 92, 103, 123, 133, 177, 191], "partial": [35, 97, 123, 181], "input_train_mask": 35, "input_test_mask": 35, "output_test_mask": 35, "latent_test_mask": 35, "arguabl": [35, 94], "input_train_rot": 35, "90": [35, 65, 69, 75, 81, 114, 116, 124, 125, 151, 171, 173, 189, 191, 197, 198], "input_test_rot": 35, "output_test_rot": 35, "latent_test_rot": 35, "melt": 35, "my_input_train": 35, "my_input_test": 35, "my_y_test": 35, "my_latent_test": 35, "occupi": [35, 124, 125, 126], "Will": [35, 126, 147, 148, 155], "evenli": [35, 70, 89, 189, 198], "intersect": [35, 155, 156, 157], "cond_a": 35, "cond_b": 35, "missing_a": 35, "missing_b": 35, "47335": 35, "7885": 35, "_removing_the_most_dominant_class_exercis": 35, "asia": 35, "supposedli": 35, "revers": [35, 69, 74, 146, 147, 148, 149, 171, 174], "shuffle_image_idx": 35, "unshuffl": 35, "input_shuffl": 35, "shuffle_rev_image_idx": 35, "empty_lik": 35, "pos_idx": 35, "po": [35, 124, 171], "input_train_shuffl": 35, "input_test_shuffl": 35, "input_train_shuffle_noisi": 35, "input_test_shuffle_noisi": 35, "confirm": [35, 197], "latent_test_shuffle_noisi": 35, "output_test_shuffle_noisi": 35, "hoorai": [35, 140, 149], "hope": [35, 98, 189], "embed": [35, 36, 37, 38, 117, 174], "imprint": 35, "coin": [35, 139, 140, 189], "daniel": 35, "kahneman": 35, "psycholog": [35, 119, 133, 163, 186, 188], "replic": [35, 63, 124], "middlebrook": [36, 37, 38], "panelist": [36, 37, 38], "adrienn": 36, "fairhal": 36, "bing": [36, 137, 138, 139, 140], "kanaka": 36, "rajan": 36, "audio": [36, 37, 38, 75, 76, 81], "ifram": [36, 37, 38], "src": [36, 37, 38], "braininspir": [36, 37, 38], "casto": [36, 37, 38], "player": [36, 37, 38], "563932": 36, "height": [36, 37, 38, 65, 74, 124, 125, 126, 163, 164], "athena": [37, 177, 182], "akrami": 37, "demba": 37, "ba": 37, "kunlin": 37, "wei": [37, 92, 156, 157], "560014": 37, "yael": 38, "niv": [38, 184], "konrad": [38, 87, 88, 89, 90, 165, 197, 198, 199, 200], "sam": 38, "gershman": 38, "tim": 38, "behren": 38, "569670": 38, "sun": [39, 52, 59, 60, 119], "ceremoni": 39, "utc": [39, 41], "pm": [39, 63, 171], "mon": 39, "tue": 39, "wed": 39, "fri": 39, "15": [39, 63, 65, 69, 70, 71, 74, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 103, 107, 108, 114, 115, 116, 117, 119, 123, 124, 125, 126, 133, 137, 139, 140, 147, 148, 149, 155, 156, 157, 163, 164, 165, 167, 172, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "22": [39, 65, 71, 76, 80, 81, 88, 89, 92, 97, 98, 99, 103, 107, 114, 115, 116, 119, 124, 125, 126, 137, 138, 139, 140, 147, 149, 155, 156, 163, 165, 171, 172, 173, 175, 181, 182, 190, 191, 197, 199, 200], "24": [39, 63, 65, 69, 71, 75, 76, 80, 87, 88, 89, 97, 98, 99, 103, 107, 108, 114, 124, 126, 137, 138, 139, 140, 142, 147, 148, 149, 151, 156, 157, 165, 171, 173, 175, 177, 181, 182, 188, 190, 191, 197, 199, 200], "reinforc": [39, 85, 94, 121, 161, 169, 179, 184, 186, 188, 189, 190, 201], "graduat": 39, "45": [39, 65, 69, 74, 75, 76, 80, 88, 89, 90, 96, 107, 115, 124, 125, 126, 137, 138, 139, 140, 148, 155, 156, 165, 171, 173, 174, 181, 182, 189, 191, 198, 199, 200], "ii": [39, 74, 76, 148, 156, 157, 191], "asynchron": [39, 201], "synchron": [39, 144], "info": [39, 76, 181], "mentor": 39, "farewel": 39, "certiic": 39, "cour": 39, "goodby": 39, "impos": [39, 182], "quarter": [39, 188], "overlap": [39, 117, 125, 189, 193], "late": [39, 124, 159], "attend": 39, "live": [39, 139, 175], "tbd": 39, "updat": [39, 63, 65, 69, 71, 74, 81, 88, 115, 123, 125, 126, 137, 139, 146, 147, 148, 149, 155, 156, 157, 161, 163, 171, 172, 173, 174, 175, 179, 181, 188, 190, 197, 199, 200], "zone": 41, "tz": 42, "environ": [44, 46, 47, 63, 69, 80, 108, 117, 121, 181, 188, 189, 190, 191], "portal": 45, "conduct": [45, 75, 76, 80, 103, 133, 142, 146, 147, 163], "violat": 45, "precours": [45, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 85], "exempt": 45, "shrubhlgswj8dua7": 45, "shrlp9uktpr5o9u28": 45, "particip": [45, 80, 81, 94, 165], "certif": 45, "assist": [45, 105], "circumst": [45, 87, 197], "beyond": [45, 71, 99, 100, 174, 191], "ill": 45, "electr": [45, 87, 88, 148, 167], "blackout": 45, "request": [45, 87, 89, 107, 108, 123, 124, 125, 126, 174], "grant": [45, 47, 123], "portion": [45, 80, 191, 200], "drop": [45, 47, 74, 97, 101, 115, 147, 148, 181], "elig": 45, "button": [46, 47, 87, 181], "overwrit": [46, 81], "git": 46, "ipynb": 46, "china": 47, "substitut": [47, 69, 70, 71, 97, 171, 198], "regist": [47, 165], "asococi": 47, "workaround": 47, "user": [47, 81, 126, 174], "phone": 47, "gpu": [47, 123], "internet": 47, "sidebar": 47, "enter": [47, 87, 116, 140, 190], "credenti": 47, "kernel": [47, 124, 125, 126, 146, 148, 149], "restart": 47, "newli": [47, 98], "NOT": [47, 70, 165, 181], "comp": [47, 71, 201], "menu": [47, 74, 126], "artwork": [48, 49, 82, 132, 141, 150], "daniela": [48, 49, 82], "buchwald": [48, 49, 82], "arvind": [50, 60, 74, 75, 76, 146, 147, 148, 149, 155, 156, 157], "kumar": [50, 55, 60, 74, 75, 76, 133, 146, 147, 148, 149, 155, 156, 157], "caption": [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61], "ashish": [50, 57, 61], "sahoo": [50, 57, 61], "kushaan": [50, 57, 61], "gupta": [50, 57, 61, 167], "cynthia": 50, "castillo": [50, 173, 181], "shuze": [50, 52, 54, 55, 56, 57, 58, 59, 60, 61], "liu": [50, 52, 54, 55, 56, 57, 58, 59, 60, 61, 197, 198, 199, 200], "8zxfvwxw": [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81], "w0d0_t1": 50, "jen": 51, "kremkow": 51, "jiaxin": [51, 54, 58], "tu": [51, 54, 58], "pooya": [51, 55, 56, 69, 70, 80, 81], "pakarian": [51, 55, 56, 69, 70, 80, 81], "maryam": [51, 87, 88, 89, 146, 147, 148, 155, 156, 157], "ansari": 51, "antoni": 51, "puthusseri": 51, "w0d0_t10": 51, "emanuela": 52, "santini": 52, "ethan": [52, 53, 57, 80, 81, 138, 146], "cheng": [52, 53, 57, 80, 81, 138, 146, 188, 189, 190, 191], "anoop": [52, 53, 57, 61, 69, 70, 80, 81, 163, 164, 188, 189, 190, 191], "kulkarni": [52, 53, 57, 61, 69, 70, 80, 81, 103, 163, 164, 188, 189, 190, 191], "manisha": [52, 53, 54, 58, 60], "sinha": [52, 53, 54, 58, 60], "andrew": [52, 59, 60], "carolina": [52, 56, 57], "shimabukuro": [52, 57], "yihe": 52, "lu": 52, "w0d0_t11": 52, "christof": 53, "koch": [53, 167], "lili": [53, 188, 189, 190, 191], "ghinwa": [53, 59], "el": [53, 59, 63, 65], "masri": [53, 59], "w0d0_t12": 53, "jenni": 54, "zahra": [54, 59, 163, 164], "arjmandi": [54, 59, 163, 164], "lui": [54, 55, 58, 59, 60, 61], "alvarez": [54, 55, 58, 59, 60, 61], "tong": 54, "liang": 54, "w0d0_t2": 54, "swapnil": [55, 75, 76], "jeremi": [55, 56], "forest": [55, 56], "aditya": 55, "yang": [55, 57, 61], "lin": [55, 57, 61], "w0d0_t3": 55, "churchland": [56, 83, 133], "chaoqun": 56, "yin": 56, "alex": [56, 96, 97, 98, 99, 100, 101, 114, 115, 116, 117], "kostiuk": 56, "luka": 56, "oesch": 56, "ryan": 56, "ashlei": 56, "chen": [56, 133, 167], "joao": 56, "couto": 56, "oluwatomisin": [56, 61], "faniyan": [56, 61], "sirisha": [56, 58, 75], "sripada": [56, 58, 75], "shimabuku": 56, "w0d0_t4": 56, "thoma": [57, 133], "tago": 57, "w0d0_t5": 57, "gaut": 58, "einevol": 58, "richard": [58, 114, 115, 116, 117, 119, 137, 138, 139, 140, 144, 146, 147, 148, 149, 155, 156, 157, 159], "gao": [58, 114, 115, 116, 117, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 167], "zhanao": [58, 59], "fu": [58, 59], "w0d0_t6": 58, "nihan": 59, "alp": 59, "natali": [59, 80, 81, 114, 115, 116, 117], "schaworonkow": [59, 80, 81, 114, 115, 116, 117], "w0d0_t7": 59, "pedro": 60, "vald": 60, "sosa": 60, "benjamin": [60, 103, 107, 108, 197, 198, 199, 200], "becker": 60, "carlo": [60, 81], "lopez": 60, "liangyou": 60, "zhang": [60, 119], "w0d0_t8": 60, "yeka": 61, "apont": 61, "matt": [61, 74, 87, 88, 89, 90, 114, 115, 116, 117, 165, 171, 172, 174, 175, 181, 182, 188, 189, 190, 191], "mccann": [61, 74, 75, 76], "w0d0_t9": 61, "fun": [63, 81, 107, 137, 139, 155, 156, 188], "sneak": 63, "workhors": 63, "unlock": 63, "couldn": 63, "evolut": [63, 65, 71, 119, 155, 156], "w0d1_t1": 63, "_python_basics_and_the_lif_model_video": 63, "tau_m": [63, 75, 76, 146, 147, 148, 149], "e_": [63, 148, 149], "quad": [63, 65, 76, 88, 89, 96, 97, 98, 99, 107, 108, 114, 115, 116, 146, 147, 148, 155, 157, 189], "leq": [63, 108], "v_": [63, 65, 81, 88, 146, 188], "th": [63, 65, 75, 89, 99, 107, 115, 116, 123, 125, 146, 148, 149, 171], "leak": [63, 76, 146, 147, 148, 149, 157], "resist": [63, 75, 76, 88, 146], "voltag": [63, 65, 74, 75, 76, 88, 142, 146, 147, 148, 149, 172, 200], "v_m": [63, 65, 88], "conveni": [63, 69, 81, 88, 97, 116, 138, 149, 171, 174, 181], "charg": [63, 88], "ordinari": [63, 74, 100, 101, 107, 137, 148], "_nano_recap_of_comments_and_strings_video": 63, "modifi": [63, 114, 123, 125, 126, 139, 146, 149, 181, 200], "t_max": [63, 65, 173], "150e": [63, 65], "1e": [63, 65, 87, 123, 126, 149, 155, 156, 157, 172, 198, 199], "tau": [63, 65, 74, 146, 155, 173], "20e": [63, 65], "60e": [63, 65], "milivolt": [63, 65], "vr": [63, 65], "70e": [63, 65], "vth": [63, 65], "50e": [63, 65], "100e6": [63, 65], "ohm": [63, 65, 148], "i_mean": [63, 65, 74, 146], "25e": [63, 65], "amper": [63, 65], "07": [63, 108, 119, 151, 165, 175, 177], "100000000": 63, "5e": [63, 107, 126], "_defining_parameters_ecercis": 63, "notat": [63, 71, 80, 81, 137, 157, 164, 165, 173, 174, 182, 197, 200], "goe": [63, 74, 75, 80, 124, 137, 146, 149, 155, 163, 164, 171, 172, 190, 191], "sinusoid": [63, 76, 182], "i_": [63, 74, 75, 76, 88, 146, 148, 149, 155, 157], "01": [63, 65, 74, 75, 76, 81, 83, 87, 88, 98, 103, 108, 124, 125, 126, 133, 138, 139, 142, 146, 155, 156, 157, 163, 164, 165, 172, 173, 174, 181, 182, 189, 197, 198, 199, 200], "009": [63, 83, 133, 177, 200], "delta": [63, 76, 139, 146, 148, 156, 157, 171, 172, 173, 191], "syntax": [63, 123, 155], "sine": 63, "dagger": 63, "nameerror": [63, 76, 107, 114, 115, 116, 117, 125, 126, 139, 140, 149, 157, 165, 174, 175, 182, 188, 189, 190, 197, 200], "traceback": [63, 65, 69, 71, 74, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "recent": [63, 65, 69, 71, 74, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 137, 138, 139, 140, 144, 146, 147, 148, 149, 155, 156, 157, 163, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "969463130731183e": 63, "877641290737885e": 63, "9694631307311837e": 63, "5000000000000007e": 63, "0305368692688176e": 63, "2235870926211617e": 63, "223587092621159e": 63, "0305368692688186e": 63, "_simulating_an_input_current_ecercis": 63, "3f": [63, 123, 126, 137, 138, 140, 146, 147, 148, 149, 155, 156, 157, 174, 198, 199, 200], "decim": 63, "4e": 63, "exponenti": [63, 74, 75, 76, 85, 87, 88, 89, 97, 107, 137, 147, 148, 149, 155, 164, 173, 175, 188], "14159265e": 63, "314": 63, "1416e": 63, "step_end": [63, 65], "5000e": 63, "9695e": 63, "002": [63, 65, 103, 119, 126, 175], "8776e": 63, "003": [63, 133, 174, 184], "005": [63, 87, 110, 142, 151, 163, 174], "0305e": 63, "007": [63, 65, 75, 76, 142], "2236e": 63, "_printing_pretty_numbers_ecercis": 63, "_for_loops_and_discrete_time_integration_video": 63, "indent": [63, 74, 172, 173], "formul": [63, 94, 116, 140, 175], "stepsiz": [63, 80, 81, 156], "_nano_recap_of_discrete_time_integration_video": 63, "qquad": [63, 75, 76, 148, 155, 156, 157], "manipul": [63, 75, 76, 88, 171, 172, 173, 181, 188], "euler": [63, 74, 85, 146, 148, 149, 155, 156, 157], "e_l": [63, 75, 76, 146, 148, 149], "reorgan": 63, "eq": [63, 148, 157, 182, 197], "v0": 63, "8750e": 63, "6828e": 63, "4548e": 63, "2381e": 63, "0778e": 63, "9989e": 63, "9974e": 63, "0414e": 63, "0832e": 63, "0775e": 63, "_simulating_membrane_potential_exercis": 63, "_intro_to_plotting_video": 63, "_nano_recap_of_plotting_video": 63, "024": [63, 149], "ko": [63, 155, 156, 157], "curent": 63, "_plotting_current_exercis": 63, "t_": [63, 65, 74, 75, 76, 137, 146, 148, 149, 175, 200], "nearest": [63, 125], "smaller": [63, 71, 74, 76, 89, 108, 123, 124, 125, 126, 140, 147, 148, 149, 156, 157], "_plotting_membrane_potential_exercis": 63, "perspect": [63, 69, 70, 83, 119, 124, 133, 193], "xi": [63, 146, 155, 175], "sim": [63, 80, 88, 97, 114, 139, 155, 171, 172, 173, 174, 188, 197, 200], "pseudo": [63, 81, 98], "random_num": [63, 80], "_adding_randomness_exercis": 63, "_lists_": 63, "_ensemble_statistics_video": 63, "_nano_recap_of_ensemble_statistics_": 63, "_lists_video": 63, "impress": [63, 108], "autocovari": [63, 146], "v_n": [63, 65], "langl": 63, "rangl": 63, "sum_": [63, 65, 69, 81, 89, 96, 97, 99, 108, 115, 116, 123, 124, 125, 126, 147, 149, 163, 171, 174, 175, 182, 188, 197], "command": [63, 123], "symbol": [63, 74, 99], "beta": [63, 81, 88, 108, 164, 200], "tex": 63, "markup": 63, "intiati": 63, "xkcd": [63, 74, 75, 76, 81, 165, 175, 190], "transpar": 63, "34": [63, 74, 76, 80, 98, 99, 101, 107, 115, 117, 119, 123, 125, 126, 137, 139, 148, 155, 165, 174, 175, 177, 181, 188, 189, 197, 198, 200], "_storing_simulations_in_lists_exercis": 63, "v_mean": [63, 65], "_plotting_sample_mean_exercis": 63, "equiv": [63, 108, 155, 163, 182], "var": [63, 81, 100, 108, 114, 116, 125, 139, 147, 163, 172, 173, 175, 182, 200], "v_var": 63, "49": [63, 65, 76, 81, 101, 126, 146, 174, 188, 191, 200], "81": [63, 65, 81, 133, 182], "v_var_n": 63, "v_std": 63, "markers": [63, 74, 100, 126, 139, 173, 181], "c7": 63, "38": [63, 65, 75, 81, 87, 89, 98, 99, 107, 108, 114, 115, 123, 126, 139, 146, 148, 149, 171, 173, 175, 181, 189, 198, 199, 200], "_plotting_sample_standard_deviation_exercis": 63, "_using_numpy_video": 63, "significantli": [63, 124], "narr": [63, 65], "_nano_recap_of_using_numpy_video": 63, "t_rang": [63, 65], "endpoint": [63, 164, 197, 198, 199, 200], "44": [63, 65, 74, 76, 80, 126, 137, 156, 171, 173, 174, 177, 181, 182, 197, 198], "_rewriting_with_numpy_exercis": 63, "i_step": 63, "46": [63, 65, 126, 156, 165, 171, 173, 174, 188, 191, 197, 200], "_using_enumerate_and_indexing_exercis": 63, "_aggregation_video": 63, "_nano_recap_of_aggregation_video": 63, "transpos": [63, 99, 172, 197, 199, 200], "52": [63, 76, 96, 101, 126, 146, 156, 171, 174, 188, 191, 197, 200], "_using_2d_arrays_exercis": 63, "54": [63, 126, 138, 146, 147, 156, 171, 181, 191, 197, 200], "_plotting_sample_mean_and_standard_deviation_exercis": 63, "_overview_video": 63, "repeatedli": [65, 189, 191], "elsewher": [65, 164], "w0d2_t1": 65, "creation": [65, 70, 71, 74, 75, 76, 80, 81], "plot_al": 65, "spikes_mean": 65, "membran": [65, 74, 76, 88, 89, 133, 142, 146, 147, 149, 172], "ax1": [65, 74, 88, 97, 98, 114, 115, 123, 126, 149, 156, 157, 172, 174, 181, 182, 188, 189, 190], "c1": [65, 81, 87, 96, 98, 99, 188], "auto": [65, 97, 116, 117, 123, 125, 126, 133, 140, 163, 165, 174, 190, 191, 200], "sharex": [65, 107, 108, 156, 157, 163, 164, 182], "ones_lik": [65, 107, 140, 164, 198, 199], "hz": [65, 74, 75, 76, 147, 148, 149, 175], "_histograms_video": 65, "t_k": [65, 76, 148], "m_j": 65, "fall": [65, 69, 71, 87, 89, 98, 107, 123, 124, 125, 126, 144, 181], "nbin": 65, "histtyp": [65, 87, 97], "stepfil": [65, 87, 97], "appear": [65, 69, 71, 87, 107, 108, 116, 117, 123, 124, 125, 126, 147, 174, 188, 190, 191, 198], "patch": [65, 69, 124, 125, 126, 163, 172, 175, 200], "edg": [65, 87, 88, 89, 124, 126, 189, 190, 197], "_nano_recap_of_histograms_video": 65, "_plotting_a_histogram_exercis": 65, "_dictionaries_": 65, "_introducing_spikes_video": 65, "geq": [65, 107, 146, 188], "_nano_recap_of_dictionaries_video": 65, "spike_tim": [65, 75, 76, 88, 89, 146], "sharei": [65, 107, 108, 125, 156, 157, 163, 164, 182], "1st": [65, 137, 148, 181], "my_data_left": 65, "my_data_right": 65, "spikes_n": 65, "vm": 65, "_adding_spiking_to_the_lif_neuron_exercis": 65, "_boolean_indexes_video": 65, "itself": [65, 69, 71, 74, 75, 87, 108, 123, 140, 149, 161, 174, 190], "_nano_recap_of_boolean_indexes_video": 65, "v_rest": 65, "__main__": [65, 71, 87, 101, 114, 115, 116, 117, 125, 140, 146, 147, 148, 149, 155, 156, 157, 172], "v_thr": 65, "_using_boolean_indexing_exercis": 65, "v_reset": [65, 75, 76, 146, 147, 148, 149], "_making_a_binary_raster_plot_exercis": 65, "_refractory_period_video": 65, "millisecond": [65, 88, 149], "synapt": [65, 71, 74, 103, 124, 144, 146, 147, 151, 155, 157], "2nd": [65, 70, 75, 76, 137, 181, 189], "biophys": [65, 142, 151, 156, 157], "_nano_recap_of_refractory_period_video": 65, "ref": [65, 146], "lambda": [65, 69, 70, 71, 76, 80, 88, 107, 139, 140, 147, 155, 172, 175], "clamp": [65, 74, 146, 179, 188, 197, 200], "t_ref": 65, "last_spik": 65, "_investigating_refractory_periods_exercis": 65, "random_ref_period": 65, "syn": [65, 147, 148], "_": [65, 69, 70, 71, 74, 75, 76, 80, 81, 88, 89, 96, 97, 100, 114, 115, 116, 123, 126, 137, 138, 146, 147, 148, 149, 155, 157, 165, 171, 173, 174, 175, 181, 182, 188, 191, 197, 198, 199, 200], "_random_refractory_period_interactive_demo": 65, "_functions_video": 65, "_nano_recap_of_functions_video": 65, "spike_clamp": 65, "ode_step": 65, "discret": [65, 76, 81, 87, 89, 133, 137, 139, 146, 147, 148, 149, 155, 156, 157, 164, 165, 167, 171, 172, 173, 174, 182], "delta_spik": 65, "87": [65, 139, 171, 177], "89": [65, 171, 191], "92": [65, 137, 142, 149, 175], "93": [65, 69, 103, 133, 137, 191], "27": [65, 69, 71, 76, 87, 89, 96, 97, 99, 101, 107, 108, 114, 116, 119, 123, 125, 126, 137, 138, 139, 147, 148, 149, 155, 156, 157, 165, 172, 173, 175, 181, 182, 189, 191, 199, 200], "41": [65, 70, 99, 107, 108, 115, 119, 126, 139, 146, 149, 156, 165, 171, 173, 181, 182, 191, 197, 198, 199, 200], "43": [65, 71, 81, 88, 96, 107, 108, 114, 115, 119, 126, 133, 139, 156, 163, 165, 171, 173, 174, 182, 191, 197, 198, 200], "47": [65, 76, 80, 103, 126, 137, 156, 173, 174, 191, 197, 200], "48": [65, 76, 80, 81, 101, 124, 125, 126, 137, 146, 165, 173, 174, 188, 200], "_rewriting_code_with_functions_exercis": 65, "_classes_video": 65, "reliabl": [65, 107, 147, 148, 163], "unimport": 65, "attribut": [65, 69, 87, 123, 124, 125, 126, 163, 188], "_nano_recap_of_classes_video": 65, "lifneuron": 65, "spike_and_clamp": 65, "t_ref_mu": 65, "t_ref_sigma": 65, "histori": [65, 71, 81, 103, 138, 140, 144, 148, 171, 174, 181, 191], "ran": [65, 171, 191], "74": [65, 69, 126, 171, 172, 182, 191], "_making_a_lif_class_exercis": 65, "_last_concepts_": 65, "_recap_video": 65, "butler": [67, 73, 74, 75, 76, 78, 84, 93, 104, 111, 120, 128, 134, 137, 138, 139, 140, 143, 152, 160, 168, 171, 172, 175, 178, 185, 194, 201], "w0d3_daysummari": 67, "_slide": [67, 73, 78], "patient": [68, 69, 71, 79, 86, 95, 106, 113, 122, 130, 136, 145, 154, 162, 170, 173, 180, 187, 196], "delai": [68, 79, 86, 87, 95, 106, 113, 122, 130, 136, 140, 145, 147, 154, 162, 170, 180, 187, 188, 190, 196], "redirect": [68, 79, 86, 95, 106, 113, 122, 130, 136, 145, 154, 162, 170, 180, 187, 196], "keith": [69, 70, 76, 80, 81, 171], "antwerp": [69, 70, 80, 81, 171], "siddharth": [69, 70, 114, 115, 116, 117, 155, 156, 157], "suresh": [69, 70, 114, 115, 116, 117, 155, 156, 157], "geometr": [69, 70, 99, 115], "w0d3_t1": 69, "fix": [69, 70, 80, 81, 89, 96, 97, 98, 99, 126, 146, 147, 148, 153, 156, 164, 172, 173, 174, 181, 182, 188, 189, 197, 198, 199, 201], "fancyarrowpatch": 69, "mpl_toolkit": [69, 70, 74, 107, 197, 200], "mplot3d": [69, 70, 74], "proj3d": 69, "visualize_vector": 69, "v_unit": 69, "aesthet": 69, "set_color": [69, 70, 71, 74, 108, 149], "set_posit": [69, 70, 71, 74, 181], "zorder": [69, 71, 107, 125, 126, 139, 147, 148, 149, 155, 157, 164, 174, 181], "v_arr": 69, "648fff": [69, 71], "length_includes_head": [69, 70, 71, 137, 197, 198, 199, 200], "v_unit_arr": 69, "dc267f": [69, 71], "leg": [69, 71], "tild": [69, 101, 123, 125, 126, 165], "handlelength": [69, 71, 156, 157], "fontsiz": [69, 70, 71, 74, 108, 139, 147, 148, 149, 155, 156, 172, 175, 181, 182, 197, 199], "upper": [69, 74, 76, 80, 87, 89, 107, 125, 126, 164, 171, 172, 173, 181, 182, 191, 197], "handl": [69, 71, 83, 88, 98, 101, 119, 175, 190, 191, 200], "legendhandl": [69, 71], "get_facecolor": [69, 71], "arrow3d": 69, "xs": [69, 87], "ys": [69, 87], "zs": 69, "kwarg": [69, 70, 88, 123, 126, 146, 147, 148, 149, 155, 156, 157], "_verts3d": 69, "xs3d": 69, "ys3d": 69, "zs3d": 69, "proj_transform": 69, "do_3d_project": 69, "_why_do_we_care_about_linear_algebra_video": 69, "_vector_definition_": 69, "_properties_video": 69, "bmatrix": [69, 70, 71, 99, 108, 123, 125, 126, 157, 172, 174, 197, 199], "_i": [69, 71, 81, 96, 99, 108, 115, 125, 147, 156, 157, 165], "x_1": [69, 70, 80, 81, 89, 97, 99, 114, 137, 139, 140, 197], "x_2": [69, 70, 80, 81, 89, 99, 114, 137, 140, 197], "x_3": [69, 70, 81, 89, 197], "normalize_vector": 69, "input_vector": 69, "n_dim": 69, "linalg": [69, 70, 71, 81, 99, 100, 101, 107, 115, 116, 137, 138, 140, 157, 197, 198, 199, 200], "vector_length": 69, "normalized_vector": 69, "33": [69, 80, 81, 87, 99, 100, 101, 103, 107, 114, 116, 117, 119, 123, 126, 137, 139, 147, 148, 155, 156, 157, 165, 171, 173, 174, 175, 181, 188, 189, 191, 197, 200], "_normalizing_vectors_exercis": 69, "_linear_combinations_of_vectors_video": 69, "180": [69, 114, 124, 125, 126, 146], "_1": [69, 71, 123, 137, 140, 171, 174, 199], "vdot": [69, 99, 125, 126], "_n": [69, 99], "stack": [69, 99, 100, 101, 114, 124, 125, 138, 172, 175, 190, 197], "tail": [69, 70, 189], "essenc": [69, 100, 164], "parallelogram": 69, "4th": [69, 70], "vertex": 69, "c_1": [69, 71], "c_2": [69, 71], "fraction": [69, 87, 116, 126, 138, 147, 148, 173, 199, 200], "slider": [69, 71, 74, 80, 81, 87, 88, 89, 114, 115, 116, 137, 156, 163, 171, 172, 173, 181, 182, 188, 199], "releas": [69, 71, 148], "coupl": [69, 71, 76, 81, 89, 148, 155, 156, 157, 164], "desir": [69, 71, 80, 114, 115, 164, 171, 179, 191, 200], "plot_arrow": [69, 71], "a_times_x": [69, 71], "b_times_i": [69, 71], "set_aspect": [69, 70, 71, 123, 125, 126, 165, 173, 182, 197, 198, 199, 200], "xticklabel": [69, 71, 107, 163], "yticklabel": [69, 71, 163], "z_arr": [69, 71], "x_orig": [69, 71], "y_orig": [69, 71], "ax_arr": [69, 71], "by_arr": [69, 71], "bbox_to_anchor": [69, 71, 74, 125, 171, 172], "get_color": [69, 71], "floatslid": [69, 71, 75, 76, 80, 87, 96, 97, 114, 137, 146, 148, 149, 155, 156, 157, 163, 164, 171, 172, 173, 174, 181, 182, 188, 189], "plot_linear_combin": [69, 71], "_linear_combinations_of_vectors_interactive_demo": 69, "35": [69, 70, 81, 87, 88, 89, 99, 100, 101, 107, 108, 114, 116, 117, 119, 123, 125, 126, 137, 139, 147, 148, 149, 155, 156, 163, 164, 171, 172, 173, 174, 181, 189, 191, 197, 198, 199, 200], "_span_and_linear_independence_video": 69, "rm": [69, 146, 147, 148, 149, 155, 157, 172, 173, 174, 181], "written": [69, 71, 75, 76, 80, 81, 99, 123, 124, 137, 138, 139, 140, 155, 156, 165, 173, 188, 198], "111": [69, 74, 83, 119, 157, 165, 173, 190], "mutation_scal": 69, "lw": [69, 70, 87, 108, 146, 148, 149, 155, 157, 172, 173], "arrowstyl": [69, 137], "add_artist": 69, "785ef0": 69, "ffb000": 69, "zlim": 69, "zlabel": [69, 74, 99], "attributeerror": [69, 126, 174], "callback": [69, 81, 155], "_draw_all_if_interact": 69, "0x7fd146de61f0": 69, "post_execut": 69, "typeerror": 69, "hostedtoolcach": [69, 81, 123, 126, 137, 155, 174, 198, 199], "x64": [69, 81, 123, 126, 137, 155, 174, 198, 199], "lib": [69, 81, 123, 126, 137, 155, 174, 198, 199], "python3": [69, 81, 123, 126, 137, 155, 174, 198, 199], "site": [69, 74, 81, 123, 126, 137, 155, 174, 181, 198, 199], "py": [69, 81, 123, 126, 137, 139, 140, 155, 163, 174, 198, 199], "268": 69, "267": 69, "is_interact": 69, "draw_al": 69, "_pylab_help": 69, "131": 69, "gcf": 69, "cl": 69, "129": [69, 177], "get_all_fig_manag": 69, "130": 69, "stale": 69, "draw_idl": 69, "backend_bas": 69, "1905": [69, 133], "figurecanvasbas": 69, "1903": 69, "_is_idle_draw": 69, "1904": 69, "_idle_draw_cntx": 69, "backend": [69, 70, 74], "backend_agg": 69, "387": [69, 103], "figurecanvasagg": 69, "384": 69, "lock": [69, 189], "cach": [69, 81, 107, 191], "385": 69, "toolbar": 69, "_wait_cursor_for_draw_cm": 69, "386": 69, "nullcontext": 69, "388": [69, 133], "gui": 69, "389": [69, 174], "superclass": 69, "390": 69, "artist": 69, "95": [69, 75, 98, 133, 137, 139, 142, 147, 165, 181, 182], "_finalize_raster": 69, "draw_wrapp": 69, "wrap": 69, "94": [69, 103, 137, 191], "96": [69, 137, 156, 157, 181, 191], "_raster": 69, "97": [69, 75, 76, 98, 103, 133, 137, 142, 191], "stop_raster": 69, "allow_raster": 69, "69": [69, 81, 123, 126, 171, 172, 182], "get_agg_filt": 69, "70": [69, 76, 81, 116, 123, 126, 146, 163, 172, 182, 188], "start_filt": 69, "73": [69, 81, 123, 126, 146, 171, 182, 191], "3162": 69, "3159": 69, "valueerror": 69, "resiz": 69, "3161": 69, "mimag": 69, "_draw_list_compositing_imag": 69, "3163": 69, "suppresscomposit": 69, "3165": 69, "close_group": 69, "3166": 69, "132": 69, "parent": [69, 123, 126], "suppress_composit": 69, "not_composit": 69, "has_imag": 69, "133": 69, "134": 69, "composit": [69, 89, 133], "135": 69, "image_group": 69, "axes3d": [69, 70, 74], "441": 69, "437": [69, 167], "zorder_offset": 69, "get_zord": 69, "438": 69, "_axis_map": 69, "439": 69, "collection_zord": 69, "patch_zord": 69, "collections_and_patch": 69, "442": 69, "443": 69, "444": 69, "mcoll": 69, "445": 69, "instanc": [69, 81, 101, 117, 123, 139, 146, 149, 157, 172, 174, 175, 188, 189, 191], "nonetyp": 69, "formatt": 69, "340": [69, 83, 133], "baseformatt": 69, "__call__": 69, "obj": 69, "338": [69, 103], "339": [69, 83, 133, 142], "printer": 69, "341": 69, "342": 69, "get_real_method": 69, "print_method": 69, "pylabtool": 69, "retina_figur": 69, "base64": 69, "160": [69, 191], "161": 69, "png": [69, 108], "162": [69, 81], "163": [69, 81], "byte": 69, "167": [69, 138], "168": [69, 81], "pngdata": 69, "print_figur": 69, "fmt": [69, 108], "170": 69, "171": 69, "172": 69, "152": [69, 137], "bbox_inch": 69, "149": [69, 142], "bytes_io": 69, "kw": [69, 107], "153": [69, 83, 137, 177], "getvalu": 69, "154": [69, 137], "svg": 69, "2175": 69, "dpi": [69, 70], "facecolor": [69, 70, 74, 98, 156, 157, 163, 172, 175, 182], "edgecolor": [69, 70, 74, 173], "pad_inch": 69, "bbox_extra_artist": 69, "2172": [69, 177], "draw_without_rend": 69, "2173": 69, "inject": [69, 74, 146, 147, 148, 155, 157, 197, 200], "2174": 69, "getattr": 69, "_draw_dis": 69, "2176": 69, "2177": 69, "tight": [69, 88, 195], "800x600": [69, 139, 155], "o\u011ful": 69, "yurdakul": 69, "geogebra": 69, "hherq78z": 69, "_determing_dependence_discuss": 69, "_basis_vectors_video": 69, "tradit": 69, "applic": [69, 75, 76, 98, 105, 110, 121, 124, 129, 133, 140, 142, 156, 157, 171, 172, 173, 174, 179, 193, 197, 200], "unwieldi": 69, "though": [69, 70, 71, 87, 88, 89, 96, 100, 101, 108, 123, 126, 138, 148, 149, 161, 164, 171, 174, 188, 189, 198], "plane": [69, 70, 74, 99, 153, 155], "unusu": [69, 107], "tightli": 69, "subspac": 69, "r3": 69, "xx": [69, 97, 99, 107, 124, 125, 126, 140, 164], "yy": [69, 97, 99, 124, 125, 126, 140, 164], "meshgrid": [69, 70, 74, 124, 125, 126, 137, 156, 157, 163], "plot_surfac": [69, 74, 99], "invert_xaxi": 69, "_figuring_out_a_basis_discuss": 69, "hr": [69, 108, 123, 163], "_the_dot_product_video": 69, "retin": [69, 70, 71, 99, 103, 119], "synaps": [69, 133, 144, 147, 197], "dot_prod": 69, "r_1": [69, 70, 123], "r_2": [69, 70, 123], "w_1r_1": 69, "w_2r_2": 69, "heatmap": [69, 81, 107, 123, 126, 190, 191, 197, 198, 199], "combo": 69, "highest": [69, 81, 89, 99, 126, 163, 164, 189], "postsynapt": [69, 142, 146, 147, 148], "minim": [69, 70, 81, 96, 97, 98, 99, 107, 116, 123, 125, 126, 165, 181, 182], "x_vec": 69, "y_vec": 69, "n_pixel": 69, "coord1": 69, "coord2": 69, "circle_mask": 69, "coord_i": 69, "coord_j": 69, "mask": [69, 174], "plot_heatmap": 69, "masked_x": 69, "masked_i": 69, "outer": 69, "im": [69, 81, 97, 124, 126, 188, 190, 191, 197, 198, 199, 200], "bwr": [69, 124, 126], "cbar": [69, 81, 123, 125, 126, 165, 197, 198], "colorbar": [69, 71, 74, 81, 97, 107, 116, 117, 123, 124, 125, 126, 165, 188, 190, 191, 197, 198, 199, 200], "set_label": [69, 165], "rotat": [69, 70, 71, 75, 76, 81, 114, 125, 156, 157, 173, 197, 198], "270": 69, "labelpad": [69, 137, 138, 173, 197, 198], "set_label_coord": [69, 181], "fr_arr": 69, "40b0a6": 69, "we_arr": 69, "frameon": [69, 149, 164], "description_width": [69, 163], "neuron1_fir": 69, "neuron2_fir": 69, "firing_r": 69, "_lgn_firing_interactive_demo": 69, "_the_geometry_of_the_dot_product_video": 69, "largest": [69, 76, 99, 189, 197, 200], "smallest": [69, 99], "perpendicular": 69, "axiom": 69, "cd": 69, "mostli": [69, 81, 107, 108, 125, 129, 148, 174, 193, 197, 199], "p_3": [69, 80], "c_o": 69, "c_1x": 69, "c_2x": 69, "c_3x": 69, "c_0": 69, "c_3": 69, "obei": [69, 138], "prove": [69, 100, 171], "law": [69, 148], "cosin": 69, "formula": [69, 70, 74, 76, 80, 81, 89, 101, 125, 126, 139, 147, 164, 171, 197], "subtract": [69, 74, 114, 115, 116, 123, 125], "aderogba": [70, 74], "bayo": [70, 74], "openedx": 70, "sea": [70, 177], "gwu": 70, "gw": 70, "engcomp4": 70, "plot_linear_transform": 70, "licens": 70, "bsd": 70, "claus": 70, "lorena": 70, "barba": 70, "tingyu": 70, "IS": 70, "BY": 70, "THE": 70, "copyright": 70, "holder": 70, "contributor": 70, "AS": 70, "warranti": 70, "TO": [70, 116, 117, 123, 125, 126, 172], "OF": [70, 75, 76], "merchant": 70, "FOR": 70, "IN": 70, "NO": 70, "shall": [70, 99, 157], "BE": 70, "liabl": 70, "indirect": [70, 164], "incident": 70, "exemplari": 70, "consequenti": 70, "damag": 70, "procur": 70, "servic": 70, "profit": 70, "interrupt": [70, 174], "ON": [70, 107], "liabil": 70, "contract": 70, "strict": 70, "tort": 70, "neglig": 70, "IF": 70, "advis": 70, "SUCH": 70, "w0d3_t2": 70, "inv": [70, 71, 99, 100, 101, 107], "eig": [70, 71, 137, 138, 155, 157], "ticker": [70, 188], "get_backend": 70, "rc": 70, "cycl": [70, 137, 175], "_int_backend": 70, "gtk3agg": 70, "gtk3cairo": 70, "macosx": 70, "nbagg": 70, "qt4agg": 70, "qt4cairo": 70, "qt5agg": 70, "qt5cairo": 70, "tkagg": 70, "tkcairo": 70, "webagg": 70, "wx": 70, "wxagg": 70, "wxcairo": 70, "_backend": 70, "shrink": [70, 108, 173, 197, 198], "fig_scal": 70, "808080": 70, "gold": [70, 83, 96, 163, 198], "cab18c": 70, "lightblu": 70, "0096d6": 70, "008367": 70, "red": [70, 74, 76, 80, 81, 88, 97, 114, 115, 116, 137, 148, 149, 155, 156, 163, 164, 171, 172, 173, 181, 191], "e31937": 70, "darkblu": 70, "004065": 70, "pink": [70, 123, 126], "yellow": [70, 74, 76, 173, 191], "brown": [70, 103, 133, 147, 159, 193], "ef7b9d": 70, "fbd349": 70, "ffa500": 70, "a35cff": 70, "731d1d": 70, "quiver_param": 70, "xy": [70, 156, 157, 163, 164], "scale_unit": [70, 156, 157], "grid_param": 70, "set_rc": 70, "func": [70, 155, 156, 157], "wrapper": [70, 198, 199, 200], "serif": 70, "axisbelow": 70, "titles": [70, 74], "plot_vector": 70, "assert": [70, 163, 164, 171, 172, 197, 198, 199, 200], "zeros_lik": [70, 80, 81, 137, 138, 139, 140, 155, 164, 165, 171, 174, 189], "tile": [70, 124, 165, 172, 175, 190, 191], "nvector": 70, "ntail": 70, "xlimit": [70, 116], "ylimit": 70, "hstack": [70, 81, 99, 100, 101, 175], "quiver": [70, 156, 157, 190, 191], "finer": [70, 71], "get_xtick": [70, 188], "get_ytick": 70, "dy": [70, 74, 76], "multipleloc": 70, "set_major_loc": [70, 107, 188], "hide": [70, 71], "plot_transformation_help": 70, "unit_vector": 70, "unit_circl": 70, "helper": [70, 81, 87, 97, 98, 107, 114, 137, 139, 146, 155, 172, 190, 197], "2x2": [70, 137, 157, 163], "bool": [70, 171, 172], "circl": [70, 76, 156, 157], "grid_rang": 70, "x_": [70, 76, 96, 98, 99, 100, 107, 137, 139, 140, 175, 197, 198, 199, 200], "y_": [70, 76, 96, 98, 100, 175, 200], "color_cycl": 70, "vector_": 70, "vstack": [70, 138, 140], "circle_tran": 70, "set_linewidth": [70, 108, 188], "axis1": 70, "axis2": 70, "plot_eig_vec_transform": 70, "vec_nam": 70, "vec": [70, 71, 157, 197, 198, 199, 200], "prop_cycl": [70, 71], "by_kei": [70, 71], "i_vec": 70, "head_width": [70, 137, 197, 198, 199, 200], "transformed_vec": 70, "matmul": [70, 115, 116], "_systems_of_equations_video": 70, "3x_1": 70, "2x_2": 70, "y_1": [70, 76, 97, 123, 164], "7x_1": 70, "2x_3": 70, "y_2": [70, 123, 164], "y_3": 70, "appeal": 70, "cast": 70, "lgn": [70, 71], "dictat": [70, 138], "g_": [70, 148, 149, 173, 182, 188], "p_1": [70, 76, 80, 126], "p_2": [70, 80, 126], "3r_2": 70, "2r_1": 70, "_p": [70, 123], "g_p": 70, "ellipsi": [70, 80], "q": [70, 142, 164, 174, 182, 189], "invert": [70, 81, 108, 199], "g_q": 70, "_understanding_neural_transformations_exercis": 70, "_linear_transformations_video": 70, "enact": 70, "manner": [70, 105, 146, 148], "straight": [70, 76], "flip": [70, 115, 116, 139, 140, 189], "bar": [70, 74, 81, 99, 100, 101, 115, 124, 125, 138, 147, 148, 149, 163, 173, 182, 189], "_creating_matrices_for_transformations_exercis": 70, "_rank_": 70, "_null_space_video": 70, "li": [70, 71, 99, 107, 119, 146, 147, 148, 149, 155, 156, 157, 175], "aren": [70, 123, 163, 164, 189], "intrins": [70, 116, 177], "_neural_coding_discuss": 70, "_eigenstuff_video": 70, "infinit": [70, 80, 108, 123, 164, 182], "jog": 70, "expans": 70, "vertic": [70, 74, 76, 81, 88, 124, 125, 126], "_identifying_transformations_from_eigenvectors_discuss": 70, "_matrix_multiplication_video": 70, "pen": [70, 163], "wr": 70, "matrix1": 70, "matrix2": 70, "_computation_corner_exercis": 70, "interconnect": [71, 197], "explod": [71, 155, 182], "w0d3_bonu": 71, "plot_circuit_respons": 71, "cs": [71, 184], "textz": 71, "tracker_text": 71, "transax": [71, 126], "eigval": 71, "eigvec": 71, "lc1": 71, "lc2": 71, "cm": [71, 123, 124, 125, 126, 137, 163, 165], "coolwarm": [71, 99, 107, 197, 198, 199, 200], "a_1": [71, 197, 200], "a_2": 71, "scalarmapp": 71, "get_eigval_specified_matrix": 71, "target_eig": 71, "unless": [71, 164], "distinct": [71, 164, 175, 182], "diag": [71, 155, 175], "bc": 71, "squeez": [71, 107, 108, 124, 126, 175], "_a_neural_circuit_video": 71, "subscript": [71, 97, 148], "a_": [71, 137, 149, 156, 157, 175, 181, 182, 188, 189, 190, 197], "w_": [71, 76, 126, 156, 157, 173], "chop": 71, "weird": 71, "faithfulli": 71, "symmetr": [71, 114, 115, 125, 164, 171], "mess": [71, 200], "luckili": [71, 74, 99, 101, 164, 199], "concern": [71, 74, 97, 147, 149], "quantiti": [71, 80, 123, 125, 126, 148, 149, 164, 186, 188], "unsurprisingli": 71, "embrac": 71, "tomorrow": [71, 139, 163], "w2d2": [71, 75, 144, 153], "circuit_implement": 71, "_0": [71, 137, 174, 197, 199], "a0": 71, "i_t": [71, 197], "u0": [71, 148], "42": [71, 76, 80, 88, 107, 108, 114, 115, 126, 137, 139, 146, 163, 165, 171, 173, 175, 177, 181, 182, 191, 197, 198, 199, 200], "_implementing_the_circuit_exercis": 71, "infin": 71, "incred": 71, "115": [71, 74, 119, 126, 177], "a_i": [71, 156, 157, 175], "ia_0": 71, "a_0": [71, 197, 198, 199, 200], "_looking_at_activity_along_an_eigenvector_video": 71, "rewrit": [71, 107, 116, 155, 156, 157, 171], "subsitut": 71, "subsequ": [71, 125], "lie": [71, 139], "plot_system": 71, "_changing_the_eigenvalue_interactive_demo": 71, "_understanding_general_dynamics_using_eigenstuff_video": 71, "lambda_1": 71, "lambda_2": 71, "a0_1": 71, "a0_2": 71, "eigenvalue1": 71, "eigenvalue2": 71, "lag": [71, 107, 147, 199, 200], "update_rang": 71, "_changing_both_eigenvalues_interactive_demo": 71, "until": [71, 88, 101, 124, 139, 148, 171, 173, 174, 190], "proof": [71, 119, 190], "sustain": 71, "_t": [71, 173, 174, 181, 182, 197, 199, 200], "takeawai": [71, 198, 200], "whose": [71, 74, 80, 89, 115, 123, 125, 126, 139, 148, 173, 190], "w0d4_daysummari": 73, "tessi": [74, 75], "tom": [74, 75], "matthew": [74, 75, 76, 137, 138, 139, 140, 146, 147, 148, 149, 188, 189, 190, 191], "rusti": 74, "w0d4_t1": 74, "sp": [74, 80, 81, 146, 148], "toolbox": [74, 80, 92, 119], "rendr": 74, "my_layout": [74, 75, 76, 146, 147, 148, 149], "my_fonts": 74, "my_param": 74, "labels": [74, 181, 197, 198], "move_sympyplot_to_ax": 74, "process_seri": 74, "plot_funct": [74, 108, 173], "show_deriv": 74, "show_integr": 74, "2t": [74, 171], "parabol": 74, "diff_f": 74, "p1": [74, 171, 172], "line_color": 74, "int_f": 74, "plot_alpha_func": 74, "df_dt": 74, "au": 74, "plot_charge_transf": 74, "psp": [74, 148], "numerical_integr": 74, "_why_do_we_care_about_calculus_video": 74, "_a_geometrical_interpretation_of_differentiation_and_integration_video": 74, "eigenfunct": 74, "contin": [74, 164], "slight": [74, 81, 189, 190], "distanc": [74, 80, 117, 164, 181], "travel": [74, 80], "vehicl": 74, "decreas": [74, 76, 87, 88, 89, 108, 114, 115, 116, 126, 146, 148, 149, 157, 175], "different": 74, "5t": 74, "4t": 74, "function_opt": 74, "dropdown": [74, 126, 137, 164], "checkbox": [74, 148, 163, 172, 173], "on_value_chang": 74, "eigenvector": [74, 116, 138], "imagin": [74, 80, 81, 99, 108, 114, 126, 148, 149, 164, 171, 172, 173, 189, 191, 197, 200], "_geometrical_understanding_interactive_demo": 74, "_differentiation_video": 74, "trusti": 74, "friend": 74, "wikipedia": 74, "nt": [74, 107], "me": 74, "3t": 74, "du": [74, 148], "dv": [74, 75, 76, 88, 146, 147, 148, 149], "u_t": 74, "v_t": [74, 182], "du_dt": 74, "dv_dt": 74, "_derivative_of_the_postsynaptic_potential_alpha_function_exercis": 74, "dr": [74, 105, 148, 155, 157, 174, 188], "da": [74, 175], "expon": [74, 89], "_chain_rule_math_exercis": 74, "hood": 74, "fd": 74, "rightarrow": [74, 76, 97, 108, 125, 138, 149, 156, 157, 172], "accur": [74, 76, 100, 112, 126, 133, 137, 140, 147, 163, 165, 173, 174, 181, 199], "numerical_derivative_demo": 74, "tx": 74, "sine_fun": 74, "diffrenti": 74, "cos_fun": 74, "n_tx": 74, "n_sine_fun": 74, "sine_diff": 74, "ncol": [74, 88, 89, 96, 97, 98, 107, 172, 173, 174, 189, 190, 191], "fancybox": 74, "_numerical_differentiation_of_the_sine_function_interactive_demo": 74, "dc": [74, 107, 148], "eta": [74, 139, 140, 146, 155, 174, 200], "visit": [74, 80], "timestep": [74, 76, 88, 137, 138, 174, 182, 188, 197, 198, 199, 200], "compute_rate_and_gain": 74, "current_timestep": 74, "plot_rate_and_gain": 74, "i_1": [74, 147], "rate_1": 74, "i_2": [74, 147], "rate_2": 74, "input_rang": 74, "output_rang": 74, "ital": 74, "bbox": [74, 172], "pad": [74, 107, 124, 125, 126, 163, 197, 199, 200], "_calculating_the_transfer_function_and_gain_of_a_neuron_interactive_demo": 74, "_functions_of_multiple_variables_video": 74, "inhibitori": [74, 76, 89, 151, 153, 157], "derriv": 74, "multivari": [74, 99, 116, 123, 200], "2xy": 74, "2y": 74, "curvi": 74, "f2d_string": 74, "plot_partial_deriv": 74, "f2d": 74, "f2d_dx": 74, "f2d_dy": 74, "plot3d": 74, "p2": 74, "p3": 74, "jacobian": [74, 156], "_visualize_partial_derivatives_interactive_demo": 74, "_numerical_integration_video": 74, "wish": [74, 96, 99, 148, 171, 200], "rectangl": [74, 175], "approcah": 74, "cut": 74, "stripe": 74, "downsid": 74, "underestim": 74, "overestim": 74, "riemann_sum_demo": 74, "step_siz": [74, 80], "min_val": [74, 175], "max_val": [74, 175], "ftn": 74, "int_ftn": 74, "r_tx": 74, "fun_valu": 74, "r_sum": 74, "cumsum": [74, 116, 138, 139, 164, 171, 175, 182], "lebesgu": 74, "rung": 74, "kutta": 74, "_riemann_sum_vs_analytical_integral_with_changing_step_size_interactive_demo": 74, "68": [74, 87, 148, 182], "incom": [74, 88, 148, 173], "elicit": [74, 148, 149], "tau_": [74, 76, 146, 148, 149, 155, 156, 157], "t_sp": [74, 147, 148, 149], "rectangle_area": 74, "_calculating_charge_transfer_with_excitatory_input_exercis": 74, "_filtering_operations_video": 74, "consequ": [74, 148, 163, 164, 173, 174, 182], "akin": 74, "shock": 74, "absorb": 74, "noise_sign": 74, "wave": 74, "x1_diff": 74, "x1_integr": 74, "sec": [74, 146, 147], "0x7fbf14ebdd30": 74, "amplifi": [74, 153], "suppress": [74, 151, 153], "smooth": [74, 87, 89, 99, 126, 188], "easili": [74, 81, 96, 99, 121, 123, 125, 163, 172, 174, 189], "took": [74, 163, 165, 173, 189, 190], "tradeoff": [74, 101, 108, 189], "trough": 74, "smoothen": 74, "enhanc": 74, "inhibit": [74, 76, 85, 148, 153, 156], "sigmoid_funct": 74, "exc_input": 74, "inh_input": 74, "exc_a": 74, "exc_theta": 74, "inh_a": 74, "inh_theta": 74, "jj": 74, "lg_txt": 74, "ax2": [74, 88, 97, 98, 114, 115, 123, 126, 149, 156, 157, 172, 173, 174, 181, 188, 189, 190], "ax3": [74, 114, 115, 189], "surf": 74, "rstride": 74, "cstride": 74, "viridi": 74, "set_zlabel": 74, "expectedli": 74, "downward": 74, "tediou": [74, 107, 137], "plot_2d_neuron_transfer_funct": 74, "rate_d": 74, "rate_di": 74, "surf1": 74, "exc": [74, 88, 148, 157], "inh": [74, 88, 148], "view_init": 74, "xde": 74, "yde": 74, "surf2": 74, "wrt": 74, "xdi": 74, "ydi": 74, "surf3": 74, "_numerical_partial_derivatives_bonus_discuss": 74, "rebecca": 75, "bradi": 75, "gate": 75, "blood": 75, "nobel": 75, "prize": 75, "hodgkin": [75, 133], "huxlei": [75, 133], "axon": [75, 142], "paradox": [75, 151], "mc": [75, 76], "escher": 75, "paint": 75, "motiv": [75, 76, 87, 105, 201], "raster": [75, 76, 147, 149, 175], "breakdown": 75, "w0d4_t2": 75, "ipd": [75, 76], "gridspec": [75, 76, 163, 182], "plot_dpdt": 75, "birth": [75, 76, 200], "gs": [75, 76, 114, 115, 163, 182], "dpdt": 75, "fucntion": 75, "plot_v_no_input": 75, "v_rang": 75, "dvdt": 75, "hline": [75, 76, 81, 164], "linestyl": [75, 76, 88, 107, 108, 149, 164, 171, 172, 173, 182, 190, 191], "vline": [75, 76, 88, 96, 97, 164, 181], "mv": [75, 76, 146, 147, 148, 149], "plot_if": [75, 76], "height_ratio": [75, 76, 188], "na": [75, 76, 199], "plot_dvdt": 75, "85": [75, 151, 171, 175, 182, 191], "g_l": [75, 146, 147, 148], "exact_integrate_and_fir": 75, "v_exact": 75, "t_isi": [75, 76], "v_th": [75, 76, 146, 147, 148, 149], "_why_do_we_care_about_differential_equations_video": 75, "_population_differential_equation_video": 75, "_interpretating_the_behavior_of_a_linear_population_equation_discuss": 75, "obscur": 75, "p_0": [75, 76], "grow": [75, 121, 137, 139, 155, 157], "declin": 75, "asid": [75, 125], "mathematician": 75, "taunt": 75, "3p": 75, "generaliz": 75, "countri": 75, "transit": [75, 81, 137, 153, 172, 174, 175, 182, 188, 190, 191], "450px": [75, 76, 146, 148], "pop_widget": [75, 76], "_parameter_change_interactive_demo": 75, "simplif": [75, 88], "pronounc": 75, "growth": [75, 76, 87], "extern": [75, 76, 105, 126, 146, 147, 148, 149, 151, 156, 157], "weather": 75, "predat": [75, 126], "prei": [75, 173], "_the_leaky_integrate_and_fire_model_video": 75, "loui": [75, 146], "\u00e9douard": [75, 146], "lapicqu": [75, 76, 142, 146], "1907": [75, 76, 142, 146], "subthreshold": [75, 146], "r_mi": [75, 76], "r_m": [75, 76, 88], "minu": [75, 107, 125, 126, 164], "arrang": [75, 76, 125], "_effect_of_membrane_potential_interactive_demo": 75, "91": [75, 191], "v_reset_widget": 75, "_initial_condition_vreset_interactive_demo": 75, "_the_impact_of_input_interactive_demo": 75, "t_rest": 75, "_adding_firing_to_the_lif_video": 75, "plateau": 75, "isi": [75, 85, 88, 148], "\ud835\udc46\ud835\udc5d\ud835\udc56\ud835\udc58\ud835\udc52": 75, "discontinu": [75, 76], "eleg": [75, 76, 105], "electrophysiologist": [75, 76], "_input_on_spikes_interactive_demo": 75, "exectur": 75, "fi": 75, "i_rang": 75, "spike_r": [75, 148], "weak": [75, 81, 164, 171, 189], "_summary_video": [75, 76, 81, 197, 198, 200], "lotka": [75, 76], "1920": [75, 76], "rhythmic": [75, 76], "inorgan": [75, 76], "410": [75, 76], "415": [75, 76, 151], "brunel": [75, 76, 142, 151, 153], "rossum": [75, 76, 142], "frog": [75, 76, 142], "cybern": [75, 76], "dec": [75, 76], "337": [75, 76, 133, 142], "1007": [75, 76, 83, 103, 133, 142, 177, 193], "s00422": [75, 76, 133, 142], "0190": [75, 76, 142], "epub": [75, 76], "oct": [75, 76], "pmid": [75, 76], "17968583": [75, 76], "2001": [75, 76, 85, 119, 133, 177], "strogatz": [75, 76], "chao": [75, 76, 151], "chemistri": [75, 76], "westview": [75, 76], "press": [75, 76, 83, 87, 92, 103, 119, 133, 142, 151, 159, 177, 184, 188, 193], "lindsai": [75, 76, 119, 151], "bloomsburi": [75, 76], "2004": [75, 76, 92, 103, 107, 142, 148], "sync": [75, 76, 172, 173], "emerg": [75, 76, 83, 119, 133, 147, 190, 195], "penguin": [75, 76], "uk": [75, 76, 92, 103, 119, 159], "joi": [75, 76], "quantamagazin": [75, 76], "tag": [75, 76, 171, 172, 182], "quanta": [75, 76], "magazin": [75, 76], "harvei": [76, 103], "mccone": 76, "odd": [76, 80, 124, 125, 172], "mysteri": 76, "w0d4_t3": 76, "plot_slop": 76, "og": 76, "plot_stepeul": 76, "bo": [76, 146, 147, 149, 155, 156], "t_1": [76, 137], "e_1": 76, "visualize_population_approx": 76, "e_k": 76, "plot_reri": 76, "r_e": [76, 148, 155], "r_i": [76, 125, 157], "plot_reri_simpl": 76, "plot_reri_matrix": 76, "null_r": 76, "null_ri": 76, "_intro_to_numerical_methods_for_differential_equations_video": 76, "leonhard": 76, "1707": [76, 126], "1783": 76, "t_0": [76, 137, 138], "y_0": [76, 174], "_slope_of_a_line_interactive_demo": 76, "p_0e": 76, "pretti": [76, 94, 98, 114, 140, 165, 197, 198, 200], "rearrang": [76, 114], "henc": [76, 80, 81, 149, 171, 197], "_euler_error_of_single_step_interactive_demo": 76, "_taking_more_steps_video": 76, "segment": [76, 96], "t_2": [76, 137], "t_3": 76, "t_4": 76, "times1": 76, "_step_step_step_exercis": 76, "_leaky_integrate_and_fire_video": 76, "v_k": 76, "euler_integrate_and_fir": 76, "esitm": 76, "53": [76, 101, 107, 108, 110, 138, 146, 147, 156, 165, 171, 174, 190, 191, 200], "_lif_and_euler_exercis": 76, "_systems_of_differential_equations_video": 76, "grip": 76, "regul": [76, 177, 198], "dr_e": [76, 148, 157], "ee": [76, 156, 157], "ei": [76, 156, 157], "tau_i": [76, 156, 157], "dr_i": [76, 157], "ie": [76, 107, 148, 155, 156, 157, 182, 200], "timescal": [76, 133, 137, 149, 155, 156, 157, 173, 197, 198, 199, 200], "120": [76, 107, 149, 156], "100m": 76, "120m": 76, "01m": 76, "r_": [76, 88, 147, 155, 188, 189], "euler_simple_linear_system": 76, "_euler_on_a_simple_system_exercis": 76, "_simple_euler_solution_to_the_wilson_cowan_model_discuss": 76, "stabl": [76, 101, 137, 151, 157, 182, 200], "orbit": 76, "_discuss_the_plots_discuss": 76, "57": [76, 83, 107, 126, 138, 146, 156, 157, 171, 190, 191, 200], "re_": 76, "re_k": 76, "ri_k": 76, "ri_": 76, "re_0": 76, "ri_0": 76, "willson": 76, "euler_linear_system_matrix": 76, "w_ee": 76, "n_er": 76, "dre": [76, 155, 156, 157], "n_ir": 76, "dri": [76, 156, 157], "w_ei": 76, "w_ie": 76, "w_ii": 76, "_oscillations_discuss": 76, "62": [76, 81, 126, 151, 155, 171, 190, 191, 198], "maintain": [76, 88, 139, 174, 182], "_small_change_changes_everything_interactive_demo": 76, "k_1": 76, "y_k": 76, "k_2": 76, "k_3": 76, "k_4": 76, "tk_3": 76, "2k_2": 76, "2k_3": 76, "p_": [76, 81, 165, 171, 172, 175, 181], "rk4": 76, "t_fine": 76, "prk4": 76, "dp": [76, 175], "k1": [76, 116], "k2": [76, 116], "k3": 76, "k4": 76, "ro": [76, 80, 149, 156], "entre": 76, "constitut": [76, 195], "essai": [76, 83], "dowl": 76, "florencia": 76, "assaneo": 76, "omega": 76, "x_k": [76, 139, 140], "x_0": [76, 107, 137, 139, 140, 197], "plot_stuart_landa": 76, "width_ratio": [76, 107, 182], "euler_stuart_landau": 76, "lamba": 76, "doell": 76, "perfectli": [76, 125], "lamda": 76, "_oscillator_bonus_interactive_demo": 76, "4hz": 76, "freq": 76, "flash": 76, "50hz": 76, "_stuart_landau_system_bonus_interactive_demo": 76, "e3001234": 76, "pbio": 76, "3001234": 76, "gadget": 78, "w0d5_daysummari": 78, "ulrik": [80, 81], "beierholm": [80, 81], "hyosub": [80, 81, 163, 164], "kim": [80, 81, 133, 163, 164], "previous": [80, 81, 89, 98, 107, 108, 117, 148, 157, 179, 181, 191], "w0d5_t1": 80, "hbox": [80, 81, 163, 164, 172, 173, 175], "vbox": [80, 81, 163, 164, 172, 173, 175], "interact_manu": [80, 81, 189], "plot_random_sampl": 80, "figtitl": [80, 81, 137], "datax": 80, "datai": 80, "plot_random_walk": 80, "plot_hist": [80, 81], "num_bin": [80, 81], "my_plot_singl": 80, "px": [80, 81, 163], "c2": [80, 81, 87, 188], "plot_gaussian_samples_tru": [80, 81], "xspace": [80, 81], "num_sampl": [80, 81, 171], "densiti": [80, 81, 97, 137, 164, 165, 173], "_stochastic_world_video": 80, "bound": [80, 81, 89, 139, 149, 174], "generate_random_sampl": 80, "num_point": [80, 81, 172], "uniformli": [80, 89, 99, 137, 138, 147, 148, 149, 175, 181], "_create_randomness_exercis": 80, "although": [80, 107, 138, 139, 148], "smoothli": [80, 87, 89], "increasingli": [80, 124, 201], "gen_and_plot_random_sampl": 80, "selectionslid": 80, "_random_sample_generation_from_uniform_distribution_interactive_demo": 80, "_random_walk_video": 80, "rat": [80, 81, 133, 171], "generate_random_walk": 80, "enclos": 80, "num_step": 80, "random_x_step": 80, "random_y_step": 80, "restrict": [80, 87, 123, 147, 182], "_modeling_a_random_walk_exercis": 80, "arena": 80, "intslid": [80, 81, 88, 89, 108, 156, 172, 173, 174, 188, 189, 199], "gen_and_plot_random_walk": 80, "_varying_parameters_of_a_random_walk_interactive_demo": 80, "nevertheless": 80, "preview": [80, 81], "_binomial_distribution_video": 80, "bernoulli": [80, 108, 125, 140, 200], "thankfulli": 80, "maze": [80, 81, 190], "food": [80, 81, 126, 139, 181, 188], "mutual": [80, 164], "exclus": [80, 197], "binom": 80, "coeffici": [80, 99, 108, 114, 123, 125, 126, 140, 146, 147, 164, 174, 197, 198, 199, 200], "mass": 80, "sum_k": [80, 148], "n_sampl": [80, 81, 96, 97, 98, 99, 100, 101, 108, 117], "visualis": 80, "left_turn_samples_1000": 80, "_binomial_distribution_sampling_discuss": 80, "p_4": 80, "sum_i": [80, 81, 89, 101, 108, 163, 165, 175], "p_i": [80, 81, 89, 126, 149], "multinomi": 80, "markov": [80, 133, 169, 173, 174, 175, 179, 181, 186, 188], "chain": [80, 96, 123, 157, 172, 174, 175], "_poisson_distribution_video": 80, "encapsul": [80, 81], "sampled_spike_count": 80, "drawn": [80, 81, 97, 123, 126, 139, 172, 182, 189], "_poisson_distribution_sampling_exercis": 80, "asymmetr": [80, 164], "lambda_valu": 80, "gen_and_plot_possion_sampl": 80, "_varying_parameters_of_poisson_distribution_interactive_demo": 80, "typo": [80, 81], "vido": 80, "mu_1": [80, 164], "sigma_1": [80, 114, 164], "mu_2": [80, 164], "sigma_2": [80, 114, 164], "_continuous_distributions_video": 80, "ourselv": [80, 81, 108, 123, 137, 139, 182, 199], "000120141": 80, "believ": [80, 96, 108, 140, 164], "int_": [80, 165, 174], "int_a": 80, "infti": [80, 108, 139, 140, 164, 182, 188], "permit": [80, 164], "my_gaussian": [80, 81, 165], "therefor": [80, 87, 96, 98, 107, 121, 123, 124, 125, 126, 138, 147, 148, 149, 155, 156, 157, 163, 165, 190, 191, 199], "x_point": [80, 81, 165], "normalis": [80, 81], "_gaussian_distribution_exercis": 80, "standard_dev": 80, "gen_and_plot_normal_sampl": 80, "distriut": 80, "everywher": [80, 94, 164, 195, 197], "_sampling_from_a_gaussian_distribution_interactive_demo": 80, "gotten": [80, 140], "textbook": [80, 173], "summaris": 81, "maximis": 81, "w0d5_t2": 81, "default_rng": 81, "plot_likelihood": 81, "mean_val": 81, "variance_v": 81, "va": [81, 108, 163, 197, 198], "set_xtick": [81, 116, 123, 124, 125, 126, 163, 172, 175, 181, 190, 191, 197, 198, 200], "set_ytick": [81, 116, 123, 124, 125, 126, 163, 164, 172, 173, 181, 190, 191], "set_xticklabel": [81, 114, 163, 175, 188, 190, 191, 197, 198, 200], "set_yticklabel": [81, 126, 163, 172, 173, 181, 190, 191], "posterior_plot": 81, "posterior_pointwis": 81, "auditori": 81, "plot_classical_vs_bayesian_norm": 81, "mu_class": 81, "var_class": 81, "mu_bay": 81, "var_bay": 81, "_basic_probability_video": 81, "marginalis": 81, "cap": 81, "summat": [81, 148], "b0": 81, "db": [81, 173], "hubel": [81, 124], "wiesel": [81, 124], "1959": 81, "fiction": 81, "inact": 81, "h_": [81, 124, 125, 174], "h_0": [81, 200], "v_0": 81, "percent": [81, 188, 199], "horizon": [81, 181, 182, 190], "lastli": [81, 195], "latter": 81, "_probability_example_main_exercis": 81, "_markov_chains_video": 81, "memoryless": 81, "freeli": [81, 92, 174], "bright": 81, "state_i": 81, "state_": 81, "determinist": [81, 89, 138, 173, 188, 191], "tt": 81, "jth": 81, "transition_matrix": [81, 182], "p0": [81, 171, 172], "matrix_pow": 81, "p4": 81, "4311": 81, "spent": [81, 138, 139], "implicit": 81, "ergod": 81, "p_random": 81, "p_average_time_sp": 81, "4473": 81, "4211": 81, "1316": 81, "_markov_chains_exercis": 81, "satiat": 81, "tire": 81, "mont": 81, "_statistical_inference_and_likelihood_video": 81, "x_i": [81, 89, 96, 97, 99, 108, 114, 115, 165, 175], "unbias": [81, 195], "x_n": [81, 89, 97], "prod_": [81, 97, 171], "emphas": [81, 146, 163], "logarithm": [81, 89, 97, 126], "compute_likelihood_norm": 81, "standard_dev_v": 81, "p_data": 81, "true_mean": 81, "true_standard_dev": 81, "guess_mean": 81, "guess_standard_dev": 81, "92904": 81, "meaningless": 81, "ry": 81, "initialis": 81, "gvien": 81, "idxmean": 81, "idxvar": 81, "_computing_likelihood_exercis": 81, "_maximum_likelihood_video": 81, "implicitli": [81, 94], "underset": [81, 97, 126, 189], "operatornam": [81, 97, 100, 189], "argmax": [81, 97, 108, 126, 164, 165, 175, 181, 189, 190, 191], "gave": 81, "manual": [81, 126], "bunch": [81, 138, 171], "val": [81, 101, 108], "plotfnc": 81, "loglikelihood": [81, 165], "_maximum_likelihood_inference_interactive_demo": 81, "machin": [81, 92, 100, 103, 105, 108, 112, 116, 119, 123, 124, 126, 133, 140, 173, 174, 177, 189, 191, 195, 199, 201], "minimis": 81, "optimis": 81, "hundr": [81, 87, 123], "negloglik": 81, "bnd": 81, "optimal_paramet": 81, "_minim": 81, "713": 81, "x0": [81, 87, 99, 107, 137, 138, 139, 140, 155, 157], "jac": [81, 155], "hess": 81, "hessp": 81, "tol": [81, 107, 155], "710": 81, "_minimize_newtoncg": 81, "711": 81, "712": 81, "meth": [81, 155], "bfg": 81, "_minimize_lbfgsb": 81, "714": 81, "715": 81, "tnc": 81, "716": 81, "_minimize_tnc": 81, "717": 81, "_lbfgsb_py": 81, "347": [81, 193], "disp": 81, "maxcor": 81, "ftol": 81, "gtol": 81, "maxfun": 81, "maxit": 81, "iprint": 81, "maxl": 81, "finite_diff_rel_step": 81, "unknown_opt": [81, 155], "344": 81, "346": [81, 119], "_prepare_scalar_funct": 81, "sf": [81, 124, 125, 126], "epsilon": [81, 97, 99, 155, 171, 190, 191, 197, 198, 199, 200], "348": 81, "349": 81, "351": 81, "func_and_grad": 81, "fun_and_grad": 81, "353": 81, "fortran_int": 81, "_lbfgsb": 81, "intvar": 81, "_optim": 81, "288": 81, "284": 81, "inf": [81, 155, 175], "286": 81, "scalarfunct": 81, "grad": [81, 123], "287": 81, "289": 81, "291": [81, 119], "_differentiable_funct": 81, "166": 81, "finite_diff_bound": 81, "fun_wrap": [81, 137], "165": 81, "_update_fun_impl": 81, "update_fun": 81, "_update_fun": 81, "callabl": [81, 108], "262": 81, "260": 81, "261": 81, "f_updat": 81, "145": 81, "141": [81, 83, 147], "nfev": [81, 137], "142": 81, "send": [81, 164], "143": [81, 147], "undefin": [81, 89], "144": [81, 126, 165], "fx": 81, "146": 81, "147": 81, "isscalar": 81, "280": 81, "148": 81, "_maximum_likelihood_estimation_exercis": 81, "9547432925098045": 81, "9870331586690259": 81, "theseparamet": 81, "mle": [81, 107, 163], "wiki": 81, "_analytical_solution_exercis": 81, "_bayesian_inference_with_gaussian_distribution_video": 81, "denomin": [81, 101, 198, 199], "classic_vs_bayesian_norm": 81, "mean_class": 81, "mean_bay": 81, "ndata": 81, "random_num_gener": 81, "xsupp": 81, "compris": [81, 123, 124, 125, 126], "benefici": [81, 89, 174], "_bayesian_inference_with_gaussian_distribution_discuss": 81, "_conjugate_priors_video": 81, "binomi": [81, 103, 181], "mathrm": [81, 88, 97, 99, 100, 101, 107, 146, 149, 155, 157], "priorl": 81, "priorr": 81, "numl": 81, "numr": 81, "betapdf": 81, "betaprior": 81, "datapoint": [81, 108], "stabilis": 81, "fluctuat": [81, 142, 146, 148, 149, 157], "willing": 81, "peaki": 81, "conid": 81, "regularis": [81, 199], "badli": 81, "benefit": [81, 181, 191, 200], "_conjugate_priors_interactive_demo": 81, "skeleton": [81, 123], "pointwis": [81, 165], "predefin": 81, "compute_posterior_pointwis": 81, "localization_simul": 81, "mu_auditori": 81, "sigma_auditori": 81, "mu_visu": 81, "sigma_visu": 81, "82": [81, 182, 191], "79": [81, 92, 171], "71": [81, 126, 172, 182, 191], "66": [81, 133, 181, 182, 191], "devot": 81, "_finding_the_posterior_computationally_bonus_exercis": 81, "belief": [81, 161, 173, 189, 190], "frequentist": 81, "paradigm": [81, 188], "aka": [81, 85, 107, 126, 188, 190], "hous": 81, "unreli": [81, 164, 173], "sprinkler": 81, "water": 81, "grass": 81, "rain": 81, "wet": 81, "obvious": [81, 191], "999": [81, 103, 133, 142, 174], "99": [81, 123, 125, 126, 163, 164, 175, 191, 198], "home": 81, "eqnarrai": [81, 137, 146, 148, 149, 164, 165, 174, 175, 182], "pw1r1s1": 81, "pw1r1s0": 81, "pw1r0s1": 81, "pw1r0s0": 81, "ps": [81, 163], "7522": 81, "neighbour": 81, "_bayes_net_bonus_exercis": 81, "stuctur": 81, "_causality_in_the_brain_bonus_discuss": 81, "bassett": 83, "zurn": 83, "566": 83, "578": [83, 151], "s41583": [83, 119], "018": [83, 110, 119, 133, 184, 193], "0038": 83, "postprint": [83, 103, 110, 119, 133, 142, 151, 177, 184, 193], "europepmc": [83, 103, 110, 119, 133, 151, 177, 184], "pmc6466618": 83, "bennett": 83, "hacker": 83, "2003": [83, 92, 142, 151, 159], "philosoph": 83, "foundat": [83, 112, 139, 161, 169, 174, 181, 193, 201], "wilei": 83, "blackwel": 83, "1998": [83, 142, 173, 174], "occam": [83, 92], "razor": [83, 92], "philosophi": 83, "pp": [83, 119, 133, 193], "195": [83, 133], "clarendon": 83, "oxford": [83, 159], "chandrasekhar": 83, "chicago": 83, "chater": 83, "oaksford": 83, "1999": [83, 103], "ration": 83, "trend": [83, 92, 181], "s1364": 83, "6613": 83, "98": [83, 108, 133, 137, 151, 177, 188, 191], "01273": 83, "sejnowski": [83, 151], "1990": 83, "343": 83, "382": [83, 142, 151], "2307": 83, "2214198": 83, "cnl": 83, "salk": 83, "20represent": 83, "20and": 83, "20neural": 83, "20comput": 83, "201990": 83, "3325": 83, "1988": [83, 147], "242": 83, "4879": 83, "741": 83, "745": [83, 174], "3055294": 83, "cichi": [83, 119], "kaiser": 83, "305": 83, "317": 83, "tic": [83, 92], "2005": [83, 103, 142, 171, 184], "feldman": 83, "interdisciplinari": 83, "330": 83, "1002": 83, "wc": 83, "1406": 83, "pmc5125387": 83, "gillett": 83, "cambridg": [83, 92, 142, 151, 159, 193], "goldstein": [83, 119], "e40018": 83, "7554": [83, 92, 103, 133, 151], "40018": 83, "jona": [83, 193], "microprocessor": 83, "e1005268": 83, "1005268": 83, "josephson": 83, "ed": [83, 103, 159], "1996": [83, 133, 142, 151, 159], "abduct": 83, "infer": [83, 87, 92, 96, 97, 98, 99, 100, 101, 103, 116, 117, 121, 133, 159, 161, 163, 169, 171, 173, 174, 175, 179, 181, 186, 193, 197, 201], "technolog": 83, "kaplan": 83, "2011": [83, 103, 159, 167], "synthes": [83, 173], "183": [83, 151, 193], "373": 83, "s11229": 83, "011": [83, 92, 103, 119], "9970": 83, "31219": 83, "3vy69": 83, "lee": 83, "criss": 83, "devez": 83, "donkin": 83, "etz": 83, "leit": 83, "vandekerckhov": 83, "31234": 83, "dmfhk": 83, "lombrozo": 83, "1093": 83, "oxfordhb": 83, "9780199734689": 83, "013": 83, "0014": 83, "marr": 83, "poggio": 83, "1976": [83, 177], "circuitri": 83, "intellig": [83, 119, 186, 188], "laboratori": 83, "memo": 83, "massachusett": 83, "institut": 83, "357": 83, "dspace": [83, 193], "1721": [83, 193], "5782": 83, "parker": 83, "metasci": 83, "vol": [83, 92, 159, 182, 193], "s11016": 83, "9567": 83, "pearl": [83, 193, 195], "mackenzi": [83, 193], "russel": 83, "1917": 83, "mystic": 83, "5962": 83, "bhl": 83, "19230": 83, "archiv": 83, "download": [83, 87, 107, 108, 123, 124, 125, 126, 174], "mysticismlogicot00russiala": 83, "mysticismlogicot00russiala_bw": 83, "simon": 83, "1969": 83, "ma": [83, 92, 159, 174, 177, 182], "trappenberg": 83, "oup": 83, "collin": [83, 92, 133], "e49547": [83, 92], "49547": [83, 92], "w1d1_daysummari": 84, "_day_summari": [84, 93, 104, 111, 120, 128, 134, 143, 178, 185], "meta": [85, 184], "remaind": [85, 129], "compactli": 85, "quantifi": [85, 89, 98, 116, 123, 125, 139, 146, 163, 171, 181, 182, 197, 198, 200], "bay": [85, 105, 159, 161, 169, 171, 179], "quest": 85, "opportun": [85, 129], "t1": [85, 94, 105, 164], "t3": 85, "w1d1_intro": 85, "w1d1_outro": 86, "_outro_video": [86, 95, 165], "laport": [87, 88, 89, 90], "byron": [87, 88, 89, 90, 96, 97, 98, 99, 110, 112, 171, 174, 188, 189, 190, 191], "galbraith": [87, 88, 89, 90, 96, 97, 98, 99, 171, 174, 188, 189, 190, 191], "dalin": [87, 88, 89], "guo": [87, 88, 89], "aishwarya": [87, 88, 89], "balwani": [87, 88, 89], "madineh": [87, 88, 89, 97, 123, 124, 125, 126, 197, 198, 199, 200], "sarvestani": [87, 88, 89, 97, 123, 124, 125, 126, 197, 198, 199, 200], "vaziri": [87, 88, 89, 146, 147, 148, 155, 156, 157], "pashkam": [87, 88, 89, 146, 147, 148, 155, 156, 157], "gagana": [87, 88, 89, 90, 114, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 188, 189, 191, 197, 198, 199, 200], "acknowledg": [87, 89, 96, 107, 108, 174, 175], "flavor": [87, 88, 89, 108], "w1d1_t1": 87, "script": [87, 165], "corner": [87, 191, 198], "keyboard": 87, "shortcut": [87, 129, 191], "cmd": 87, "mac": 87, "ctrl": 87, "bracket": 87, "inlin": [87, 88, 89, 107, 108, 124, 125, 131, 164, 165, 182], "plot_isi": 87, "single_neuron_isi": 87, "axvlin": [87, 88, 96, 97, 98, 125, 149, 156, 164, 165, 182, 191], "durat": [87, 107, 137, 138, 139, 146, 147, 148, 149, 155, 156, 157, 173, 175], "sy5xt": [87, 89], "status_cod": [87, 89, 107, 108, 123, 124, 125, 126, 174], "bytesio": [87, 89, 174], "allow_pickl": [87, 89, 174], "_what_models_video": [87, 137], "probe": [87, 108], "implant": 87, "electrod": [87, 88], "nearbi": 87, "preced": [87, 107, 165, 171, 188], "incomplet": [87, 165, 171, 172], "partli": 87, "undocu": 87, "unfamiliar": 87, "734": 87, "sep": [87, 89], "826": 87, "321": [87, 149], "9723": 87, "i_neuron": 87, "i_print": 87, "slice": [87, 197, 198, 199, 200], "8149": 87, "822467": 87, "9646": 87, "1436": 87, "8709": 87, "0698667": 87, "1536334": 87, "2403667": 87, "7072": 87, "799": 87, "n_neuron": [87, 108, 123, 124, 125, 126, 197, 198, 199, 200], "total_spikes_per_neuron": 87, "spike_times_i": 87, "five": [87, 98, 149, 172, 174], "2818": 87, "3953": [87, 133], "646": 87, "1115": [87, 133, 174], "_exploring_the_dataset_video": 87, "loud": [87, 164, 165], "percentag": [87, 140, 189], "mean_spike_count": 87, "frac_below_mean": 87, "major": [87, 181, 190, 191], "exception": 87, "median_spike_count": 87, "limegreen": [87, 173, 174], "50th": 87, "percentil": [87, 98, 123, 126], "interquartil": 87, "_comparing_mean_and_median_neurons_exercis": 87, "restrict_spike_tim": 87, "inner": 87, "interval_spike_tim": 87, "interval_mask": 87, "t_interv": 87, "original_count": 87, "interval_count": 87, "frac_interval_spik": 87, "ptp": 87, "spike_times_flat": 87, "experiment_dur": 87, "interval_dur": 87, "frac_interval_tim": 87, "neuron_idx": [87, 89, 197, 198, 199, 200], "51": [87, 126, 133, 138, 146, 147, 164, 174, 188, 191, 200], "5th": 87, "_visualizing_activity_video": 87, "energi": [87, 88, 89, 177], "cellular": 87, "machineri": 87, "refractori": [87, 146, 147, 148, 149, 197], "metabol": 87, "longest": 87, "interspik": [87, 89, 146, 149], "compute_single_neuron_isi": 87, "single_neuron_spik": 87, "283": [87, 89, 177], "shorter": [87, 89, 198], "predomin": 87, "rapidli": [87, 88, 107, 157, 173, 191], "absenc": [87, 139], "agre": [87, 125, 140], "domin": [87, 147, 148], "_isis_and_their_distributions_exercis": 87, "_isi_distribution_video": 87, "maxima": [87, 189], "parameter": [87, 97, 123, 155, 181], "offset": [87, 99, 107, 164, 171, 172, 181, 199, 200], "y0": [87, 137], "single_neuron_idx": 87, "c4": 87, "exp_scal": 87, "20000": [87, 107, 188, 200], "250": [87, 101, 116, 139, 146, 181, 199], "exp_rat": 87, "exp_x0": 87, "inv_scal": 87, "3e2": 87, "inv_x0": 87, "lin_slop": 87, "1e5": 87, "6e5": 87, "lin_y0": 87, "4e4": 87, "fit_plot": 87, "2000": [87, 88, 98, 110, 117, 142, 151, 177, 193, 198, 200], "func_param": 87, "fill_between": [87, 88, 89, 164, 171, 173, 181, 182, 198, 199, 200], "_isi_functions_explorer_interactive_demo_and_discuss": 87, "_fitting_models_by_hand_video": 87, "_reflecting_on_what_models_discuss": 87, "poke": 87, "realist": [88, 146, 155, 182, 188, 190], "w1d1_t2": 88, "ax_arg": 88, "duplic": 88, "shade": [88, 89], "drawstyl": [88, 89], "heurist": [88, 105], "ymin": [88, 96, 97, 172], "ymax": [88, 89, 96, 97, 172, 175], "yscale": 88, "autoscal": 88, "plot_neuron_stat": 88, "n_bin": [88, 89, 124, 126], "xmax": [88, 97], "_how_models_video": 88, "discharg": [88, 151], "preserv": [88, 89, 97], "presynapt": [88, 148], "ge": [88, 148, 149], "suitabl": [88, 89, 96], "lif_neuron": 88, "alia": 88, "n_step": [88, 188, 189], "precomput": [88, 108, 117, 174], "_compute_dvm_exercis": 88, "_lif_neuron": 88, "floatlogslid": [88, 174, 189], "plot_lif_neuron": 88, "_linear_if_neuron_interactive_demo_and_discuss": 88, "_linear_if_models_video": 88, "empir": [88, 98, 101, 103, 138, 164, 175], "upon": [88, 125, 173, 179, 188, 189, 191, 197, 201], "tendenc": [88, 139, 200], "steadi": [88, 155, 156, 157], "lambda_": [88, 175], "lif_neuron_inh": 88, "exc_rat": [88, 148], "inh_rat": [88, 148], "_compute_dvm_with_inhibitory_signals_exercis": 88, "_lif_neuron_inh": 88, "_lif_and_inhibition_neuron_interactive_demo_and_discuss": 88, "_lif_and_inhibition_video": 88, "_reflecting_on_how_models_discuss": 88, "c_m": [88, 146], "capacit": [88, 146], "ion": [88, 138, 148, 172], "revert": 88, "insul": 88, "capacitor": 88, "resistor": 88, "millivolt": 88, "megaohm": 88, "w1d1_t3": 89, "plot_pmf": 89, "isi_rang": 89, "pmf_": 89, "steinmetz_spik": 89, "_why_models_video": 89, "consum": [89, 148], "deplet": 89, "replenish": 89, "downstream": [89, 133, 147], "shannon": 89, "h_b": 89, "log_b": [89, 175], "nat": 89, "subdivid": 89, "concentr": [89, 197], "log2": [89, 198], "nan": [89, 126, 146, 191], "convent": [89, 125, 174], "exclud": [89, 101], "2f": [89, 96, 97, 98, 99, 123, 126, 137, 139, 140, 146, 147, 163, 181, 182, 189, 198, 199, 200], "_optimization_and_information_exercis": 89, "log_2": 89, "likewis": [89, 138], "taller": 89, "certainti": [89, 188], "h_2": 89, "_entropy_of_different_distributions_video": 89, "nervou": 89, "budget": 89, "expenditur": 89, "mean_isi": 89, "025": [89, 103, 126, 149], "mean_idx": 89, "searchsort": 89, "pmf_singl": 89, "pmf_uniform": 89, "pmf_exp": 89, "dist": 89, "_probabilities_from_histogram_video": 89, "n_i": 89, "nolimits_": 89, "taken": [89, 123, 125, 147, 155, 174, 181, 182, 186, 189, 190, 191], "pmf_from_count": 89, "_probability_mass_function_exercis": 89, "_calculating_entropy_from_pmf_video": 89, "_pmf_from_count": 89, "_entropi": 89, "steinmetz_pmf": 89, "_entropy_of_neurons_interactive_demo": 89, "_reflecting_on_why_models_discuss": 89, "_summary_of_model_types_video": 89, "congratul": [89, 146, 148, 156, 165, 188], "discov": [89, 119, 124, 126, 174, 181], "closest": [89, 105, 125, 165], "exhibit": [89, 156], "1948": 89, "claud": 89, "began": 89, "subdivis": 89, "i_b": 89, "unsurpris": 89, "prefer": [90, 101, 108, 126, 189], "w1d1_t4": 90, "favorit": [90, 105, 114], "_model_discussions_discuss": 90, "palminteri": 92, "wyart": 92, "koechlin": 92, "falsif": 92, "425": 92, "433": 92, "079798": 92, "bishop": [92, 173, 174], "nasrabadi": 92, "738": 92, "york": [92, 159, 174, 193], "springer": [92, 159, 193], "microsoft": 92, "en": 92, "cmbishop": 92, "mackai": [92, 159], "itprnn": [92, 159], "arlot": 92, "celiss": 92, "1214": 92, "ss054": 92, "acerbi": 92, "lacerbi": 92, "boyd": [92, 99, 107, 182], "vandenbergh": [92, 99, 107], "convex": [92, 96, 97, 105, 107, 123, 175], "stanford": [92, 107, 188], "cvxbook": 92, "motor": [92, 133, 165, 177, 179], "101": [92, 133, 172, 175], "655": 92, "664": 92, "90545": 92, "w1d2_daysummari": 93, "confront": 94, "systemat": [94, 129, 133, 140, 147, 198], "bread": 94, "butter": 94, "zoo": 94, "embodi": [94, 165], "assess": [94, 98, 101, 112, 119, 142], "t2": [94, 105], "w1d2_intro": 94, "w1d2_outro": 95, "pierr": [96, 97, 98, 99, 100, 101, 107, 108], "\u00e9tienn": [96, 97, 98, 99, 100, 101], "fiquet": [96, 97, 98, 99, 100, 101, 107, 108], "anqi": [96, 97, 98, 99, 100, 101, 105], "wu": [96, 97, 98, 99, 100, 101, 167, 181, 182], "hyafil": [96, 97, 98, 99, 100, 101], "lina": [96, 97, 98, 99, 100, 101], "teichmann": [96, 97, 98, 99, 100, 101], "saeed": [96, 98, 99, 163, 164, 165, 181, 182], "salehi": [96, 98, 99, 163, 164, 165, 181, 182], "patrick": [96, 97, 98, 99, 100, 101], "mineault": [96, 97, 98, 99, 100, 101], "bootstrap": [96, 97, 99, 100, 101], "polynomi": [96, 97, 98, 100, 101], "trade": [96, 97, 98, 99, 101, 119, 171, 174, 190], "thank": [96, 99, 107], "eero": 96, "simoncelli": [96, 103, 133], "mathtool": 96, "w1d2_t1": 96, "plot_observed_vs_predict": 96, "y_hat": [96, 98, 99, 100, 101], "theta_hat": [96, 97, 98, 99, 100, 101], "residu": [96, 99, 100, 101, 119, 123], "_mean_squared_error_video": 96, "old": [96, 105, 140], "ls": [96, 146, 148, 149, 156, 164, 165, 171, 181], "suppos": [96, 175, 182, 199, 200], "explanatori": 96, "corrupt": [96, 107, 108, 116, 123, 124, 125, 126, 174], "epsilon_": 96, "synthet": [96, 98, 140, 165], "luxuri": [96, 98], "psuedorandom": [96, 97, 98, 99], "randn": [96, 97, 98, 99, 100, 101, 146, 147, 148, 155, 157, 173, 182, 197], "_compute_mse_exercis": 96, "lowest": [96, 101], "plot_data_estim": 96, "_mse_explorer_interactive_demo_discuss": 96, "landscap": [96, 119, 123], "textrm": [96, 97, 107, 108, 163, 164, 171], "theta_hat_grid": 96, "best_error": 96, "argmin": [96, 125, 164, 165, 182], "theta_": [96, 156, 157], "candid": [96, 171, 174, 181, 191], "solve_normal_eqn": [96, 98], "_solve_for_the_optimal_estimator_exercis": 96, "y_i": [96, 97, 98, 99, 101, 108], "2x_i": [96, 98], "waskomli": 97, "incorpor": [97, 99, 101, 123, 125, 126, 133, 138, 140, 148, 172, 189, 191], "w1d2_t2": 97, "plot_density_imag": 97, "xmin": 97, "wistia": [97, 163], "_maximum_likelihood_estimation_video": 97, "treat": [97, 121, 125, 126, 155, 200], "nuisanc": 97, "plot_normal_dist": 97, "_gaussian_distribution_explorer_interactive_demo_and_discuss": 97, "pair": [97, 105, 110, 117, 123, 125, 126, 140, 147, 149, 156, 157, 163, 164, 188, 190, 191, 197, 200], "invok": [97, 98, 99, 108, 123, 126, 197, 198], "get_ylim": [97, 98, 126, 172, 173, 175], "inher": [97, 174], "11344443599846923": 97, "_likelihood_function_exercis": 97, "joint": [97, 114, 115, 148, 163, 164, 175], "y_n": 97, "arithmet": 97, "underflow": 97, "circumv": 97, "routin": [97, 99, 153, 191], "likelihhood": 97, "remark": [97, 116], "theta_hat_ml": 97, "gaug": 98, "w1d2_t3": 98, "plot_original_and_resampl": 98, "get_xlim": [98, 126, 175], "_confidence_intervals_and_bootstrapping_video": 98, "bradlei": 98, "efron": 98, "epsilon_i": 98, "resample_with_replac": 98, "sample_idx": 98, "_resample_dataset_with_replacement_exercis": 98, "thata_hat": 98, "bootstrap_estim": 98, "123": [98, 156, 177], "27550888": 98, "17317819": 98, "18198819": 98, "25329255": 98, "20714664": 98, "_bootsrap_estimates_exercis": 98, "get_legend_handles_label": 98, "set_alpha": 98, "uncertain": 98, "ci": 98, "reassur": 98, "ag": 98, "trevor": 98, "hasti": [98, 100, 171], "w1d2_t4": 99, "evaluate_fit": 99, "order_list": [99, 101], "mse_list": 99, "plot_fitted_polynomi": 99, "x_grid": 99, "max_ord": [99, 100, 101], "x_design": [99, 100, 101], "univari": 99, "regressor": [99, 107, 199, 200], "theta_0": 99, "theta_1": 99, "theta_2": 99, "theta_d": 99, "x_d": 99, "boldsymbol": [99, 107], "paramt": 99, "ol": 99, "_multiple_linear_regression_and_polynomial_regression_video": 99, "ganglion": [99, 103, 119], "light": [99, 123, 125, 165, 174, 191], "1234": 99, "n_regressor": [99, 100, 101], "ordinary_least_squar": [99, 100, 101], "13861386": 99, "09395731": 99, "16370742": 99, "_ordinary_least_squares_estimator_exercis": 99, "mgrid": [99, 164], "50j": 99, "y_hat_grid": 99, "theta_3": 99, "theta_4": 99, "output_nois": 99, "input_nois": 99, "ldot": [99, 123, 125, 126], "_m": 99, "broadcast": [99, 100, 101], "design_matrix": [99, 100, 101], "51194917": 99, "35259945": 99, "solve_poly_reg": [99, 100, 101], "this_theta": [99, 100, 101], "lapack": 99, "stephen": [99, 107, 133, 182], "lieven": [99, 107], "w1d2_t5": 100, "plot_mse_poly_fit": 100, "mse_train": 100, "mse_test": 100, "held": [100, 101, 123], "_bias_variance_tradeoff_video": 100, "n_train_sampl": [100, 101], "n_test_sampl": [100, 101], "overli": [100, 193], "underfit": [100, 101], "overfit": [100, 101, 105, 123, 126, 140], "fortmann": 100, "roe": 100, "biasvari": 100, "metric": [100, 117, 125, 193, 197], "t4": 100, "port": 100, "evaluate_poly_reg": [100, 101], "evalute_poly_reg": 100, "compute_ms": 100, "_compute_train_vs_test_error_exercis": 100, "strike": 100, "modern": 100, "tibshirani": 100, "friedman": [100, 197, 198, 199, 200], "_proof_bias_variance_for_mse_bonus_exercis": 100, "w1d2_t6": 101, "kfold": 101, "plot_cross_validate_ms": 101, "mse_al": 101, "k_fold": 101, "n_split": 101, "plot_aic": 101, "aic_list": 101, "_crossvalidation_video": 101, "commonli": [101, 108, 123, 125, 126, 139, 164], "hasn": [101, 108, 189], "reassign": 101, "fold": [101, 108, 119], "divis": [101, 125], "sacrif": 101, "preciou": 101, "consensu": 101, "former": 101, "cross_valid": 101, "wrongli": 101, "kfold_iter": 101, "i_split": 101, "train_indic": 101, "val_indic": 101, "x_cv_train": 101, "y_cv_train": 101, "x_cv_val": 101, "y_cv_val": 101, "mse_this_split": 101, "_implement_cross_validation_exercis": 101, "strive": 101, "2k": 101, "plug": [101, 108, 123, 155], "cancel": [101, 147, 171], "sse": 101, "this_aic": 101, "_compute_aic_bonus_exercis": 101, "gerwinn": 103, "bethg": [103, 119], "mack": [103, 107, 108], "seeger": 103, "neurip": 103, "cc": [103, 119, 147, 167], "hash": [103, 119, 167], "46ba9f2a6976570b0353203ec4474217": 103, "glaser": 103, "farhoodi": [103, 123, 124, 125, 126, 181, 182], "supervis": [103, 107, 108, 119], "neurobiolog": [103, 110, 142, 184], "175": 103, "126": 103, "137": [103, 147], "pneurobio": 103, "pmc8454059": 103, "chowdhuri": 103, "perich": 103, "0506": 103, "hardcastl": 103, "maheswaranathan": [103, 119], "ganguli": [103, 119, 133], "giocomo": 103, "multiplex": 103, "heterogen": 103, "medial": 103, "entorhin": 103, "375": 103, "latim": [103, 167], "riek": 103, "pillow": [103, 107, 133, 167], "e47012": 103, "47012": 103, "bues": 103, "cunningham": [103, 110, 133], "yu": [103, 110, 112, 133], "shenoi": [103, 133], "sahani": [103, 133], "nip": [103, 119, 167], "7143d7fbadfa4693b9eec507d9d37443": 103, "kastner": 103, "baccu": [103, 119], "multilay": [103, 119], "e1006291": 103, "1006291": 103, "mccullagh": 103, "nelder": 103, "1989": [103, 171, 188, 190], "chapman": [103, 159], "hall": [103, 159], "london": 103, "mcfarland": 103, "cui": 103, "butt": 103, "e1003143": 103, "1003143": 103, "paninski": [103, 119, 133, 142, 151], "cascad": 103, "243": 103, "0954": 103, "898x": 103, "panzeri": 103, "piasini": 103, "latham": 103, "fellin": 103, "crack": 103, "intervent": [103, 193, 198, 200], "491": [103, 159, 193], "507": 103, "036": 103, "park": [103, 105], "covari": [103, 105, 114, 116, 119, 147, 173, 174, 182, 199, 200], "6395ebd0f4b478145ecfbaf939454fa4": 103, "e1002219": 103, "1002219": 103, "meister": 103, "huk": [103, 167, 171], "pariet": 103, "sensorimotor": [103, 110], "1395": 103, "1403": 103, "3800": 103, "pmc4176983": 103, "uzzel": [103, 107], "chichilniski": [103, 107, 133], "11003": 103, "11013": 103, "jneurosci": [103, 119, 142, 147, 151, 177], "3305": 103, "shlen": [103, 110, 133], "sher": [103, 119, 133], "litk": [103, 119, 133], "spatio": [103, 119, 133], "454": [103, 133], "7207": [103, 133], "995": [103, 133], "nature07140": [103, 133], "pmc2684455": [103, 133], "b55ec28c52d5f6205684a473a2193564": 103, "1404": [103, 110], "schwartz": 103, "327": 103, "gazzaniga": 103, "iii": 103, "stevenson": 103, "obi": [103, 110], "sach": 103, "reimer": 103, "englitz": 103, "e1002775": 103, "1002775": 103, "truccolo": 103, "eden": [103, 159, 193], "fellow": 103, "donoghu": [103, 167], "extrins": [103, 116], "1074": 103, "1089": [103, 177], "00697": 103, "vidn": 103, "ahmadian": [103, 151], "s10827": 103, "0376": 103, "pmc3560841": 103, "weber": 103, "repertoir": [103, 144], "3260": 103, "3289": 103, "1162": [103, 119, 151], "neco_a_01021": 103, "1602": 103, "07389": 103, "zhao": 103, "iyengar": 103, "nonconverg": 103, "1231": 103, "1244": 103, "neco": 103, "982": 103, "w1d3_daysummari": 104, "unifi": [105, 142, 151, 173, 174], "swiss": 105, "armi": 105, "knife": 105, "intent": 105, "spot": [105, 140, 197], "protect": 105, "l1": [105, 108, 126], "reverend": 105, "christina": 105, "savin": [105, 174], "canon": [105, 188], "she": [105, 144, 148, 153], "qu": 105, "prof": 105, "georgia": 105, "tech": 105, "mem": [105, 148], "cat": [105, 124, 179, 182], "he": [105, 112, 119, 140, 144, 153], "danger": [105, 164, 181, 182, 191], "touch": [105, 123], "readout": [105, 147], "w1d3_intro": 105, "_day_intro": 105, "w1d3_outro": 106, "_day_outro": 106, "etienn": [107, 108], "ari": [107, 108, 197, 198, 199, 200], "jakob": [107, 108], "david": [107, 108, 159], "valeriani": [107, 108], "alish": [107, 108], "dipani": [107, 108], "ej": 107, "permiss": 107, "jonathan": 107, "w1d3_t1": 107, "loadmat": 107, "plot_stim_and_spik": 107, "stim": [107, 174], "intens": 107, "ax_stim": 107, "ax_spik": 107, "nrow": [107, 188, 190, 191], "plot_glm_matric": 107, "boundarynorm": 107, "axes_grid1": [107, 197, 200], "make_axes_locat": [107, 197, 200], "skinni": 107, "ax_x": [107, 163, 164], "ax_i": [107, 163, 164], "gridspec_kw": [107, 188], "imx": 107, "pcolormesh": 107, "setp": 107, "visibl": [107, 148, 159], "divx": 107, "caxx": 107, "append_ax": [107, 197, 200], "cbarx": 107, "cax": [107, 123, 124, 126, 197, 200], "set_tick": 107, "set_ticklabel": 107, "imi": 107, "magma": 107, "invert_yaxi": [107, 165], "divi": 107, "caxi": 107, "cbari": 107, "plot_spike_filt": 107, "gca": [107, 124, 125, 126, 175, 197, 198, 199], "axhlin": [107, 108, 146, 148, 165, 188], "plot_spikes_with_predict": 107, "predicted_spik": 107, "t0": [107, 137], "stem": [107, 108, 188], "set_zord": [107, 126], "setdefault": [107, 155], "yhat": 107, "maxnloc": 107, "hashlib": [107, 108, 123, 124, 125, 126, 174], "fname": [107, 108, 123, 124, 125, 126, 174], "rgcdata": 107, "mat": [107, 108], "mzuj": 107, "expected_md5": [107, 108, 123, 124, 125, 126, 174], "1b2977453020bce5319f2608c94d38d0": 107, "connectionerror": [107, 108, 123, 124, 125, 126, 174], "md5": [107, 108, 123, 124, 125, 126, 174], "hexdigest": [107, 108, 123, 124, 125, 126, 174], "wb": [107, 108, 123, 124, 125, 126, 174], "fid": [107, 108, 123, 124, 125, 126, 174], "_linear_gaussian_model_video": 107, "lumin": 107, "rgc": 107, "flicker": 107, "120hz": 107, "144051": 107, "spcount": 107, "dtstim": 107, "dt_stim": 107, "cellnum": 107, "keep_timepoint": 107, "ij": [107, 115, 124, 125, 126, 147, 172, 175, 197], "onset": 107, "padded_stim": 107, "_create_design_matrix_exercis": 107, "augment": 107, "column_stack": [107, 114, 115], "lg": 107, "theta_lg": 107, "predict_spike_counts_lg": 107, "predicted_count": 107, "_predict_counts_with_linear_gaussian_model_exercis": 107, "bump": [107, 164], "troublingli": 107, "failur": [107, 199], "subcas": 107, "sta": 107, "statement": [107, 181, 197, 200], "_bonus_challenge_act": 107, "_generalized_linear_model_video": 107, "unfortun": [107, 163, 200], "stuck": [107, 189], "chord": 107, "4g": 107, "566e": 107, "88846e": 107, "bear": 107, "emphasi": 107, "moment": [107, 133, 138, 148, 188, 191], "start_point": 107, "mew": 107, "lnp": 107, "mid": [107, 165, 172, 197, 199], "sum_t": [107, 181], "y_t": [107, 174, 175, 200], "x_t": [107, 172, 175, 197, 198], "lambda_t": 107, "neg_log_lik_lnp": 107, "loglik": 107, "log_lik": 107, "fit_lnp": 107, "minmiz": 107, "theta_lnp": 107, "59": [107, 126, 171, 190, 191, 198], "_fitting_the_poisson_glm_exercis": 107, "broadli": [107, 186, 188], "predict_spike_counts_lnp": 107, "_predict_spike_counts_exercis": 107, "_predict_spike_counts_bonu": 107, "oftentim": 108, "awak": [108, 121], "asleep": 108, "car": 108, "bu": 108, "choi": 108, "hyperparamet": [108, 123, 188, 199, 200], "w1d3_t2": 108, "plot_weight": [108, 124, 126], "atleast_1d": [108, 155], "set_mark": 108, "c3": 108, "plot_model_select": 108, "c_valu": 108, "set_xscal": 108, "best_c": 108, "1g": 108, "plot_non_zero_coef": 108, "non_zero_l1": 108, "n_voxel": 108, "r9gh8": 108, "w1d4_steinmetz_data": 108, "npz": [108, 123, 124, 125, 126, 174], "d19716354fed0981267456b80db07ea8": 108, "load_steinmetz_data": 108, "data_fnam": [108, 174], "dobj": [108, 123, 124, 125, 126, 174], "_logistic_regression_video": 108, "coinflip": 108, "squash": [108, 125, 197], "Its": [108, 125, 164], "_implement_the_sigmoid_function_exercis": 108, "wheel": 108, "gabor": [108, 124, 125, 126], "kordinglab": 108, "nogo": 108, "n_trial": [108, 147, 175, 188, 189, 198, 199, 200], "0s": [108, 197], "1s": [108, 197], "276": 108, "691": 108, "n_featur": [108, 117], "log_reg": 108, "rerun": [108, 117, 126], "trust": [108, 117], "unabl": [108, 117, 157, 199], "nbviewer": [108, 117], "nbsp": [108, 117], "logisticregressionifittedlogisticregress": 108, "score": [108, 115, 116, 117, 119, 123, 124, 126], "compute_accuraci": 108, "train_accuraci": 108, "_classifier_accuracy_video": 108, "idiosyncrat": 108, "justcv": 108, "brief": [108, 157, 198, 201], "tini": 108, "_regularization_video": [108, 126], "priori": 108, "idiosyncraci": 108, "ridg": 108, "beta2": 108, "theta_i": [108, 156, 157], "unregular": 108, "log_reg_l2": 108, "log_c_step": 108, "penalized_model": 108, "log_c": 108, "max_it": [108, 199, 200], "5000": [108, 138, 139, 188, 197, 198, 199, 200], "plot_observ": [108, 199, 200], "frac1": 108, "lasso": [108, 200], "log_reg_l1": 108, "ugli": [108, 184], "warn": [108, 126, 163, 164, 181, 188], "spars": [108, 117, 151, 197, 198, 199, 200], "unpack": 108, "dens": 108, "m_spars": 108, "text_kw": 108, "iter_part": 108, "1f": [108, 114, 115, 139, 140, 146, 149, 155, 157], "count_non_zero_coef": 108, "non_zero_coef": 108, "coef": 108, "non_zero": 108, "logspac": [108, 171], "_effect_of_l1_on_sparsity_exercis": 108, "bigger": [108, 123, 198], "sparser": [108, 126], "thalamu": 108, "carri": [108, 115, 123, 188], "scheme": [108, 125, 137, 146, 149], "acc": 108, "_model_selection_exercis": 108, "poorli": [108, 117, 123, 200], "risk": [108, 119, 163, 189, 191], "ny_i": 108, "fresh": [108, 173], "proper": [108, 157, 201], "1708": [108, 126], "00909": 108, "1100": 110, "hyvarinen": 110, "oja": 110, "411": 110, "430": [110, 151], "s0893": 110, "6080": 110, "00026": 110, "cse": 110, "msu": 110, "cse902": 110, "s03": 110, "icasurvei": 110, "gilli": 110, "nonneg": 110, "1401": 110, "5226": 110, "coenen": 110, "pearc": 110, "wattenberg": [110, 117], "viega": 110, "johnson": [110, 133], "distil": [110, 117, 119], "23915": [110, 119], "00002": 110, "1500": 110, "1509": 110, "3776": 110, "pmc4433019": 110, "golub": [110, 133], "chase": [110, 164], "batista": 110, "dissect": [110, 119], "opinion": [110, 142, 184], "58": [110, 126, 146, 190, 198, 200], "conb": [110, 142, 184], "sadtler": 110, "ryu": [110, 133], "tyler": 110, "kabara": 110, "reassoci": 110, "607": 110, "s41593": [110, 119, 184], "0095": 110, "pmc5876156": 110, "512": 110, "7515": 110, "423": 110, "426": 110, "nature13665": 110, "pmc4393644": 110, "w1d4_daysummari": 111, "orthonorm": [112, 115, 116], "constantli": [112, 155, 182], "w1d4_intro": 112, "_intro": [112, 121], "w1d4_outro": 113, "_outro": 113, "cayco": [114, 115, 116, 117], "gajic": [114, 115, 116, 117], "roozbeh": [114, 115, 116, 117, 123, 124, 125, 126, 181, 182], "farhoudi": [114, 115, 116, 117], "kraus": [114, 115, 116, 117, 137, 138, 139, 140, 146, 147, 148, 149, 165, 171, 172, 174, 175, 181, 182, 188, 189, 190, 191], "w1d4_t1": 114, "plot_data": [114, 115], "bivari": [114, 115, 200], "add_gridspec": [114, 115], "markerfacecolor": [114, 115], "markeredgewidth": [114, 115, 147, 148, 149], "corr": [114, 115, 147, 163, 164, 197, 198, 199, 200], "corrcoef": [114, 115, 125, 197, 198, 199, 200], "plot_basis_vector": [114, 115], "plot_data_new_basi": [114, 115], "ascend": [114, 115], "_geometric_view_of_data_video": 114, "mu_i": [114, 147, 164], "sigma_i": [114, 147, 164], "rho": [114, 163, 164, 182], "cov": [114, 115, 125, 147, 163, 173, 174, 182, 200], "bf": [114, 115, 116, 137, 182], "pmatrix": [114, 172], "diagon": [114, 125, 175], "_multivariate_data_video": 114, "get_data": [114, 115, 123, 126], "cov_matrix": [114, 115, 116], "multivariate_norm": [114, 115, 164, 174, 197, 198, 199, 200], "indices_for_sort": [114, 115], "argsort": [114, 115, 116, 126], "calculate_cov_matrix": [114, 115], "var_1": [114, 115], "var_2": [114, 115], "corr_coef": [114, 115, 125], "variance_1": [114, 115], "variance_2": [114, 115], "_draw_samples_from_a_distribution_exercis": 114, "cloud": 114, "_calculate_cov_matrix": 114, "visualize_correlated_data": 114, "_correlation_effect_on_data_interactive_demo_and_discuss": 114, "_orthonormal_bases_video": 114, "u_1": 114, "u_2": 114, "w_2": 114, "orthogon": [114, 115, 116], "define_orthonormal_basi": [114, 115], "orthonom": 114, "_find_an_orthonormal_basis_exercis": 114, "_change_of_basis_video": 114, "change_of_basi": [114, 115, 116], "_change_to_orthonormal_basis_exercis": 114, "uncorrel": [114, 115, 149, 200], "tan": 114, "_play_with_basis_vectors_interactive_demo_and_discuss": 114, "mixtur": [114, 148], "decorrel": 114, "beautifulli": [115, 193], "w1d4_t2": 115, "plot_eigenvalu": [115, 116], "scree": 115, "sort_evals_descend": [115, 116], "evector": [115, 116], "_pca_video": 115, "sigma_": [115, 146, 147, 155, 163, 164, 165, 173], "x_j": 115, "n_": 115, "_j": 115, "get_sample_cov_matrix": [115, 116], "sample_cov_matrix": 115, "99315313": 115, "82347589": 115, "01281397": 115, "_calculate_the_covariance_matrix_exercis": 115, "eigh": [115, 116], "descend": [115, 123], "_eigenvectors_of_the_covariance_matrix_exercis": 115, "_pca_implementation_exercis": 115, "_exploration_of_the_correlation_coefficient_interactive_demo_and_discuss": 115, "lose": [115, 163], "_properties_of_pca_bonus_video": 115, "w1d4_t3": 116, "plot_variance_explain": 116, "variance_explain": 116, "plot_mnist_reconstruct": 116, "x_reconstruct": 116, "keep_dim": 116, "tick_param": [116, 173, 175, 181, 197, 198], "labelbottom": 116, "clim": [116, 117], "plot_mnist_sampl": 116, "plot_mnist_weight": 116, "seismic": 116, "add_nois": 116, "frac_noisy_pixel": 116, "x_noisi": 116, "n_noise_ix": 116, "noise_ix": 116, "_pca_for_dimensionality_reduction_video": 116, "unravel": 116, "nine": 116, "parser": [116, 117], "elbow": 116, "_scree_plot_of_mnist_exercis": 116, "lambda_i": [116, 175], "get_variance_explain": 116, "csum": 116, "_plot_the_explained_variance_exercis": 116, "_data_reconstruction_video": 116, "reconstruct_data": 116, "x_mean": 116, "_data_reconstruction_exercis": 116, "_reconstruct_the_data_matrix_using_different_numbers_of_pcs_interactive_demo_and_discuss": 116, "100th": 116, "500th": 116, "700th": 116, "_visualization_of_the_weights_exercis": 116, "inflat": 116, "implic": [116, 148], "salt": 116, "pepper": 116, "score_noisi": 116, "evectors_noisi": 116, "evals_noisi": 116, "variance_explained_noisi": 116, "_add_noise_to_the_data_bonus_exercis": 116, "x_noisy_mean": 116, "projx_noisi": 116, "_denoising_bonus_exercis": 116, "w1d4_t4": 117, "visualize_compon": 117, "component1": 117, "component2": 117, "categori": [117, 124, 144], "_pca_applications_video": 117, "reload": 117, "x_all": 117, "labels_al": 117, "pca_model": 117, "pcaifittedpca": 117, "_base": 117, "_pca": 117, "x_new": 117, "_visualization_of_mnist_in_2d_using_pca_exercis": 117, "_pca_visualization_discuss": 117, "_nonlinear_methods_video": 117, "manifold": [117, 125], "tsne_model": 117, "fit_transform": [117, 125], "_t_sne": 117, "csr": 117, "csc": 117, "coo": 117, "barnes_hut": 117, "emb": 117, "_apply_tsne_on_mnist_exercis": 117, "explore_perplex": 117, "perp": 117, "redefin": 117, "_run_tsne_with_different_perplexities_exercis": 117, "_tsne_visualization_discuss": 117, "openreview": 119, "id": [119, 147, 149, 174], "bjjsrmfcz": 119, "lillicrap": 119, "beaudoin": 119, "bogacz": 119, "christensen": 119, "1761": 119, "1770": 119, "0520": 119, "ncbi": [119, 133, 177], "nlm": [119, 133, 177], "nih": [119, 133, 177], "gov": [119, 133, 177], "pmc": [119, 133, 177], "pmc7115933": 119, "convolut": [119, 121], "2031": 119, "jocn_a_01544": 119, "07092": 119, "dnn": 119, "khosla": [119, 172, 175], "torralba": 119, "hierarch": [119, 124], "srep27755": 119, "hasson": 119, "nastas": 119, "evolutionari": 119, "105": [119, 133, 156], "416": 119, "434": 119, "heuer": 119, "gulban": 119, "bazin": 119, "osoianu": 119, "valabregu": 119, "santin": 119, "toro": 119, "neocort": [119, 142, 146, 148], "phylogenet": 119, "primat": [119, 124, 133], "speci": [119, 171], "04": [119, 151, 167, 199, 200], "zhou": 119, "lapedriza": 119, "detector": 119, "cnn": 119, "iclr": 119, "san": 119, "diego": 119, "ca": 119, "usa": 119, "1412": 119, "6856": 119, "bau": 119, "ieee": [119, 133, 177], "transact": [119, 133, 177], "2131": 119, "2145": 119, "1109": [119, 133, 177], "tpami": 119, "2858759": 119, "stringer": [119, 123, 124, 125, 126], "e15": 119, "679324": 119, "merel": 119, "brackbil": 119, "heitman": 119, "recurr": [119, 133, 157], "toulon": 119, "franc": 119, "hkei22jeg": 119, "cadena": 119, "denfield": 119, "walker": [119, 190], "gati": 119, "tolia": 119, "ecker": 119, "macaqu": 119, "e1006897": 119, "1006897": 119, "mcintosh": 119, "nayebi": 119, "a1d33d0dfec820b41b54430b50e96b5c": 119, "sinz": 119, "cobo": 119, "muhammad": 119, "froudaraki": 119, "fahei": 119, "incept": 119, "2060": 119, "2065": 119, "0517": 119, "guclu": 119, "gerven": 119, "stream": [119, 169, 174, 189], "10005": 119, "10014": 119, "5023": 119, "khaligh": 119, "razavi": 119, "unsupervis": [119, 133, 147, 149], "IT": [119, 124], "e1003915": 119, "1003915": 119, "mohsenzadeh": [119, 125], "mullin": 119, "lahner": 119, "peripheri": 119, "s41598": 119, "020": 119, "61409": 119, "yamin": 119, "hong": 119, "cadieu": 119, "solomon": 119, "seibert": 119, "dicarlo": 119, "8619": 119, "8624": 119, "1403112111": 119, "pmc4060707": 119, "goh": 119, "e6": 119, "00006": 119, "ren": 119, "770": 119, "778": 119, "ieeexplor": 119, "stamp": 119, "jsp": 119, "arnumb": 119, "7780459": 119, "ioff": 119, "szegedi": 119, "448": [119, 147], "456": 119, "pmlr": 119, "mlr": 119, "v37": 119, "ioffe15": 119, "xu": [119, 177], "taylor": 119, "studer": 119, "a41b3bb3e6b050b6c9067c67f663b915": 119, "neuralnetworksanddeeplearn": 119, "chap4": 119, "olah": 119, "conv": [119, 124, 125, 126, 190, 191], "modular": 119, "colah": 119, "jozwik": 119, "storr": 119, "outperform": 119, "1726": [119, 151], "fpsyg": 119, "01726": 119, "dougla": 119, "1148": 119, "1160": 119, "0210": 119, "pmc6706072": 119, "kietzmann": 119, "spoerer": 119, "s\u00f6rensen": 119, "hauk": 119, "116": [119, 126, 133, 142], "21854": 119, "21863": 119, "1905544116": 119, "kubiliu": 119, "schrimpf": 119, "kar": 119, "rajalingham": 119, "majaj": 119, "nips2019": 119, "santoro": 119, "marri": 119, "akerman": 119, "hinton": 119, "335": 119, "0277": 119, "ora": 119, "ox": 119, "ac": 119, "uuid": 119, "862189c1": 119, "0088": 119, "4f78": 119, "b17a": 119, "2748c2019209": 119, "download_fil": 119, "safe_filenam": 119, "lillicrap_v6_2020": 119, "file_format": 119, "type_of_work": 119, "nili": 119, "wingfield": 119, "walther": 119, "su": 119, "marslen": 119, "e1003553": 119, "1003553": 119, "issa": 119, "407007": 119, "mehrer": 119, "charest": 119, "e1008215": 119, "1008215": 119, "inferior": 119, "2044": 119, "2064": 119, "jocn_a_01755": 119, "ubn": 119, "ru": 119, "nl": 119, "bitstream": [119, 193], "2066": 119, "237374": 119, "tang": 119, "lotter": 119, "moerman": 119, "pared": 119, "caro": 119, "kreiman": 119, "8835": 119, "8840": 119, "1719397115": 119, "chamber": 119, "seethapathi": 119, "saluja": 119, "loeb": 119, "pierc": 119, "bogen": 119, "infant": [119, 121, 200], "neuromotor": 119, "rehabilit": 119, "2431": 119, "2442": 119, "tnsre": 119, "3029121": 119, "pmc8011647": 119, "w1d5_daysummari": 120, "aud": [121, 124], "propag": [121, 123, 144, 172, 174], "caveat": 121, "taskonomi": 121, "reward": [121, 184, 186, 190, 191], "w1d5_intro": 121, "w1d5_outro": 122, "_outro_video1": 122, "_outro_video2": 122, "jorg": [123, 124, 125, 126], "menendez": [123, 124, 125, 126], "carsen": [123, 124, 125, 126], "thrive": 123, "w1d5_t1": 123, "mpl": [123, 124, 125, 126, 165], "plot_data_matrix": [123, 126], "plot_train_loss": 123, "train_loss": [123, 126], "load_data": [123, 125, 126], "data_nam": [123, 124, 125, 126], "bin_width": [123, 125, 126], "679324v2": [123, 124, 125, 126], "calcium": [123, 124, 125, 126, 148, 175], "smoother": [123, 125, 126, 146, 174], "resp": [123, 125, 126], "n_stimuli": [123, 124, 125, 126], "mention": [123, 124, 125, 126, 146, 147, 148, 174, 175], "360": [123, 125, 126], "stimuli_bin": [123, 125, 126], "resp_bin": [123, 125, 126], "resp_tensor": [123, 125, 126], "stimuli_tensor": [123, 124, 125, 126], "unsqueez": [123, 124, 125, 126], "singleton": [123, 125, 126, 175], "n_stim": [123, 126], "train_data": [123, 125, 126], "train_label": [123, 125, 126], "radian": [123, 124, 125, 126], "istim": [123, 126], "ori": [123, 124, 125, 126], "w3d4_stringer_oribinned1": [123, 125, 126], "683xc": [123, 125, 126], "436599dfd8ebe6019f066c38aed20580": [123, 125, 126], "_decoding_from_neural_data_video": 123, "front": 123, "photon": 123, "thousand": 123, "24000": 123, "circ": [123, 126], "resp_al": [123, 126], "stimuli_al": [123, 126], "ineuron": [123, 125, 126], "stimuli_train": [123, 126], "resp_train": [123, 124, 126], "stimuli_test": [123, 126], "resp_test": [123, 124, 126], "ishuffl": [123, 125, 126], "randperm": [123, 125, 126], "itrain": [123, 126], "itest": [123, 126], "entail": 123, "r_n": 123, "infrastructur": 123, "deepnet": 123, "declar": [123, 124], "in_lay": [123, 126], "out_lay": [123, 126], "sent": [123, 190], "_nonlinear_activation_functions_video": 123, "relu": [123, 124, 125, 126, 155], "sole": 123, "tanh": [123, 155], "rectif": 123, "ctifi": 123, "inear": 123, "nit": 123, "nonsens": 123, "1532": [123, 126], "_wrapped_call_impl": [123, 126], "1530": [123, 126], "_compiled_call_impl": [123, 126], "misc": [123, 126], "1531": [123, 126], "_call_impl": [123, 126], "1541": [123, 126], "1536": [123, 126], "hook": [123, 125, 126], "1537": [123, 126], "1538": [123, 126], "_backward_hook": [123, 126], "_backward_pre_hook": [123, 126], "_forward_hook": [123, 126], "_forward_pre_hook": [123, 126], "1539": [123, 126], "_global_backward_pre_hook": [123, 126], "_global_backward_hook": [123, 126], "1540": [123, 126], "_global_forward_hook": [123, 126], "_global_forward_pre_hook": [123, 126], "forward_cal": [123, 126], "1543": [123, 126], "1544": [123, 126], "139": 123, "_nonlinear_activations_exercis": 123, "_loss_functions_and_gradient_descent_video": 123, "nowher": 123, "shortli": [123, 124, 149, 188], "y_p": 123, "42949": 123, "dw": [123, 149], "accordingli": [123, 126, 139, 148, 157], "realiti": 123, "rocki": 123, "gif": [123, 124], "blob": 123, "grad_desc": 123, "lr": [123, 125, 126], "blank": 123, "learning_r": [123, 125, 126], "67": [123, 126, 172, 181, 182, 191], "_gradient_descent_in_pytorch_exercis": 123, "monkei": [123, 171, 175], "xor": [123, 181], "drastic": 123, "neat": 123, "truli": [123, 140, 190], "said": [123, 124, 138], "prone": 123, "rescu": 123, "leftarrow": [123, 188, 189, 190, 200], "minima": [123, 165, 189], "odot": [123, 165], "prime": 123, "hadamard": [123, 165], "elementwis": [123, 172], "infeas": [123, 175, 200], "bypass": 123, "demand": 123, "subsampl": [123, 199], "induc": [123, 148, 149, 198], "whatev": 123, "suffic": 123, "w1d5_t2": 124, "show_stimulu": [124, 125], "img": [124, 125, 174], "conv_channel": [124, 126], "wmax": [124, 126], "cb_ax": 124, "add_ax": [124, 126, 163, 164], "plot_example_activ": 124, "load_data_split": [124, 126], "imaging": [124, 125, 126], "repsons": [124, 126], "resp_train_tensor": [124, 126], "resp_test_tensor": [124, 126], "out_channel": [124, 125, 126], "wide_gaussian": [124, 125, 126], "center_surround": [124, 125, 126], "lam": [124, 125, 126, 137, 138, 139, 140], "newaxi": [124, 125, 126, 140, 175, 190, 191], "640": [124, 125, 126], "480": [124, 125, 126], "deg2rad": [124, 125, 126], "wpix": [124, 125, 126], "hpix": [124, 125, 126], "xcent": [124, 125, 126], "ycent": [124, 125, 126], "xxc": [124, 125, 126], "yyc": [124, 125, 126], "icirc": [124, 125, 126], "w3d4_stringer_oribinned6_split": [124, 126], "p3aeb": [124, 126], "b3f7245c6221234a676b71a1f43c3bb5": [124, 126], "slid": 124, "k_x": 124, "k_y": 124, "miro": 124, "medium": 124, "5bwzuqaqffp5f3wkyq6wjg": 124, "_2d_convolutions_video": 124, "revolution": 124, "alexnet": 124, "depict": 124, "downsampl": 124, "attach": [124, 125, 126, 173], "proxim": 124, "stride": [124, 126], "convolutionallay": 124, "conv2d": [124, 125, 126], "barrel": 124, "whisker": 124, "unsolv": 124, "advent": 124, "790": 124, "1okwhewf5kctipafib4xaa": 124, "counterpart": [124, 191], "substanti": [124, 157, 165, 174, 175], "versu": [124, 140, 172, 173, 175, 197], "n_col": [124, 125], "0f": [124, 125, 126], "c_in": [124, 125, 126, 147], "c_out": [124, 125, 126], "kernel_s": [124, 125, 126], "predesign": 124, "example_filt": [124, 126], "convout": 124, "in_channel": 124, "convlay": [124, 126], "h_in": [124, 125], "w_in": [124, 125, 126], "_2d_convolution_in_pytorch_exercis": 124, "_output_and_weight_shapes_conv_layer_discuss": 124, "vocabulari": 124, "teas": 124, "wherebi": [124, 125], "union": 124, "firstli": [124, 125], "mammalian": [124, 125], "mammal": 124, "secondli": [124, 125], "_visualizing_convolutional_filter_weights_bonus_exercis": 124, "_complex_cell_bonus_discuss": 124, "yalda": 125, "shed": 125, "rsa": 125, "w1d5_t3": 125, "zscore": 125, "plot_corr_matrix": 125, "plot_multiple_rdm": 125, "rdm_dict": 125, "resp_dict": 125, "plot_rdm_rdm_correl": 125, "rdm_sim": 125, "nwith": [125, 157], "plot_rdm_row": 125, "ori_list": 125, "rdm_ori": 125, "ori_plot": 125, "iori": 125, "nto": 125, "tilt": 125, "maxpool2d": 125, "fc": 125, "convolv": [125, 190, 191], "kpool": 125, "10d": 125, "0005": 125, "cf": 125, "appendix": [125, 174, 197], "minibatch_data": 125, "minibatch_label": 125, "2e": [125, 146], "get_hidden_act": 125, "layer_label": 125, "hidden_act": 125, "module_label": 125, "_modul": 125, "argwher": [125, 197], "register_forward_hook": 125, "children": 125, "pred": [125, 174], "_deep_convolutional_network_for_orientation_discrimination_video": 125, "conceiv": 125, "courtesi": 125, "10e": 125, "17e": 125, "32e": 125, "29e": 125, "08e": 125, "resp_v1": 125, "resp_model": 125, "aggreg": 125, "_quantitative_comparisons_of_cnns_and_neural_activity_video": 125, "zz": [125, 164], "zresp": 125, "dictcomp": 125, "_compute_rdms_exercis": 125, "_solution_discussion_video": 125, "m_": [125, 171, 172, 173, 174, 181], "ss": 125, "overcount": 125, "moreov": [125, 144, 153, 182], "correlate_rdm": 125, "rdm1": 125, "rdm2": 125, "ioffdiag": 125, "triu_indic": 125, "rdm1_offdiag": 125, "rdm2_offdiag": 125, "rdm_model": 125, "rdm_v1": 125, "pop": 125, "_correlate_rdms_exercis": 125, "55": [125, 146, 147, 148, 149, 163, 164, 171, 190, 191, 197, 200], "plot_resp_lowd": 125, "resp_lowd": 125, "twilight": 125, "_vizualizing_reduced_dimensionality_representations_discuss": 125, "fourier": 125, "convfc": [125, 126], "lfloor": 125, "rfloor": 125, "convpoolfc": 125, "neighbor": 125, "leftrightarrow": [125, 197], "gd": [125, 126], "gather": [125, 138, 181], "z_i": 125, "z_n": 125, "ddot": 125, "w1d5_t4_bonu": 126, "plot_decoded_result": 126, "test_loss": 126, "test_label": 126, "predicted_test_label": 126, "n_class": 126, "class_bin": 126, "visualize_weight": 126, "w_in_sort": 126, "w_out": 126, "visualize_hidden_unit": 126, "plot_tun": 126, "respi_train": 126, "respi_test": 126, "neuron_index": 126, "plot_predict": 126, "plot_training_curv": 126, "identitylin": 126, "lim": [126, 197, 198, 199], "minval": 126, "maxval": 126, "equal_lim": 126, "stimulus_class": 126, "accomod": 126, "regularized_mse_loss": 126, "l2_penalti": 126, "l1_penalti": 126, "scala": 126, "penalti": [126, 164], "cuda": 126, "is_avail": 126, "runtim": 126, "hardwar": 126, "opim": 126, "12219": 126, "759": 126, "1672": 126, "731": 126, "548": 126, "097": 126, "235": [126, 155, 181], "619": [126, 137], "jump": [126, 137, 172, 190, 198], "obstacl": [126, 190], "23589": 126, "gaussian_filter1d": 126, "resp_smooth": 126, "preferred_orient": 126, "resort": 126, "isort": 126, "_visualizing_weights_exercis": 126, "b_in": 126, "_interpreting_weights_discuss": 126, "weren": 126, "axtick": 126, "_delving_into_error_problems_discuss": 126, "359": [126, 133], "2b": [126, 138, 173], "3b": 126, "p_c": 126, "softmax": 126, "troubl": 126, "logsoftmax": 126, "l_i": 126, "deepnetsoftmax": 126, "logprob": 126, "logp": 126, "nllloss": 126, "test_data": 126, "n_iter": [126, 182], "decode_orient": 126, "train_binned_label": 126, "test_binned_label": 126, "out_label": 126, "frac_correct": 126, "_a_new_loss_function_exercis": 126, "regularized_loss": 126, "_add_regularization_to_training_exercis": 126, "_convolutional_encoding_model_video": 126, "grating_stimuli": 126, "neuronsto": 126, "tmp": [126, 139, 140, 175], "ipykernel_4890": 126, "554819614": 126, "deprecationwarn": [126, 139, 140], "__array__": 126, "_number_of_units_and_weights_discuss": 126, "custom_loss": 126, "param_group": 126, "conv1d": 126, "normal_": 126, "_add_linear_layer_exercis": 126, "ineur": 126, "runtimeerror": 126, "mat1": 126, "mat2": 126, "720x16": 126, "23589x20": 126, "1709": 126, "__getattr__": 126, "__name__": 126, "w2d1_daysummari": 128, "kick": 129, "accompani": 129, "regret": [129, 189], "forgot": 129, "w2d1_intro": 129, "w2d1_outro": 130, "revis": [131, 165, 174, 175], "w2d1_t1": 131, "_introduction_to_tutorial_video": 131, "_asking_a_question_video": 131, "_asking_your_own_question_discuss": 131, "_literature_review_and_background_knowledge_video": 131, "_literature_review_discuss": 131, "_submit_your_feedback_video": 131, "_determine_your_basic_ingredients_discuss": 131, "_formulating_your_hypothesis_video": 131, "_formulating_your_hypothesis_discuss": 131, "2002": [131, 151, 167], "03211v1": 131, "ekaterina": [132, 141, 150], "morozova": [132, 141, 150], "costa": 133, "aham": 133, "1501": [133, 193], "1510": 133, "1813476116": 133, "billeh": 133, "cai": 133, "gratii": 133, "iyer": 133, "gouwen": 133, "arkhipov": 133, "106": [133, 156, 172, 177], "403": [133, 177], "040": 133, "botvinick": [133, 184], "brodi": 133, "6128": 133, "1233912": 133, "kutz": 133, "258": 133, "010": [133, 188], "gilson": 133, "burkitt": 133, "grayden": 133, "hemmen": 133, "plastic": [133, 144], "cybernet": [133, 142], "102": [133, 167, 172, 177], "0319": 133, "aravkin": 133, "autoregress": [133, 200], "siam": 133, "2335": 133, "2358": 133, "1137": 133, "20m1338058": 133, "08389": 133, "1952": [133, 142], "nerv": [133, 142], "117": [133, 142, 156], "544": [133, 177], "1113": [133, 142], "jphysiol": [133, 142], "sp004764": [133, 142], "hu": 133, "cain": 133, "mihala": 133, "shea": [133, 147], "motif": [133, 151], "062312": 133, "1103": [133, 193], "physrev": 133, "izhikevich": [133, 142], "burst": [133, 175], "blei": 133, "1610": 133, "08466": 133, "mant": 133, "sussillo": 133, "newsom": [133, 171], "prefront": [133, 184], "503": 133, "7474": 133, "nature12742": 133, "pmc4121670": 133, "morrison": 133, "curto": 133, "combinatori": 133, "241": 133, "277": [133, 177], "academ": [133, 159], "b978": 133, "814066": 133, "00008": 133, "1804": 133, "01487": 133, "ocker": 133, "litwin": 133, "doiron": [133, 147], "microcircuit": 133, "e1004458": 133, "1004458": 133, "josi\u0107": [133, 147], "buic": 133, "e1005583": 133, "1005583": 133, "seung": 133, "13339": 133, "13344": 133, "usher": 133, "mcclelland": [133, 188], "compet": 133, "108": [133, 156, 190], "550": 133, "1037": 133, "0033": 133, "295x": 133, "s41467": 133, "10772": 133, "kaufman": 133, "foster": 133, "nuyujukian": 133, "487": 133, "7405": 133, "nature11129": 133, "pmc3393826": 133, "gilja": 133, "pandarinath": 133, "blabe": 133, "simer": 133, "sarma": 133, "henderson": 133, "prosthesi": 133, "medicin": 133, "1142": 133, "1145": [133, 193], "nm": 133, "pmc4805425": 133, "kao": 133, "ncomms8759": 133, "935": 133, "945": 133, "tbme": 133, "2582691": 133, "nonhuman": 133, "jproc": 133, "2586967": 133, "pmc7970827": 133, "albit": 133, "sanabria": 133, "saab": 133, "jarosiewicz": 133, "tablet": 133, "paralysi": 133, "e0204566": 133, "pone": [133, 167], "0204566": 133, "jozefowicz": 133, "staviski": 133, "805": 133, "815": 133, "s41592": 133, "0109": 133, "pmc6380887": 133, "soric": 133, "willett": 133, "intracort": 133, "e18554": 133, "18554": 133, "santhanam": 133, "afshar": 133, "prosthes": 133, "1315": 133, "1330": 133, "00097": 133, "annual": [133, 193], "062111": 133, "150509": 133, "visuomotor": 133, "null": [133, 200], "208": [133, 151], "023": 133, "murphi": [133, 151], "rezaii": 133, "avansino": 133, "dorsal": 133, "speech": 133, "e46015": 133, "46015": 133, "trautmann": 133, "lahiri": 133, "103": [133, 172], "292": [133, 174], "308": 133, "vya": 133, "1177": 133, "1186": 133, "249": [133, 181], "092619": 133, "094115": 133, "pmc7402639": 133, "329": 133, "deo": 133, "hochberg": 133, "knob": 133, "premotor": 133, "bodi": 133, "181": 133, "396": 133, "409": 133, "043": 133, "william": [133, 188, 189, 190, 191], "discoveri": [133, 193], "demix": 133, "1099": 133, "015": 133, "nips2008": 133, "w2d2_daysummari": 134, "w2d2_intro": 135, "w2d2_outro": 136, "wen": [137, 138, 139, 140], "alic": [137, 139], "schwarz": [137, 139], "norma": [137, 138, 139, 140], "kuhn": [137, 138, 139, 140, 142, 148], "w2d2_t1": 137, "solve_ivp": 137, "plot_trajectori": 137, "initial_condit": 137, "portrait": 137, "figtitlt": 137, "t_span": 137, "t_eval": 137, "dense_output": 137, "timecolor": 137, "ah1": [137, 139], "ah2": [137, 139], "ah3": 137, "set_size_inch": 137, "bx": 137, "subplots_adjust": 137, "wspace": 137, "plot_streamplot": 137, "x1dot": 137, "x2dot": 137, "log1p": 137, "sca": 137, "streamplot": 137, "cividi": 137, "arrows": 137, "eigenvector1": [137, 138], "eigenvector2": [137, 138], "plot_specific_example_stream_plot": 137, "a_opt": 137, "eigstr": 137, "y_label": [137, 164], "righthand": 137, "hspace": [137, 149], "_linear_dynamical_systems_video": [137, 174], "serv": [137, 138, 139], "govern": [137, 138, 139, 155, 191], "t_i": [137, 175], "sudden": 137, "1b": 137, "integrate_exponenti": 137, "xdot": 137, "_forward_euler_integration_exercis": 137, "\u03b1": [137, 164, 189], "readout_format": [137, 188], "plot_euler_integr": 137, "clunki": 137, "259": 137, "_forward_euler_integration_interactive_demo_discuss": 137, "imaginari": 137, "oscil": [137, 151, 153, 156], "hertz": 137, "0001": [137, 155, 188], "_oscillatory_dynamics_interactive_demo_discuss": 137, "_multidimensional_dynamics_video": 137, "bigg": [137, 156, 164], "1c": 137, "\ud835\udc651": 137, "\ud835\udc652": 137, "a00": 137, "a01": 137, "a10": 137, "a11": 137, "xdot1": 137, "xdot2": 137, "_ivp": 137, "ivp": 137, "621": 137, "618": 137, "tf": 137, "623": 137, "624": 137, "ts": [137, 175], "rk": 137, "rungekutta": 137, "t_bound": 137, "max_step": [137, 190, 191], "rtol": 137, "atol": 137, "first_step": 137, "extran": 137, "validate_max_step": 137, "validate_tol": 137, "h_ab": 137, "select_initial_step": 137, "error_estimator_ord": 137, "odesolv": 137, "fun_singl": 137, "check_argu": 137, "asarrai": [137, 163, 172, 181, 199], "593": 137, "592": [137, 151], "_sample_trajectories_in_2_dimensions_exercis": 137, "a_option_1": 137, "a_option_2": 137, "a_option_3": 137, "a_option_4": 137, "_varying_a_interactive_demo_discuss": 137, "x0_option_1": 137, "x0_option_2": 137, "x0_option_3": 137, "_varying_initial_conditions_interactive_demo_discuss": 137, "fortun": [137, 174, 182], "1_0": 137, "2_0": 137, "shrunk": 137, "_interpreting_eigenvalues_and_eigenvectors_discuss": 137, "elli": 138, "stradquist": 138, "markovian": [138, 188], "w2d2_t2": 138, "plot_switch_simul": 138, "plot_interswitch_interval_histogram": 138, "inter_switch_interv": 138, "plot_state_prob": 138, "prob": [138, 163, 172, 175, 181], "_markov_process_video": 138, "mu_": [138, 147, 164, 171, 172, 173], "c2o": 138, "o2c": 138, "req": [138, 146, 147, 156, 163, 164, 172, 201], "ion_channel_open": 138, "switch_tim": 138, "uniti": 138, "myrand": 138, "random_sampl": 138, "2a": [138, 173], "_computing_intervals_between_switches_exercis": 138, "return_count": 138, "undergon": 138, "adopt": 138, "plot_inter_switch_interv": 138, "_varying_transition_probability_values_and_t_interactive_demo_and_discuss": 138, "_k": 138, "x_kp1": 138, "plu": [138, 139, 163, 171, 200], "simulate_prob_prop": 138, "latest": [138, 173], "_probability_propagation_exercis": 138, "settl": [138, 139, 189], "relax": 138, "_continuous_vs_discrete_time_fromulation_video": 138, "eigendecomposit": 138, "988": 138, "98058068": 138, "19611614": 138, "70710678": 138, "_finding_a_stable_state_discuss": 138, "biraj": [139, 140], "pandei": [139, 140], "neither": 139, "face": [139, 164, 174, 189, 200], "w2d2_t3": 139, "plot_random_walk_sim": 139, "nsim": 139, "3a": 139, "plot_mean_var_by_timestep": 139, "plot_ddm": 139, "xinfti": [139, 140], "var_comparison_plot": 139, "plot_dynam": [139, 181], "_ecoli_and_random_walks_video": 139, "gander": 139, "wander": 139, "aimlessli": 139, "bacterium": 139, "odor": 139, "substrat": [139, 184], "seek": [139, 181, 190], "dog": 139, "blindfold": 139, "flail": 139, "brownian": 139, "terminolog": 139, "microscop": 139, "protein": 139, "mintag": 139, "this_step": 139, "random_walk_simul": 139, "nxt": 139, "random_walk_simulator_funct": 139, "_random_walk_simulation_exercis": 139, "bacteria": 139, "2500": 139, "sig2": 139, "mytitl": [139, 140], "sharpli": 139, "_random_walk_and_variance_exercis": 139, "plot_gaussian": [139, 164], "_influence_of_parameter_choice_interactive_demo_and_discuss": 139, "_combining_deterministic_and_stochastic_processes_video": 139, "ddm": [139, 140], "hang": [139, 164], "imperfectli": 139, "land": [139, 190, 191], "simulate_ddm": 139, "_driftdiffusion_model_exercis": 139, "stimul": [139, 148, 155, 195], "_driftdiffusion_simulation_observations_discuss": 139, "_balance_of_variances_video": 139, "pull": [139, 174, 189], "restor": 139, "standard_norm": [139, 140], "ddm_eq_var": 139, "hack": 139, "sweep": 139, "empirical_vari": 139, "analytical_vari": 139, "ipykernel_5183": 139, "1365116358": 139, "convers": [139, 140], "deprec": [139, 140], "_computing_the_variances_empirically_exercis": 139, "interplai": [139, 148], "w2d2_t4": 140, "plot_residual_histogram": 140, "4a": 140, "stdev": 140, "plot_training_fit": 140, "4b": 140, "build_time_delay_matric": 140, "xprime": 140, "roll": 140, "ar_predict": 140, "ar_model": 140, "error_r": 140, "mismatch": [140, 174], "count_nonzero": 140, "_autoregressive_models_video": 140, "ipykernel_5214": 140, "4059738216": 140, "bird": [140, 177], "reformul": 140, "rnk": 140, "lstsq": 140, "rcond": 140, "lam_hat": 140, "_residuals_of_the_autoregressive_model_exercis": 140, "_monkey_at_a_typewriter_video": 140, "alpha_0": 140, "alpha_1": 140, "alpha_2": 140, "alpha_3": 140, "alpha_": [140, 157], "jot": 140, "monkey_at_typewrit": 140, "1010101010101010101010101010101010101010101010101": 140, "100100100100100100100100100100100100100": 140, "char": 140, "char2arrai": 140, "_understanding_autoregressive_parameters_discuss": 140, "notori": 140, "terribl": 140, "yr": 140, "laptop": 140, "jab": 140, "10010101001101000111001010110001100101000101101001010010101010001101101001101000011110100011011010010011001101000011101001110000011111011101000011110000111101001010101000111100000011111000001010100110101001011010010100101101000110010001100011100011100011100010110010111000101": 140, "test_monkei": 140, "00100101100001101001100111100101011100101011101001010101000010110101001010100011110": 140, "randint": 140, "unpredict": 140, "jitter": 140, "_fitting_ar_models_exercis": 140, "x1_test": 140, "x2_test": 140, "err": 140, "rr": 140, "test_error": 140, "sweet": 140, "6th": 140, "gerstner": [142, 151], "kistler": [142, 151], "naud": [142, 144, 146, 147, 148, 149, 151], "katz": 142, "giant": 142, "loligo": 142, "424": 142, "sp004716": 142, "fitzhugh": 142, "nagumo": 142, "scholarpedia": 142, "1349": 142, "4249": 142, "1955": 142, "bulletin": 142, "257": 142, "278": [142, 174], "bf02477753": 142, "hakim": 142, "richardson": 142, "155": 142, "326": [142, 149], "5951": 142, "379": 142, "380": 142, "1181936": 142, "infosci": 142, "epfl": [142, 151], "142067": 142, "naud09": 142, "jolivet": 142, "kobayashi": 142, "rauch": 142, "shinomoto": 142, "417": [142, 151], "118680": 142, "jolivet08": 142, "lewi": 142, "959": 142, "976": 142, "00190": 142, "larkum": 142, "nevian": 142, "sandler": 142, "polski": 142, "schiller": 142, "tuft": 142, "dendrit": [142, 144], "pyramid": 142, "325": [142, 149], "5941": 142, "756": [142, 177], "760": 142, "1171958": 142, "poirazi": [142, 144], "brannon": 142, "mel": 142, "989": [142, 174], "s0896": 142, "6273": 142, "00149": 142, "aertsen": [142, 147, 148], "rotter": [142, 148], "2345": 142, "2356": 142, "3349": 142, "markram": 142, "tsodyk": [142, 151], "redistribut": 142, "efficaci": [142, 146, 148], "6594": 142, "807": 142, "810": 142, "382807a0": 142, "5323": 142, "5328": 142, "steven": 142, "1995": [142, 159, 177, 182], "depress": [142, 149], "795": 142, "802": [142, 147], "0896": 142, "90223": 142, "nelson": [142, 184], "tame": 142, "beast": 142, "1178": 142, "1183": 142, "81453": 142, "bi": [142, 147, 164], "poo": 142, "modif": [142, 149], "cultur": 142, "hippocamp": [142, 184], "10464": 142, "10472": 142, "song": 142, "competit": [142, 184], "hebbian": 142, "919": 142, "926": 142, "78829": 142, "w2d3_daysummari": 143, "upi": 144, "bhalla": 144, "irregular": [144, 147, 148, 151], "synchroni": 144, "yiota": 144, "morpholog": 144, "w3d5": [144, 153], "dysfunct": [144, 177], "w2d3_intro": 144, "w2d3_outro": 145, "qinglong": [146, 147, 148, 149, 155, 156, 157], "gu": [146, 147, 148, 149, 155, 156, 157], "songtin": [146, 147, 148, 149, 155, 156, 157], "lorenzo": [146, 147, 148, 149, 155, 156, 157], "fontolan": [146, 147, 148, 149, 155, 156, 157], "w2d3_t1": 146, "plot_volt_trac": [146, 148], "par": [146, 147, 148, 149, 155, 156, 157], "trajetori": [146, 148], "volt": [146, 148], "range_t": [146, 147, 148, 149, 155, 156, 157], "sp_num": [146, 148, 149], "nicer": [146, 148], "npotenti": 146, "plot_gwn": 146, "i_gwn": [146, 147, 148], "pa": [146, 147, 148], "my_hist": 146, "isi1": 146, "isi2": 146, "cv1": 146, "cv2": 146, "sigma1": [146, 164], "sigma2": [146, 164], "my_bin": [146, 147], "_lif_model_video": 146, "laurenc": 146, "eqn": 146, "mimick": [146, 147], "exceed": 146, "default_par": [146, 147, 148, 156, 157], "simulation_tim": 146, "time_step": [146, 155, 156, 157], "new_param": 146, "ns": [146, 147, 148], "v_init": [146, 147, 148, 149], "tref": [146, 147, 148, 149], "000e": 146, "997e": 146, "998e": [146, 199], "999e": 146, "run_lif": [146, 147], "iinj": [146, 147, 148], "puls": 146, "rec_v": [146, 147, 148, 149], "rec_sp": 146, "lt": [146, 147, 148, 149, 155, 156, 157, 182], "rec_spik": [146, 147, 148, 149], "tr": [146, 147, 148, 149], "counter": [146, 147], "_lif_model_exercis": 146, "_response_lif_model_video": 146, "cosmet": 146, "rheobas": 146, "i_dc": 146, "diff_dc": 146, "_parameter_exploration_of_dc_input_amplitude_interactive_demo_and_discuss": 146, "vivo": [146, 148, 188, 200], "mimic": 146, "my_gwn": [146, 147, 148], "myse": [146, 147, 148, 149, 155, 157], "amplitut": [146, 147, 148, 149, 155, 157], "mu_gwn": 146, "diff_gwn_to_lif": 146, "_gaussian_white_noise_interactive_demo_and_discuss": 146, "clock": [146, 147], "_analyzing_gwn_effects_on_spiking_discuss": 146, "textbf": 146, "clocklik": 146, "diff_std_affect_fi": 146, "spk_count": 146, "spk_count_dc": 146, "v_dc": 146, "rec_sp_dc": 146, "_f_i_explorer_interactive_demo_and_discuss": 146, "isi_cv_lif": 146, "spike_train": [146, 147, 149], "sig_gwn1": 146, "sig_gwn2": 146, "i_gwn1": 146, "sp1": [146, 147], "i_gwn2": 146, "sp2": [146, 147], "_compute_cv_isi_exercis": 146, "cv_isi": [146, 148], "_spike_irregularity_interactive_demo_and_discuss": 146, "shot": [146, 147], "my_ou": [146, 155, 157], "i_ou": [146, 155, 157], "tau_ou": [146, 155, 157], "sig_ou": [146, 155, 157], "mu_ou": 146, "190": 146, "220": 146, "lif_with_": 146, "_lif_explorer_with_ou_input_bonus_interactive_demo_and_discuss": 146, "_extension_to_integrate_and_fire_bonus_video": 146, "lif": [147, 155], "w2d3_t2": 147, "example_plot_mycc": 147, "50000": 147, "r12": 147, "i1gl": 147, "i2gl": 147, "correlate_input": 147, "my_cc": 147, "my_raster_poisson": 147, "ffunction": 147, "exce": [147, 149, 157], "rater": 147, "plot_c_r_lif": 147, "mycolor": [147, 156, 157], "mylabel": [147, 156, 157], "polyfit": 147, "c_rang": 147, "v_l": [147, 148, 149], "mebran": [147, 148, 149], "lif_output_cc": 147, "bin_siz": 147, "coe": 147, "sp_rate": 147, "i_trial": 147, "sp1_count": 147, "sp2_count": 147, "poisson_gener": [147, 148, 149], "coincid": 147, "uni": 147, "direction": 147, "gap": [147, 199], "junction": 147, "stronger": [147, 200], "forthcom": 147, "impair": 147, "_input_and_output_correlations_video": 147, "unconnect": 147, "i_i": [147, 157], "xi_i": 147, "xi_c": 147, "le": 147, "le1": 147, "whute": 147, "xi_1": 147, "xi_2": 147, "i_j": 147, "pearson": [147, 198], "rodger": 147, "nicewand": 147, "rij": 147, "rxy": 147, "tip1": 147, "a1": 147, "a2": 147, "a3": 147, "b1": 147, "b2": 147, "b3": 147, "tip2": 147, "tip3": 147, "var_i": 147, "var_j": 147, "_compute_the_correlation_exercis": 147, "\ud835\udc36\ud835\udc49isi": 147, "pre_spike_train": [147, 148, 149], "ith": [147, 148, 149], "u_rand": [147, 148, 149], "poisson_train": [147, 148, 149], "generate_corr_poisson": 147, "poi_rat": 147, "mother_r": 147, "mother_spike_train": 147, "sp_mother": 147, "l_sp_mother": 147, "sp_mother_id": 147, "l_sp_corr": 147, "corr_coeff_pair": 147, "r_12": 147, "diff_trial": 147, "simu": 147, "197": 147, "_measure_the_correlation_between_spike_trains_exercis": 147, "aforement": [147, 148], "gwn_mean": 147, "gwn_std": 147, "80000": 147, "starttim": [147, 149], "perf_count": [147, 149], "r12_ss": 147, "sp_ss": 147, "endtim": [147, 149], "timecost": [147, 149], "8000": 147, "140": 147, "138": 147, "ic": 147, "_input_output_correlation_discuss": 147, "r12_l": 147, "r12_sl": 147, "sp_l": 147, "sp_sl": 147, "_gwn_and_the_correlation_transfer_function_discuss": 147, "campbel": 147, "unphysiolog": 147, "ou": [147, 155, 157], "la": [147, 177], "rocha": 147, "rey": 147, "806": 147, "nature06028": 147, "bujan": 147, "af": 147, "evok": 147, "neocortex": 147, "8611": 147, "4536": 147, "_correlations_and_network_activity_discuss": 147, "correlogram": 147, "response_of_ensemble_of_neurons_to_time_varying_input_bonus_video": 147, "chemic": 148, "neurotransmitt": 148, "cleft": 148, "permeabl": 148, "partner": 148, "undergo": [148, 188], "w2d3_t3": 148, "my_illus_lifsyn": 148, "v_fmp": 148, "illustart": 148, "fmp": 148, "alongsid": 148, "pot": 148, "my_illus_std": 148, "tau_d": 148, "tau_f": 148, "plot_out": 148, "constantr": 148, "ot": 148, "t_simu": 148, "isi_num": 148, "1e3": 148, "dynamic_syn": 148, "g_bar": 148, "tau_syn": 148, "spt": [148, 149], "gwn": 148, "poissonian": 148, "_static_and_dynamic_synapses_video": 148, "depolar": 148, "hyperpolar": 148, "transient": [148, 157], "dg_": 148, "g_e": [148, 149], "g_i": [148, 149, 157], "e_i": 148, "inj": 148, "bombard": 148, "run_lif_cond": 148, "i_inj": 148, "pre_spike_train_ex": [148, 149], "pre_spike_train_in": 148, "gi": 148, "ge_bar": [148, 149], "gi_bar": 148, "vi": 148, "tau_syn_": [148, 149], "tau_syn_i": 148, "pre_spike_train_ex_tot": 148, "pre_spike_train_in_tot": 148, "cv_": 148, "descriptor": 148, "_measure_the_mean_free_membrane_potential_exercis": 148, "ei_isi_regular": 148, "lip": [148, 167], "211": [148, 149, 156, 157], "fontweight": [148, 149, 157], "spk": 148, "_lif_explorer_interactive_demo_and_discuss": 148, "_excitatory_inhibitory_balance_discuss": 148, "vesicl": 148, "termin": [148, 188], "fashion": 148, "influx": 148, "du_e": 148, "u_": 148, "u_0": 148, "5mm": [148, 149], "dg_e": 148, "_e": [148, 156, 157], "spiketim": 148, "ur": 148, "gg": 148, "incur": [148, 190, 191], "phenomenolog": [148, 149], "kinet": 148, "dg": [148, 157], "regularli": 148, "uncheck": 148, "my_std_diff_r": 148, "_std_explorer_with_input_rate_interactive_demo_and_discuss": 148, "her": [148, 200], "10th": 148, "input_r": 148, "g_1": 148, "g_2": 148, "st": 148, "_stf_explorer_with_input_rate_interactive_demo_and_discuss": 148, "therebi": [148, 191], "imping": 148, "run_lif_cond_stp": 148, "u0_": 148, "tau_d_": 148, "tau_f_": 148, "u0i": 148, "tau_di": 148, "tau_fi": 148, "u0_i": 148, "tau_d_i": 148, "tau_f_i": 148, "ne": 148, "ni": 148, "ue": 148, "ge_tot": 148, "ui": 148, "ri": [148, 156, 157], "gi_tot": 148, "tau_ratio": 148, "lif_stp": 148, "t_plot_rang": 148, "400m": 148, "onward": 148, "_lif_with_stp_bonus_interactive_demo": 148, "w2d3_t4_bonu": 149, "my_raster_plot": 149, "raster_plot": 149, "my_example_p": 149, "ltp": 149, "rastert": 149, "color_set": 149, "cyan": 149, "212": [149, 156, 157], "mystdp_plot": 149, "a_plu": 149, "a_minu": 149, "tau_stdp": 149, "time_diff": 149, "biphas": 149, "default_pars_stdp": 149, "ltd": 149, "_stdp_video": 149, "weaken": 149, "latenc": 149, "delta_w": 149, "pre_spik": 149, "post_spik": 149, "_compute_stdp_changes_exercis": 149, "dm": 149, "displaystyl": [149, 155], "sp_or_not": 149, "generate_p": 149, "_compute_dp_exercis": 149, "foral": 149, "run_lif_cond_stdp": 149, "ge_init": 149, "ge_bar_upd": 149, "id_temp": 149, "epsp": 149, "322": 149, "323": 149, "324": 149, "_analyzing_synaptic_strength_discuss": 149, "depotenti": 149, "example_lif_stdp": 149, "inputr": 149, "tsim": 149, "120000": 149, "intputr": 149, "014": 149, "gbar_norm": 149, "620px": 149, "sample_tim": 149, "my_visual_stdp_distribut": 149, "g_di": 149, "_lif_and_stdp_interactive_demo_and_discuss": 149, "example_lif_stdp_corrinput": 149, "i_pr": 149, "figtemp": 149, "iput": 149, "get_text": [149, 181], "legend_handl": 149, "g_dis_cc": 149, "g_dis_dp": 149, "unaffect": [149, 200], "_lif_plasticity_correlated_inputs_interactive_demo_and_discuss": 149, "loooong": 149, "neuronaldynam": 151, "ch4": 151, "cowan": [151, 153], "1972": [151, 156, 157], "s0006": [151, 156, 157], "3495": [151, 156, 157], "86068": [151, 156, 157], "635": 151, "648": 151, "ozeki": 151, "finn": 151, "schaffer": 151, "ferster": 151, "028": 151, "sanzeni": 151, "akitak": 151, "goldbach": 151, "leedi": 151, "widespread": 151, "e54875": 151, "54875": 151, "skagg": 151, "mcnaughton": 151, "1997": [151, 184], "interneuron": 151, "4388": 151, "04382": 151, "rubin": [151, 159, 193, 197], "1994": 151, "2037": 151, "neco_a_00472": 151, "pmc4026108": 151, "1202": 151, "6670": 151, "cerebr": 151, "109": 151, "3373": 151, "3391": 151, "031": [151, 167], "1908": 151, "10101": 151, "hennequin": 151, "lengyel": 151, "attractor": [151, 153], "846": 151, "860": [151, 184], "017": 151, "875534": 151, "hooser": 151, "402": 151, "026": [151, 174], "vreeswijk": 151, "sompolinski": 151, "274": 151, "5293": 151, "1724": 151, "1023": 151, "1008925309027": 151, "01095": 151, "w2d4_daysummari": 152, "_daysummari": [152, 160, 168, 174, 194], "nicola": 153, "juliana": 153, "georgieva": 153, "ken": 153, "expos": [153, 201], "amplif": 153, "supra": 153, "w2d3": 153, "manifest": 153, "oscillatori": [153, 156, 157, 174], "w2d4_intro": 153, "w2d4_outro": 154, "julijana": [155, 156, 157], "gjorgjieva": [155, 156, 157], "mainli": 155, "signatur": [155, 174, 191], "diseas": [155, 177], "epilepsi": 155, "parkinson": 155, "homogen": 155, "w2d4_t1": 155, "plot_fi": 155, "plot_dr_r": 155, "drdt": 155, "x_fp": [155, 156, 157], "plot_dfdt": 155, "dfdt": 155, "_dynamic_networks_video": 155, "feed": 155, "ext": [155, 156, 157], "default_pars_singl": 155, "i_ext": 155, "r_init": 155, "t_sim": [155, 156, 157], "new_para": [155, 156, 157], "my_func": 155, "hyperbol": 155, "tangent": [155, 156], "_implement_fi_curve_exercis": 155, "interactive_plot_fi": 155, "expecxt": 155, "_parameter_exploration_of_fi_curve_interactive_demo_and_discuss": 155, "simulate_singl": 155, "ana": 155, "myplot_e_diffi_difftau": 155, "r_ana": 155, "_parameter_exploration_of_single_population_dynamics_interactive_demo_and_discuss": 155, "_finite_activities_discuss": 155, "_finding_fixed_points_video": 155, "deduc": 155, "compute_drdt": 155, "other_par": [155, 156, 157], "unus": 155, "_visualization_of_the_fixed_points_exercis": 155, "my_fp_singl": 155, "r_guess": 155, "check_fp_singl": 155, "fp": [155, 157], "my_fp_find": 155, "r_guess_vector": 155, "my_wcr": [155, 157], "mytol": [155, 157], "toler": [155, 157, 199], "correct_fp": 155, "student_exercis": 155, "_numerical_calculation_of_fixed_points_exercis": 155, "plot_intersection_singl": 155, "r_init_vector": 155, "_fixed_points_inputs_interactive_demo_and_discuss": 155, "_root": 155, "236": 155, "233": 155, "fatol": 155, "hybr": 155, "sol": 155, "_root_hybr": 155, "237": [155, 181], "238": [155, 181], "_root_leastsq": 155, "_minpack_pi": 155, "232": 155, "col_deriv": 155, "xtol": 155, "maxfev": 155, "230": 155, "231": 155, "_check_func": 155, "fsolv": [155, 163], "epsfcn": 155, "234": [155, 181], "checker": 155, "argnam": 155, "thefunc": 155, "numinput": 155, "output_shap": 155, "plot_single_diffeinit": 155, "_dynamics_initial_value_interactive_demo_and_discuss": 155, "800x500": 155, "_stable_vs_unstable_fixed_points_discuss": 155, "_inhibitory_populations_discuss": 155, "_stability_of_fixed_points_bonus_video": 155, "perturb": [155, 157, 195, 198, 199, 200], "wf": 155, "dfdx": [155, 156, 157], "eig_singl": 155, "r_fp": 155, "eig_fp": 155, "point1": [155, 156, 157], "583": 155, "point2": 155, "447": 155, "498": 155, "point3": 155, "900": 155, "626": 155, "_compute_eigenvalues_bonus_exercis": 155, "ornstein": [155, 157], "uhlenbeck": [155, 157], "uhlenback": 155, "becam": 156, "w2d4_t2": 156, "plot_fi_invers": [156, 157], "f_inv": [156, 157], "plot_fi_ei": [156, 157], "fi_exc": [156, 157], "fi_inh": [156, 157], "my_test_plot": [156, 157], "re1": [156, 157], "ri1": [156, 157], "re2": [156, 157], "ri2": [156, 157], "plot_nullclin": [156, 157], "exc_null_r": [156, 157], "exc_null_ri": [156, 157], "inh_null_r": [156, 157], "inh_null_ri": [156, 157], "my_plot_nullclin": [156, 157], "get_e_nullclin": [156, 157], "get_i_nullclin": [156, 157], "my_plot_vector": [156, 157], "my_n_skip": [156, 157], "myscal": [156, 157], "ei_grid": [156, 157], "dredt": [156, 157], "dridt": [156, 157], "eideriv": [156, 157], "n_skip": [156, 157], "my_plot_trajectori": [156, 157], "x_init": [156, 157], "re_init": [156, 157], "ri_init": [156, 157], "re_tj": [156, 157], "ri_tj": [156, 157], "simulate_wc": [156, 157], "e_grid": [156, 157], "trjectori": [156, 157], "plot_complete_analysi": [156, 157], "nfor": [156, 157], "nlow": [156, 157], "nhigh": [156, 157], "plot_fp": [156, 157], "wee": 156, "wie": [156, 157], "wii": [156, 157], "i_ext_": [156, 157], "i_ext_i": [156, 157], "_phase_analysis_video": 156, "subtyp": 156, "f_e": [156, 157], "f_i": [156, 157], "ae": 156, "ai": 156, "_plot_fi_exercis": 156, "_numerical_integration_of_we_model_exercis": 156, "plot_ei_diffiniti": 156, "_population_trajectories_with_different_initial_values_interactive_demo_and_discuss": 156, "_nullclines_and_vector_fields_video": 156, "n_t": [156, 189], "plot_activity_phas": 156, "_time_plane_to_phase_plane_interactive_demo_and_discuss": 156, "1mm": [156, 157], "shere": 156, "ln": [156, 157], "f_invers": [156, 157], "finvers": [156, 157], "_compute_the_nullclines_we_exercis": 156, "travers": 156, "119": [156, 177], "124": 156, "125": [156, 199], "104": [156, 172], "770x600": 156, "_compute_the_vector_field_exercis": 156, "_analyzing_the_vector_field_discuss": 156, "w2d4_t3_bonu": 157, "_fixed_points_and_stability_video": 157, "my_fp": 157, "check_fp": 157, "vicin": 157, "x_fp_1": 157, "x_fp_2": 157, "x_fp_3": 157, "_find_the_fixed_points_of_we_exercis": 157, "attract": 157, "yield": 157, "get_eig_jacobian": 157, "eig_1": 157, "eig_2": 157, "eig_3": 157, "_compute_the_jacobian_exercis": 157, "pitchfork": 157, "bifurc": 157, "plot_nullcline_diffwe": 157, "clip_on": 157, "_effect_of_wee_interactive_demo_and_discuss": 157, "time_constant_effect": 157, "ei_grid_": 157, "ei_grid_i": 157, "_limit_cycle_and_oscillations_interactive_demo": 157, "subpopul": 157, "alpha_i": 157, "noninhibit": 157, "get_dgd": 157, "dgde": 157, "dgdre": 157, "dgdre1": 157, "dgdre2": 157, "dgdre3": 157, "fp1": 157, "fp2": 157, "fp3": 157, "x_fp_lc": 157, "dgdre_lc": 157, "fp_lc": 157, "650": 157, "519": [157, 200], "706": 157, "837": 157, "_compute_dgdre_exercis": 157, "iff": 157, "det": 157, "fw": 157, "steeper": 157, "isn_i_perturb": 157, "_nullclines_of_isn_and_nonisn_interactive_demo_and_discuss": 157, "20201": 157, "20202": 157, "se": [157, 200], "outlast": 157, "my_inject": 157, "t_start": 157, "t_lag": 157, "n_start": 157, "n_lag": 157, "i_puls": 157, "l_puls": 157, "wc_with_puls": 157, "2022": [157, 159, 193], "_persistent_activity_interactive_demo_and_discuss": 157, "treatment": [159, 193, 195, 199, 200], "goldreich": 159, "cn": 159, "nyu": 159, "malab": 159, "bayesianbook": 159, "gelman": 159, "carlin": 159, "stern": 159, "crc": 159, "mcelreath": 159, "rethink": 159, "stan": 159, "stuff": 159, "downei": 159, "reilli": 159, "media": 159, "inc": 159, "kruschk": 159, "jag": 159, "knill": 159, "propel": 159, "welchman": 159, "trommershaus": 159, "landi": 159, "cue": [159, 188], "kass": [159, 193], "w3d1_daysummari": 160, "fish": [161, 164, 169, 171, 172, 179], "astrocat": [161, 169, 179, 182], "rl": [161, 186, 188], "w3d1_intro": 161, "w3d1_outro": 162, "xaq": [163, 164, 171, 172, 173, 174, 181, 182], "pitkow": [163, 164, 171, 172, 173, 174, 181, 182], "w3d1_t1": 163, "namedtupl": [163, 172, 173, 175, 182], "gridspeclayout": 163, "togglebutton": [163, 181], "interactive_output": [163, 164], "clear_output": [163, 164], "filterwarn": [163, 164], "plot_joint_prob": 163, "marginal_i": 163, "marginal_x": 163, "joint_prob": 163, "rect_histx": 163, "rect_histi": 163, "rect_x_cmap": 163, "rect_y_cmap": 163, "matshow": 163, "barh": 163, "ind": 163, "tick_bottom": 163, "tick_left": 163, "silver": [163, 184], "plot_prior_likelihood_posterior": 163, "small_width": 163, "left_spac": 163, "added_spac": 163, "rect_prior": 163, "rect_likelihood": 163, "rect_posterior": 163, "ax_prior": 163, "ax_likelihood": 163, "ax_posterior": 163, "rect_colormap": 163, "tick_right": 163, "set_ticks_posit": 163, "plot_prior_likelihood": 163, "p_a_s1": 163, "p_a_s0": 163, "small_pad": 163, "prior_colormap": 163, "posterior_colormap": 163, "plot_util": 163, "rect_util": 163, "rect_expect": 163, "ax_util": 163, "ax_expect": 163, "plot_prior_likelihood_util": 163, "expected_colormap": 163, "compute_margin": 163, "cor": 163, "p11": 163, "p01": 163, "p10": 163, "p00": 163, "compute_cor_rang": 163, "cmax": 163, "cmin": 163, "_introduction_to_bayesian_statistics_and_decisions_video": 163, "_gone_fishin_video": 163, "losss": 163, "_utility_video": 163, "submarin": 163, "sunburn": 163, "afternoon": 163, "dock": 163, "weigh": [163, 164], "correspondingli": [163, 174], "ps_widget": 163, "make_utility_plot": 163, "_exploring_the_decision_interactive_demo_and_discuss": 163, "_utility_demo_discussion_video": 163, "_likelihood_video": 163, "fisher": 163, "_guessing_the_location_of_the_fish_discuss": 163, "knew": [163, 171], "_correlation_and_marginalization_video": [163, 164], "golden": 163, "cor_widget": 163, "\u03c1": [163, 164, 182], "px_widget": 163, "py_widget": 163, "make_corr_plot": 163, "_covarying_probability_distributions_discuss": 163, "journei": 163, "irrelev": 163, "njoint": 163, "n1": 163, "n2": 163, "n3": 163, "_computing_marginal_probabilities_math_exercis": 163, "caught": [163, 172, 181], "nprior": 163, "nlikelihood": 163, "_computing_marginal_likelihood_math_exercis": 163, "_posterior_beliefs_video": [163, 164], "propto": [163, 164, 165, 172], "intract": 163, "whfere": 163, "bother": 163, "unnorm": 163, "_calculating_a_posterior_probability_math_exercis": 163, "compute_posterior": 163, "p_m": 163, "_computing_posteriors_exercis": 163, "incorrect": [163, 171], "exert": 163, "p_a_s1_widget": 163, "370px": 163, "p_a_s0_widget": 163, "observed_widget": 163, "button_styl": [163, 181], "flex": [163, 164], "widget_ui": [163, 164], "widget_out": [163, 164], "_what_affects_the_posterior_interactive_demo_and_discuss": 163, "_posterior_beliefs_exercises_discussion_video": 163, "_bayesian_decisions_video": [163, 164], "econom": [163, 177, 186, 188], "ecolog": 163, "300px": 163, "_probabilities_vs_utilities_interactive_demo_and_discuss": 163, "_bayesian_decisions_demo_discussion_video": 163, "rho_": [163, 164], "w3d1_t2": 164, "gamma_distribut": 164, "affine2d": 164, "plot_mixture_prior": 164, "gaussian1": 164, "gaussian2": 164, "plot_loss": 164, "mse_loss": 164, "abs_loss": 164, "zero_one_loss": 164, "ax_gau": 164, "ax_error": 164, "gaussian_mixtur": 164, "mu1": [164, 171], "mu2": 164, "deepskyblu": 164, "aquamarin": 164, "plot_utility_mixture_dist": 164, "mu_g": 164, "sigma_g": 164, "mu_loc": 164, "mu_dist": 164, "plot_utility_row": 164, "mu_post": 164, "sigma_post": 164, "product_guassian": 164, "sigma_mix": 164, "mu_mix1": 164, "mu_mix2": 164, "gaus_mix1": 164, "gaus_mix2": 164, "plot_bayes_utility_row": 164, "plot_bayes_row": 164, "plot_mvn2d": 164, "cov12": 164, "mvn2d": 164, "contourf": 164, "plot_margin": 164, "c_x": 164, "c_y": 164, "p_x": 164, "p_y": 164, "mu_x_i": 164, "mu_y_x": 164, "sigma_x_i": 164, "sigma_y_x": 164, "p_x_y": 164, "p_y_x": 164, "p_c_y": 164, "p_c_x": 164, "rect_z": 164, "rect_x": 164, "rect_i": 164, "ax_z": 164, "set_axis_off": 164, "plot_bay": 164, "plot_inform": 164, "mu3": 164, "sigma3": 164, "satellit": 164, "plot_information_glob": 164, "reverse_product": 164, "plot_loss_utility_gaussian": 164, "loss_f": 164, "mu_tru": 164, "plot_loss_util": 164, "plot_loss_utility_mixtur": 164, "calc_mean_mode_median": 164, "calc_loss_func": 164, "calc_expected_loss": 164, "min_expected_loss": 164, "dashdot": 164, "plot_loss_utility_bay": 164, "plot_simple_utility_gaussian": 164, "mu_c": 164, "sigma_c": 164, "plot_utility_gaussian": 164, "plot_utility_mixtur": 164, "mu_m1": 164, "mu_m2": 164, "sigma_m1": 164, "sigma_m2": 164, "plot_utility_uniform": 164, "plot_utility_gamma": 164, "gamma_pdf": 164, "max_util": 164, "plot_bayes_loss_utility_gaussian": 164, "plot_bayes_loss_util": 164, "plot_bayes_loss_utility_uniform": 164, "plot_bayes_loss_utility_gamma": 164, "plot_bayes_loss_utility_mixtur": 164, "expected_loss": 164, "global_loss_plot_switch": 164, "loss_plot_switch": 164, "what_to_plot": 164, "loss_f_opt": 164, "mu_slid": 164, "\u00b5_estim": 164, "continuous_upd": [164, 199], "sigma_slid": 164, "\u03c3_estim": 164, "mu_true_slid": 164, "\u00b5_true": 164, "mu1_slid": 164, "\u00b5_est_p": 164, "mu2_slid": 164, "\u00b5_est_q": 164, "sigma1_slid": 164, "\u03c3_est_p": 164, "sigma2_slid": 164, "\u03c3_est_q": 164, "factor_slid": 164, "\u03c0": 164, "global_plot_prior_switch": 164, "plot_prior_switch": 164, "\u00b5_prior": 164, "\u00b5_likelihood": 164, "\u03c3_prior": 164, "\u03c3_likelihood": 164, "alpha_slid": 164, "\u03b1_prior": 164, "beta_slid": 164, "\u03b2_prior": 164, "offset_slid": 164, "gaus_label": 164, "justify_cont": 164, "gamma_label": 164, "mu_m1_slid": 164, "\u00b5_mix_p": 164, "mu_m2_slid": 164, "\u00b5_mix_q": 164, "sigma_m1_slid": 164, "\u03c3_mix_p": 164, "sigma_m2_slid": 164, "\u03c3_mix_q": 164, "global_plot_bayes_loss_utility_switch": 164, "plot_bayes_loss_utility_switch": 164, "empty_label": 164, "\u03bc": 164, "\u03b2": 164, "mvn": 164, "dstack": 164, "j_1": 164, "j_2": 164, "j_3": 164, "mu_prod": 164, "sigma_prod": 164, "calc": [164, 165], "cdf": 164, "_introduction_video": [164, 172, 174, 175, 188], "astronaut": 164, "jetpack": [164, 179, 182], "thumb": 164, "jet": [164, 182], "pack": [164, 182], "earth": [164, 182], "glimps": 164, "_astrocat_video": 164, "remot": 164, "tenni": 164, "_the_gaussian_distribution_video": 164, "ormal": 164, "clarif": 164, "\u00b5": 164, "_exploring_gaussian_parameters_interactive_demo_and_discuss": 164, "mu_3": 164, "sigma_3": 164, "_multiplying_gaussians_video": 164, "\u00b5_1": 164, "\u00b5_2": 164, "\u03c3_1": 164, "\u03c3_2": 164, "distro_1_label": 164, "distro_2_label": 164, "_multiplying_gaussians_interactive_demo_and_discuss": 164, "multimod": 164, "_mixtures_of_gaussians_video": 164, "\u00b5_p": 164, "\u00b5_q": 164, "\u03c3_p": 164, "\u03c3_q": 164, "mixture_label": 164, "_exploring_gaussian_mixtures_interactive_demo_and_discuss": 164, "_utility_loss_estimators_video": 164, "_exploring_loss_with_different_distributions_interactive_demo_and_discuss": 164, "fairli": [164, 200], "safe": [164, 189], "eu": 164, "mu_g_slid": 164, "\u00b5_gain": 164, "mu_c_slid": 164, "\u00b5_cost": 164, "sigma_g_slid": 164, "\u03c3_gain": 164, "sigma_c_slid": 164, "\u03c3_cost": 164, "distro_label": 164, "gain_label": 164, "loss_label": 164, "_complicated_cat_costs_interactive_demo_and_discuss": 164, "mu_x": 164, "sigma_x": 164, "anticorrel": 164, "\u00b5_x": 164, "\u00b5_y": 164, "\u03c3_x": 164, "\u03c3_y": 164, "corr_slid": 164, "distro1_label": 164, "distro2_label": 164, "corr_label": 164, "_covarying_2d_gaussian_interactive_demo_and_discuss": 164, "c_x_slider": 164, "cx": 164, "c_y_slid": 164, "cy": 164, "_marginalization_and_information_interactive_demo_and_discuss": 164, "2_": [164, 172], "secton": 164, "guassian": 164, "_prior_exploration_interactive_demo_and_discuss": 164, "modal": 164, "_standard_loss_functions_with_various_priors_interactive_demo_and_discuss": 164, "dist_label": 164, "\u00b51_c": 164, "\u00b52_c": 164, "loc_label": 164, "mu_dist_slid": 164, "mu_loc_slid": 164, "_complicated_cat_costs_with_various_priors_interactive_demo_and_discuss": 164, "vincent": 165, "valton": 165, "jess": [165, 171, 172, 174, 175], "livezei": [165, 171, 172, 174, 175], "outdat": 165, "w3d1_t3_bonu": 165, "plot_myarrai": 165, "plot_my_bayes_model": 165, "ex": 165, "alpha_tri": 165, "nll": 165, "i_tri": 165, "p_independ": 165, "ix": 165, "plot_simulated_behavior": 165, "true_stim": 165, "moments_myfunc": 165, "cdf_function": 165, "noisili": 165, "puppet": 165, "curtain": 165, "speaker": 165, "distant": 165, "hypothetical_stim": 165, "compute_likelihood_arrai": 165, "stim_arrai": 165, "likelihood_arrai": 165, "_auditory_likelihood_exercis": 165, "_prior_array_video": 165, "peakier": 165, "calculate_prior_arrai": 165, "p_indep": 165, "prior_mean_common": 165, "prior_sigma_common": 165, "prior_mean_indep": 165, "prior_sigma_indep": 165, "indep": 165, "prior_common": 165, "prior_indep": 165, "prior_mix": 165, "prior_arrai": 165, "fcn": 165, "_implement_prior_array_exercis": 165, "_posterior_array_video": 165, "calculate_posterior_arrai": 165, "posterior_arrai": 165, "_calculate_posterior_exercis": 165, "_binary_decision_matrix_video": 165, "unobserv": [165, 172, 175, 199, 200], "scan": [165, 174], "x_column": 165, "calculate_binary_decision_arrai": 165, "binary_decision_arrai": 165, "docstr": [165, 181], "_calculate_estimated_response_exercis": 165, "_input_array_video": 165, "generate_input_arrai": 165, "input_arrai": 165, "_generate_input_array_exercis": 165, "_marginalization_video": 165, "snippet": 165, "artifact": 165, "my_margin": 165, "marginalization_arrai": 165, "_implement_marginalization_matrix_exercis": 165, "recoveri": 165, "gone": 165, "x_stim": 165, "x_hat": [165, 200], "prior_mean": [165, 173], "prior_sigma1": 165, "prior_sigma2": 165, "prior1": 165, "prior2": 165, "prior_combin": 165, "i_stim": 165, "likelihood_mean": 165, "likelihood_sigma": 165, "_loglikelihood_video": 165, "my_bayes_model_ms": 165, "recomput": [165, 189], "trial_ll": 165, "marginal_nonzero": 165, "neg_ll": 165, "_fitting_a_model_to_generated_data_exercis": 165, "went": [165, 190, 191], "katahira": 167, "suzuki": 167, "okanoya": 167, "okada": 167, "birdsong": 167, "e24516": 167, "0024516": 167, "hmm": [167, 169, 173, 174, 181], "serruya": 167, "shaikhouni": 167, "bienenstock": 167, "cursor": 167, "169779d3852b32ce8b1a1724dbf5217d": 167, "kf": [167, 174, 182], "mormann": 167, "malmaud": 167, "huth": 167, "rangel": 167, "pressur": 167, "449": 167, "2139": 167, "ssrn": 167, "1901533": 167, "zoltowski": 167, "yate": 167, "1249": 167, "1258": 167, "demystifi": 167, "vannevar": 167, "ec": 167, "uw": 167, "techsit": 167, "uweetr": 167, "0002": 167, "w3d2_daysummari": 168, "recreat": [169, 188], "plenti": 169, "lesson": [169, 173, 179, 181], "pervas": 169, "fluoresc": 169, "w3d2_intro": 169, "w3d2_outro": 170, "yicheng": [171, 172, 175], "fei": [171, 172, 175], "melvin": 171, "selim": 171, "atai": 171, "posterior": [171, 172, 173, 174, 179, 181, 182], "w3d2_t1": 171, "erf": 171, "plot_accuracy_vs_stoptim": 171, "stop_time_list": 171, "accuracy_analytical_list": 171, "accuracy_list": 171, "stop_time_list_plot": 171, "sigma_st_max": 171, "stop_tim": 171, "ins": 171, "inset_ax": 171, "mu_st": 171, "sigma_st": 171, "lbl": [171, 172], "crimson": [171, 172, 173, 181], "solid": [171, 201], "domain0": 171, "simulate_and_plot_sprt_fixedtim": 171, "evidence_history_list": 171, "ttotal_evid": 171, "tdecis": 171, "evidence_histori": 171, "mvec": 171, "simulate_sprt_fixedtim": 171, "maxlen_evid": 171, "simulate_and_plot_sprt_fixedthreshold": 171, "threshold_from_errorr": 171, "ttime": 171, "taccumul": 171, "simulate_sprt_threshold": 171, "simulate_and_plot_accuracy_vs_threshold": 171, "threshold_list": 171, "alpha_list": 171, "decision_spe": 171, "simulate_accuracy_vs_threshold": 171, "amin": 171, "amax": 171, "_overview_of_tutorials_video": 171, "identi": 171, "iid": 171, "l_t": [171, 182], "m_t": [171, 172, 173, 174, 182], "tp": 171, "delta_t": 171, "l_": 171, "epsilon_t": [171, 197, 199, 200], "_sequential_probability_ratio_test_video": 171, "m_i": 171, "rewritten": [171, 174], "bt": 171, "log_likelihood_ratio": 171, "logpdf": 171, "llvec": 171, "true_dist": 171, "mu_po": 171, "mu_neg": 171, "p_po": 171, "p_neg": 171, "ll_ratio_vec": 171, "total_evid": 171, "_simulating_an_sprt_model_exercis": 171, "_trajectories_under_the_fixed_time_stop": 171, "rule_interactive_demo_and_discuss": 171, "_section_1_exercises_discussion_video": [171, 172], "_speed_vs_accuracy_tradeoff_video": 171, "buri": 171, "simulate_accuracy_vs_stoptim": 171, "no_numer": 171, "stop_list_list": 171, "flag": [171, 174], "decisions_list": 171, "tracker": [171, 174], "accuracies_analyt": 171, "i_stop_tim": 171, "sigma_sum_gaussian": 171, "_speed_vs_accuracy_tradeoff_exercis": 171, "inset": 171, "_speed_vs_accuracy_tradeoff_interactive_demo_and_discuss": 171, "_section_2_exercises_discussion_video": 171, "kinematogram": 171, "britten": 171, "movshon": 171, "rightward": 171, "leftward": 171, "shadlen": 171, "pamela": 171, "reinagl": 171, "youtu": [171, 174, 175], "odxcytn": 171, "0o": 171, "learnt": 171, "_fixed_threshold_on_confidence_bonus_video": 171, "variant": [171, 173], "th_1": 171, "th_0": 171, "th_": 171, "pl": 171, "mul": 171, "has_enough_data": 171, "data_histori": 171, "current_evid": 171, "ll_ratio": 171, "chunk": 171, "log10_alpha": 171, "log10": 171, "_simulating_the_ddm_with_fixed_confidence_thresholds_bonus_exercis": 171, "_ddm_with_fixed_confidence_threshold_bonus_interactive_demo": 171, "ant": 171, "bee": 171, "rodent": 171, "incentiv": 171, "suppli": 171, "decision_speed_list": 171, "decision_time_list": 171, "decision_list": 171, "decision_tim": 171, "decision_length": 171, "decision_accuraci": 171, "86": [171, 191], "_speed_vs_accuracy_tradeoff_revisited_bonus_exercis": 171, "_speed_vs_accuracy_with_a_threshold_rule_bonus_interactive_demo": 171, "meenakshi": [172, 175], "sleep": [172, 199], "wake": 172, "indirectli": 172, "s_t": [172, 173, 174, 181, 182, 188, 190], "emiss": [172, 175], "w3d2_t2": 172, "linear_sum_assign": [172, 175], "plot_hmm1": 172, "flag_m": [172, 173], "hmmlearn": 172, "nstep": [172, 188], "aspect_ratio": 172, "states_forplot": 172, "twinx": [172, 173, 181], "maroon": 172, "fill_betweenx": [172, 173], "plot_marginal_seq": 172, "predictive_prob": 172, "switch_prob": 172, "prob_neg": 172, "p_vec": 172, "prob_po": 172, "boxstyl": 172, "wheat": 172, "plot_evidence_vs_noevid": 172, "posterior_matrix": 172, "nsampl": 172, "posterior_mean": [172, 173], "plot_forward_infer": 172, "states_inf": 172, "posterior_prob": 172, "flag_d": 172, "flag_pr": 172, "flag_lik": 172, "flag_post": 172, "gaussianhmm": 172, "states_interpol": 172, "borderaxespad": 172, "bar_scal": 172, "dodgerblu": [172, 173], "keepdim": 172, "wholli": 172, "s_": [172, 173, 174, 182, 188, 190], "d_": 172, "p_t": [172, 174], "_binary_hmm_with_gaussian_measurements_video": 172, "noise_level": 172, "create_hmm": 172, "transmat_": 172, "gaussianhmm1d": [172, 175], "startprob": [172, 175], "startprob_vec": 172, "transmat": [172, 175], "transmat_mat": 172, "means_vec": 172, "vars_vec": 172, "transition_vector": 172, "09355908": 172, "58552915": 172, "93502804": 172, "98819072": 172, "32506947": 172, "_simulating_binary_hmm_with_gaussian_measurements_exercis": 172, "plot_samples_widget": 172, "log10_noise_level": 172, "_binary_hmm_interactive_demo_and_discuss": 172, "_forgetting_in_a_changing_world_video": 172, "s_0": [172, 174], "simulate_prediction_onli": 172, "prob_switch": 172, "entropy_list": 172, "_forgetting_in_a_changing_world_interactive_demo_and_discuss": 172, "_section_2_exercise_discussion_video": 172, "_forward_inference_in_an_hmm_video": 172, "markov_forward": 172, "one_step_upd": 172, "compute_likelihood": 172, "simulate_forward_infer": 172, "rv0": 172, "rv1": 172, "predictive_state1": 172, "posterior_state1": 172, "hte": 172, "condtion": 172, "posterior_tm1": 172, "posterior_t": 172, "_forward_inference_of_hmm_exercis": 172, "log_10_noise_level": 172, "plot_forward_inference_widget": 172, "_forward_inference_of_hmm_interactive_demo": 172, "_section_3_exercise_discussion_video": 172, "rowei": [173, 174], "ghahramani": [173, 174], "mission": [173, 182], "w3d2_t3": 173, "visualize_astrocat": 173, "plot_measur": [173, 181], "y1": 173, "y2": 173, "y3": 173, "y4": 173, "y5": 173, "y6": 173, "process_nois": 173, "measurement_nois": 173, "todays_prior": 173, "info_prior": 173, "info_likelihood": 173, "info_posterior": 173, "prior_weight": 173, "likelihood_weight": 173, "posterior_cov": 173, "todays_posterior": 173, "predicted_estim": [173, 182], "predicted_covari": [173, 182], "innovation_estim": [173, 182], "innovation_covari": [173, 182], "updated_mean": [173, 182], "updated_cov": [173, 182], "paintmyfilt": 173, "initial_guess": 173, "cov_": 173, "filter_s_": 173, "filter_cov_": 173, "process_noise_std": 173, "measurement_noise_std": 173, "smin": 173, "smax": 173, "pscale": 173, "lightgrai": 173, "_astrocat_through_time_video": 173, "_quantifying_astrocat_dynamics_video": 173, "ds_": [173, 174], "w_t": [173, 174, 182], "sigma_p": 173, "actuat": 173, "propuls": 173, "tau_min": 173, "tau_max": 173, "process_noise_min": 173, "process_noise_max": 173, "measurement_noise_min": 173, "measurement_noise_max": 173, "unit_process_nois": 173, "unit_measurement_nois": 173, "s0": 173, "_simulating_astrocats_movements_exercis": 173, "_playing_with_astrocat_movement_interactive_demo_and_discuss": 173, "_exercise_1": 173, "1_discussion_video": 173, "_measuring_astrocats_movements_video": 173, "sigma_measur": 173, "read_collar": 173, "_reading_measurements_from_astrocats_collar_exercis": 173, "_comparing_true_states_to_measured_states_video": 173, "catastroph": 173, "sbound": 173, "_compare_true_states_to_measured_states_exercis": 173, "2_discussion_video": 173, "_the_kalman_filter_video": 173, "15ex": [173, 181, 182], "flag_": 173, "flag_s_": 173, "flag_err_": 173, "stochastic_system": 173, "timelin": [173, 181, 182], "process_noise_cov": 173, "measurement_noise_cov": 173, "prior_cov": 173, "captured_prior": 173, "captured_likelihood": 173, "captured_posterior": 173, "onfilt": 173, "show_pdf": 173, "pdf_likelihood": 173, "pdf_post": 173, "pdf_prior": 173, "_the_kalman_filter_in_action_interactive_demo": 173, "_interactive_demo_2": 173, "_implementing_a_kalman_filter_video": 173, "recip": 173, "broaden": 173, "sigma_w": 173, "sigma_m": 173, "textit": 173, "congrat": 173, "partwai": 173, "_implement_your_own_kalman_filter_exercis": 173, "_exercise_2": 173, "_compare_states_estimates_and_measurements_video": 173, "errorbar": 173, "yerr": 173, "mfc": 173, "mec": 173, "axhist": 173, "pdf_g": 173, "_compare_states_estimates_and_measurements_interactive_demo": 173, "_how_long_does_it_take_to_find_astrocat_video": 173, "hone": 173, "snr": 173, "decibel": 173, "equilibr": 173, "snrdb": 173, "pcov": 173, "equilibrium_posterior_var": 173, "equilibrium_process_var": 173, "labelcolor": 173, "set_major_formatt": 173, "funcformatt": 173, "format_func": 173, "nprocess": 173, "_how_long_does_it_take_to_find_astrocat_interactive_demo": 173, "3_discussion_video": 173, "carolin": 174, "haimerl": 174, "cristina": 174, "w3d2_t4_bonu": 174, "sy": 174, "set_printopt": [174, 189], "plot_kalman": 174, "plot_gaze_data": 174, "plot_kf_stat": 174, "mu_0": 174, "n_dim_stat": 174, "initial_state_mean": [174, 182], "w2d3_mit_eyetracking_2009": 174, "jfk8w": 174, "20c7bc4a6f61f49450997e381cf5e0dd": 174, "load_eyetracking_data": 174, "imread": 174, "jpg": 174, "6f_51l3i5aq": 174, "2swh639ygeg": 174, "condition": 174, "hs_": 174, "eta_t": 174, "sigma_0": 174, "tractabl": 174, "apolog": 174, "timecours": 174, "n_dim_ob": 174, "sample_ld": 174, "n_timestep": 174, "ob": 174, "_sampling_from_a_linear_dynamical_system_exercis": 174, "explore_dynam": 174, "_adjusting_system_dynamics_interactive_demo": 174, "vbozov9qmoi": 174, "_kalman_filtering_video": 174, "m_1": 174, "sigma_t": 174, "mathsf": 174, "newest": 174, "k_t": 174, "k_th": 174, "hdz_": 174, "kalman_filt": 174, "mu_pr": 174, "sigma_pr": 174, "filtered_state_mean": 174, "filtered_state_covari": 174, "_implement_kalman_filtering_exercis": 174, "m7ouxmvwhgi": 174, "_fitting_eye_gaze_data_video": 174, "devic": 174, "calibr": 174, "ambient": 174, "eyetrack": 174, "databas": 174, "judd": 174, "fixat": 174, "subject_id": 174, "image_id": 174, "plot_subject_trac": 174, "_tracking_eye_gaze_interactive_demo": 174, "influenti": 174, "texttt": 174, "transition_matric": 174, "transition_covari": [174, 182], "observation_matric": 174, "observation_covari": [174, 182], "initial_state_covari": [174, 182], "kalmanfilt": [174, 182], "em_var": 174, "016": 174, "219": 174, "774": 174, "596": 174, "magenta": 174, "triangl": 174, "plot_smoothed_trac": 174, "decent": 174, "nonetheless": 174, "kf_state": 174, "kf_data": 174, "initial_st": 174, "observation_offset": 174, "_last_dim": 174, "1116": 174, "1117": 174, "1118": 174, "1119": 174, "1120": 174, "1121": 174, "1122": 174, "observation_matrix": [174, 182], "1123": 174, "1124": 174, "1125": 174, "newbyteord": 174, "1127": 174, "1128": 174, "1130": 174, "arr": 174, "environment": [174, 177, 191], "mitig": 174, "delet": 174, "arbitrarili": 174, "cb": 174, "4ar2myz1nm": 174, "_kalman_smoothing_and_the_em_algorithm_bonus_video": 174, "j_t": 174, "z_t": 174, "kalman_smooth": 174, "mu_hat": 174, "sigma_hat": 174, "smoothed_state_mean": 174, "smoothed_state_covari": 174, "_implement_kalman_smoothing_bonus_exercis": 174, "dz": 174, "kl": 174, "kept": 174, "s_ts_": 174, "j_": [174, 182, 197], "q_0": 174, "s_0s_0": 174, "s_ts_t": 174, "ny_ty_t": 174, "sean": 175, "escola": 175, "w3d2_t5_bonu": 175, "plot_spike_train": 175, "hot": 175, "trial_t": 175, "rect": 175, "add_patch": 175, "plot_ll": 175, "plot_lls_ecl": 175, "plot_epoch": 175, "save_v": 175, "minll": 175, "maxll": 175, "bs": 175, "lls_for_plot": 175, "eclls_for_plot": 175, "ecll": 175, "framealpha": 175, "plot_learnt_vs_tru": 175, "l_true": 175, "a_tru": 175, "run_em": 175, "psi": 175, "flot": 175, "e_step": 175, "print_everi": 175, "psi_new": 175, "a_new": 175, "l_new": 175, "m_step": 175, "interpol": [175, 190, 191], "extrapol": 175, "b_min": 175, "b_max": 175, "b_lim": 175, "num_plot_v": 175, "logpmf": 175, "diff_ll": 175, "ceqxn0ouafo": 175, "wb8mf5chmyi": 175, "_hmm_for_poisson_spiking_neurons_video": 175, "thalam": 175, "relai": 175, "tonic": 175, "rapid": 175, "receptor": 175, "molecular": 175, "n_frozen_tri": 175, "max_firing_r": 175, "max_transition_r": 175, "expens": 175, "craft": 175, "psi_tru": 175, "xf": 175, "yf": 175, "one_hot": 175, "umu4wuwlkvg": 175, "_em_tutorial_video": 175, "b_i": 175, "pairwis": 175, "gamma_": 175, "xi_": 175, "sum_j": 175, "ji": 175, "a_j": 175, "b_j": 175, "b_": 175, "psi_i": 175, "gamma_i": 175, "compact": 175, "o_j": 175, "o_": 175, "lj": 175, "l1j": 175, "node": [175, 198], "log_a": 175, "log_ob": 175, "maxtmp": 175, "h4ggtg_9bae": 175, "_implement_the_m_step_video": 175, "swapax": 175, "_implement_m_step_exercis": 175, "6utsxxe3hg0": 175, "_running_and_plotting_em_video": 175, "\ud835\udf03": [175, 181], "8684143040628": 175, "481": [175, 177], "5065734432824": 175, "cost_mat": 175, "true_ind": 175, "est_ind": 175, "bertseka": [177, 182], "bellman": 177, "1966": 177, "3731": 177, "charnov": 177, "forag": 177, "136": 177, "doyl": 177, "1978": 177, "lqg": 177, "757": 177, "tac": 177, "1101812": 177, "kalman": 177, "1960": 177, "boletin": 177, "sociedad": 177, "matematica": 177, "mexicana": 177, "kappen": 177, "g\u00f3mez": 177, "opper": 177, "159": 177, "182": 177, "s10994": 177, "5278": 177, "todorov": 177, "11478": 177, "11483": 177, "0710743106": 177, "pmc2705278": 177, "castro": 177, "hadjiosif": 177, "hemphil": 177, "1050": 177, "1061": 177, "cub": 177, "049": 177, "brandt": 177, "shadmehr": 177, "disord": 177, "huntington": 177, "6769": 177, "549": 177, "35000576": 177, "harvard": 177, "motorlab": 177, "reprint": 177, "nature00": 177, "sing": 177, "joiner": 177, "nanayakkara": 177, "brayanov": 177, "primit": 177, "575": 177, "589": 177, "wagner": 177, "10663": 177, "10673": 177, "5479": 177, "bautista": 177, "tinbergen": 177, "kacelnik": 177, "fly": 177, "1094": 177, "pmc14713": 177, "ralston": 177, "1958": 177, "international": 177, "zeitschrift": 177, "f\u00fcr": 177, "angewandt": 177, "physiologi": 177, "einschliesslich": 177, "arbeitsphysiologi": 177, "bf00698754": 177, "ahm": 177, "vigor": 177, "neuroeconom": 177, "zee": 177, "saccad": 177, "196": [177, 184], "475": 177, "s00221": 177, "1879": 177, "pmc2771693": 177, "yoon": 177, "geari": 177, "e10476": 177, "e10485": 177, "1812979115": 177, "pmc6217431": 177, "jaleel": 177, "2161": 177, "00700": 177, "w3d3_daysummari": 178, "w3d3_intro": 179, "w3d3_outro": 180, "zhengwei": [181, 182], "shreya": [181, 182], "saxena": [181, 182], "melisa": 181, "maidana": 181, "capitan": 181, "pomdp": 181, "agent": [181, 186, 188, 189, 190, 191], "greatest": 181, "w3d3_t1": 181, "isclos": [181, 182], "plot_fish": 181, "fish_stat": 181, "cornflowerblu": 181, "rel_po": 181, "red_i": 181, "blue_i": 181, "royalblu": 181, "plot_act_loc": 181, "ax_loc": 181, "act_down": 181, "act_up": 181, "plot_belief": 181, "choose_polici": 181, "midnightblu": 181, "get_yticklabel": 181, "time_rang": 181, "mea": 181, "ax0": [181, 182], "ax_bel": 181, "belief_histogram": 181, "plot_value_threshold": 181, "threshold_arrai": 181, "value_arrai": 181, "yrang": 181, "star_loc": 181, "fig_": 181, "cost_sw": 181, "fist": 181, "init_t": 181, "rnd_tele": 181, "rnd_high_rwd": 181, "rnd_low_rwd": 181, "get_random": 181, "binomial_tel": 181, "getrandom": 181, "excerciseerror": 181, "assertionerror": [181, 182], "binaryhmm": 181, "fish_initi": 181, "loc_initi": 181, "fish_dynam": 181, "telegraph": 181, "p_stai": 181, "tele_oper": 181, "generate_process_lazi": 181, "rwd": 181, "p_low_rwd": 181, "p_high_rwd": 181, "p_rwd_vector": 181, "binaryhmm_belief": 181, "generate_process": 181, "low_rew_p": 181, "high_rew_p": 181, "rew_prob": 181, "belief_0": 181, "belief_upd": 181, "lazi": 181, "policy_threshold": 181, "policy_lazi": 181, "belief_past": 181, "rew_prob_matrix": 181, "belief_1": 181, "test_policy_threshold": 181, "well_don": 181, "test_value_funct": 181, "get_valu": 181, "value_funct": 181, "_gone_fishing_video": 181, "secretli": 181, "sw": 181, "q_": [181, 189], "price": 181, "prescrib": 181, "b_t": 181, "stay_prob": 181, "update_ex_1": 181, "swim": 181, "binaryhmm_test": 181, "_examining_fish_dynamics_interactive_demo_and_discuss": 181, "_catch_some_fish_video": 181, "seren": 181, "high_rew_prob": 181, "low_rew_prob": 181, "radiobutton": [181, 182], "update_ex_2": 181, "agent_initi": 181, "_examining_the_reward_function_interactive_demo_and_discuss": 181, "_where_are_the_fish_video": 181, "_examining_the_beliefs_interactive_demo_and_discuss": 181, "_how_should_you_act_video": 181, "239": 181, "_dynamics_threshold_based_policy_exercis": 181, "new_se": 181, "update_ex_4": 181, "_dynamics_with_different_thresholds_interactive_demo_and_discuss": 181, "_evaluate_policy_video": 181, "a_t": [181, 182, 190], "paid": 181, "actions_int": 181, "247": 181, "248": 181, "251": 181, "252": 181, "_implementing_a_value_function_exercis": 181, "brute": 181, "get_optimal_threshold": 181, "large_time_horizon": 181, "run_polici": 181, "_run_the_policy_exercise_and_discuss": 181, "mdp": 181, "illumin": 181, "_from_discrete_to_continuous_control_video": 181, "_sensitivity_of_optimal_policy_bonus_video": 181, "high_rwd": 181, "low_rwd": 181, "rarer": 181, "coars": 181, "update_ex_bonu": 181, "_explore_task_parameters_bonus_interactive_demo_and_discuss": 181, "w3d3_t2": 182, "plot_vs_tim": 182, "slabel": 182, "plot_kf_state_vs_tim": 182, "latent_st": 182, "standard_normal_nois": 182, "standard_normal_noise_mea": 182, "exerciseerror": 182, "test_lds_class": 182, "lds_class": 182, "ldsy": 182, "ini_st": 182, "noise_var": 182, "dynamics_openloop": 182, "dynamics_closedloop": 182, "test_lqr_class": 182, "lqr_class": 182, "lqreg": 182, "calculate_j_st": 182, "calculate_j_control": 182, "_flying_through_space_video": 182, "corros": 182, "unintend": 182, "ba_t": 182, "ds_t": 182, "neq": [182, 198, 199], "excercis": 182, "polici": [182, 188, 189, 191], "static_nois": 182, "_implement_state_evolution_equations_exercis": 182, "fare": 182, "simulate_ld": 182, "s_no_control": 182, "s_open_loop": 182, "s_closed_loop": 182, "a_closed_loop": 182, "_no_control_closed_lopp_open_loop_interactive_demo_and_discuss": 182, "optimum": 182, "ls_t": 182, "bl": 182, "calculate_plot_ms": 182, "num_iter": 182, "num_candid": 182, "control_gain_arrai": 182, "mse_arrai": 182, "ambiti": 182, "051": 182, "simulate_l": 182, "s_closed_loop_choic": 182, "l_theori": 182, "s_closed_loop_theoret": 182, "_closed_loop_exploration_interactive_demo_and_discuss": 182, "_lqr_video": 182, "fuel": 182, "certainli": 182, "riccati": 182, "dimitri": 182, "belmont": 182, "control_gain_lqr": 182, "p_t_1": 182, "j_state": 182, "j_control": 182, "_implement_the_cost_function_exercis": 182, "simulate_rho": 182, "s_lqr": 182, "a_lqr": 182, "_lqr_to_the_origin_interactive_demo_and_discuss": 182, "calculate_plot_cost": 182, "rho_arrai": 182, "_tracking_a_moving_goal_video": 182, "bounc": 182, "g_t": 182, "lqr_track": 182, "dynamics_track": 182, "intial": 182, "a_bar": 182, "react": 182, "goal_func": 182, "simulate_track": 182, "lqr_time": 182, "s_lqr_time": 182, "a_lqr_tim": 182, "a_bar_lqr_tim": 182, "lqr_control_to_desired_time_varying_goal_interactive_demo_and_discuss": 182, "_lqg_video": 182, "radar": 182, "proc_nois": 182, "meas_nois": 182, "get_estim": 182, "innov": 182, "ntrial": 182, "get_control_gain_infinit": 182, "control_policy_lqg": 182, "control_gain": 182, "estimated_st": 182, "current_act": [182, 198], "simulate_kf_no_control": 182, "ini_state_mean": 182, "ini_state_cov": 182, "_lqg_control_interactive_demo_and_discuss": 182, "arround": 182, "simulate_kf_with_control": 182, "_lqc_controller_varying_gains_interactive_demo": 182, "simulate_kf_with_lqg": 182, "_lqc_controller_varying_weight_interactive_demo": 182, "lqg_slider": 182, "_process_noise_measurements_noise_interactive_demo": 182, "transit_matrix_slid": 182, "n_op": 182, "process_noise_var": 182, "measurement_noise_var": 182, "mse_array_n_mea": 182, "mse_array_n_proc": 182, "jcontrol_array_n_mea": 182, "jcontrol_array_n_proc": 182, "meas_noise_arrai": 182, "proc_noise_arrai": 182, "proc": 182, "mse_array_proc": 182, "jcontrol_array_proc": 182, "control_gain_lqg": 182, "filtered_state_means_impl": 182, "filtered_state_covariances_impl": 182, "action_cost": 182, "state_cost": 182, "mse_array_mea": 182, "jcontrol_array_mea": 182, "mse_array_proc_mean": 182, "mse_array_proc_std": 182, "mse_array_meas_mean": 182, "mse_array_meas_std": 182, "jcontrol_array_proc_mean": 182, "jcontrol_array_proc_std": 182, "jcontrol_array_meas_mean": 182, "jcontrol_array_meas_std": 182, "quantif": 182, "_noise_effects_on_the_lqg_discuss": 182, "sutton": 184, "barto": 184, "schultz": 184, "montagu": 184, "5306": 184, "1593": 184, "1599": 184, "utexa": 184, "dana": 184, "daw": 184, "dorsolater": 184, "striatal": 184, "1704": 184, "1711": 184, "nn1560": 184, "185": 184, "kurth": 184, "kumaran": 184, "tirumala": 184, "soyer": 184, "leibo": 184, "868": 184, "0147": 184, "295964": 184, "mattar": [184, 188, 189, 190, 191], "replai": 184, "1609": 184, "1617": 184, "0232": 184, "pmc6203620": 184, "dabnei": 184, "uchida": 184, "starkweath": 184, "hassabi": 184, "muno": 184, "dopamin": [184, 188], "577": 184, "7792": 184, "671": 184, "675": 184, "1924": 184, "pmc7476215": 184, "mnih": 184, "kavukcuoglu": 184, "rusu": 184, "veness": 184, "bellemar": 184, "518": 184, "7540": 184, "529": 184, "533": 184, "nature14236": 184, "huang": 184, "maddison": 184, "guez": 184, "sifr": 184, "driessch": 184, "game": 184, "tree": 184, "7587": 184, "484": 184, "489": 184, "nature16961": 184, "w3d4_daysummari": 185, "exploit": [186, 189, 190], "dilemma": [186, 189], "w3d4_intro": 186, "w3d4_outro": 187, "marcelo": [188, 189, 190, 191], "sargent": [188, 189, 190, 191], "sowmya": [188, 189, 190, 191], "parthiban": [188, 189, 190, 191], "feryal": [188, 189, 190, 191], "behbahani": [188, 189, 190, 191], "jane": [188, 189, 190, 191], "ezekiel": [188, 189, 190, 191], "mehul": [188, 189, 190, 191], "rastogi": [188, 189, 190, 191], "roberto": [188, 189, 190, 191], "guidotti": [188, 189, 190, 191], "arush": [188, 189, 190, 191], "tagad": [188, 189, 190, 191], "kelson": [188, 189, 190, 191], "shill": [188, 189, 190, 191], "scrivo": [188, 189, 190, 191], "uncondit": 188, "conting": 188, "rpe": 188, "tap": 188, "w3d4_t1": 188, "plot_value_funct": 188, "plot_tde_trac": 188, "tde": 188, "indx": 188, "fixedloc": 188, "learning_summary_plot": 188, "ex1": 188, "reward_guesser_title_hint": 188, "r1": 188, "r2": 188, "mildli": 188, "obfusc": 188, "spoil": 188, "classicalcondit": 188, "reward_magnitud": 188, "reward_tim": 188, "n_action": [188, 190, 191], "cs_time": 188, "reward_st": 188, "reward_prob": 188, "set_reward": 188, "_create_state_dictionari": 188, "get_outcom": [188, 190, 191], "current_st": 188, "next_stat": [188, 190, 191], "episod": [188, 189, 190, 191], "is_delai": 188, "t_in_delai": 188, "multirewardcc": 188, "deliv": 188, "probabilisticcc": 188, "p_reward": 188, "iti": 188, "rumelhart": 188, "pdplab": 188, "pdphandbook": 188, "handbookch10": 188, "limits_": 188, "sum_a": 188, "proxi": [188, 195], "delta_": [188, 197], "discrep": 188, "tl": 188, "td_learner": 188, "env": [188, 190, 191], "_td_learning_exercis": 188, "saliv": 188, "smell": 188, "tasti": 188, "pavlov": 188, "ring": 188, "inconsist": 188, "plot_tde_by_tri": 188, "basefmt": 188, "linefmt": 188, "markerfmt": 188, "c1d": 188, "c0o": 188, "_us_to_cs_transfer_interactive_demo": 188, "plot_summary_alpha_gamma": 188, "980": 188, "\u03b3": 188, "v_param": 188, "tde_param": 188, "_learning_rates_and_discount_factors_interactive_demo_and_discuss": 188, "learner": 188, "dispens": 188, "rng_state": 188, "get_stat": 188, "v_multi": 188, "tde_multi": 188, "reward_guesser_interact": 188, "inttext": 188, "env2": 188, "v_guess": 188, "yo": 188, "set_markers": 188, "set_markerfacecolor": 188, "rx": 188, "_examining_the_td_error_discuss": 188, "intermitt": 188, "set_stat": 188, "resynchron": 188, "v_stochast": 188, "tde_stochast": 188, "_probabilistic_rewards_discuss": 188, "bewar": 188, "_removing_the_cs_bonus_discuss": 188, "w3d4_t2": 189, "plot_choic": 189, "choice_fn": 189, "rng_seed": 189, "plot_multi_armed_bandit_result": 189, "qs": 189, "plot_parameter_perform": 189, "trial_reward": 189, "trial_optim": 189, "_multiarmed_bandits_video": 189, "colloqui": 189, "lever": 189, "rig": 189, "monei": 189, "payout": 189, "r_t": [189, 190], "fatal": 189, "flaw": 189, "trap": 189, "bet": 189, "stumbl": 189, "epsilon_greedi": [189, 190, 191], "be_greedi": [189, 191], "_implement_epsilon_greedy_exercis": 189, "amongst": 189, "\u03b5": 189, "explore_epilson_valu": 189, "_changing_epsilon_interactive_demo_and_discuss": 189, "q_t": 189, "update_action_valu": 189, "_updating_action_values_exercis": 189, "multi_armed_bandit": 189, "n_arm": 189, "all_reward": 189, "optimal_act": 189, "alright": 189, "explore_bandit_paramet": 189, "worst": 189, "_changing_epsilon_and_alpha_interactive_demo": 189, "bandit": [190, 191], "w3d4_t3": 190, "plot_state_action_valu": [190, 191], "n_state": [190, 191], "plot_quiver_max_act": [190, 191], "cheese_world": [190, 191], "dim_x": [190, 191], "dim_i": [190, 191], "which_max": [190, 191], "minor": [190, 191], "plot_heatmap_max_v": [190, 191], "value_max": [190, 191], "afmhot": [190, 191], "windy_cliff_grid": [190, 191], "plot_reward": [190, 191], "n_episod": [190, 191], "average_rang": [190, 191], "smoothed_reward": [190, 191], "plot_perform": [190, 191], "reward_sum": [190, 191], "_mdps_and_q_learning_video": 190, "overcom": 190, "cliff": [190, 191], "4x10": 190, "td": 190, "watkin": 190, "max_": [190, 191], "discount": [190, 191], "greedi": [190, 191], "learn_environ": [190, 191], "lifecycl": 190, "cliffworld": 190, "probabilti": [190, 191], "border": [190, 191], "cliff_world": 190, "init_st": [190, 191], "get_all_outcom": [190, 191], "learning_rul": 190, "q_learn": [190, 191], "max_next_q": 190, "td_error": 190, "value_qlearn": 190, "reward_sums_qlearn": 190, "110": 190, "113": 190, "_implement_q_learning_algorithm_exercis": 190, "notabl": 190, "steadili": 190, "policy_next_q": 190, "policy_act": 190, "value_sarsa": 190, "reward_sums_sarsa": 190, "_implement_the_sarsa_algorithm_bonus_exercis": 190, "skittish": 190, "standpoint": 190, "skirt": 190, "wall": [190, 191], "rout": 190, "w3d4_t4": 191, "prev_valu": 191, "isnan": [191, 198, 199], "max_valu": 191, "model_updat": 191, "planner": 191, "shortcut_episod": 191, "episode_step": 191, "toggle_shortcut": 191, "quentinsworld": 191, "quentin": 191, "shortcut_st": 191, "_modelbased_rl_video": 191, "costli": 191, "fuller": 191, "assimil": 191, "10x10": 191, "trivial": 191, "tabular": 191, "forev": 191, "nontermin": 191, "dyna_q_model_upd": 191, "_dynaq_model_update_exercis": 191, "dyna_q_plan": 191, "nx2": 191, "_dynaq_planning_exercis": 191, "n_experi": 191, "planning_step": 191, "steps_per_episod": 191, "warm": 191, "upward": 191, "consolid": 191, "hernan": [193, 197], "robin": 193, "readabl": 193, "charit": 193, "dag": 193, "angrist": [193, 197], "pischk": [193, 197], "princeton": 193, "harmless": [193, 197], "imben": [193, 197], "aschengrau": 193, "seag": 193, "health": 193, "jone": 193, "bartlett": 193, "dominik": 193, "bernhard": 193, "cooper": 193, "herskovit": 193, "1992": 193, "induct": 193, "309": 193, "bf00994110": 193, "amari": 193, "arai": 193, "diekman": 193, "diesmann": 193, "kramer": 193, "041715": 193, "033733": 193, "126718": 193, "annrev2017fin": 193, "marinescu": 193, "lawlor": 193, "quasi": 193, "891": 193, "898": 193, "s41562": 193, "0466": 193, "econ": 193, "quasiexperiment": 193, "mooij": 193, "janz": 193, "zscheischler": 193, "sch\u00f6lkopf": 193, "1204": 193, "acm": 193, "5555": 193, "2946645": 193, "2946677": 193, "b\u00fchlmann": 193, "meinshausen": 193, "identif": 193, "royal": 193, "methodolog": 193, "947": 193, "1012": 193, "1111": 193, "rssb": 193, "12167": 193, "01332": 193, "scholkopf": 193, "judea": [193, 195], "765": 193, "804": 193, "3501714": 193, "3501755": 193, "1911": 193, "10500": 193, "shimizu": 193, "hoyer": 193, "hyv\u00e4rinen": 193, "kerminen": 193, "jordan": 193, "acycl": 193, "jmlr": 193, "v7": 193, "shimizu06a": 193, "spirt": 193, "glymour": 193, "schein": 193, "heckerman": 193, "causat": [193, 199, 200], "triantafil": 193, "tsamardino": 193, "2147": 193, "2205": 193, "v16": 193, "triantafillou15a": 193, "w3d5_daysummari": 194, "drug": [195, 197], "mislead": 195, "unmeasur": 195, "unavoid": 195, "w3d1": 195, "bedrock": 195, "heart": 195, "w3d5_intro": 195, "w3d5_outro": 196, "toni": [197, 198, 199, 200], "mike": [197, 198, 199, 200], "cohen": [197, 198, 199, 200], "yoni": [197, 198, 199, 200], "pproduct": 197, "w3d5_t1": 197, "see_neuron": [197, 198, 199, 200], "renorm": 197, "plot_connectivity_matrix": [197, 198, 199], "set_siz": [197, 198], "plot_connectivity_graph_matrix": 197, "plot_neural_act": [197, 200], "cax1": [197, 200], "plot_true_vs_estimated_connect": [197, 198], "estimated_connect": [197, 198, 199, 200], "true_connect": [197, 198], "selected_neuron": [197, 198, 200], "_defining_causality_video": 197, "rct": 197, "placebo": 197, "neuron_b": 197, "activity_of_a": 197, "diff_in_mean": 197, "9907195190159408": 197, "_randomized_controlled_trial_for_two_neurons_exercis": 197, "_simulated_neural_system_model_video": 197, "nonlinearli": 197, "i_n": 197, "create_connect": [197, 198, 199, 200], "nxn": [197, 198, 199, 200], "s_val": [197, 198, 199, 200], "s_val_test": [197, 200], "singular": [197, 200], "simulate_neuron": [197, 198, 199, 200], "timetep": [197, 198, 199, 200], "___t____t": 197, "1___": 197, "___1____0_____": 197, "_system_simulation_exercis": 197, "_perturbing_systems_video": 197, "frac1n": 197, "substack": 197, "interven": 197, "simulate_neurons_perturb": 197, "seriou": 197, "huh": 197, "x_perturb": 197, "boilerpl": 197, "cax0": 197, "_calculating_causality_video": 197, "start_index": 197, "end_index": 197, "count_bi": 197, "get_perturbed_connectivity_from_single_neuron": 197, "perturbed_x": 197, "neuron_perturb": 197, "all_neuron_output": 197, "this_neuron_output": 197, "one_idx": 197, "zero_idx": 197, "get_perturbed_connectivity_single_neuron": 197, "difference_in_mean": 197, "_perturbed_dynamics_to_recover_connectivity_exercis": 197, "strictli": [197, 198], "get_perturbed_connectivity_all_neuron": 197, "2n": 197, "987593404378358": 197, "econometr": 197, "proportion": 197, "w3d5_t2": 198, "plot_estimation_quality_vs_n_neuron": 198, "number_of_neuron": 198, "corr_func": 198, "corr_data": [198, 199, 200], "get_sys_corr": [198, 199, 200], "corr_mean": [198, 199, 200], "corr_std": [198, 199, 200], "correlation_for_all_neuron": [198, 199, 200], "_correlation_vs_causation_video": 198, "compute_connectivity_from_single_neuron": 198, "next_act": 198, "this_output_act": 198, "_approximate_causation_with_correlation_exercis": 198, "5f": 198, "95967": 198, "_correlation_causation_for_small_systems_video": 198, "_correlation_causation_in_large_systems_video": 198, "plot_corr": 198, "_function_base_impl": [198, 199], "2922": [198, 199], "runtimewarn": [198, 199], "stddev": [198, 199], "2923": [198, 199], "_connectivity_estimation_as_a_function_of_number_of_neurons_interactive_demo": 198, "rightli": 198, "wonder": [198, 199, 200], "_connectivity_estimation_as_a_function_of_the_sparsity_a_interactive_demo": 198, "phrase": 198, "filler": 198, "mediat": 198, "promot": 198, "_reflecting_on_causality_discuss": 198, "spearman": 198, "dichotom": 198, "concord": 198, "kappa": 198, "braini": 198, "coarse_x": 198, "get_coarse_corr": 198, "n_group": 198, "coarse_a": 198, "_compute_average_activity_bonus_exercis": 198, "neffect": 198, "controversi": 199, "w3d5_t3": 199, "multioutput": [199, 200], "multioutputregressor": [199, 200], "ratio_observ": 199, "_regression_approach_video": 199, "confound": [199, 200], "homework": 199, "grade": 199, "confond": 199, "collid": 199, "counterintuit": 199, "_fitting_a_glm_video": 199, "logit": [199, 200], "l_1": 199, "fit_intercept": [199, 200], "get_regression_estim": [199, 200], "865": 199, "703": 199, "_linear_regression_with_lasso_to_estimate_causal_connectivities_exercis": 199, "_omitted_variable_bias_video": 199, "sel_idx": [199, 200], "set_text": [199, 200], "046": [199, 200], "get_regression_estimate_full_connect": [199, 200], "get_regression_corr_full_connect": [199, 200], "reg": [199, 200], "n_job": [199, 200], "estimators_": [199, 200], "observed_ratio": [199, 200], "regression_arg": [199, 200], "betweem": [199, 200], "sel_x": [199, 200], "sel_a": [199, 200], "sel_v": [199, 200], "4000": 199, "reg_arg": [199, 200], "n_observ": [199, 200], "to_neuron": 199, "big_r": [199, 200], "nanmean": 199, "nanstd": 199, "_coordinate_desc": 199, "697": 199, "convergencewarn": 199, "dualiti": 199, "035e": 199, "170e": 199, "cd_fast": 199, "enet_coordinate_desc": 199, "194e": 199, "991e": 199, "444e": 199, "037e": 199, "527e": 199, "297e": 199, "267e": 199, "659e": 199, "612e": 199, "502e": 199, "205e": 199, "716e": 199, "571e": 199, "069e": 199, "784e": 199, "325e": 199, "105e": 199, "815e": 199, "791e": 199, "903e": 199, "089e": 199, "599e": 199, "111e": 199, "913e": 199, "078e": 199, "658e": 199, "302e": 199, "114e": 199, "018e": 199, "731e": 199, "171e": 199, "299e": 199, "472e": 199, "109e": 199, "060e": 199, "243e": 199, "636e": 199, "693e": 199, "154e": 199, "479e": 199, "440e": 199, "260e": 199, "467e": 199, "721e": 199, "617e": 199, "637e": 199, "640e": 199, "633e": 199, "605e": 199, "259e": 199, "183e": 199, "021e": 199, "204e": 199, "172e": 199, "223e": 199, "555e": 199, "058e": 199, "365e": 199, "059e": 199, "163e": 199, "291e": 199, "818e": 199, "122e": 199, "162e": 199, "268e": 199, "352e": 199, "813e": 199, "262e": 199, "152e": 199, "719e": 199, "390e": 199, "202e": 199, "340e": 199, "522e": 199, "547e": 199, "700e": 199, "904e": 199, "419e": 199, "428e": 199, "687e": 199, "013e": 199, "523e": 199, "683e": 199, "632e": 199, "665e": 199, "236e": 199, "873e": 199, "514e": 199, "361e": 199, "002e": 199, "649e": 199, "023e": 199, "741e": 199, "238e": 199, "406e": 199, "129e": 199, "656e": 199, "778e": 199, "394e": 199, "720e": 199, "902e": 199, "908e": 199, "739e": 199, "495e": 199, "708e": 199, "896e": 199, "932e": 199, "790e": 199, "575e": 199, "446e": 199, "209e": 199, "333e": 199, "165e": 199, "312e": 199, "862e": 199, "702e": 199, "094e": 199, "758e": 199, "478e": 199, "846e": 199, "533e": 199, "073e": 199, "124e": 199, "149e": 199, "776e": 199, "977e": 199, "159e": 199, "217e": 199, "102e": 199, "001e": 199, "723e": 199, "556e": 199, "173e": 199, "232e": 199, "535e": 199, "413e": 199, "339e": 199, "226e": 199, "151e": 199, "598e": 199, "910e": 199, "253e": 199, "940e": 199, "304e": 199, "768e": 199, "679e": 199, "265e": 199, "676e": 199, "043e": 199, "539e": 199, "512e": 199, "272e": 199, "497e": 199, "507e": 199, "578e": 199, "448e": 199, "355e": 199, "221e": 199, "344e": 199, "328e": 199, "883e": 199, "189e": 199, "865e": 199, "500e": 199, "317e": 199, "905e": 199, "096e": 199, "462e": 199, "751e": 199, "015e": 199, "284e": 199, "797e": 199, "263e": 199, "577e": 199, "916e": 199, "120e": 199, "435e": 199, "973e": 199, "764e": 199, "278e": 199, "878e": 199, "042e": 199, "395e": 199, "432e": 199, "468e": 199, "049e": 199, "178e": 199, "255e": 199, "364e": 199, "674e": 199, "252e": 199, "029e": 199, "965e": 199, "834e": 199, "714e": 199, "032e": 199, "837e": 199, "713e": 199, "367e": 199, "863e": 199, "476e": 199, "303e": 199, "737e": 199, "466e": 199, "130e": 199, "684e": 199, "224e": 199, "415e": 199, "_regression_performance_as_a_function_of_the_number_of_observed_neurons_interactive_demo": 199, "_summari": 199, "w3d5_t4": 200, "linearregress": 200, "compare_granger_connect": 200, "reject_nul": 200, "selecte_neuron": 200, "plot_performance_vs_eta": 200, "matri": 200, "print_corr": 200, "idx_dict": 200, "text_dict": 200, "tax": 200, "cigarett": 200, "statu": 200, "get_regression_corr": 200, "_instrumental_variables_video": 200, "wild": 200, "smoke": 200, "pregnant": 200, "wealth": 200, "tobacco": 200, "consumpt": 200, "z_": 200, "socioeconom": 200, "wealthier": 200, "birthweight": 200, "child": 200, "gram": 200, "3000": 200, "2t_": 200, "mother": 200, "babi": 200, "lighter": 200, "covar": 200, "483": 200, "740": 200, "unconfound": 200, "_stage_1_video": 200, "fit_first_stag": 200, "t_hat": 200, "stage1": 200, "t_c_corr": 200, "t_hat_c_corr": 200, "_compute_regression_stage_1_exercis": 200, "_stage_2_video": 200, "fit_second_stag": 200, "stage2": 200, "984": 200, "_compute_the_iv_estimate_exercis": 200, "ivs_in_simulated_neural_systems_video": 200, "wire": 200, "radio": 200, "simulate_neurons_iv": 200, "iv_on_this_timestep": 200, "_simulate_a_system_with_iv_exercis": 200, "get_iv_estimate_network": 200, "x_hati": 200, "corr_": 200, "_ivs_and_omitted_variable_bias_video": 200, "sel_z": 200, "iv_corr": 200, "big_v": 200, "reg_corr": 200, "compare_iv_estimate_to_regress": 200, "sel_reg_v": 200, "sel_iv_v": 200, "ncorrel": 200, "_estimating_connectivity_with_iv_vs_regression_interactive_demo": 200, "threat": 200, "discussion_questions_discuss": 200, "instrument_strength_effect": 200, "iv_v": 200, "_exploring_instrument_strength_bonus_exercis": 200, "h_a": 200, "retain": 200, "b_1": 200, "statsmodel": 200, "tsa": 200, "stattool": 200, "grangercausalitytest": 200, "get_granger_caus": 200, "bonferroni": 200, "p_val": 200, "max_lag": 200, "target_neuron": 200, "ts_data": 200, "pval": 200, "lrtest": 200, "_evaluate_granger_causality_bonus_exercis": 200, "advic": 201, "isabel": 201, "brush": 201}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"prerequisit": [0, 85, 94, 105, 161, 169], "preparatori": 0, "materi": 0, "nma": 0, "comput": [0, 70, 75, 76, 81, 88, 89, 96, 99, 100, 101, 110, 125, 138, 139, 146, 147, 149, 155, 156, 157, 163, 197, 198, 200], "neurosci": [0, 75, 76, 92, 110, 133, 184], "prepar": [0, 33, 34, 35], "yourself": 0, "cours": [0, 20, 39], "program": 0, "math": [0, 63, 74, 75, 81, 163], "skill": 0, "overview": [1, 5, 21, 28, 31, 39, 63, 85, 94, 105, 112, 121, 129, 135, 144, 153, 161, 169, 171, 177, 179, 184, 186, 195, 201], "video": [1, 5, 21, 22, 23, 28, 31, 32, 33, 34, 35, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 85, 86, 87, 88, 89, 94, 95, 96, 97, 98, 99, 100, 101, 105, 106, 107, 108, 112, 113, 114, 115, 116, 117, 121, 122, 123, 124, 125, 126, 129, 130, 131, 135, 136, 137, 138, 139, 140, 144, 145, 146, 147, 148, 149, 153, 154, 155, 156, 157, 161, 162, 163, 164, 165, 169, 170, 171, 172, 173, 174, 175, 179, 180, 181, 182, 186, 187, 188, 189, 190, 191, 195, 196, 197, 198, 199, 200, 201], "ted": 1, "talk": 1, "kai": [1, 16, 20, 21], "miller": 1, "watch": 1, "until": 1, "15": [1, 173], "45": 1, "guid": [2, 4, 12, 20, 26, 27, 29], "choos": [2, 4, 20, 27, 29, 33, 108, 189], "an": [2, 20, 63, 71, 76, 87, 114, 146, 149, 165, 171, 172, 182, 189, 200], "eeg": [2, 15, 59], "ecog": [2, 6], "lfp": [2, 58], "dataset": [2, 4, 8, 13, 16, 20, 21, 27, 28, 33, 34, 35, 87, 98, 119], "refer": [2, 20, 27, 75, 76], "face": [2, 13], "hous": 2, "fingerflex": 2, "joystick": 2, "track": [2, 149, 174, 182], "memori": [2, 13, 29, 157], "nback": 2, "direct": [2, 146], "see": 2, "motor": [2, 13, 29], "imageri": 2, "explor": [2, 13, 87, 96, 97, 115, 146, 148, 155, 163, 164, 181, 182, 200], "ajile12": [2, 13], "project": [3, 11, 12, 13, 16, 22, 24, 25, 29, 39, 45, 114, 115, 131], "behavior": [4, 5, 7, 13, 14, 55, 75], "caltech": [4, 5], "ibl": [4, 5], "laquitain": 4, "gardner": 4, "neuron": [4, 10, 17, 27, 53, 63, 65, 74, 87, 88, 89, 141, 142, 146, 147, 148, 149, 151, 155, 175, 197, 198, 199, 200], "2017": 4, "mous": [5, 13], "social": [5, 13], "bay": [5, 81, 163, 164, 165], "heurist": 5, "fmri": [9, 13, 16, 20, 21, 60], "2020": 11, "daili": [12, 39, 68, 79, 86, 95, 106, 113, 122, 130, 136, 145, 154, 162, 170, 180, 187, 196], "summari": [12, 22, 24, 25, 33, 34, 35, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 87, 88, 89, 93, 96, 97, 98, 99, 100, 101, 104, 107, 108, 111, 114, 115, 116, 117, 120, 123, 124, 125, 128, 131, 134, 137, 138, 139, 140, 143, 146, 147, 148, 149, 152, 155, 156, 160, 163, 164, 165, 168, 171, 172, 173, 178, 181, 182, 185, 188, 189, 190, 191, 194, 197, 198, 199, 200], "submiss": 12, "link": [12, 13, 45, 75, 76, 184], "templat": [12, 13], "ta": 12, "week": 12, "1": [12, 22, 25, 33, 34, 35, 62, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 119, 122, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "get": [12, 87], "start": [12, 76], "w1d2": 12, "w1d3": 12, "w1d5": 12, "w2": 12, "time": [12, 39, 63, 138, 142, 146, 147, 149, 156, 171, 173, 182], "w2d1": [12, 39], "half": [12, 39], "dai": [12, 39, 67, 73, 75, 76, 78, 84, 93, 104, 111, 120, 128, 134, 143, 152, 160, 168, 178, 185, 194], "w2d2": 12, "w2d5": [12, 39], "abstract": [12, 23, 25, 39], "write": [12, 23, 39], "bonu": [12, 33, 34, 69, 71, 74, 76, 81, 88, 89, 96, 97, 100, 101, 107, 108, 115, 116, 123, 124, 125, 126, 146, 147, 148, 149, 155, 157, 163, 165, 171, 174, 175, 181, 188, 190, 197, 198, 200], "w3": 12, "w3d5": [12, 39], "final": [12, 24, 25, 39], "present": 12, "schedul": [12, 39, 40], "logist": [12, 108], "content": 12, "question": [12, 22, 24, 25, 131, 174, 200], "flow": 13, "inform": [13, 89, 101, 164], "through": [13, 69, 173, 182, 197], "brain": [13, 57, 58, 59, 60, 61, 76, 81, 110, 119], "dure": [13, 175], "sensorimotor": 13, "task": [13, 20, 21, 123, 125, 181], "effect": [13, 75, 108, 114, 146, 147, 149, 157, 182], "stimulu": [13, 51, 165], "context": 13, "state": [13, 22, 131, 138, 155, 163, 164, 173, 181, 182, 184], "visual": [13, 33, 34, 74, 87, 116, 117, 123, 124, 125, 126, 149, 155], "represent": [13, 33, 51, 125], "cortex": 13, "map": [13, 201], "activ": [13, 33, 57, 71, 76, 87, 107, 123, 124, 125, 147, 155, 156, 157, 198], "retinotop": 13, "model": [13, 22, 23, 24, 25, 26, 29, 35, 39, 63, 69, 75, 76, 80, 82, 87, 88, 89, 90, 91, 92, 97, 99, 100, 101, 102, 107, 108, 119, 125, 126, 127, 133, 139, 140, 141, 142, 146, 148, 149, 151, 155, 156, 157, 159, 165, 167, 171, 172, 175, 191, 197, 199], "navig": 13, "afford": 13, "scene": 13, "select": [13, 23, 24, 25, 92, 100, 101, 108], "respons": [13, 123, 146, 147, 165], "differ": [13, 35, 89, 99, 108, 116, 117, 146, 148, 156, 164, 181, 188], "region": 13, "depend": [13, 24, 69, 74, 142, 149, 174, 181], "decis": [13, 25, 158, 163, 164, 165, 167, 190], "make": [13, 65, 163, 167], "mice": 13, "perform": [13, 115, 116, 126, 199], "2afc": 13, "The": [13, 33, 63, 69, 75, 76, 88, 89, 108, 139, 146, 164, 171, 173, 174, 182], "work": [13, 29, 110, 157, 200], "capac": 13, "recurr": [13, 155], "neural": [13, 69, 70, 71, 74, 76, 108, 123, 124, 125, 126, 155, 159, 197, 200], "network": [13, 119, 123, 124, 125, 126, 147, 150, 151, 155, 157, 175, 192, 198], "attractor": 13, "doe": [13, 173, 181, 182], "reflect": [13, 87, 88, 89, 198], "percept": 13, "structur": [13, 99], "probe": 13, "dynam": [13, 36, 71, 133, 137, 142, 148, 150, 155, 166, 171, 173, 174, 181, 182, 197], "human": [13, 16, 54], "estim": [13, 81, 96, 97, 98, 99, 164, 165, 173, 197, 198, 199, 200], "error": [13, 76, 96, 100, 126, 188], "bayesian": [13, 81, 158, 163, 164], "framework": 13, "function": [13, 22, 24, 33, 34, 35, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "rnn": [13, 29], "learn": [13, 37, 108, 118, 119, 124, 175, 183, 188, 189, 190, 191, 193], "connectom": 16, "stringer": [17, 27, 28], "steinmetz": [17, 27, 28, 87], "theori": [18, 19, 29, 81], "hcp": [20, 21], "fsl": 20, "retinotopi": [20, 21], "natur": 20, "imag": [20, 35, 61], "bonner": [20, 21], "algonaut": [20, 21], "cichi": [20, 21], "gallant": 21, "2021": 21, "fslcours": 21, "step": [22, 23, 26, 47, 74, 76, 131, 174, 175], "4": [22, 33, 34, 35, 63, 65, 69, 70, 74, 75, 76, 80, 81, 87, 89, 90, 97, 99, 108, 114, 116, 117, 131, 137, 140, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 189, 191, 197, 198, 199, 200], "tutori": [22, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 119, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "object": [22, 23, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "demo": [22, 65, 69, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 108, 114, 115, 116, 131, 137, 138, 139, 146, 148, 149, 155, 156, 157, 163, 164, 171, 172, 173, 174, 181, 182, 188, 189, 198, 199, 200], "introduct": [22, 33, 34, 35, 69, 74, 75, 98, 123, 124, 131, 163, 164, 165, 172, 174, 175, 188, 201], "setup": [22, 24, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "plot": [22, 24, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "gener": [22, 25, 39, 71, 80, 81, 92, 102, 107, 114, 126, 131, 142, 146, 165, 175], "data": [22, 24, 87, 89, 100, 107, 108, 114, 115, 116, 123, 124, 125, 126, 131, 140, 159, 165, 174, 175], "find": [22, 81, 97, 114, 131, 138, 155, 157, 173], "phenomenon": [22, 24, 25, 131], "ask": [22, 131], "about": [22, 27, 69, 74, 75, 108, 131, 200], "2": [22, 25, 33, 34, 35, 63, 64, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 107, 108, 114, 115, 116, 117, 119, 122, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "exampl": [22, 24, 25, 69, 75, 81, 92, 131, 149, 157, 164, 200], "think": [22, 69, 70, 75, 76, 80, 81, 87, 88, 89, 90, 117, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 163, 188, 198, 200], "your": [22, 31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "own": [22, 131, 173], "understand": [22, 70, 71, 74, 76, 124, 125, 131, 140], "art": [22, 131, 184], "background": [22, 24, 25, 131], "3": [22, 25, 33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 97, 98, 99, 108, 114, 116, 123, 124, 125, 126, 131, 137, 138, 139, 146, 147, 148, 149, 155, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "literatur": [22, 131], "review": [22, 119, 131, 174], "knowledg": [22, 85, 94, 105, 131], "determin": [22, 125, 131, 139], "basic": [22, 63, 81, 131], "ingredi": [22, 24, 25, 131], "formul": [22, 131, 138], "specif": [22, 39, 131], "mathemat": [22, 115, 131, 156], "defin": [22, 63, 69, 71, 114, 131, 175, 197], "hypothes": [22, 24, 25, 131], "5": [22, 23, 34, 63, 65, 69, 70, 74, 75, 76, 80, 81, 87, 89, 100, 108, 131, 163, 164, 165, 171, 172, 173, 174, 175, 181, 197, 200], "hypothesi": [22, 131], "next": [22, 131], "read": [22, 23, 27, 75, 76, 83, 92, 103, 110, 119, 131, 133, 142, 151, 159, 167, 173, 177, 184, 193], "10": [23, 63, 65, 163, 173], "toolkit": [23, 24, 25], "6": [23, 35, 63, 65, 69, 74, 76, 81, 101, 163, 164, 165, 171, 172, 173, 181, 200], "plan": [23, 191], "draft": [23, 24, 25], "7": [23, 63, 65, 69, 81, 163, 164, 165, 172, 173, 181], "implement": [23, 24, 25, 71, 101, 108, 115, 149, 155, 165, 173, 174, 175, 181, 182, 189, 190], "8": [23, 63, 65, 163, 164, 165, 173], "complet": [23, 24, 25], "9": [23, 63, 65, 163, 164, 173], "test": [23, 24, 25, 100, 126, 171], "evalu": [23, 24, 25, 99, 108, 125, 126, 181, 200], "publish": 23, "11": [23, 63, 65, 173], "paper": [23, 119, 193], "guidanc": 23, "suggest": [23, 83, 92, 103, 110, 119, 133, 142, 151, 159, 167, 177, 184, 193, 200], "train": [24, 25, 33, 34, 35, 87, 100, 108, 126, 147, 175], "illus": [24, 25], "instal": [24, 31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "helper": [24, 33, 34, 35, 65, 71, 75, 76, 100, 101, 108, 115, 116, 123, 124, 125, 126, 140, 147, 148, 149, 156, 157, 163, 164, 165, 171, 173, 175, 181, 182, 188, 191, 198, 199, 200], "thought": [24, 25], "vestibular": 25, "signal": [25, 57, 58, 59, 60, 61, 88], "integr": [25, 63, 74, 75, 76, 88, 137, 146, 156], "ddm": [25, 171], "mechan": 25, "threshold": [25, 171, 181], "assembl": 25, "allen": [27, 28], "institut": [27, 28], "you": [27, 181], "can": [27, 108], "more": [27, 76, 108, 163, 164], "scientif": 27, "discoveri": 27, "relat": 27, "thi": [27, 165], "our": [27, 197, 200], "preprint": 27, "databas": 29, "addit": 29, "resourc": 29, "autoencod": [30, 33, 34, 35], "intro": [31, 33, 50, 63, 69, 70, 76, 80, 85, 94, 105, 112, 115, 116, 117, 119, 121, 129, 135, 144, 153, 161, 165, 169, 177, 179, 186, 195], "import": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "feedback": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "gadget": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "slide": [31, 32, 85, 86, 94, 95, 105, 106, 112, 113, 121, 122, 129, 130, 135, 136, 144, 145, 153, 154, 161, 162, 169, 170, 179, 180, 185, 186, 187, 195, 196], "submit": [31, 32, 33, 34, 35, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 111, 112, 113, 114, 115, 116, 117, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 182, 185, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 200], "outro": [32, 68, 79, 86, 92, 95, 106, 110, 113, 119, 122, 130, 133, 136, 145, 154, 162, 165, 170, 177, 180, 187, 196], "intern": [33, 76], "figur": [33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "set": [33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 131, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "section": [33, 34, 35, 63, 65, 69, 70, 71, 74, 75, 76, 80, 81, 87, 88, 89, 90, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 164, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "0": [33, 34, 35, 69, 74, 75, 115, 116, 117, 123, 131, 148, 163, 164, 171, 172, 174, 175], "mnist": [33, 34, 35, 116, 117], "download": [33, 34, 35, 89], "sampl": [33, 63, 80, 108, 114, 115, 137, 174, 198], "latent": [33, 34, 35, 174], "space": [33, 34, 35, 69, 70, 182], "pca": [33, 110, 115, 116, 117], "code": [33, 34, 35, 63, 65, 69, 70, 71, 74, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "exercis": [33, 34, 35, 63, 65, 69, 70, 71, 74, 76, 80, 81, 87, 88, 89, 96, 97, 98, 99, 100, 101, 107, 108, 114, 115, 116, 117, 123, 124, 125, 126, 137, 138, 139, 140, 146, 147, 148, 149, 155, 156, 157, 163, 165, 171, 172, 173, 174, 175, 181, 182, 188, 189, 190, 191, 197, 198, 199, 200], "2d": [33, 34, 63, 74, 117, 124, 164], "qualit": [33, 125], "analysi": [33, 110, 115, 151, 155, 156, 157, 159], "ann": [33, 35], "design": [33, 99, 107, 182], "32d": 33, "loss": [33, 123, 126, 164], "express": [33, 123], "power": 33, "wrap": [33, 34, 35, 36, 37, 38], "up": [33, 34, 35, 36, 37, 38, 87, 108, 125, 182], "failur": [33, 198], "mode": 33, "relu": 33, "unit": [33, 126], "weight": [33, 116, 124, 126, 149, 182], "initi": [33, 71, 75, 137, 155, 156, 175], "nmf": 33, "extens": [34, 146], "architectur": 34, "dependeci": 34, "deeper": [34, 126], "build": [34, 125], "spheric": 34, "3d": 34, "deep": [34, 118, 119, 123, 124, 125], "surfac": 34, "s_2": 34, "thick": 34, "applic": [35, 74, 117, 149], "pre": [35, 149], "nois": [35, 97, 116, 146, 147, 182], "reconstruct": [35, 116], "befor": 35, "fine": 35, "tune": [35, 125, 126], "noisi": [35, 146, 155], "global": 35, "shift": 35, "occlus": 35, "after": 35, "rotat": 35, "what": [35, 69, 74, 76, 87, 108, 124, 142, 147, 163], "would": 35, "digit": 35, "look": [35, 71], "like": 35, "we": [35, 69, 74, 75, 108], "had": 35, "never": 35, "seen": 35, "remov": [35, 188], "most": 35, "domin": 35, "class": [35, 65, 188], "same": 35, "system": [36, 70, 71, 76, 110, 132, 133, 137, 155, 157, 174, 182, 197, 198, 199, 200], "podcast": [36, 37, 38, 75, 76], "panel": [36, 37, 38, 39], "discuss": [36, 37, 38, 76, 90, 125, 163, 171, 172, 173, 174, 200], "machin": [37, 193], "stochast": [38, 80, 123, 139], "process": [38, 138, 139, 140, 146, 175, 182, 190], "coursework": [39, 45], "practic": [39, 127], "propos": 39, "profession": 39, "develop": [39, 92], "share": 41, "calendar": 41, "timezon": 42, "widget": 42, "us": [43, 44, 46, 47, 63, 65, 69, 71, 74, 76, 108, 116, 117, 119, 123, 173, 182, 188, 197, 199, 200], "discord": 43, "jupyterbook": 44, "quick": 45, "polici": [45, 181, 190], "attend": 45, "googl": 46, "colab": 46, "advic": 46, "kaggl": 47, "technic": [48, 167], "help": 48, "neuro": [49, 200], "seri": 49, "neurotransmitt": 52, "conscious": 53, "psychophys": 54, "readout": 55, "live": 56, "lab": 56, "spike": [57, 63, 65, 75, 87, 88, 89, 107, 142, 146, 147, 149, 151, 175], "meg": 59, "calcium": 61, "python": [62, 63, 64, 74, 146], "workshop": [62, 64], "lif": [63, 65, 75, 76, 88, 146, 148, 149], "part": [63, 65, 76, 174], "i": [63, 146, 148, 155, 156, 157], "comment": 63, "nano": [63, 65], "recap": [63, 65], "string": 63, "paramet": [63, 75, 80, 81, 108, 139, 140, 146, 155, 157, 164, 175, 181], "oper": [63, 69, 74], "simul": [63, 139, 146, 148, 149, 155, 156, 171, 172, 173, 175, 197, 198, 200], "input": [63, 74, 75, 88, 146, 147, 148, 149, 155, 165, 182], "current": [63, 146], "print": 63, "format": [63, 108], "pretti": 63, "number": [63, 116, 126, 198, 199], "For": 63, "loop": [63, 182], "discret": [63, 71, 80, 138, 181], "membran": [63, 75, 148], "potenti": [63, 74, 75, 148], "random": [63, 65, 80, 139, 197], "synapt": [63, 142, 148, 149], "ad": [63, 65, 75, 76, 126], "list": [63, 75, 76], "ensembl": [63, 147], "statist": [63, 77, 81, 159, 163, 193], "store": 63, "mean": [63, 87, 96, 139, 147, 148], "standard": [63, 147, 164], "deviat": [63, 147], "numpi": 63, "rewrit": [63, 65], "12": [63, 65, 173], "enumer": 63, "index": [63, 65], "aggreg": 63, "13": [63, 173], "arrai": [63, 165], "14": [63, 173], "ii": 65, "histogram": [65, 89], "dictionari": 65, "introduc": [65, 182], "boolean": 65, "binari": [65, 125, 151, 163, 165, 172], "raster": [65, 87], "refractori": 65, "period": 65, "investig": [65, 126, 147], "refactori": 65, "interact": [65, 69, 71, 74, 75, 76, 80, 81, 87, 88, 89, 96, 97, 108, 114, 115, 116, 137, 138, 139, 146, 148, 149, 155, 156, 157, 163, 164, 171, 172, 173, 174, 181, 182, 188, 189, 198, 199, 200], "last": 65, "concept": [65, 201], "linear": [66, 69, 70, 75, 88, 92, 96, 97, 99, 102, 107, 110, 126, 132, 133, 137, 155, 174, 182, 199], "algebra": [66, 69], "survei": [68, 79, 86, 95, 106, 113, 122, 130, 136, 145, 154, 162, 170, 180, 187, 196], "vector": [69, 114, 156], "why": [69, 74, 75, 88, 89, 108, 124], "do": [69, 74, 75, 88, 108, 147], "care": [69, 74, 75], "definit": [69, 174], "properti": [69, 115], "normal": [69, 165], "combin": [69, 139], "span": 69, "independ": 69, "determ": 69, "basi": [69, 114, 115], "out": [69, 156], "dot": 69, "product": [69, 74, 81], "lgn": 69, "fire": [69, 71, 75, 76, 88, 146, 149, 151], "geometri": 69, "polynomi": [69, 99], "proof": [69, 100], "equival": 69, "matric": 70, "solv": [70, 96, 182, 189], "equat": [70, 75, 76, 123, 137, 156, 182], "transform": [70, 149], "creat": [70, 80, 107, 126], "rank": 70, "null": 70, "eigenvalu": [70, 71, 137, 155, 157], "eigenvector": [70, 71, 115, 137], "eigenstuff": [70, 71], "identifi": 70, "from": [70, 80, 89, 114, 123, 124, 133, 156, 173, 174, 181, 189, 197], "matrix": [70, 99, 107, 115, 116, 125, 157, 165, 197], "multipl": [70, 74, 99], "corner": 70, "circuit": 71, "A": [71, 74, 76, 81, 125, 126, 137, 164, 193, 198, 200], "rate": [71, 75, 146, 148, 149, 151, 155, 188], "along": 71, "chang": [71, 74, 75, 76, 114, 149, 157, 172, 189, 191], "both": 71, "complex": [71, 124, 164, 198], "calculu": [72, 74], "differenti": [74, 75, 76, 137], "geometr": [74, 114], "interpret": [74, 75, 126, 137], "analyt": [74, 81], "numer": [74, 76, 155, 156], "rule": [74, 163, 165, 171], "deriv": [74, 76, 96], "postsynapt": [74, 149], "alpha": [74, 189], "chain": [74, 81], "sympi": 74, "sine": 74, "transfer": [74, 147, 188], "gain": [74, 182], "calcul": [74, 89, 115, 116, 155, 163, 165, 197], "variabl": [74, 199, 200], "partial": [74, 157, 182, 199], "demonstr": 74, "riemann": 74, "sum": 74, "vs": [74, 100, 123, 138, 148, 155, 171, 175, 182, 190, 198, 200], "size": [74, 108, 198], "charg": 74, "excitatori": [74, 148, 149, 155, 156], "filter": [74, 124, 167, 173, 174, 182], "popul": [75, 76, 155, 156], "exact": 75, "solut": [75, 76, 81, 125, 137], "condit": [75, 81, 137, 174], "leaki": [75, 76, 146], "without": 75, "v": 75, "v_": 75, "reset": 75, "impact": 75, "one": 75, "thing": 75, "matter": 75, "neuromatch": [75, 76], "bibliographi": [75, 76], "supplement": [75, 76], "popular": [75, 76], "method": [76, 92, 117], "euler": [76, 137], "slope": 76, "line": 76, "approxim": [76, 198], "singl": [76, 87, 155], "take": [76, 173], "simpl": 76, "wilson": [76, 156, 157], "cowan": [76, 156, 157], "phase": [76, 151, 156, 157], "plane": [76, 151, 156, 157], "nullclin": [76, 156, 157], "connect": [76, 125, 126, 149, 197, 198, 199, 200], "oscil": [76, 157], "small": [76, 198, 200], "everyth": 76, "4th": 76, "order": [76, 99, 140], "rung": 76, "kutta": 76, "ar": [76, 140, 181], "toward": 76, "rather": 76, "than": [76, 108], "end": 76, "Not": 76, "all": 76, "alik": 76, "stuart": 76, "landau": 76, "probabl": [80, 81, 89, 138, 163, 164, 165, 171], "distribut": [80, 81, 87, 89, 97, 114, 138, 149, 163, 164, 165, 174, 181], "world": [80, 172, 191], "uniform": 80, "walk": [80, 139], "vari": [80, 108, 137, 138, 147, 182, 188], "binomi": 80, "poisson": [80, 107, 175], "continu": [80, 138, 164, 181, 182], "gaussian": [80, 81, 97, 107, 146, 147, 164, 165, 172, 174, 182], "1a": [80, 139, 147, 149], "infer": [81, 164, 172, 177], "b": 81, "joint": [81, 174], "c": [81, 108], "d": 81, "margin": [81, 163, 164, 165, 174], "markov": [81, 138, 167, 172, 190], "likelihood": [81, 97, 163, 165], "maximum": [81, 97], "search": [81, 173], "best": 81, "optim": [81, 89, 92, 96, 107, 123, 176, 181, 182], "conjug": 81, "prior": [81, 164, 165], "posterior": [81, 163, 164, 165], "computation": 81, "net": 81, "causal": [81, 165, 192, 197, 198, 199, 200], "type": [82, 89, 146], "further": [83, 92, 103, 110, 119, 125, 133, 142, 151, 159, 167, 177, 182, 184, 193], "retriev": [87, 107, 108, 123, 124, 125, 126, 174], "warm": 87, "spike_tim": 87, "warmer": 87, "count": [87, 107], "total": 87, "compar": [87, 99, 100, 119, 173, 198], "median": 87, "subset": [87, 200], "inter": 87, "interv": [87, 98, 138], "isi": [87, 89, 146], "form": 87, "fit": [87, 91, 92, 99, 107, 108, 140, 165, 174, 199], "hand": 87, "how": [88, 142, 147, 173, 181, 182, 191, 200], "dv_m": 88, "IF": 88, "inhibitori": [88, 148, 155, 156], "inhibit": [88, 151, 157], "notat": [88, 89, 96, 97, 98, 99, 107, 108, 114, 115, 116], "entropi": 89, "mass": 89, "pmf": 89, "foundat": [89, 177], "tip": 92, "On": [92, 190], "regress": [92, 96, 97, 99, 107, 108, 199, 200], "llh": 92, "maxim": [92, 174, 175], "mse": [92, 96, 99], "minim": 92, "research": 92, "squar": [96, 99, 200], "least": [96, 99, 200], "mle": 97, "probabilist": [97, 188], "confid": [98, 171], "bootstrap": 98, "resampl": 98, "replac": 98, "ordinari": 99, "qualiti": 99, "bia": [100, 199, 200], "varianc": [100, 116, 139], "trade": 100, "off": [100, 190], "tradeoff": [100, 171, 182], "decomposit": 100, "cross": [101, 108], "valid": [101, 108], "akaik": 101, "s": [101, 124, 125, 173], "criterion": 101, "aic": 101, "glm": [107, 199], "encod": [107, 119, 125, 126, 165], "load": [107, 108, 123, 124, 125, 126, 174], "retin": 107, "ganglion": 107, "cell": [107, 124, 165], "predict": [107, 172, 188], "challeng": 107, "nonlinear": [107, 110, 117, 123], "scipi": 107, "classifi": 108, "regular": [108, 126], "sigmoid": 108, "scikit": 108, "decod": [108, 123, 126], "accuraci": [108, 171, 173], "featur": 108, "lead": 108, "overfit": 108, "l_2": 108, "l_1": 108, "kei": 108, "between": [108, 138, 147, 155, 182], "sparsiti": [108, 198], "penalti": 108, "full": 108, "detail": 108, "dimension": [109, 110, 116, 117, 125, 137], "reduct": [109, 110, 116, 117, 125], "princip": [110, 115], "compon": [110, 115, 116], "other": 110, "interfac": 110, "shown": 110, "view": 114, "correl": [114, 115, 125, 147, 149, 163, 164, 198], "multivari": 114, "draw": 114, "new": [114, 126], "orthonorm": 114, "base": [114, 148, 151, 181, 191], "onto": [114, 115], "plai": [114, 173], "covari": [115, 163, 164], "coeffici": 115, "scree": 116, "explain": 116, "pc": 116, "examin": [116, 181, 188], "denois": 116, "add": [116, 126], "t": [117, 138], "sne": 117, "appli": 117, "run": [117, 165, 175, 181], "perplex": 117, "pytorch": [119, 123, 124, 125], "recommend": 119, "feed": 123, "forward": [123, 137, 172, 175], "split": 123, "gradient": 123, "descent": 123, "depth": 123, "width": 123, "sgd": 123, "gd": 123, "convolut": [124, 125, 126], "output": [124, 147, 182], "shape": 124, "layer": [124, 125, 126], "cnn": [124, 125], "norm": [125, 159], "orient": [125, 201], "discrimin": 125, "quantit": 125, "comparison": 125, "dissimilar": 125, "rdm": 125, "similar": [125, 198], "curv": [125, 126, 155, 156], "reduc": [125, 146], "fulli": [125, 126], "max": 125, "pool": 125, "classif": 125, "problem": [125, 126, 181], "z": 125, "score": 125, "explan": 125, "dive": 126, "devic": 126, "gpu": 126, "cpu": 126, "execut": 126, "set_devic": 126, "peer": 126, "insid": 126, "improv": 126, "critic": 126, "delv": 126, "frame": 131, "lectur": 133, "One": 137, "oscillatori": 137, "determinist": [137, 139], "two": [137, 155, 197, 200], "dimens": 137, "multi": [137, 189], "trajectori": [137, 155, 156, 171], "3a": [137, 146], "3b": [137, 146], "stream": 137, "telegraph": 138, "switch": 138, "transit": [138, 155], "valu": [138, 146, 155, 156, 157, 181, 188, 189], "perspect": 138, "propag": 138, "equilibrium": 138, "stabl": [138, 155], "e": [139, 148, 155, 156, 157, 175], "coli": 139, "1b": [139, 147, 149], "influenc": [139, 182], "choic": 139, "ornstein": [139, 146], "uhlenbeck": [139, 146], "ou": [139, 140, 146], "drift": [139, 171], "diffus": [139, 171], "observ": [139, 182, 199, 200], "balanc": [139, 148, 151], "empir": 139, "autoregress": 140, "residu": 140, "higher": 140, "monkei": 140, "typewrit": 140, "biolog": 141, "text": 142, "book": 142, "hodgkin": 142, "huxlei": 142, "But": 142, "point": [142, 155, 157], "extend": [142, 157], "simplifi": 142, "synaps": [142, 148, 149], "short": [142, 148, 157], "term": [142, 148], "plastic": [142, 148, 149], "dc": 146, "amplitud": 146, "white": [146, 147], "gwn": [146, 147], "analyz": [146, 149, 156, 171, 181], "irregular": 146, "f": [146, 155, 156], "sig_gwn": 146, "cv_": 146, "synchroni": 147, "origin": [147, 182], "synchron": 147, "implic": 147, "measur": [147, 148, 172, 173, 182], "affect": [147, 163], "rational": 147, "behind": 147, "mu": 147, "sigma": 147, "transmiss": 148, "static": 148, "conduct": [148, 149], "free": 148, "depress": 148, "std": 148, "facilit": 148, "stf": 148, "stp": 148, "stdp": 149, "delta": 149, "w": 149, "keep": 149, "p": 149, "dp": 149, "show": 149, "evolut": [149, 182], "2a": 149, "strength": [149, 200], "2b": 149, "increas": 149, "presynapt": 149, "receiv": 149, "amplif": 151, "stabil": [151, 155, 157], "supralinear": 151, "scheme": [155, 156], "finit": 155, "fix": [155, 157, 171], "extern": 155, "relationship": 155, "unstabl": 155, "via": 155, "drive": 155, "descript": 156, "wc": 156, "field": 156, "r_i": 156, "r_e": [156, 157], "displaystyl": [156, 157], "big": 156, "frac": [156, 157], "dr_e": 156, "dt": 156, "dr_i": 156, "limit": 157, "cycl": 157, "jacobian": 157, "wee": 157, "posit": [157, 165], "isn": 157, "g_e": 157, "non": [157, 200], "puls": 157, "induc": 157, "persist": 157, "hidden": [163, 164, 166, 167, 171, 172], "gone": [163, 181], "fishin": 163, "decid": 163, "where": [163, 181], "fish": [163, 181], "util": [163, 164], "being": 163, "either": 163, "side": 163, "guess": 163, "locat": [163, 164], "belief": [163, 164, 181], "formula": 163, "astrocat": [164, 173], "multipli": 164, "mixtur": [164, 165], "complic": 164, "cat": 164, "cost": [164, 182], "theorem": 164, "variou": 164, "auditori": 165, "true": [165, 173, 175], "hypothet": 165, "x": 165, "hat": 165, "stimuli": 165, "expect": [165, 174, 175], "some": [165, 181], "generate_data": 165, "log": 165, "kalman": [167, 173, 174, 182], "aspect": 167, "sequenti": 171, "ratio": 171, "sprt": 171, "under": 171, "stop": 171, "speed": 171, "versu": 171, "revisit": 171, "hmm": [172, 175], "futur": 172, "forget": 172, "quantifi": 173, "movement": 173, "collar": 173, "action": [173, 182, 189], "long": 173, "ld": [174, 182], "adjust": 174, "ey": 174, "gaze": 174, "pykalman": 174, "handl": 174, "blink": 174, "smooth": 174, "em": [174, 175], "algorithm": [174, 175, 190], "m": [174, 175], "case": 175, "studi": 175, "frozen": 175, "sequenc": 175, "backward": 175, "learnt": 175, "progress": 175, "control": [176, 177, 181, 182, 197], "catch": 181, "reward": [181, 188, 189], "should": 181, "act": [181, 189, 190], "follow": 181, "sensit": 181, "open": 182, "close": 182, "fly": 182, "quadrat": 182, "regul": 182, "lqr": 182, "constraint": 182, "goal": 182, "move": 182, "desir": 182, "lqg": 182, "conjunct": 182, "effort": 182, "reinforc": [183, 191], "tempor": 188, "td": 188, "guarante": 188, "cs": 188, "discount": 188, "factor": 188, "magnitud": 188, "match": 188, "arm": 189, "bandit": 189, "epsilon": 189, "greedi": 189, "updat": [189, 191], "q": [190, 191], "mdp": 190, "sarsa": 190, "rl": 191, "dyna": 191, "much": 191, "when": 191, "econometr": 193, "epidemiolog": 193, "broad": 193, "rang": 193, "relev": 193, "intervent": 197, "trial": 197, "recov": [197, 199], "perturb": 197, "causat": 198, "try": 198, "larg": [198, 200], "metric": 198, "low": 198, "resolut": 198, "coars": 198, "averag": 198, "across": 198, "group": 198, "result": 198, "truth": 198, "simultan": 199, "approach": 199, "plu": 199, "lasso": 199, "omit": [199, 200], "instrument": 200, "iv": 200, "high": 200, "level": 200, "stage": 200, "granger": 200, "curriculum": 201}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx": 56}})