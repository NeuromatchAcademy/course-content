
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Tutorial 1: Sequential Probability Ratio Test &#8212; Neuromatch Computational Neuroscience</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Tutorial 2: Hidden Markov Model" href="W3D2_Tutorial2.html" />
    <link rel="prev" title="Intro" href="../W3D2_Intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      <img src="../../../_static/nma-logo-square-4xp.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Neuromatch Computational Neuroscience</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../intro.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Pre-reqs Refresher
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">
   Python Workshop 1 (W0D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D1_PythonWorkshop1/student/W0D1_Tutorial1.html">
     Tutorial: LIF Neuron - Part I
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">
   Python Workshop 2 (W0D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D2_PythonWorkshop2/student/W0D2_Tutorial1.html">
     Tutorial 1: LIF Neuron Part II
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D3_LinearAlgebra/chapter_title.html">
   Linear Algebra (W0D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial1.html">
     Tutorial 1: Vectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial2.html">
     Tutorial 2: Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial3.html">
     Bonus Tutorial: Discrete Dynamical Systems
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D4_Calculus/chapter_title.html">
   Calculus (W0D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial1.html">
     Tutorial 1: Basics of Differential and Integral Calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial2.html">
     Tutorial 2: Differential Equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial3.html">
     Tutorial 3: Numerical Methods
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D5_Statistics/chapter_title.html">
   Statistics (W0D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial1.html">
     Neuromatch Academy: Precourse Week, Day 5, Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial2.html">
     Tutorial 2: Statistical Inference
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Intro to Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D1_ModelTypes/chapter_title.html">
   Model Types (W1D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/W1D1_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial1.html">
     Tutorial 1: “What” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial2.html">
     Tutorial 2: “How” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial3.html">
     Tutorial 3: “Why” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/W1D1_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D2_ModelingPractice/chapter_title.html">
   Modeling Practice (W1D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_ModelingPractice/W1D2_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_ModelingPractice/student/W1D2_Tutorial1.html">
     Tutorial: Framing the Question
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_ModelingPractice/W1D2_Outro.html">
     Outro
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D3_ModelFitting/chapter_title.html">
   Model Fitting (W1D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/W1D3_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial1.html">
     Tutorial 1: Linear regression with MSE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial2.html">
     Tutorial 2: Linear regression with MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial3.html">
     Tutorial 3: Confidence intervals and bootstrapping
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial4.html">
     Tutorial 4: Multiple linear regression and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial5.html">
     Tutorial 5: Model Selection: Bias-variance trade-off
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial6.html">
     Tutorial 6: Model Selection: Cross-validation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/W1D3_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/chapter_title.html">
   Generalized Linear Models (W1D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/W1D4_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/student/W1D4_Tutorial1.html">
     Tutorial 1: GLMs for Encoding
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/student/W1D4_Tutorial2.html">
     Tutorial 2: Classifiers and regularizers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/W1D4_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D5_DimensionalityReduction/chapter_title.html">
   Dimensionality Reduction (W1D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/W1D5_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial1.html">
     Tutorial 1: Geometric view of data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial2.html">
     Tutorial 2: Principal Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial3.html">
     Tutorial 3: Dimensionality Reduction &amp; Reconstruction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial4.html">
     Tutorial 4:  Nonlinear Dimensionality Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/W1D5_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D1_DeepLearning/chapter_title.html">
   Deep Learning (W2D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/W2D1_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial3.html">
     Tutorial 2: Building and Evaluating Normative Encoding Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/W2D1_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D2_LinearSystems/chapter_title.html">
   Linear Systems (W2D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/W2D2_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial1.html">
     Tutorial 1: Linear dynamical systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial2.html">
     Tutorial 2: Markov Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial3.html">
     Tutorial 3: Combining determinism and stochasticity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial4.html">
     Tutorial 4: Autoregressive models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/W2D2_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/chapter_title.html">
   Biological Neuron Models (W2D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/W2D3_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial1.html">
     Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial2.html">
     Tutorial 2: Effects of Input Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial3.html">
     Tutorial 3: Synaptic transmission - Models of static and dynamic synapses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial4.html">
     Tutorial 4: Spike-timing dependent plasticity (STDP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/W2D3_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D4_DynamicNetworks/chapter_title.html">
   Dynamic Networks (W2D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/W2D4_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial1.html">
     Tutorial 1: Neural Rate Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial2.html">
     Tutorial 2: Wilson-Cowan Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/W2D4_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Stochastic Processes
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D1_BayesianDecisions/chapter_title.html">
   Bayesian Decisions (W3D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/W3D1_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial1.html">
     Tutorial 1: Bayes with a binary hidden state
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial2.html">
     Tutorial 2: Bayesian inference and decisions with continuous hidden state
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial3.html">
     Bonus Tutorial:Fitting to data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/W3D1_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../chapter_title.html">
   Hidden Dynamics (W3D2)
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../W3D2_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Tutorial 1: Sequential Probability Ratio Test
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="W3D2_Tutorial2.html">
     Tutorial 2: Hidden Markov Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="W3D2_Tutorial3.html">
     Tutorial 3: 1D Kalman Filter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="W3D2_Tutorial4.html">
     Tutorial 4: 2D Kalman Filter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../W3D2_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D3_OptimalControl/chapter_title.html">
   Optimal Control (W3D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/W3D3_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial1.html">
     Tutorial 1: Optimal Control for Discrete States
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial2.html">
     Tutorial 2: Optimal Control for Continuous State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/W3D3_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D4_ReinforcementLearning/chapter_title.html">
   Reinforcement Learning (W3D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/W3D4_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial4.html">
     Tutorial 4: From Reinforcement Learning to Planning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/W3D4_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D5_NetworkCausality/chapter_title.html">
   Network Causality (W3D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/W3D5_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial1.html">
     Tutorial 1: Interventions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial2.html">
     Tutorial 2: Correlations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial3.html">
     Tutorial 3: Simultaneous fitting/regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial4.html">
     Tutorial 4: Instrumental Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/W3D5_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial1.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/NeuromatchAcademy/course_content/blob/master/book/tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial1.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Tutorial 1: Sequential Probability Ratio Test
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-1-introduction-to-the-sprt">
   Section 1: Introduction to the SPRT
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-1-1-the-random-dot-task">
     Section 1.1: The random dot task
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-1-2-sequential-probability-ratio-test-sprt">
     Section 1.2: Sequential Probability Ratio Test(SPRT)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-1-3-sprt-as-a-drift-diffusion-model-ddm">
     Section 1.3: SPRT as a Drift Diffusion Model (DDM)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-2-ddm-with-fixed-time-stopping-rule">
   Section 2: DDM with fixed-time stopping rule
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-2-1-simulation-of-ddm-with-fixed-time-stopping-rule">
     Section 2.1: Simulation of DDM with fixed-time stopping rule
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coding-exercise-1-simulating-an-sprt-model">
       Coding Exercise 1: Simulating an SPRT model
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-demo-2-1-trajectories-under-the-fixed-time-stopping-rule">
       Interactive Demo 2.1: Trajectories under the fixed-time stopping rule
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-2-2-accuracy-vs-stopping-time">
     Section 2.2: Accuracy vs stopping time
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coding-exercise-2-the-speed-accuracy-tradeoff">
       Coding Exercise 2: The Speed/Accuracy Tradeoff
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-demo-2-2-accuracy-versus-stop-time">
       Interactive Demo 2.2: Accuracy versus stop-time
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bonus">
   Bonus
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bonus-section-1-ddm-with-fixed-thresholds-on-confidence">
     Bonus Section 1: DDM with fixed thresholds on confidence
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#exercise-3-simulating-the-ddm-with-fixed-thresholds">
       Exercise 3: Simulating the DDM with fixed thresholds
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-demo-ddm-with-fixed-threshold">
       Interactive Demo: DDM with fixed threshold
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#exercise-4-speed-accuracy-tradeoff-revisited">
       Exercise 4: Speed/Accuracy Tradeoff Revisited
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-demo-speed-accuracy-with-a-threshold-rule">
       Interactive Demo: Speed/Accuracy with a threshold rule
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/master/tutorials/W3D2_HiddenDynamics/student/W3D2_Tutorial1.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<div class="section" id="tutorial-1-sequential-probability-ratio-test">
<h1>Tutorial 1: Sequential Probability Ratio Test<a class="headerlink" href="#tutorial-1-sequential-probability-ratio-test" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 3, Day 2: Hidden Dynamics</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Yicheng Fei and Xaq Pitkow</p>
<p><strong>Content reviewers:</strong> John Butler, Matt Krause, Spiros Chavlis, Michael Waskom, Jesse Livezey, and Byron Galbraith</p>
<hr class="docutils" />
<p>#Tutorial Objectives</p>
<p>In W3D1, we learned how to combine the sensory evidence and our prior experience with Bayes’ Theorem, producing a posterior probability distribution that would let us choose between the most probable of <em>two</em> options (fish being on the left or fish being on the right).</p>
<p>Here, we add a <em>third</em> option: choosing to collect more evidence before making a decision.</p>
<hr class="docutils" />
<p>In this notebook we will perform a <em>Sequential Probability Ratio Test</em> (SPRT) between two hypotheses <span class="math notranslate nohighlight">\(s=+1\)</span> and <span class="math notranslate nohighlight">\(s=-1\)</span> by running simulations of a <em>Drift Diffusion Model (DDM)</em>. As data comes in, we accumulate evidence linearly until a stopping criterion is met before deciding which hypothesis to accept.</p>
<p>In this tutorial, you will</p>
<ul class="simple">
<li><p>Simulate the Drift-Diffusion Model.</p></li>
<li><p>Gain intuition about the tradeoff between decision speed and accuracy.</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 1: Overview of Tutorials on Hidden Dynamics</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;ofNRpSpRxl4&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Figure settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>       <span class="c1"># interactive display</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/NeuromatchAcademy/course-content/NMA2020/nma.mplstyle&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Helper functions</span>

<span class="k">def</span> <span class="nf">simulate_and_plot_SPRT_fixedtime</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">stop_time</span><span class="p">,</span> <span class="n">num_sample</span><span class="p">,</span>
                                     <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Simulate and plot a SPRT for a fixed amount of time given a std.</span>

<span class="sd">  Args:</span>
<span class="sd">    sigma (float): Standard deviation of the observations.</span>
<span class="sd">    stop_time (int): Number of steps to run before stopping.</span>
<span class="sd">    num_sample (int): The number of samples to plot.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="n">evidence_history_list</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;#Trial</span><span class="se">\t</span><span class="s2">Total_Evidence</span><span class="se">\t</span><span class="s2">Decision&quot;</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_sample</span><span class="p">):</span>
    <span class="n">evidence_history</span><span class="p">,</span> <span class="n">decision</span><span class="p">,</span> <span class="n">Mvec</span> <span class="o">=</span> <span class="n">simulate_SPRT_fixedtime</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">stop_time</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="se">\t</span><span class="si">{:f}</span><span class="se">\t</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">evidence_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">decision</span><span class="p">))</span>
    <span class="n">evidence_history_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evidence_history</span><span class="p">)</span>

  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">maxlen_evidence</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span><span class="n">evidence_history_list</span><span class="p">)))</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">maxlen_evidence</span><span class="p">),</span> <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">evidences</span> <span class="ow">in</span> <span class="n">evidence_history_list</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">evidences</span><span class="p">)),</span> <span class="n">evidences</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Cumulated log likelihood ratio&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Log likelihood ratio trajectories under the fixed-time &quot;</span> <span class="o">+</span>
                  <span class="s2">&quot;stopping rule&quot;</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_accuracy_vs_stoptime</span><span class="p">(</span><span class="n">stop_time_list</span><span class="p">,</span> <span class="n">accuracy_list</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Simulate and plot a SPRT for a fixed amount of times given a std.</span>

<span class="sd">  Args:</span>
<span class="sd">    stop_time_list (int): List of number of steps to run before stopping.</span>
<span class="sd">    accuracy_list (int): List of accuracies for each stop time</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">stop_time_list</span><span class="p">,</span> <span class="n">accuracy_list</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Stop Time&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Average Accuracy&#39;</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">simulate_and_plot_SPRT_fixedthreshold</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">num_sample</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span>
                                          <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Simulate and plot a SPRT for a fixed amount of times given a std.</span>

<span class="sd">  Args:</span>
<span class="sd">    sigma (float): Standard deviation of the observations.</span>
<span class="sd">    num_sample (int): The number of samples to plot.</span>
<span class="sd">    alpha (float): Threshold for making a decision.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># calculate evidence threshold from error rate</span>
  <span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold_from_errorrate</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>

  <span class="c1"># run simulation</span>
  <span class="n">evidence_history_list</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;#Trial</span><span class="se">\t</span><span class="s2">Time</span><span class="se">\t</span><span class="s2">Cumulated Evidence</span><span class="se">\t</span><span class="s2">Decision&quot;</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_sample</span><span class="p">):</span>
    <span class="n">evidence_history</span><span class="p">,</span> <span class="n">decision</span><span class="p">,</span> <span class="n">Mvec</span> <span class="o">=</span> <span class="n">simulate_SPRT_threshold</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="se">\t</span><span class="si">{}</span><span class="se">\t</span><span class="si">{:f}</span><span class="se">\t</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">Mvec</span><span class="p">),</span> <span class="n">evidence_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                      <span class="n">decision</span><span class="p">))</span>
    <span class="n">evidence_history_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">evidence_history</span><span class="p">)</span>

  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">maxlen_evidence</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span><span class="n">evidence_history_list</span><span class="p">)))</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span><span class="n">maxlen_evidence</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span><span class="n">maxlen_evidence</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">maxlen_evidence</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">evidences</span> <span class="ow">in</span> <span class="n">evidence_history_list</span><span class="p">:</span>
      <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">evidences</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="n">evidences</span><span class="p">]))</span>

  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Cumulated log likelihood ratio&quot;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Log likelihood ratio trajectories under the threshold rule&quot;</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">simulate_and_plot_accuracy_vs_threshold</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">threshold_list</span><span class="p">,</span> <span class="n">num_sample</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Simulate and plot a SPRT for a set of thresholds given a std.</span>

<span class="sd">  Args:</span>
<span class="sd">    sigma (float): Standard deviation of the observations.</span>
<span class="sd">    alpha_list (float): List of thresholds for making a decision.</span>
<span class="sd">    num_sample (int): The number of samples to plot.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">accuracies</span><span class="p">,</span> <span class="n">decision_speeds</span> <span class="o">=</span> <span class="n">simulate_accuracy_vs_threshold</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span>
                                                               <span class="n">threshold_list</span><span class="p">,</span>
                                                               <span class="n">num_sample</span><span class="p">)</span>

  <span class="c1"># Plotting</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">decision_speeds</span><span class="p">,</span> <span class="n">accuracies</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">amin</span><span class="p">(</span><span class="n">decision_speeds</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">decision_speeds</span><span class="p">)],</span>
          <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Average Decision speed&quot;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Average Accuracy&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Speed/Accuracy Tradeoff&quot;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.45</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">threshold_from_errorrate</span><span class="p">(</span><span class="n">alpha</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Calculate log likelihood ratio threshold from desired error rate `alpha`</span>

<span class="sd">  Args:</span>
<span class="sd">    alpha (float): in (0,1), the desired error rate</span>

<span class="sd">  Return:</span>
<span class="sd">    threshold: corresponding evidence threshold</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="n">alpha</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">threshold</span>
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-1-introduction-to-the-sprt">
<h1>Section 1: Introduction to the SPRT<a class="headerlink" href="#section-1-introduction-to-the-sprt" title="Permalink to this headline">¶</a></h1>
<div class="section" id="section-1-1-the-random-dot-task">
<h2>Section 1.1: The random dot task<a class="headerlink" href="#section-1-1-the-random-dot-task" title="Permalink to this headline">¶</a></h2>
<p>A classic experimental task in neuroscience is the random dot kinematogram (<a class="reference external" href="https://www.nature.com/articles/341052a0.pdf">Newsome, Britten, Movshon 1989</a>), in which a pattern of moving dots are moving in random directions but with some weak coherence that favors a net rightward or leftward motion. The observer must guess the direction. Neurons in the brain are informative about this task, and have responses that correlate with the choice.</p>
<p>Below is a video by Pamela Reinagle of a rat guessing the direction of motion in such a task.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 2: Rat performing the Random Dot Motion Task</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;oDxcyTn-0os&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>In this tutorial, we will consider a model for this random dot motion task. In each time bin <span class="math notranslate nohighlight">\(t\)</span>, we are shown dots moving at net measured velocity <span class="math notranslate nohighlight">\(m_t\)</span>, either in a negative (<span class="math notranslate nohighlight">\(m&lt;0\)</span>) or positive (<span class="math notranslate nohighlight">\(m&gt;0\)</span>) direction. Although the dots’ velocities varies over time, the <span class="math notranslate nohighlight">\(m_t\)</span> are generated by a fixed probability distribution <span class="math notranslate nohighlight">\(p(m|s)\)</span> that depends on a fixed latent variable <span class="math notranslate nohighlight">\(s=\pm 1\)</span>:
$$
\</p>
<div class="amsmath math notranslate nohighlight" id="equation-eca3dc57-116c-437c-a999-2226d27c4631">
<span class="eqno">(171)<a class="headerlink" href="#equation-eca3dc57-116c-437c-a999-2226d27c4631" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
p(m|s=+1) &amp;=&amp; \mathcal{N}\left(\mu_+,\sigma^2\right) \\
&amp;&amp;\textrm{or} \\
p(m|s=-1) &amp;=&amp; \mathcal{N}\left(\mu_-,\sigma^2\right) \\
\end{eqnarray}\]</div>
<p>\
$<span class="math notranslate nohighlight">\(
Here we assume the measurement probabilities have the same variances regardless of \)</span>s<span class="math notranslate nohighlight">\(, and different means. We, like the rat, want to synthesize our evidence to determine whether \)</span>s=+1<span class="math notranslate nohighlight">\( or \)</span>-1$.</p>
</div>
<div class="section" id="section-1-2-sequential-probability-ratio-test-sprt">
<h2>Section 1.2: Sequential Probability Ratio Test(SPRT)<a class="headerlink" href="#section-1-2-sequential-probability-ratio-test-sprt" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 3: Decision making: Sequential Probability Ratio Test</span>
<span class="c1"># Insert the ID of the corresponding youtube video</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;DGoPoLkDiUw&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<!-- <img alt="PGM" width="400" src="https://github.com/NeuromatchAcademy/course-content/blob/master/tutorials/W2D3_DecisionMaking/static/W2D3_Tutorial1_PGM.png?raw=true"> -->
<img src="https://drive.google.com/uc?export=view&id=1vE2XQ5qMQ_pJgzgZRCnNVQEpP-nupt87" alt="HMM drawing" width="400">
<p>Suppose we obtain a sequence of independent measurements <span class="math notranslate nohighlight">\(m_{1:T}\)</span> from a distribution <span class="math notranslate nohighlight">\(p(m_{1:T}|s)\)</span>. Remember that <span class="math notranslate nohighlight">\(s\)</span> is our hidden state and for now, is either -1 or 1. Our measurements come from either <span class="math notranslate nohighlight">\(p(m_t|s=-1)\)</span> or <span class="math notranslate nohighlight">\(p(m_t|s=1)\)</span>. We wish to test which value of <span class="math notranslate nohighlight">\(s\)</span> is more likely given our sequence of measurements.</p>
<p>A crucial assumption in Hidden Markov Models is that all measurements are drawn independently given the latent state. In the fishing example, you might have a high or low probability of catching fish depending on where the school of fish is — but if you already <em>knew</em> the location <span class="math notranslate nohighlight">\(s\)</span> of the school (which is what we mean by a conditional probability <span class="math notranslate nohighlight">\(p(m|s)\)</span>), then your chances of catching fish at one time is unaffected by whether you caught fish there previously.</p>
<p>Mathematically, we write this independence as <span class="math notranslate nohighlight">\(p(m_1, m_2|s)=p(m_1|s)p(m_2|s)\)</span>, using the product rule of probabilities.  When we consider a whole time series of measurements <span class="math notranslate nohighlight">\(m_{1:T}\)</span>, we can compute the product <span class="math notranslate nohighlight">\(p(m_{1:T}|s)=\prod_{t=1}^T p(m_t|s)\)</span>.</p>
<p>We can then compare the total evidence up to time <span class="math notranslate nohighlight">\(T\)</span> for our two hypotheses (of whether our state is -1 or 1) by taking a ratio
of the likelihoods.</p>
<div class="math notranslate nohighlight">
\[L_t=\frac{\prod_{t=1}^T p(m_t|s=+1)}{\prod_{t=1}^T p(m_t|s=-1)}\]</div>
<p>The above tells us the likelihood of the measurements if <span class="math notranslate nohighlight">\(s = 1\)</span> divided by the likelihood of the measurements if <span class="math notranslate nohighlight">\(s = -1\)</span>.</p>
<p>It is convenient to take the <em>log</em> of this likelihood ratio, converting the products to sums:</p>
<div class="math notranslate nohighlight">
\[S_t = \log L_t = \sum_{t=1}^T \log \frac{p(m_t|s=+1)}{p(m_t|s=-1)} \tag{1}\]</div>
<p>We can name each term in the sum as
$<span class="math notranslate nohighlight">\(\Delta_t= \log \frac{p(m_t|s=+1)}{p(m_t|s=-1)}\)</span>$
Due to the independence of measurements, this can be calculated recursively <em>online</em> as new data points arrive:</p>
<div class="math notranslate nohighlight">
\[ S_t =  S_{t-1} + \Delta_t \tag{2}\]</div>
<p>where we update our log-likelihood ratio <span class="math notranslate nohighlight">\(S_t\)</span> by <span class="math notranslate nohighlight">\(\Delta_t\)</span> every time we see a new measurement <span class="math notranslate nohighlight">\(m_t\)</span>.</p>
<p>We will use <span class="math notranslate nohighlight">\(S_t\)</span> to make our decisions! If <span class="math notranslate nohighlight">\(S_t\)</span> is positive, the likelihood of <span class="math notranslate nohighlight">\(s = 1\)</span> is higher. If it is negative, the likelihood of <span class="math notranslate nohighlight">\(s = -1\)</span> is higher. We need to figure out when we make our decision though, as <span class="math notranslate nohighlight">\(S_t\)</span> can change with each new measurement.</p>
<p>A rule for making a decision can be implemented in two ways:</p>
<ol class="simple">
<li><p>Fixed time (Section 2): Stop collecting data after a predetermined number of measurements <span class="math notranslate nohighlight">\(t\)</span>, and accept the hypothesis that <span class="math notranslate nohighlight">\(s=+1\)</span> if <span class="math notranslate nohighlight">\(S_t&gt;0\)</span>, otherwise accept <span class="math notranslate nohighlight">\(s=-1\)</span> if <span class="math notranslate nohighlight">\(S_t&lt;0\)</span> (and choose randomly if <span class="math notranslate nohighlight">\(S_t=0\)</span>). The significance level or desired error rate <span class="math notranslate nohighlight">\(\alpha\)</span> can then be determined as <span class="math notranslate nohighlight">\(\alpha = (1+\exp(|S_t|))^{-1}\)</span>.</p></li>
<li><p>Confidence threshold (Bonus Section 1): Choose an acceptable error rate <span class="math notranslate nohighlight">\(\alpha\)</span>. Then accept the hypothesis <span class="math notranslate nohighlight">\(s=1\)</span> when <span class="math notranslate nohighlight">\(S_t \ge b=\log \frac{1-\alpha}{\alpha}\)</span>, analogously accept <span class="math notranslate nohighlight">\(s=-1\)</span> when <span class="math notranslate nohighlight">\(S_t\le -b\)</span>, and keep collecting data until one of those confidence thresholds is reached. Historical note: this is the rule that Alan Turing used to break the Enigma code and win World War II!</p></li>
</ol>
</div>
<div class="section" id="section-1-3-sprt-as-a-drift-diffusion-model-ddm">
<h2>Section 1.3: SPRT as a Drift Diffusion Model (DDM)<a class="headerlink" href="#section-1-3-sprt-as-a-drift-diffusion-model-ddm" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 4: SPRT and the Random Dot Motion Task</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;7WBB4M_Vf58&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>The evidence favoring the two latent states is random, but according to our model it will weakly favor one hypothesis over another. The accumulation of evidence will thus “drift” toward one outcome, while “diffusing” in random directions, hence the term “drift-diffusion model” (DDM). The process is most likely (but not guaranteed) to reach the correct outcome eventually. We can do a little math below to show that the update <span class="math notranslate nohighlight">\(\Delta_t\)</span> to the log-likelihood ratio is a gaussian random number. You can derive this yourself, filling in the steps below, or skip to the end result.</p>
<p><strong>Bonus exercise: derive Drift Diffusion Model from SPRT</strong></p>
<p>Assume measurements are Gaussian-distributed with different means depending on the discrete latent variable <span class="math notranslate nohighlight">\(s\)</span>:
$<span class="math notranslate nohighlight">\(p(m|s=\pm 1) = \mathcal{N}\left(\mu_\pm,\sigma^2\right)=\frac{1}{\sqrt{2\pi\sigma^2}}\exp{\left[-\frac{(m-\mu_\pm)^2}{2\sigma^2}\right]}\)</span>$</p>
<p>In the log likelihood ratio for a single data point <span class="math notranslate nohighlight">\(m_i\)</span>, the normalizations cancel to give
$<span class="math notranslate nohighlight">\(\Delta_t=\log \frac{p(m_t|s=+1)}{p(m_t|s=-1)} = \frac{1}{2\sigma^2}\left[-\left(m_t-\mu_+\right)^2 + (m_t-\mu_-)^2\right] \tag{5}\)</span>$</p>
<p>It’s convenient to rewrite <span class="math notranslate nohighlight">\(m=\mu_\pm + \sigma \epsilon\)</span>, where <span class="math notranslate nohighlight">\(\epsilon\sim \mathcal{N}(0,1)\)</span> is a standard Gaussian variable with zero mean and unit variance. (Why does this give the correct probability for <span class="math notranslate nohighlight">\(m\)</span>?). The preceding formula can then be rewritten as
$<span class="math notranslate nohighlight">\(\Delta_t = \frac{1}{2\sigma^2}\left( -((\mu_\pm+\sigma\epsilon)-\mu_+)^2 + ((\mu_\pm+\sigma\epsilon)-\mu_-)^2\right) \tag{5}\)</span><span class="math notranslate nohighlight">\(
Let's assume that \)</span>s=+1<span class="math notranslate nohighlight">\( so \)</span>\mu_\pm=\mu_+<span class="math notranslate nohighlight">\( (if \)</span>s=-1<span class="math notranslate nohighlight">\( then the result is the same with a reversed sign). In that case, the means in the first term \)</span>m_t-\mu_+<span class="math notranslate nohighlight">\( cancel, leaving
\)</span><span class="math notranslate nohighlight">\(\Delta_t = \frac{(\mu_+-\mu_-)^2}{2\sigma^2}+\frac{\mu_+-\mu_-}{\sigma}\epsilon \tag{5}\)</span><span class="math notranslate nohighlight">\(
where the first term is the constant *drift*, and the second term is the random *diffusion*. Adding these \)</span>\Delta_t<span class="math notranslate nohighlight">\( over time gives a biased random walk known as the Drift Diffusion Model, \)</span>S_t=\sum_t \Delta_t<span class="math notranslate nohighlight">\(. The log-likelihood ratio is then normally distributed with a time-dependent mean and variance, 
\)</span><span class="math notranslate nohighlight">\(S_t\sim\mathcal{N}\left(\tfrac{1}{2}\frac{\delta\mu^2}{\sigma^2}t,\ \frac{\delta\mu^2}{\sigma^2}t\right)\)</span><span class="math notranslate nohighlight">\(
where \)</span>\delta\mu=\mu_+-\mu_-<span class="math notranslate nohighlight">\(. The mean and the variance both increase linearly with time, so the standard deviation grows more slowly, as only \)</span>\sqrt{t}$. This means that the distributions becomes more and more distinct as evidence is acquired over time. You will simulate this process below.</p>
<p><strong>Neural application</strong></p>
<p>Neural responses in lateral intraparietal cortex (LIP) to the random-dots kinematogram has been well-described by this drift-diffusion process (Huk and Shadlen 2005), suggesting that these neurons gradually integrate evidence. Interestingly there is also a more recent competing hypothesis that neural activity jumps from low to high at random latent times, such that on average it looks like a gradual ramping (Latimer et al 2015). Scientific evidence about these processes are judged by how well the corresponding Hidden Markov Models fit the data!</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-2-ddm-with-fixed-time-stopping-rule">
<h1>Section 2: DDM with fixed-time stopping rule<a class="headerlink" href="#section-2-ddm-with-fixed-time-stopping-rule" title="Permalink to this headline">¶</a></h1>
<div class="section" id="section-2-1-simulation-of-ddm-with-fixed-time-stopping-rule">
<h2>Section 2.1: Simulation of DDM with fixed-time stopping rule<a class="headerlink" href="#section-2-1-simulation-of-ddm-with-fixed-time-stopping-rule" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 5: Simulate the DDM with a fixed-time stopping rule</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;9WNAZnEa64Y&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="coding-exercise-1-simulating-an-sprt-model">
<h3>Coding Exercise 1: Simulating an SPRT model<a class="headerlink" href="#coding-exercise-1-simulating-an-sprt-model" title="Permalink to this headline">¶</a></h3>
<p>Assume we are performing a random dot motion task and at each time we see a moving dot with a sensory measurement <span class="math notranslate nohighlight">\(m_t\)</span> of velocity. All data points are sampled from the same distribution <span class="math notranslate nohighlight">\(p\)</span>, which is either <span class="math notranslate nohighlight">\(p_+=\mathcal{N}\left(\mu,\sigma^2\right)\)</span> or <span class="math notranslate nohighlight">\(p_-=\mathcal{N}\left(-\mu,\sigma^2\right)\)</span>, depending on which direction the dots are moving in. Let’s now generate some simulated data under this setting and perform SPRT using the fixed time stopping rule.</p>
<p>In this exercise, without loss of generality, we assume the true data-generating model is <span class="math notranslate nohighlight">\(p_+\)</span>.</p>
<p>We will implement a function <code class="docutils literal notranslate"><span class="pre">simulate_SPRT_fixedtime</span></code>, which will generate measurements based on <span class="math notranslate nohighlight">\(\mu\)</span>, <span class="math notranslate nohighlight">\(\sigma\)</span>, and the true state. It will then accumulate evidence and output a decision on the state. We will use the helper function <code class="docutils literal notranslate"><span class="pre">log_likelihood_ratio</span></code>, implemented in the next cell, which computes the log of the likelihood of the state being 1 divided by the likelihood of the state being -1.</p>
<p>We will then run and visualize 10 simulations of evidence accumulation and decision.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to enable the helper function log_likelihood_ratio</span>

<span class="k">def</span> <span class="nf">log_likelihood_ratio</span><span class="p">(</span><span class="n">Mvec</span><span class="p">,</span> <span class="n">p0</span><span class="p">,</span> <span class="n">p1</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Given a sequence(vector) of observed data, calculate the log of</span>
<span class="sd">  likelihood ratio of p1 and p0</span>

<span class="sd">  Args:</span>
<span class="sd">    Mvec (numpy vector):           A vector of scalar measurements</span>
<span class="sd">    p0 (Gaussian random variable): A normal random variable with `logpdf&#39;</span>
<span class="sd">                                    method</span>
<span class="sd">    p1 (Gaussian random variable): A normal random variable with `logpdf`</span>
<span class="sd">                                    method</span>

<span class="sd">  Returns:</span>
<span class="sd">    llvec: a vector of log likelihood ratios for each input data point</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">p1</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">Mvec</span><span class="p">)</span> <span class="o">-</span> <span class="n">p0</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">Mvec</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simulate_SPRT_fixedtime</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">stop_time</span><span class="p">,</span> <span class="n">true_dist</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Simulate a Sequential Probability Ratio Test with fixed time stopping</span>
<span class="sd">  rule. Two observation models are 1D Gaussian distributions N(1,sigma^2) and</span>
<span class="sd">  N(-1,sigma^2).</span>

<span class="sd">  Args:</span>
<span class="sd">    sigma (float): Standard deviation of observation models</span>
<span class="sd">    stop_time (int): Number of samples to take before stopping</span>
<span class="sd">    true_dist (1 or -1): Which state is the true state.</span>

<span class="sd">  Returns:</span>
<span class="sd">    evidence_history (numpy vector): the history of cumulated evidence given</span>
<span class="sd">                                      generated data</span>
<span class="sd">    decision (int): 1 for s = 1, -1 for s = -1</span>
<span class="sd">    Mvec (numpy vector): the generated sequences of measurement data in this trial</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1">#################################################</span>
  <span class="c1">## TODO for students ##</span>
  <span class="c1"># Fill out function and remove</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student exercise: complete simulate_SPRT_fixedtime&quot;</span><span class="p">)</span>
  <span class="c1">#################################################</span>

  <span class="c1"># Set means of observation distributions</span>
  <span class="n">mu_pos</span> <span class="o">=</span> <span class="mf">1.0</span>
  <span class="n">mu_neg</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>

  <span class="c1"># Make observation distributions</span>
  <span class="n">p_pos</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="n">mu_pos</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">)</span>
  <span class="n">p_neg</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="n">mu_neg</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">)</span>

  <span class="c1"># Generate a random sequence of measurements</span>
  <span class="k">if</span> <span class="n">true_dist</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">Mvec</span> <span class="o">=</span> <span class="n">p_pos</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="n">stop_time</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">Mvec</span> <span class="o">=</span> <span class="n">p_neg</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="n">stop_time</span><span class="p">)</span>

  <span class="c1"># Calculate log likelihood ratio for each measurement (delta_t)</span>
  <span class="n">ll_ratio_vec</span> <span class="o">=</span> <span class="n">log_likelihood_ratio</span><span class="p">(</span><span class="n">Mvec</span><span class="p">,</span> <span class="n">p_neg</span><span class="p">,</span> <span class="n">p_pos</span><span class="p">)</span>

  <span class="c1"># Calculate cumulated evidence (S) given a vector of individual evidences (hint: np.cumsum)</span>
  <span class="n">evidence_history</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># Make decision</span>
  <span class="k">if</span> <span class="n">evidence_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="c1"># Decision given positive S_t (last value of evidence history)</span>
    <span class="n">decision</span> <span class="o">=</span> <span class="o">...</span>
  <span class="k">elif</span> <span class="n">evidence_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="c1"># Decision given negative S_t (last value of evidence history)</span>
    <span class="n">decision</span> <span class="o">=</span> <span class="o">...</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1"># Random decision if S_t is 0</span>
    <span class="n">decision</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">evidence_history</span><span class="p">,</span> <span class="n">decision</span><span class="p">,</span> <span class="n">Mvec</span>


<span class="c1"># Set random seed</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Set model parameters</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">3.5</span>  <span class="c1"># standard deviation for p+ and p-</span>
<span class="n">num_sample</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># number of simulations to run</span>
<span class="n">stop_time</span> <span class="o">=</span> <span class="mi">150</span> <span class="c1"># number of steps before stopping</span>

<span class="n">simulate_and_plot_SPRT_fixedtime</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">stop_time</span><span class="p">,</span> <span class="n">num_sample</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D2_HiddenDynamics/solutions/W3D2_Tutorial1_Solution_85d9b919.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=573 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D2_HiddenDynamics/static/W3D2_Tutorial1_Solution_85d9b919_1.png>
</div>
<div class="section" id="interactive-demo-2-1-trajectories-under-the-fixed-time-stopping-rule">
<h3>Interactive Demo 2.1: Trajectories under the fixed-time stopping rule<a class="headerlink" href="#interactive-demo-2-1-trajectories-under-the-fixed-time-stopping-rule" title="Permalink to this headline">¶</a></h3>
<p>In the following demo, you can change the noise level in the observation model (sigma) and the number of time steps before stopping (stop_time) using the sliders. You will then observe 10 simulations with those parameters.</p>
<ol class="simple">
<li><p>Are you more likely to make the wrong decision (choose the incorrect state) with high or low noise?</p></li>
<li><p>What happens when sigma is very small? Why?</p></li>
<li><p>Are you more likely to make the wrong decision (choose the incorrect state) with fewer or more time steps before stopping?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>
<span class="k">def</span> <span class="nf">simulate_SPRT_fixedtime</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">stop_time</span><span class="p">,</span> <span class="n">true_dist</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Simulate a Sequential Probability Ratio Test with fixed time stopping</span>
<span class="sd">  rule. Two observation models are 1D Gaussian distributions N(1,sigma^2) and</span>
<span class="sd">  N(-1,sigma^2).</span>

<span class="sd">  Args:</span>
<span class="sd">    sigma (float): Standard deviation of observation models</span>
<span class="sd">    stop_time (int): Number of samples to take before stopping</span>
<span class="sd">    true_dist (1 or -1): Which state is the true state.</span>

<span class="sd">  Returns:</span>
<span class="sd">    evidence_history (numpy vector): the history of cumulated evidence given</span>
<span class="sd">                                      generated data</span>
<span class="sd">    decision (int): 1 for s = 1, -1 for s = -1</span>
<span class="sd">    Mvec (numpy vector): the generated sequences of measurement data in this trial</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1"># Set means of observation distributions</span>
  <span class="n">mu_pos</span> <span class="o">=</span> <span class="mf">1.0</span>
  <span class="n">mu_neg</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>

  <span class="c1"># Make observation distributions</span>
  <span class="n">p_pos</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="n">mu_pos</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">)</span>
  <span class="n">p_neg</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="n">mu_neg</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">)</span>

  <span class="c1"># Generate a random sequence of measurements</span>
  <span class="k">if</span> <span class="n">true_dist</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">Mvec</span> <span class="o">=</span> <span class="n">p_pos</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="n">stop_time</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">Mvec</span> <span class="o">=</span> <span class="n">p_neg</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="n">stop_time</span><span class="p">)</span>

  <span class="c1"># Calculate log likelihood ratio for each measurement (delta_t)</span>
  <span class="n">ll_ratio_vec</span> <span class="o">=</span> <span class="n">log_likelihood_ratio</span><span class="p">(</span><span class="n">Mvec</span><span class="p">,</span> <span class="n">p_neg</span><span class="p">,</span> <span class="n">p_pos</span><span class="p">)</span>

  <span class="c1"># Calculate cumulated evidence (S) given a vector of individual evidences (hint: np.cumsum)</span>
  <span class="n">evidence_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">ll_ratio_vec</span><span class="p">)</span>

  <span class="c1"># Make decision</span>
  <span class="k">if</span> <span class="n">evidence_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="c1"># Decision given positive S_t (last value of evidence history)</span>
    <span class="n">decision</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="k">elif</span> <span class="n">evidence_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="c1"># Decision given negative S_t (last value of evidence history)</span>
    <span class="n">decision</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1"># Random decision if S_t is 0</span>
    <span class="n">decision</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">evidence_history</span><span class="p">,</span> <span class="n">decision</span><span class="p">,</span> <span class="n">Mvec</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">num_sample</span> <span class="o">=</span> <span class="mi">10</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span>
<span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="n">sigma</span><span class="o">=</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">),</span> <span class="n">stop_time</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1</span><span class="p">)):</span>
  <span class="n">simulate_and_plot_SPRT_fixedtime</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">stop_time</span><span class="p">,</span> <span class="n">num_sample</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D2_HiddenDynamics/solutions/W3D2_Tutorial1_Solution_8ab841e6.py"><em>Click for solution</em></a></p>
</div>
</div>
<div class="section" id="section-2-2-accuracy-vs-stopping-time">
<h2>Section 2.2: Accuracy vs stopping time<a class="headerlink" href="#section-2-2-accuracy-vs-stopping-time" title="Permalink to this headline">¶</a></h2>
<p>If you stop taking samples too early, (e.g., make a decision after only seeing 5 samples), or there’s a huge amount of observation noise that buries the signal, you are likely to be driven by observation noise to a negative cumulated log likelihood ratio and thus make a wrong decision. You could get a sense of this by increasing noise level or decreasing stopping time in the last exercise.</p>
<p>Now let’s look at how decision accuracy varies with the number of samples we see quantitatively.Accuracy is simply defined as the proportion of correct trials across our repeated simulations: <span class="math notranslate nohighlight">\(\frac{\# \textrm{ correct decisions}}{\# \textrm{ total simulation runs}}\)</span>.</p>
<div class="section" id="coding-exercise-2-the-speed-accuracy-tradeoff">
<h3>Coding Exercise 2: The Speed/Accuracy Tradeoff<a class="headerlink" href="#coding-exercise-2-the-speed-accuracy-tradeoff" title="Permalink to this headline">¶</a></h3>
<p>We will fix our observation noise level. In this exercise you will implement a function to run several repeated simulations for a certain stopping time and calculate the average decision accuracy. We will then visualize the relation average decision accuracy and stopping time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simulate_accuracy_vs_stoptime</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">stop_time_list</span><span class="p">,</span> <span class="n">num_sample</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Calculate the average decision accuracy vs. stopping time by running</span>
<span class="sd">  repeated SPRT simulations for each stop time.</span>

<span class="sd">  Args:</span>
<span class="sd">      sigma (float): standard deviation for observation model</span>
<span class="sd">      stop_list_list (list-like object): a list of stopping times to run over</span>
<span class="sd">      num_sample (int): number of simulations to run per stopping time</span>

<span class="sd">  Returns:</span>
<span class="sd">      accuracy_list: a list of average accuracies corresponding to input</span>
<span class="sd">                      `stop_time_list`</span>
<span class="sd">      decisions_list: a list of decisions made in all trials</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1">#################################################</span>
  <span class="c1">## TODO for students##</span>
  <span class="c1"># Fill out function and remove</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Student exercise: complete simulate_accuracy_vs_stoptime&quot;</span><span class="p">)</span>
  <span class="c1">#################################################</span>

  <span class="c1"># Determine true state (1 or -1)</span>
  <span class="n">true_dist</span> <span class="o">=</span> <span class="mi">1</span>

  <span class="c1"># Set up tracker of accuracy and decisions</span>
  <span class="n">accuracies</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stop_time_list</span><span class="p">),)</span>
  <span class="n">decisions_list</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="c1"># Loop over stop times</span>
  <span class="k">for</span> <span class="n">i_stop_time</span><span class="p">,</span> <span class="n">stop_time</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">stop_time_list</span><span class="p">):</span>

    <span class="c1"># Set up tracker of decisions for this stop time</span>
    <span class="n">decisions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_sample</span><span class="p">,))</span>

    <span class="c1"># Loop over samples</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_sample</span><span class="p">):</span>

      <span class="c1"># Simulate run for this stop time (hint: last exercise)</span>
      <span class="n">_</span><span class="p">,</span> <span class="n">decision</span><span class="p">,</span> <span class="n">_</span><span class="o">=</span> <span class="o">...</span>

      <span class="c1"># Log decision</span>
      <span class="n">decisions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">decision</span>

    <span class="c1"># Calculate accuracy</span>
    <span class="n">accuracies</span><span class="p">[</span><span class="n">i_stop_time</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># Log decisions</span>
    <span class="n">decisions_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decisions</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">accuracies</span><span class="p">,</span> <span class="n">decisions_list</span>


<span class="c1"># Set random seed</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Set parameters of model</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">4.65</span>  <span class="c1"># standard deviation for observation noise</span>
<span class="n">num_sample</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># number of simulations to run for each stopping time</span>
<span class="n">stop_time_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># Array of stopping times to use</span>

<span class="c1"># Calculate accuracies for each stop time</span>
<span class="n">accuracies</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">simulate_accuracy_vs_stoptime</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">stop_time_list</span><span class="p">,</span>
                                                   <span class="n">num_sample</span><span class="p">)</span>

<span class="c1"># Visualize</span>
<span class="n">plot_accuracy_vs_stoptime</span><span class="p">(</span><span class="n">stop_time_list</span><span class="p">,</span> <span class="n">accuracies</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D2_HiddenDynamics/solutions/W3D2_Tutorial1_Solution_d5a87445.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=560 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D2_HiddenDynamics/static/W3D2_Tutorial1_Solution_d5a87445_0.png>
</div>
<div class="section" id="interactive-demo-2-2-accuracy-versus-stop-time">
<h3>Interactive Demo 2.2: Accuracy versus stop-time<a class="headerlink" href="#interactive-demo-2-2-accuracy-versus-stop-time" title="Permalink to this headline">¶</a></h3>
<p>In the following demo, we will show the same visualization as in the previous exercise, but you will be able to vary the noise level <code class="docutils literal notranslate"><span class="pre">sigma</span></code> of the observation distributions. First think and discuss,</p>
<ol class="simple">
<li><p>What do you expect low levels of noise to do to the accuracy vs stop time plot?</p></li>
<li><p>What do you expect high levels of noise to do to the accuracy vs stop time plot?</p></li>
</ol>
<p>Play with the demo and see if you were correct or not.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>
<span class="k">def</span> <span class="nf">simulate_accuracy_vs_stoptime</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">stop_time_list</span><span class="p">,</span> <span class="n">num_sample</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Calculate the average decision accuracy vs. stopping time by running</span>
<span class="sd">  repeated SPRT simulations for each stop time.</span>

<span class="sd">  Args:</span>
<span class="sd">      sigma (float): standard deviation for observation model</span>
<span class="sd">      stop_list_list (list-like object): a list of stopping times to run over</span>
<span class="sd">      num_sample (int): number of simulations to run per stopping time</span>

<span class="sd">  Returns:</span>
<span class="sd">      accuracy_list: a list of average accuracies corresponding to input</span>
<span class="sd">                      `stop_time_list`</span>
<span class="sd">      decisions_list: a list of decisions made in all trials</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1"># Determine true state (1 or -1)</span>
  <span class="n">true_dist</span> <span class="o">=</span> <span class="mi">1</span>

  <span class="c1"># Set up tracker of accuracy and decisions</span>
  <span class="n">accuracies</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stop_time_list</span><span class="p">),)</span>
  <span class="n">decisions_list</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="c1"># Loop over stop times</span>
  <span class="k">for</span> <span class="n">i_stop_time</span><span class="p">,</span> <span class="n">stop_time</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">stop_time_list</span><span class="p">):</span>

    <span class="c1"># Set up tracker of decisions for this stop time (hint: last exercise)</span>
    <span class="n">decisions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_sample</span><span class="p">,))</span>

    <span class="c1"># Loop over samples</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_sample</span><span class="p">):</span>

      <span class="c1"># Simulate run for this stop time</span>
      <span class="n">_</span><span class="p">,</span> <span class="n">decision</span><span class="p">,</span> <span class="n">_</span><span class="o">=</span> <span class="n">simulate_SPRT_fixedtime</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">stop_time</span><span class="p">,</span> <span class="n">true_dist</span><span class="p">)</span>

      <span class="c1"># Log decision</span>
      <span class="n">decisions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">decision</span>

    <span class="c1"># Calculate accuracy</span>
    <span class="n">accuracies</span><span class="p">[</span><span class="n">i_stop_time</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">decisions</span> <span class="o">==</span> <span class="n">true_dist</span><span class="p">)</span> <span class="o">/</span> <span class="n">decisions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Log decisions</span>
    <span class="n">decisions_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decisions</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">accuracies</span><span class="p">,</span> <span class="n">decisions_list</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">num_sample</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">stop_time_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span>
<span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="n">sigma</span><span class="o">=</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)):</span>
 <span class="c1"># Calculate accuracies for each stop time</span>
  <span class="n">accuracies</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">simulate_accuracy_vs_stoptime</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">stop_time_list</span><span class="p">,</span>                                             <span class="n">num_sample</span><span class="p">)</span>

  <span class="c1"># Visualize</span>
  <span class="n">plot_accuracy_vs_stoptime</span><span class="p">(</span><span class="n">stop_time_list</span><span class="p">,</span> <span class="n">accuracies</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D2_HiddenDynamics/solutions/W3D2_Tutorial1_Solution_a956a168.py"><em>Click for solution</em></a></p>
<p>Please see Bonus Section 1 to learn about and work with a different stopping rule for DDMs: a fixed threshold on confidence.</p>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p>Good job! By simulating Drift Diffusion Models to perform decision making, you have learnt how to</p>
<ol class="simple">
<li><p>Calculate individual sample evidence as the log likelihood ratio of two candidate models, accumulate evidence from new data points, and make decision based on current evidence in <code class="docutils literal notranslate"><span class="pre">Exercise</span> <span class="pre">1</span></code></p></li>
<li><p>Run repeated simulations to get an estimate of decision accuraries in <code class="docutils literal notranslate"><span class="pre">Exercise</span> <span class="pre">2</span></code></p></li>
<li><p>Implement the thresholding stopping rule where we can control our error rate by taking adequate amounts of data, and calculate the evidence threshold from desired error rate in <code class="docutils literal notranslate"><span class="pre">Exercise</span> <span class="pre">3</span></code></p></li>
<li><p>Explore and gain intuition about the speed/accuracy tradeoff for perceptual decision making in <code class="docutils literal notranslate"><span class="pre">Exercise</span> <span class="pre">4</span></code></p></li>
</ol>
</div>
<hr class="docutils" />
<div class="section" id="bonus">
<h1>Bonus<a class="headerlink" href="#bonus" title="Permalink to this headline">¶</a></h1>
<div class="section" id="bonus-section-1-ddm-with-fixed-thresholds-on-confidence">
<h2>Bonus Section 1: DDM with fixed thresholds on confidence<a class="headerlink" href="#bonus-section-1-ddm-with-fixed-thresholds-on-confidence" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 6: Fixed threshold on confidence</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;E8lvgFeIGQM&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>The next exercises consider a variant of the DDM with fixed confidence thresholds instead of fixed decision time. This may be a better description of neural integration. Please complete this material after you have finished the main content of all tutorials, if you would like extra information about this topic.</p>
<div class="section" id="exercise-3-simulating-the-ddm-with-fixed-thresholds">
<h3>Exercise 3: Simulating the DDM with fixed thresholds<a class="headerlink" href="#exercise-3-simulating-the-ddm-with-fixed-thresholds" title="Permalink to this headline">¶</a></h3>
<p>In this exercise, we will use thresholding as our stopping rule and observe the behavior of the DDM.</p>
<p>With thresholding stopping rule, we define a desired error rate and will continue making measurements until that error rate is reached. Experimental evidence suggested that evidence accumulation and thresholding stopping strategy happens at neuronal level (see <a class="reference external" href="https://www.annualreviews.org/doi/full/10.1146/annurev.neuro.29.051605.113038">this article</a> for further reading).</p>
<ul class="simple">
<li><p>Complete the function <code class="docutils literal notranslate"><span class="pre">threshold_from_errorrate</span></code> to calculate the evidence threshold from desired error rate <span class="math notranslate nohighlight">\(\alpha\)</span> as described in the formulas below. The evidence thresholds <span class="math notranslate nohighlight">\(th_1\)</span> and <span class="math notranslate nohighlight">\(th_0\)</span> for <span class="math notranslate nohighlight">\(p_+\)</span> and <span class="math notranslate nohighlight">\(p_-\)</span> are opposite of each other as shown below, so you can just return the absolute value.
$$</p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-3a2d0f8e-99ee-4d01-acf0-68d1dab9250a">
<span class="eqno">(172)<a class="headerlink" href="#equation-3a2d0f8e-99ee-4d01-acf0-68d1dab9250a" title="Permalink to this equation">¶</a></span>\[\begin{align}
 th_{L} &amp;= \log \frac{\alpha}{1-\alpha} &amp;= -th_{R} \\
 th_{R} &amp;= \log \frac{1-\alpha}{\alpha} &amp;= -th{_1}\\
 \end{align}\]</div>
<p>$$</p>
<ul class="simple">
<li><p>Complete the function <code class="docutils literal notranslate"><span class="pre">simulate_SPRT_threshold</span></code> to simulate an SPRT with thresholding stopping rule given noise level and desired threshold</p></li>
<li><p>Run repeated simulations for a given noise level and a desired error rate visualize the DDM traces using our provided code</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simulate_SPRT_threshold</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">threshold</span> <span class="p">,</span> <span class="n">true_dist</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Simulate a Sequential Probability Ratio Test with thresholding stopping</span>
<span class="sd">  rule. Two observation models are 1D Gaussian distributions N(1,sigma^2) and</span>
<span class="sd">  N(-1,sigma^2).</span>

<span class="sd">  Args:</span>
<span class="sd">    sigma (float): Standard deviation</span>
<span class="sd">    threshold (float): Desired log likelihood ratio threshold to achieve</span>
<span class="sd">                        before making decision</span>

<span class="sd">  Returns:</span>
<span class="sd">    evidence_history (numpy vector): the history of cumulated evidence given</span>
<span class="sd">                                      generated data</span>
<span class="sd">    decision (int): 1 for pR, 0 for pL</span>
<span class="sd">    data (numpy vector): the generated sequences of data in this trial</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">muL</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
  <span class="n">muR</span> <span class="o">=</span> <span class="mf">1.0</span>

  <span class="n">pL</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">muL</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
  <span class="n">pR</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">muR</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>

  <span class="n">has_enough_data</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="n">data_history</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">evidence_history</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">current_evidence</span> <span class="o">=</span> <span class="mf">0.0</span>

  <span class="c1"># Keep sampling data until threshold is crossed</span>
  <span class="k">while</span> <span class="ow">not</span> <span class="n">has_enough_data</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">true_dist</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">Mvec</span> <span class="o">=</span> <span class="n">pR</span><span class="o">.</span><span class="n">rvs</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">Mvec</span> <span class="o">=</span> <span class="n">pL</span><span class="o">.</span><span class="n">rvs</span><span class="p">()</span>

    <span class="c1">########################################################################</span>
    <span class="c1"># Insert your code here to:</span>
    <span class="c1">#      * Calculate the log-likelihood ratio for the new sample</span>
    <span class="c1">#      * Update the accumulated evidence</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;`simulate_SPRT_threshold` is incomplete&quot;</span><span class="p">)</span>
    <span class="c1">########################################################################</span>
    <span class="c1"># individual log likelihood ratios</span>
    <span class="n">ll_ratio</span> <span class="o">=</span> <span class="n">log_likelihood_ratio</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="c1"># cumulated evidence for this chunk</span>
    <span class="n">evidence_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="c1"># update the collection of all data</span>
    <span class="n">data_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Mvec</span><span class="p">)</span>
    <span class="n">current_evidence</span> <span class="o">=</span> <span class="n">evidence_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># check if we&#39;ve got enough data</span>
    <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">current_evidence</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">:</span>
      <span class="n">has_enough_data</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="n">data_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data_history</span><span class="p">)</span>
  <span class="n">evidence_history</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">evidence_history</span><span class="p">)</span>

  <span class="c1"># Make decision</span>
  <span class="k">if</span> <span class="n">evidence_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">decision</span> <span class="o">=</span> <span class="mi">1</span>
  <span class="k">elif</span> <span class="n">evidence_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">decision</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">decision</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">evidence_history</span><span class="p">,</span> <span class="n">decision</span><span class="p">,</span> <span class="n">data_history</span>


<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">2.8</span>
<span class="n">num_sample</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">log10_alpha</span> <span class="o">=</span> <span class="o">-</span><span class="mf">6.5</span> <span class="c1"># log10(alpha)</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">log10_alpha</span><span class="p">)</span>

<span class="c1">################################################################################</span>
<span class="c1"># Un-comment the following code after completing this exercise</span>
<span class="c1">################################################################################</span>
<span class="c1"># simulate_and_plot_SPRT_fixedthreshold(sigma, num_sample, alpha)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D2_HiddenDynamics/solutions/W3D2_Tutorial1_Solution_f93723a3.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=560 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D2_HiddenDynamics/static/W3D2_Tutorial1_Solution_f93723a3_2.png>
</div>
<div class="section" id="interactive-demo-ddm-with-fixed-threshold">
<h3>Interactive Demo: DDM with fixed threshold<a class="headerlink" href="#interactive-demo-ddm-with-fixed-threshold" title="Permalink to this headline">¶</a></h3>
<p><strong>Suggestion</strong></p>
<ul class="simple">
<li><p>Play with difference values of <code class="docutils literal notranslate"><span class="pre">alpha</span></code> and <code class="docutils literal notranslate"><span class="pre">sigma</span></code> and observe how that affects the dynamics of Drift-Diffusion Model.</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title</span>

<span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">num_sample</span> <span class="o">=</span> <span class="mi">10</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span>
<span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="n">sigma</span><span class="o">=</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">),</span> <span class="n">log10_alpha</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">.1</span><span class="p">)):</span>
  <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">log10_alpha</span><span class="p">)</span>
  <span class="n">simulate_and_plot_SPRT_fixedthreshold</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">num_sample</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="exercise-4-speed-accuracy-tradeoff-revisited">
<h3>Exercise 4: Speed/Accuracy Tradeoff Revisited<a class="headerlink" href="#exercise-4-speed-accuracy-tradeoff-revisited" title="Permalink to this headline">¶</a></h3>
<p>The faster you make a decision, the lower your accuracy often is. This phenomenon is known as the <strong>speed/accuracy tradeoff</strong>. Humans can make this tradeoff in a wide range of situations, and many animal species, including ants, bees, rodents, and monkeys also show similar effects.</p>
<p>To illustrate the speed/accuracy tradeoff under thresholding stopping rule, let’s run some simulations under different thresholds and look at how average decision “speed” (1/length) changes with average decision accuracy. We use speed rather than accuracy because in real experiments, subjects can be incentivized to respond faster or slower; it’s much harder to precisely control their decision time or error threshold.</p>
<ul class="simple">
<li><p>Complete the function <code class="docutils literal notranslate"><span class="pre">simulate_accuracy_vs_threshold</span></code> to simulate and compute average accuracies vs. average decision lengths for a list of error thresholds. You will need to supply code to calculate average decision ‘speed’ from the lengths of trials. You should also calculate the overall accuracy across these trials.</p></li>
<li><p>We’ve set up a list of error thresholds. Run repeated simulations and collect average accuracy with average length for each error rate in this list, and use our provided code to visualize the speed/accuracy tradeoff. You should see a positive correlation between length and accuracy.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simulate_accuracy_vs_threshold</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">threshold_list</span><span class="p">,</span> <span class="n">num_sample</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Calculate the average decision accuracy vs. average decision length by</span>
<span class="sd">  running repeated SPRT simulations with thresholding stopping rule for each</span>
<span class="sd">  threshold.</span>

<span class="sd">  Args:</span>
<span class="sd">      sigma (float): standard deviation for observation model</span>
<span class="sd">      threshold_list (list-like object): a list of evidence thresholds to run</span>
<span class="sd">                                          over</span>
<span class="sd">      num_sample (int): number of simulations to run per stopping time</span>

<span class="sd">  Returns:</span>
<span class="sd">      accuracy_list: a list of average accuracies corresponding to input</span>
<span class="sd">                      `threshold_list`</span>
<span class="sd">      decision_speed_list: a list of average decision speeds</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">decision_speed_list</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">accuracy_list</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">threshold_list</span><span class="p">:</span>
    <span class="n">decision_time_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">decision_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_sample</span><span class="p">):</span>
      <span class="c1"># run simulation and get decision of current simulation</span>
      <span class="n">_</span><span class="p">,</span> <span class="n">decision</span><span class="p">,</span> <span class="n">Mvec</span> <span class="o">=</span> <span class="n">simulate_SPRT_threshold</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span>
      <span class="n">decision_time</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Mvec</span><span class="p">)</span>
      <span class="n">decision_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decision</span><span class="p">)</span>
      <span class="n">decision_time_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decision_time</span><span class="p">)</span>

    <span class="c1">########################################################################</span>
    <span class="c1"># Insert your code here to:</span>
    <span class="c1">#      * Calculate mean decision speed given a list of decision times</span>
    <span class="c1">#      * Hint: Think about speed as being inversely proportional</span>
    <span class="c1">#        to decision_length. If it takes 10 seconds to make one decision,</span>
    <span class="c1">#        our &quot;decision speed&quot; is 0.1 decisions per second.</span>
    <span class="c1">#      * Calculate the decision accuracy</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;`simulate_accuracy_vs_threshold` is incomplete&quot;</span><span class="p">)</span>
    <span class="c1">########################################################################</span>
    <span class="c1"># Calculate and store average decision speed and accuracy</span>
    <span class="n">decision_speed</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">decision_accuracy</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">decision_speed_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decision_speed</span><span class="p">)</span>
    <span class="n">accuracy_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decision_accuracy</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">accuracy_list</span><span class="p">,</span> <span class="n">decision_speed_list</span>


<span class="c1">################################################################################</span>
<span class="c1"># Un-comment the following code block after completing this exercise</span>
<span class="c1">################################################################################</span>
<span class="c1"># np.random.seed(100)</span>
<span class="c1"># sigma = 3.75</span>
<span class="c1"># num_sample = 200</span>
<span class="c1"># alpha_list = np.logspace(-2, -0.1, 8)</span>
<span class="c1"># threshold_list = threshold_from_errorrate(alpha_list)</span>
<span class="c1"># simulate_and_plot_accuracy_vs_threshold(sigma, threshold_list, num_sample)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D2_HiddenDynamics/solutions/W3D2_Tutorial1_Solution_656ae75a.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=560 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D2_HiddenDynamics/static/W3D2_Tutorial1_Solution_656ae75a_0.png>
</div>
<div class="section" id="interactive-demo-speed-accuracy-with-a-threshold-rule">
<h3>Interactive Demo: Speed/Accuracy with a threshold rule<a class="headerlink" href="#interactive-demo-speed-accuracy-with-a-threshold-rule" title="Permalink to this headline">¶</a></h3>
<p><strong>Suggestions</strong></p>
<ul class="simple">
<li><p>Play with difference values of  noise level <code class="docutils literal notranslate"><span class="pre">sigma</span></code> and observe how that affects the speed/accuracy tradeoff.</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title</span>

<span class="c1">#@markdown Make sure you execute this cell to enable the widget!</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">num_sample</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">alpha_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">threshold_list</span> <span class="o">=</span> <span class="n">threshold_from_errorrate</span><span class="p">(</span><span class="n">alpha_list</span><span class="p">)</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span>
<span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="n">sigma</span><span class="o">=</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)):</span>
  <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">log10_alpha</span><span class="p">)</span>
  <span class="n">simulate_and_plot_accuracy_vs_threshold</span><span class="p">(</span><span class="n">sigma</span><span class="p">,</span> <span class="n">threshold_list</span><span class="p">,</span> <span class="n">num_sample</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W3D2_HiddenDynamics/student"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../W3D2_Intro.html" title="previous page">Intro</a>
    <a class='right-next' id="next-link" href="W3D2_Tutorial2.html" title="next page">Tutorial 2: Hidden Markov Model</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Neuromatch<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>