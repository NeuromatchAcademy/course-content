{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/master/tutorials/W0D5_Statistics/student/W0D5_Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Probability Distributions\n",
    "**Week 0, Day 5: Probability & Statistics**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ Ulrik Beierholm\n",
    "\n",
    "__Content reviewers:__ Natalie Schaworonkow, Keith van Antwerp, Anoop Kulkarni, Pooya Pakarian, Hyosub Kim\n",
    "\n",
    "__Production editors:__ Ethan Cheng, Ella Batty \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n",
    "\n",
    "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tutorial Objectives\n",
    "\n",
    "We will cover the basic ideas from probability and statistics, as a reminder of what you have hopefully previously learned. These ideas will be important for almost every one of the following topics covered in the course. \n",
    "\n",
    "There are many additional topics within probability and statistics that we will not cover as they are not central to the main course. We also do not have time to get into a lot of details, but this should help you recall material you have previously encountered.\n",
    "\n",
    "\n",
    "By completing the exercises in this tutorial, you should:\n",
    "* get some intuition about how stochastic randomly generated data can be\n",
    "* understand how to model data using simple probability distributions\n",
    "* understand the difference between discrete and continuous probability distributions\n",
    "* be able to plot a Gaussian distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:29.002774Z",
     "iopub.status.busy": "2021-07-02T11:23:29.002190Z",
     "iopub.status.idle": "2021-07-02T11:23:29.933616Z",
     "shell.execute_reply": "2021-07-02T11:23:29.932974Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy.stats import norm  # the normal probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:29.940391Z",
     "iopub.status.busy": "2021-07-02T11:23:29.938712Z",
     "iopub.status.idle": "2021-07-02T11:23:30.015541Z",
     "shell.execute_reply": "2021-07-02T11:23:30.015040Z"
    }
   },
   "outputs": [],
   "source": [
    "#@title Figure settings\n",
    "import ipywidgets as widgets    # interactive display\n",
    "from ipywidgets import interact, fixed, HBox, Layout, VBox, interactive, Label, interact_manual\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")\n",
    "#plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/NMA2020/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:30.031188Z",
     "iopub.status.busy": "2021-07-02T11:23:30.029936Z",
     "iopub.status.idle": "2021-07-02T11:23:30.031731Z",
     "shell.execute_reply": "2021-07-02T11:23:30.032118Z"
    }
   },
   "outputs": [],
   "source": [
    "#@title Plotting Functions\n",
    "\n",
    "def plot_random_sample(x, y, figtitle = None):\n",
    "  \"\"\" Plot the random sample between 0 and 1 for both the x and y axes.\n",
    "\n",
    "    Args:\n",
    "      x (ndarray): array of x coordinate values across the random sample\n",
    "      y (ndarray): array of y coordinate values across the random sample\n",
    "      figtitle (str): title of histogram plot (default is no title)\n",
    "\n",
    "    Returns:\n",
    "      Nothing.\n",
    "  \"\"\"\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_xlabel('x')\n",
    "  ax.set_ylabel('y')\n",
    "  plt.xlim([-0.25, 1.25]) # set x and y axis range to be a bit less than 0 and greater than 1\n",
    "  plt.ylim([-0.25, 1.25])\n",
    "  plt.scatter(dataX, dataY)\n",
    "  if figtitle is not None:\n",
    "    fig.suptitle(figtitle, size=16)\n",
    "  plt.show()\n",
    "\n",
    "def plot_random_walk(x, y, figtitle = None):\n",
    "  \"\"\" Plots the random walk within the range 0 to 1 for both the x and y axes.\n",
    "\n",
    "    Args:\n",
    "      x (ndarray): array of steps in x direction\n",
    "      y (ndarray): array of steps in y direction\n",
    "      figtitle (str): title of histogram plot (default is no title)\n",
    "\n",
    "    Returns:\n",
    "      Nothing.\n",
    "  \"\"\"\n",
    "  fig, ax = plt.subplots()\n",
    "  plt.plot(x,y,'b-o', alpha = 0.5)\n",
    "  plt.xlim(-0.1,1.1)\n",
    "  plt.ylim(-0.1,1.1)\n",
    "  ax.set_xlabel('x location')\n",
    "  ax.set_ylabel('y location')\n",
    "  plt.plot(x[0], y[0], 'go')\n",
    "  plt.plot(x[-1], y[-1], 'ro')\n",
    "\n",
    "  if figtitle is not None:\n",
    "    fig.suptitle(figtitle, size=16)\n",
    "  plt.show()\n",
    "\n",
    "def plot_hist(data, xlabel, figtitle = None, num_bins = None):\n",
    "  \"\"\" Plot the given data as a histogram.\n",
    "\n",
    "    Args:\n",
    "      data (ndarray): array with data to plot as histogram\n",
    "      xlabel (str): label of x-axis\n",
    "      figtitle (str): title of histogram plot (default is no title)\n",
    "      num_bins (int): number of bins for histogram (default is 10)\n",
    "\n",
    "    Returns:\n",
    "      count (ndarray): number of samples in each histogram bin\n",
    "      bins (ndarray): center of each histogram bin\n",
    "  \"\"\"\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_xlabel(xlabel)\n",
    "  ax.set_ylabel('Count')\n",
    "  if num_bins is not None:\n",
    "    count, bins, _ = plt.hist(data, bins = num_bins)\n",
    "  else:\n",
    "    count, bins, _ = plt.hist(data, bins = np.arange(np.min(data)-.5, np.max(data)+.6)) # 10 bins default\n",
    "  if figtitle is not None:\n",
    "    fig.suptitle(figtitle, size=16)\n",
    "  plt.show()\n",
    "  return count, bins\n",
    "\n",
    "def my_plot_single(x, px):\n",
    "  \"\"\"\n",
    "  Plots normalized Gaussian distribution\n",
    "\n",
    "    Args:\n",
    "        x (numpy array of floats):     points at which the likelihood has been evaluated\n",
    "        px (numpy array of floats):    normalized probabilities for prior evaluated at each `x`\n",
    "\n",
    "    Returns:\n",
    "        Nothing.\n",
    "  \"\"\"\n",
    "  if px is None:\n",
    "      px = np.zeros_like(x)\n",
    "\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.plot(x, px, '-', color='C2', LineWidth=2, label='Prior')\n",
    "  ax.legend()\n",
    "  ax.set_ylabel('Probability')\n",
    "  ax.set_xlabel('Orientation (Degrees)')\n",
    "\n",
    "def plot_gaussian_samples_true(samples, xspace, mu, sigma, xlabel, ylabel):\n",
    "  \"\"\" Plot a histogram of the data samples on the same plot as the gaussian\n",
    "  distribution specified by the give mu and sigma values.\n",
    "\n",
    "    Args:\n",
    "      samples (ndarray): data samples for gaussian distribution\n",
    "      xspace (ndarray): x values to sample from normal distribution\n",
    "      mu (scalar): mean parameter of normal distribution\n",
    "      sigma (scalar): variance parameter of normal distribution\n",
    "      xlabel (str): the label of the x-axis of the histogram\n",
    "      ylabel (str): the label of the y-axis of the histogram\n",
    "\n",
    "    Returns:\n",
    "      Nothing.\n",
    "  \"\"\"\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_xlabel(xlabel)\n",
    "  ax.set_ylabel(ylabel)\n",
    "  # num_samples = samples.shape[0]\n",
    "\n",
    "  count, bins, _ = plt.hist(samples, density=True)\n",
    "  plt.plot(xspace, norm.pdf(xspace, mu, sigma),'r-')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 1: Stochasticity and randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.1: Intro to Randomness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:30.042852Z",
     "iopub.status.busy": "2021-07-02T11:23:30.039370Z",
     "iopub.status.idle": "2021-07-02T11:23:30.108583Z",
     "shell.execute_reply": "2021-07-02T11:23:30.109313Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title Video 1: Stochastic World\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "      def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "          self.id=id\n",
    "          src = 'https://player.bilibili.com/player.html?bvid={0}&page={1}'.format(id, page)\n",
    "          super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=\"BV1sU4y1G7Qt\", width=854, height=480, fs=1)\n",
    "  print('Video available at https://www.bilibili.com/video/{0}'.format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=\"-QwTPDp7-a8\", width=854, height=480, fs=1, rel=0)\n",
    "  print('Video available at https://youtube.com/watch?v=' + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Before trying out different probability distributions, let's start with the simple uniform distribution, U(a,b), which assigns equal probability to any value between a and b.\n",
    "\n",
    "To show that we are drawing a random number $x$ from a uniform distribution with lower and upper bounds $a$ and $b$ we will use this notation:\n",
    "$x \\sim U(a,b)$. Alternatively, we can say that all the potential values of $x$ are distributed as a uniform distribution between $a$ and $b$. $x$ here is a random variable: a variable whose value depends on the outcome of a random process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Exercise 1.1: Create randomness\n",
    "\n",
    "Numpy has many functions and capabilities related to randomness.  We can draw random numbers from various probability distributions. For example, to draw 5 uniform numbers between 0 and 100, you would use `np.random.uniform(0, 100, size = (5,))`. \n",
    "\n",
    " We will use `np.random.seed` to set a specific seed for the random number generator. For example, `np.random.seed(0)` sets the seed as 0. By including this, we are actually making the random numbers reproducible, which may seem odd at first. Basically if we do the below code without that 0, we would get different random numbers every time we run it. By setting the seed to 0, we ensure we will get the same random numbers. There are lots of reasons we may want randomness to be reproducible. In NMA-world, it's so your plots will match the solution plots exactly! \n",
    "\n",
    "```\n",
    "np.random.seed(0)\n",
    "random_nums = np.random.uniform(0, 100, size = (5,))\n",
    "```\n",
    "\n",
    "Below, you will complete a function `generate_random_sample` that randomly generates `num_points` $x$ and $y$ coordinate values, all within the range 0 to 1. You will then generate 10 points and visualize.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:30.120533Z",
     "iopub.status.busy": "2021-07-02T11:23:30.120005Z",
     "iopub.status.idle": "2021-07-02T11:23:30.212596Z",
     "shell.execute_reply": "2021-07-02T11:23:30.212062Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_random_sample(num_points):\n",
    "  \"\"\" Generate a random sample containing a desired number of points (num_points)\n",
    "  in the range [0, 1] using a random number generator object.\n",
    "\n",
    "  Args:\n",
    "    num_points (int): number of points desired in random sample\n",
    "\n",
    "  Returns:\n",
    "    dataX, dataY (ndarray, ndarray): arrays of size (num_points,) containing x\n",
    "    and y coordinates of sampled points\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  ###################################################################\n",
    "  ## TODO for students: Draw the uniform numbers\n",
    "  ## Fill out the following then remove\n",
    "  raise NotImplementedError(\"Student exercise: need to complete generate_random_sample\")\n",
    "  ###################################################################\n",
    "\n",
    "  # Generate desired number of points uniformly between 0 and 1 (using uniform) for\n",
    "  #     both x and y\n",
    "  dataX = ...\n",
    "  dataY = ...\n",
    "\n",
    "  return dataX, dataY\n",
    "\n",
    "# Set a seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set number of points to draw\n",
    "num_points = 10\n",
    "\n",
    "# Draw random points\n",
    "dataX, dataY = generate_random_sample(num_points)\n",
    "\n",
    "# Visualize\n",
    "plot_random_sample(dataX, dataY, \"Random sample of 10 points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:30.218729Z",
     "iopub.status.busy": "2021-07-02T11:23:30.218227Z",
     "iopub.status.idle": "2021-07-02T11:23:30.501496Z",
     "shell.execute_reply": "2021-07-02T11:23:30.501041Z"
    }
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_0e972635.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=1120.0 height=845.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W0D5_Statistics/static/W0D5_Tutorial1_Solution_0e972635_0.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Demo 1.1: Random Sample Generation from Uniform Distribution\n",
    "In practice this may not look very uniform, although that is of course part of the randomness! Uniform randomness does not mean smoothly uniform. When we have very little data it can be hard to see the distribution.\n",
    "\n",
    "Below, you can adjust the number of points sampled with a slider. Does it look more uniform now? Try increasingly large numbers of sampled points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:30.509457Z",
     "iopub.status.busy": "2021-07-02T11:23:30.508974Z",
     "iopub.status.idle": "2021-07-02T11:23:30.799779Z",
     "shell.execute_reply": "2021-07-02T11:23:30.800286Z"
    }
   },
   "outputs": [],
   "source": [
    "#@markdown Make sure you execute this cell to enable the widget!\n",
    "\n",
    "def generate_random_sample(num_points):\n",
    "  \"\"\" Generate a random sample containing a desired number of points (num_points)\n",
    "  in the range [0, 1] using a random number generator object.\n",
    "\n",
    "  Args:\n",
    "    num_points (int): number of points desired in random sample\n",
    "\n",
    "  Returns:\n",
    "    dataX, dataY (ndarray, ndarray): arrays of size (num_points,) containing x\n",
    "    and y coordinates of sampled points\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  # Generate desired number of points uniformly between 0 and 1 (using uniform) for\n",
    "  #     both x and y\n",
    "  dataX = np.random.uniform(0, 1, size = (num_points,))\n",
    "  dataY = np.random.uniform(0, 1, size = (num_points,))\n",
    "\n",
    "  return dataX, dataY\n",
    "\n",
    "@widgets.interact\n",
    "def gen_and_plot_random_sample(num_points = widgets.SelectionSlider(options=[(\"%g\"%i,i) for i in np.arange(0, 500, 10)])):\n",
    "\n",
    "  dataX, dataY = generate_random_sample(num_points)\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.set_xlabel('x')\n",
    "  ax.set_ylabel('y')\n",
    "  plt.xlim([-0.25, 1.25])\n",
    "  plt.ylim([-0.25, 1.25])\n",
    "  plt.scatter(dataX, dataY)\n",
    "  fig.suptitle(\"Random sample of \" + str(num_points) + \" points\", size=16)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.2: Random walk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:30.811634Z",
     "iopub.status.busy": "2021-07-02T11:23:30.810276Z",
     "iopub.status.idle": "2021-07-02T11:23:30.861948Z",
     "shell.execute_reply": "2021-07-02T11:23:30.861546Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title Video 2: Random walk\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "      def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "          self.id=id\n",
    "          src = 'https://player.bilibili.com/player.html?bvid={0}&page={1}'.format(id, page)\n",
    "          super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=\"BV11U4y1G7Bu\", width=854, height=480, fs=1)\n",
    "  print('Video available at https://www.bilibili.com/video/{0}'.format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=\"Tz9gjHcqj5k\", width=854, height=480, fs=1, rel=0)\n",
    "  print('Video available at https://youtube.com/watch?v=' + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic models can be used to create models of behaviour. As an example, imagine that a rat is placed inside a novel environment, a box. We could try and model its exploration behaviour by assuming that for each time step it takes a random uniformly sampled step in any direction (simultaneous random step in x direction and random step in y direction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Exercise 1.2: Modeling a random walk\n",
    "\n",
    "\n",
    "Use the `generate_random_sample` function from above to obtain the random steps the rat takes at each time step and complete the generate_random_walk function below. For plotting, the box will be represented graphically as the unit square enclosed by the points (0, 0) and (1, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:30.877684Z",
     "iopub.status.busy": "2021-07-02T11:23:30.877188Z",
     "iopub.status.idle": "2021-07-02T11:23:30.885893Z",
     "shell.execute_reply": "2021-07-02T11:23:30.885386Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_random_walk(num_steps, step_size):\n",
    "  \"\"\" Generate the points of a random walk within a 1 X 1 box.\n",
    "\n",
    "  Args:\n",
    "    num_steps (int): number of steps in the random walk\n",
    "    step_size (float): how much each random step size is weighted\n",
    "\n",
    "  Returns:\n",
    "    x, y (ndarray, ndarray): the (x, y) locations reached at each time step of the walk\n",
    "\n",
    "  \"\"\"\n",
    "  x = np.zeros(num_steps + 1)\n",
    "  y = np.zeros(num_steps + 1)\n",
    "\n",
    "  ###################################################################\n",
    "  ## TODO for students: Collect random step values with function from before\n",
    "  ## Fill out the following then remove\n",
    "  raise NotImplementedError(\"Student exercise: need to complete generate_random_walk\")\n",
    "  ###################################################################\n",
    "\n",
    "  # Generate the uniformly random x, y steps for the walk\n",
    "  random_x_steps, random_y_steps = ...\n",
    "\n",
    "  # Take steps according to the randomly sampled steps above\n",
    "  for step in range(num_steps):\n",
    "\n",
    "    # take a random step in x and y. We remove 0.5 to make it centered around 0\n",
    "    x[step + 1] = x[step] + (random_x_steps[step] - 0.5)*step_size\n",
    "    y[step + 1] = y[step] + (random_y_steps[step] - 0.5)*step_size\n",
    "\n",
    "    # restrict to be within the 1 x 1 unit box\n",
    "    x[step + 1]= min(max(x[step + 1], 0), 1)\n",
    "    y[step + 1]= min(max(y[step + 1], 0), 1)\n",
    "\n",
    "  return x, y\n",
    "\n",
    "# Set a random seed\n",
    "np.random.seed(2)\n",
    "\n",
    "# Select parameters\n",
    "num_steps = 100   # number of steps in random walk\n",
    "step_size = 0.5   # size of each step\n",
    "\n",
    "# Generate the random walk\n",
    "x, y = generate_random_walk(num_steps, step_size)\n",
    "\n",
    "# Visualize\n",
    "plot_random_walk(x, y, \"Rat's location throughout random walk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:30.924075Z",
     "iopub.status.busy": "2021-07-02T11:23:30.905857Z",
     "iopub.status.idle": "2021-07-02T11:23:31.197857Z",
     "shell.execute_reply": "2021-07-02T11:23:31.197428Z"
    }
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_84dec82b.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=1120.0 height=845.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W0D5_Statistics/static/W0D5_Tutorial1_Solution_84dec82b_0.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put a little green dot for the starting point and a red point for the ending point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Demo 1.2: Varying parameters of a random walk\n",
    "In the interactive demo below, you can examine random walks with different numbers of steps or step sizes, using the sliders. \n",
    "\n",
    "\n",
    "1.  What could an increased step size mean for the actual rat's movement we are simulating?\n",
    "2. For a given number of steps, is the rat more likely to visit all general areas of the arena with a big step size or small step size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:31.224556Z",
     "iopub.status.busy": "2021-07-02T11:23:31.223935Z",
     "iopub.status.idle": "2021-07-02T11:23:31.446015Z",
     "shell.execute_reply": "2021-07-02T11:23:31.444479Z"
    }
   },
   "outputs": [],
   "source": [
    "# @markdown Make sure you execute this cell to enable the widget!\n",
    "\n",
    "@widgets.interact(num_steps = widgets.IntSlider(value=100, min=0, max=500, step=1), step_size = widgets.FloatSlider(value=0.1, min=0.1, max=1, step=0.1))\n",
    "def gen_and_plot_random_walk(num_steps, step_size):\n",
    "  x, y = generate_random_walk(num_steps, step_size)\n",
    "  plot_random_walk(x, y, \"Rat's location throughout random walk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:31.450614Z",
     "iopub.status.busy": "2021-07-02T11:23:31.450037Z",
     "iopub.status.idle": "2021-07-02T11:23:31.452194Z",
     "shell.execute_reply": "2021-07-02T11:23:31.452612Z"
    }
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_6e912c89.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice a uniform random movement is too simple an assumption. Rats do not move completely randomly; even if you could assume that, you would need to approximate with a more complex probability distribution.\n",
    "\n",
    "Nevertheless, this example highlights how you can use sampling to approximate behaviour. \n",
    "\n",
    "**Main course preview:** On day W3D2 we will see how random walk models can be used to also model accumulation of information in decision making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 2: Discrete distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1: Binomial distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:31.463003Z",
     "iopub.status.busy": "2021-07-02T11:23:31.459841Z",
     "iopub.status.idle": "2021-07-02T11:23:31.514732Z",
     "shell.execute_reply": "2021-07-02T11:23:31.511421Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title Video 3: Binomial distribution\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "      def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "          self.id=id\n",
    "          src = 'https://player.bilibili.com/player.html?bvid={0}&page={1}'.format(id, page)\n",
    "          super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=\"BV1Ev411W7mw\", width=854, height=480, fs=1)\n",
    "  print('Video available at https://www.bilibili.com/video/{0}'.format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=\"kOXEQlmzFyw\", width=854, height=480, fs=1, rel=0)\n",
    "  print('Video available at https://youtube.com/watch?v=' + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This video covers the Bernoulli and binomial distributions.\n",
    "\n",
    "<details>\n",
    "<summary> <font color='blue'>Click here for text recap of video </font></summary>\n",
    "\n",
    "The uniform distribution is very simple, and can only be used in some rare cases. If we only had access to this distribution, our statistical toolbox would be very empty. Thankfully we do have some more advanced distributions!\n",
    "\n",
    "The uniform distribution that we looked at above is an example of a continuous distribution. The value of $X$ that we draw from this distribution can take **any value** between $a$ and $b$.\n",
    "\n",
    "However, sometimes we want to be able to look at discrete events. Imagine that the rat from before is now placed in a T-maze, with food placed at the end of both arms. Initially, we would expect the rat to be choosing randomly between the two arms, but after learning it should choose more consistently.\n",
    "\n",
    "A simple way to model such random behaviour is with a single **Bernoulli trial**, that has two outcomes, {$Left, Right$}, with probability $P(Left)=p$ and $P(Right)=1-p$ as the two mutually exclusive possibilities (whether the rat goes down the left or right arm of the maze).\n",
    "</details>\n",
    "\n",
    "The binomial distribution simulates $n$ number of binary events, such as the $Left, Right$ choices of the random rat in the T-maze. Imagine that you have done an experiment and found that your rat turned left in 7 out of 10 trials. What is the probability of the rat indeed turning left 7 times ($k = 7$)?\n",
    "\n",
    "This is given by the binomial probability of $k$, given $n$ trials and probability $p$:\n",
    "\n",
    "$$ P(k|n,p)= \\left( \\begin{array} \\\\n \\\\ k\\end{array} \\right) p^k (1-p)^{n-k}$$\n",
    "$$\\binom {n}{k}={\\frac {n!}{k!(n-k)!}}$$\n",
    "\n",
    "In this formula, $p$ is the probability of turning left, $n$ is the number of binary events, or trials, and $k$ is the number of times the rat turned left. The term $\\binom {n}{k}$ is the binomial coefficient.\n",
    "\n",
    "This is an example of a *probability mass function*, which specifies the probability that a discrete random variable is equal to each value. In other words, how large a part of the probability space (mass) is placed at each exact discrete value. We require that all probability adds up to 1, i.e. that \n",
    "\n",
    "\n",
    "$\\sum_k P(k|n,p)=1$.\n",
    "\n",
    "Essentially, if $k$ can only be one of 10 values, the probabilities of $k$ being equal to each possible value have to sum up to 1 because there is a probability of 1 it will equal one of those 10 values (no other options exist).\n",
    "\n",
    "\n",
    "If we assume an equal chance of turning left or right, then $p=0.5$. Note that if we only have a single trial $n=1$ this is equivalent to a single Bernoulli trial (feel free to do the math!).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Think! 2.1: Binomial distribution sampling\n",
    "We will draw a desired number of random samples from a binomial distribution, with $n = 10$ and $p = 0.5$. Each sample returns the number of trials, $k$, a rat turns left out of $n$ trials.\n",
    "\n",
    "We will draw 1000 samples of this (so it is as if we are observing 10 trials of the rat, 1000 different times). We can do this using numpy: `np.random.binomial(n, p, size = (n_samples,))`\n",
    "\n",
    "See below to visualize a histogram of the different values of $k$, or the number of times the rat turned left in each of the 1000 samples. In a histogram all the data is placed into bins and the contents of each bin is counted, to give a visualisation of the distribution of data. Discuss the following questions.\n",
    "\n",
    "\n",
    "1.   What are the x-axis limits of the histogram and why?\n",
    "2.   What is the shape of the histogram?\n",
    "3.  Looking at the histogram, how would you interpret the outcome of the simulation if you didn't know what p was? Would you have guessed p = 0.5?\n",
    "3.   What do you think the histogram would look like if the probability of turning left is 0.8 ($p = 0.8$)?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:31.522765Z",
     "iopub.status.busy": "2021-07-02T11:23:31.521530Z",
     "iopub.status.idle": "2021-07-02T11:23:31.726598Z",
     "shell.execute_reply": "2021-07-02T11:23:31.726971Z"
    }
   },
   "outputs": [],
   "source": [
    "# @markdown Execute this cell to see visualization\n",
    "\n",
    "# Select parameters for conducting binomial trials\n",
    "n = 10\n",
    "p = 0.5\n",
    "n_samples = 1000\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(1)\n",
    "\n",
    "# Now draw 1000 samples by calling the function again\n",
    "left_turn_samples_1000 = np.random.binomial(n, p, size = (n_samples,))\n",
    "\n",
    "# Visualize\n",
    "count, bins = plot_hist(left_turn_samples_1000, 'Number of left turns in sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:31.731339Z",
     "iopub.status.busy": "2021-07-02T11:23:31.730845Z",
     "iopub.status.idle": "2021-07-02T11:23:31.735258Z",
     "shell.execute_reply": "2021-07-02T11:23:31.735624Z"
    }
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_06a79c9b.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with the Bernoulli and binomial distributions, there are only 2 possible outcomes (in this case, turn left or turn right). In the more general case where there are $n$ possible outcomes (our rat is an n-armed maze) each with their own associated probability $p_1, p_2, p_3, p_4, ...$ , we use a **categorical distribution**. Draws from this distribution are a simple extension of the Bernoulli trial: we now have a probability for each outcome and draw based on those probabilities. We have to make sure that the probabilities sum to one:\n",
    "\n",
    "$$\\sum_i P(x=i)=\\sum_i p_i =1$$\n",
    "\n",
    "If we sample from this distribution multiple times, we can then describe the distribution of outcomes from each sample as the **multinomial distribution**. Essentially, the categorical distribution is the multiple outcome extension of the Bernoulli, and the multinomial distribution is the multiple outcome extension of the binomial distribution. We'll see a bit more about this in the next tutorial when we look at Markov chains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.2: Poisson distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:31.746609Z",
     "iopub.status.busy": "2021-07-02T11:23:31.746138Z",
     "iopub.status.idle": "2021-07-02T11:23:31.802669Z",
     "shell.execute_reply": "2021-07-02T11:23:31.802029Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title Video 4: Poisson distribution\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "      def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "          self.id=id\n",
    "          src = 'https://player.bilibili.com/player.html?bvid={0}&page={1}'.format(id, page)\n",
    "          super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=\"BV1wV411x7P6\", width=854, height=480, fs=1)\n",
    "  print('Video available at https://www.bilibili.com/video/{0}'.format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=\"E_nvNb596DY\", width=854, height=480, fs=1, rel=0)\n",
    "  print('Video available at https://youtube.com/watch?v=' + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This video covers the Poisson distribution and how it can be used to describe neural spiking.\n",
    "<details>\n",
    "<summary> <font color='blue'>Click here for text recap of  video </font></summary>\n",
    "\n",
    "For some phenomena there may not be a natural limit on the maximum number of possible events or outcomes. \n",
    "\n",
    "The Poisson distribution is a '**point-process**', meaning that it determines the number of discrete 'point', or binary, events that happen within a fixed space or time, allowing for the occurence of a potentially infinite number of events. The Poisson distribution is specified by a single parameter $\\lambda$ that encapsulates the mean number of events that can occur in a single time or space interval (there will be more on this concept of the 'mean' later!). \n",
    "\n",
    "Relevant to us, we can model the number of times a neuron spikes within a time interval using a Poisson distribution. In fact, neuroscientists often do! As an example, if we are recording from a neuron that tends to fire at an average rate of 4 spikes per second, then the Poisson distribution specifies the distribution of recorded spikes over one second, where $\\lambda=4$.\n",
    "\n",
    "</details>\n",
    "\n",
    "The formula for a Poisson distribution on $x$ is: \n",
    "\n",
    "$$P(x)=\\frac{\\lambda^x e^{-\\lambda}}{x!}$$\n",
    "where $\\lambda$ is a parameter corresponding to the average outcome of $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Exercise 2.2: Poisson distribution sampling\n",
    "\n",
    "In the exercise below we will draw some samples from the Poisson distribution and see what the histogram looks.\n",
    "\n",
    "In the code, fill in the missing line so we draw 5 samples from a Poisson distribution with $\\lambda = 4$. Use `np.random.poisson`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:31.811638Z",
     "iopub.status.busy": "2021-07-02T11:23:31.809434Z",
     "iopub.status.idle": "2021-07-02T11:23:31.813392Z",
     "shell.execute_reply": "2021-07-02T11:23:31.813780Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Draw 5 samples from a Poisson distribution with lambda = 4\n",
    "sampled_spike_counts = ...\n",
    "\n",
    "# Print the counts\n",
    "print(\"The samples drawn from the Poisson distribution are \" +\n",
    "          str(sampled_spike_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:31.817970Z",
     "iopub.status.busy": "2021-07-02T11:23:31.817494Z",
     "iopub.status.idle": "2021-07-02T11:23:31.819266Z",
     "shell.execute_reply": "2021-07-02T11:23:31.819654Z"
    }
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_90422623.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the neuron spiked 6 times, 7 times, 1 time, 8 times, and 4 times in 5 different intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Demo 2.2: Varying parameters of Poisson distribution\n",
    "\n",
    "Use the interactive demo below to vary $\\lambda$ and the number of samples, and then visualize the resulting histogram.\n",
    "\n",
    "\n",
    "1.  What effect does increasing the number of samples have?  \n",
    "2.  What effect does changing $\\lambda$ have?\n",
    "3.  With a small lambda, why is the distribution asymmetric?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:31.845916Z",
     "iopub.status.busy": "2021-07-02T11:23:31.845426Z",
     "iopub.status.idle": "2021-07-02T11:23:32.066660Z",
     "shell.execute_reply": "2021-07-02T11:23:32.066231Z"
    }
   },
   "outputs": [],
   "source": [
    "# @markdown Make sure you execute this cell to enable the widget!\n",
    "\n",
    "@widgets.interact(lambda_value = widgets.FloatSlider(value=4, min=0.1, max=10, step=0.1),\n",
    "                  n_samples = widgets.IntSlider(value=5, min=5, max=500, step=1))\n",
    "\n",
    "def gen_and_plot_possion_samples(lambda_value, n_samples):\n",
    "  sampled_spike_counts = np.random.poisson(lambda_value, n_samples)\n",
    "  count, bins = plot_hist(sampled_spike_counts, 'Recorded spikes per second')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:32.074313Z",
     "iopub.status.busy": "2021-07-02T11:23:32.073853Z",
     "iopub.status.idle": "2021-07-02T11:23:32.078121Z",
     "shell.execute_reply": "2021-07-02T11:23:32.078740Z"
    }
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_81eb1b08.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 3: Continuous distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:32.089797Z",
     "iopub.status.busy": "2021-07-02T11:23:32.080846Z",
     "iopub.status.idle": "2021-07-02T11:23:32.143675Z",
     "shell.execute_reply": "2021-07-02T11:23:32.144043Z"
    }
   },
   "outputs": [],
   "source": [
    "# @title Video 5: Continuous distributions\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "      def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "          self.id=id\n",
    "          src = 'https://player.bilibili.com/player.html?bvid={0}&page={1}'.format(id, page)\n",
    "          super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=\"BV1dq4y1L7eC\", width=854, height=480, fs=1)\n",
    "  print('Video available at https://www.bilibili.com/video/{0}'.format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=\"LJ4Zdokb6lc\", width=854, height=480, fs=1, rel=0)\n",
    "  print('Video available at https://youtube.com/watch?v=' + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not have to restrict ourselves to only probabilistic models of discrete events. While some events in neuroscience are discrete (e.g. number of spikes by a neuron), many others are continuous (e.g. neuroimaging signals in EEG or fMRI, distance traveled by an animal, human pointing in a direction of a stimulus).\n",
    "\n",
    "\n",
    "While for discrete outcomes we can ask about the probability of an specific event (\"what is the probability this neuron will fire 4 times in the next second\"), this is not defined for a continuous distribution (\"what is the probability of the BOLD signal being exactly 4.000120141...\"). Hence we need to focus on intervals when calculating probabilities from a continuous distribution. \n",
    "\n",
    "If we want to make predictions about possible outcomes (\"I believe the BOLD signal from the area will be in the range $x_1$ to $ x_2 $\") we can use the integral $\\int_{x_1}^{x_2} P(x)$.\n",
    "$P(x)$ is now a **probability density function**, sometimes written as $f(x)$ to distinguish it from the probability mass functions.\n",
    "\n",
    "\n",
    "With continuous distributions we have to replace the normalising sum \n",
    "\\begin{equation}\\sum_i P(x=p_i) =1\\end{equation}\n",
    "over all possible events, with an integral\n",
    "\\begin{equation}\\int_a^b P(x) =1\\end{equation}\n",
    "\n",
    "where a and b are the limits of the random variable $x$ (often $-\\infty$ and $\\infty$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3.1: Gaussian Distribution\n",
    "\n",
    "The most widely used continuous distribution is probably the Gaussian (also known as Normal) distribution. It is extremely common across all kinds of statistical analyses. Because of the central limit theorem, many quantities are Gaussian distributed. Gaussians also have some nice mathematical properties that permit simple closed-form solutions to several important problems. \n",
    "\n",
    "As a working example, imagine that a human participant is asked to point in the direction where they perceived a sound coming from. As an approximation, we can assume that the variability in the direction/orientation they point towards is Gaussian distributed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Exercise 3.1A: Gaussian Distribution\n",
    "\n",
    "In this exercise, you will implement a Gaussian by filling in the missing portions of code for the function `my_gaussian` below. Gaussians have two parameters. The **mean** $\\mu$, which sets the location of its center, and its \"scale\" or spread is controlled by its **standard deviation** $\\sigma$, or **variance** $\\sigma^2$ (i.e. the square of standard deviation). **Be careful not to use one when the other is required.**\n",
    "\n",
    "The equation for a Gaussian probability density function is:\n",
    "$$\n",
    "f(x;\\mu,\\sigma^2)=\\mathcal{N}(\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(\\frac{-(x-\\mu)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "In Python $\\pi$ and $e$ can be written as `np.pi` and `np.exp` respectively.\n",
    "\n",
    "As a probability distribution this has an integral of one when integrated from $-\\infty$ to $\\infty$, however in the following your numerical Gaussian will only be computed over a finite number of points (for the cell below we will sample from -8 to 9 in step sizes of 0.1). You therefore need to explicitly normalize it to sum to one yourself. \n",
    "\n",
    "\n",
    "Test out your implementation with a $\\mu = -1$ and $\\sigma = 1$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:32.152923Z",
     "iopub.status.busy": "2021-07-02T11:23:32.152432Z",
     "iopub.status.idle": "2021-07-02T11:23:32.164253Z",
     "shell.execute_reply": "2021-07-02T11:23:32.163751Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_gaussian(x_points, mu, sigma):\n",
    "  \"\"\" Returns normalized Gaussian estimated at points `x_points`, with\n",
    "  parameters: mean `mu` and standard deviation `sigma`\n",
    "\n",
    "  Args:\n",
    "      x_points (ndarray of floats): points at which the gaussian is evaluated\n",
    "      mu (scalar): mean of the Gaussian\n",
    "      sigma (scalar): standard deviation of the gaussian\n",
    "\n",
    "  Returns:\n",
    "      (numpy array of floats) : normalized Gaussian evaluated at `x`\n",
    "  \"\"\"\n",
    "\n",
    "  ###################################################################\n",
    "  ## TODO for students: Implement the formula for a Gaussian\n",
    "  ## Add code to calculate the gaussian px as a function of mu and sigma,\n",
    "  ## for every x in x_points\n",
    "  ## Function Hints: exp -> np.exp()\n",
    "  ##                 power -> z**2\n",
    "  ##\n",
    "  ## Fill out the following then remove\n",
    "  raise NotImplementedError(\"Student exercise: need to implement Gaussian\")\n",
    "  ###################################################################\n",
    "  px = ...\n",
    "\n",
    "  # as we are doing numerical integration we have to remember to normalise\n",
    "  # taking into account the stepsize (0.1)\n",
    "  px = px/(0.1*sum(px))\n",
    "  return px\n",
    "\n",
    "x = np.arange(-8, 9, 0.1)\n",
    "\n",
    "# Generate Gaussian\n",
    "px = my_gaussian(x, -1, 1)\n",
    "\n",
    "# Visualize\n",
    "my_plot_single(x, px)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:32.181206Z",
     "iopub.status.busy": "2021-07-02T11:23:32.180711Z",
     "iopub.status.idle": "2021-07-02T11:23:32.453450Z",
     "shell.execute_reply": "2021-07-02T11:23:32.453820Z"
    }
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D5_Statistics/solutions/W0D5_Tutorial1_Solution_2730515e.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=1115.0 height=828.0 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W0D5_Statistics/static/W0D5_Tutorial1_Solution_2730515e_1.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Demo 3.1: Sampling from a Gaussian distribution\n",
    "\n",
    "Now that we have gained a bit of intuition about the shape of the Gaussian, let's imagine that a human participant is asked to point in the direction of a sound source, which we then measure in horizontal degrees. To simulate that we draw samples from a Normal distribution:\n",
    "\n",
    "$$x \\sim \\mathcal{N}(\\mu,\\sigma) $$\n",
    "\n",
    "\n",
    "We can sample from a Gaussian with mean $\\mu$ and standard deviation $\\sigma$ using `np.random.normal(mu, sigma, size = (n_samples,))`.\n",
    "\n",
    "In the demo below, you can change the mean and standard deviation of the Gaussian, and the number of samples, we can compare the histogram of the samples to the true analytical distribution (in red).\n",
    "\n",
    "\n",
    "\n",
    "1.   With what number of samples would you say that the full distribution (in red) is well approximated by the histogram? \n",
    "2.   What if you just wanted to approximate the variables that defined the distribution, i.e. mean and variance?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-07-02T11:23:32.487369Z",
     "iopub.status.busy": "2021-07-02T11:23:32.486789Z",
     "iopub.status.idle": "2021-07-02T11:23:32.728740Z",
     "shell.execute_reply": "2021-07-02T11:23:32.728215Z"
    }
   },
   "outputs": [],
   "source": [
    "#@markdown Make sure you execute this cell to enable the widget!\n",
    "\n",
    "\n",
    "@widgets.interact(mean = widgets.FloatSlider(value=0, min=-5, max=5, step=0.5),\n",
    "                  standard_dev = widgets.FloatSlider(value=0.5, min=0, max=10, step=0.1),\n",
    "                  n_samples = widgets.IntSlider(value=5, min=1, max=300, step=1))\n",
    "def gen_and_plot_normal_samples(mean, standard_dev, n_samples):\n",
    "  x = np.random.normal(mean, standard_dev, size = (n_samples,))\n",
    "  xspace = np.linspace(-20, 20, 100)\n",
    "  plot_gaussian_samples_true(x, xspace, mean, standard_dev,\n",
    "                            'orientation (degrees)', 'probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main course preview:** Gaussian distriutions are everywhere and are critical for filtering, linear systems (W2D2), optimal control (W3D3) and almost any statistical model of continuous data (W3D1, W3D2, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "Across the different exercises you should now:\n",
    "* have gotten some intuition about how stochastic randomly generated data can be\n",
    "* understand how to model data using simple distributions \n",
    "* understand the difference between discrete and continuous distributions\n",
    "* be able to plot a Gaussian distribution\n",
    "\n",
    "For more reading on these topics see just about any statistics textbook, or take a look at the online resources at\n",
    "https://github.com/NeuromatchAcademy/precourse/blob/master/resources.md"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W0D5_Tutorial1",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
