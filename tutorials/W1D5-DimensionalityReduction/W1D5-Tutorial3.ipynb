{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of W1D5-Tutorial 3",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/W1D5/tutorials/W1D5-DimensionalityReduction/W1D5-Tutorial3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1pq-AcBBJ5L",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Neuromatch Academy: Week 1, Day 5, Tutorial 3\n",
        "# Dimensionality Reduction and reconstruction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_coTqnWnBo7V",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "In this notebook we'll learn to apply PCA for dimensionality reduction, using a classic dataset that is often used to benchmark machine learning algorithms: the MNIST dataset of handwritten digits. We'll also learn how to use PCA for reconstruction and denoising.\n",
        "\n",
        "Steps:\n",
        " 1. Perform PCA on MNIST dataset.\n",
        " 2. Calculate the variance explained.\n",
        " 3. Reconstruct data with different numbers of PCs.\n",
        " 4. Examine denoising using PCA.\n",
        "\n",
        "To learn more about MNIST: \n",
        "* https://en.wikipedia.org/wiki/MNIST_database\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3An8t_BXkpj",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "bbe64162-3daf-407d-f0a6-9165d9fbc6ed"
      },
      "source": [
        "#@title Video: Logistic regression\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"ew0-P7-6Nho\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "video\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video available at https://youtube.com/watch?v=ew0-P7-6Nho\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"854\"\n",
              "            height=\"480\"\n",
              "            src=\"https://www.youtube.com/embed/ew0-P7-6Nho?fs=1\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f735dda34e0>"
            ],
            "image/jpeg": "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\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvd-FYmlXyiH",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n",
        "Run these cells to get the tutorial started."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExhYAoZHv-8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import libraries\n",
        "import time                        # import time \n",
        "import numpy as np                 # import numpy\n",
        "import scipy as sp                 # import scipy\n",
        "import math                        # import basic math \n",
        "import random                      # import basic random number generator functions\n",
        "\n",
        "import matplotlib.pyplot as plt    # import matplotlib\n",
        "from IPython import display   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GcQOmtlBb8V",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "# @title Figure Settings\n",
        "fig_w, fig_h = (10, 4)\n",
        "plt.rcParams.update({'figure.figsize': (fig_w, fig_h)})\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFts1a8oflAC",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "# @title Helper Functions\n",
        "# New helper functions\n",
        "\n",
        "def plot_variance_explained(variance_explained):\n",
        "  \"\"\"\n",
        "  Plots eigenvalues.\n",
        "  \n",
        "  Args:\n",
        "     variance_explained (numpy array of floats) : Vector of variance explained for each PC\n",
        "     \n",
        "  Returns: \n",
        "    Nothing.\n",
        "    \n",
        "  \"\"\"\n",
        "  plt.figure()\n",
        "  plt.plot(np.arange(1,len(variance_explained)+1),variance_explained,'o-k')\n",
        "  plt.xlabel('Number of components')\n",
        "  plt.ylabel('Variance explained')\n",
        "\n",
        "def plot_MNIST_reconstruction(X,X_reconstructed):\n",
        "  \"\"\"\n",
        "  Plots 9 images in the MNIST dataset side-by-side with the reconstructed images.\n",
        "  \n",
        "  Args:\n",
        "     X (numpy array of floats):   Data matrix \n",
        "                                  each column corresponds to a different random variable \n",
        "     X_reconstructed (numpy array of floats):   Data matrix \n",
        "                                  each column corresponds to a different random variable \n",
        "    \n",
        "  Returns: \n",
        "    Nothing.\n",
        "    \n",
        "  \"\"\"\n",
        "  plt.figure()\n",
        "  ax = plt.subplot(1,2,1)\n",
        "  k=0\n",
        "  for k1 in range(3):\n",
        "    for k2 in range(3):\n",
        "      k = k+1\n",
        "      plt.imshow(np.reshape(X[k,:],(28,28)),extent=[(k1+1)*28,k1*28,(k2+1)*28,k2*28],vmin=0,vmax=255)\n",
        "  plt.xlim((3*28,0))\n",
        "  plt.ylim((3*28,0))\n",
        "  plt.tick_params(axis='both',which='both',bottom=False,top=False,labelbottom=False)\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([]) \n",
        "  plt.title('Data')\n",
        "  plt.clim([0,250])\n",
        "  ax = plt.subplot(1,2,2)\n",
        "  k=0\n",
        "  for k1 in range(3):\n",
        "    for k2 in range(3):\n",
        "      k = k+1\n",
        "      plt.imshow(np.real(np.reshape(X_reconstructed[k,:],(28,28))),extent=[(k1+1)*28,k1*28,(k2+1)*28,k2*28],vmin=0,vmax=255)\n",
        "  plt.xlim((3*28,0))\n",
        "  plt.ylim((3*28,0))\n",
        "  plt.tick_params(axis='both',which='both',bottom=False,top=False,labelbottom=False)\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([]) \n",
        "  plt.clim([0,250])\n",
        "  plt.title('Reconstructed')\n",
        "\n",
        "\n",
        "def plot_MNIST_sample(X):\n",
        "  \"\"\"\n",
        "  Plots 9 images in the MNIST dataset.\n",
        "  \n",
        "  Args:\n",
        "     X (numpy array of floats):   Data matrix \n",
        "                                  each column corresponds to a different random variable \n",
        "\n",
        "  Returns: \n",
        "    Nothing.\n",
        "    \n",
        "  \"\"\"\n",
        "  plt.figure()\n",
        "  fig, ax = plt.subplots()\n",
        "  k=0\n",
        "  for k1 in range(3):\n",
        "    for k2 in range(3):\n",
        "      k = k+1\n",
        "      plt.imshow(np.reshape(X[k,:],(28,28)),extent=[(k1+1)*28,k1*28,(k2+1)*28,k2*28],vmin=0,vmax=255)\n",
        "  plt.xlim((3*28,0))\n",
        "  plt.ylim((3*28,0))\n",
        "  plt.tick_params(axis='both',which='both',bottom=False,top=False,labelbottom=False)\n",
        "  plt.clim([0,250])\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([])\n",
        "\n",
        "def plot_MNIST_weights(weights):\n",
        "  \"\"\"\n",
        "  Visualize PCA basis vector weights for MNIST. Red = positive weights, blue = \n",
        "  negative weights, white = zero weight.\n",
        "  \n",
        "  Args:\n",
        "     weights (numpy array of floats) : PCA basis vector\n",
        "     \n",
        "  Returns: \n",
        "     Nothing.\n",
        "    \n",
        "  \"\"\"\n",
        "  plt.figure()\n",
        "  fig, ax = plt.subplots()\n",
        "  cmap = plt.cm.get_cmap('seismic')\n",
        "  plt.imshow(np.reshape(weights,(28,28)),cmap=cmap)\n",
        "  plt.tick_params(axis='both',which='both',bottom=False,top=False,labelbottom=False)\n",
        "  plt.clim(-.15,.15)\n",
        "  plt.colorbar(ticks=[-.15,-.1,-.05,0,.05,.1,.15])\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([])\n",
        "\n",
        "def add_noise(X,frac_noisy_pixels):\n",
        "  \"\"\"\n",
        "  Randomly corrupts a fraction of the pixels by setting them to random values.\n",
        "  \n",
        "  Args:\n",
        "     X (numpy array of floats) : Data matrix\n",
        "     frac_noisy_pixels (scalar) : Fraction of noisy pixels\n",
        "     \n",
        "  Returns: \n",
        "     (numpy array of floats) : Data matrix + noise\n",
        "    \n",
        "  \"\"\"\n",
        "  X_noisy = np.reshape(X,(X.shape[0]*X.shape[1]))\n",
        "  N_noise_ixs = int(X_noisy.shape[0] * frac_noisy_pixels)\n",
        "  noise_ixs = np.random.choice(X_noisy.shape[0],size= N_noise_ixs,replace=False)\n",
        "  X_noisy[noise_ixs] = np.random.uniform(0,255,noise_ixs.shape)\n",
        "  X_noisy = np.reshape(X_noisy,(X.shape[0],X.shape[1]))\n",
        "  return X_noisy\n",
        "\n",
        "\n",
        "\n",
        "  # Old helper functions from Tutorial 1-2\n",
        "\n",
        "def change_of_basis(X,W):\n",
        "  \"\"\"\n",
        "  Projects data onto a new basis.\n",
        "  \n",
        "  Args:\n",
        "    X (numpy array of floats) : Data matrix\n",
        "                                each column corresponding to a different random variable\n",
        "    W (numpy array of floats):  new orthonormal basis\n",
        "                                columns correspond to basis vectors\n",
        "  \n",
        "  Returns: \n",
        "    (numpy array of floats) : Data matrix expressed in new basis\n",
        "  \"\"\"\n",
        "  Y = np.matmul(X,W)\n",
        "  return Y\n",
        "\n",
        "def get_sample_cov_matrix(X):\n",
        "  \"\"\"\n",
        "    Returns the sample covariance matrix of data X\n",
        "    \n",
        "    Args:\n",
        "      X (numpy array of floats):   Data matrix \n",
        "                                  each column corresponds to a different random variable \n",
        "      \n",
        "    Returns: \n",
        "      (numpy array of floats) : Covariance matrix\n",
        "  \"\"\"\n",
        "  X = X - np.mean(X,0)\n",
        "  cov_matrix = 1./X.shape[0]*np.matmul(X.T,X)\n",
        "  return cov_matrix\n",
        "\n",
        "def sort_evals_descending(evals,evectors):\n",
        "  \"\"\"  \n",
        "  Sorts eigenvalues and eigenvectors in decreasing order. Also aligns first two\n",
        "  eigenvectors to be in first two quadrants (if 2D).\n",
        "\n",
        "  Args:\n",
        "    evals (numpy array of floats):   Vector of eigenvalues \n",
        "    evectors (numpy array of floats):   Corresponding matrix of eigenvectors \n",
        "                                each column corresponds to a different eigenvalue \n",
        "    \n",
        "  Returns: \n",
        "    (numpy array of floats) : Vector of eigenvalues after sorting\n",
        "    (numpy array of floats) : Matrix of eigenvectors after sorting\n",
        "  \"\"\"\n",
        "  index = np.flip(np.argsort(evals))\n",
        "  evals = evals[index]\n",
        "  evectors = evectors[:,index]\n",
        "  if evals.shape[0] == 2:\n",
        "    if np.arccos(np.matmul(evectors[:,0], 1./np.sqrt(2)*np.array([1,1]))) > np.pi/2.:\n",
        "      evectors[:,0] = -evectors[:,0]\n",
        "    if np.arccos(np.matmul(evectors[:,1], 1./np.sqrt(2)*np.array([-1,1]))) > np.pi/2.:\n",
        "      evectors[:,1] = -evectors[:,1]\n",
        "  return evals, evectors\n",
        "\n",
        "def pca(X):\n",
        "  \"\"\"\n",
        "  Performs PCA on multivariate data. Eigenvalues are sorted in decreasing order.\n",
        "  \n",
        "  Args:\n",
        "     X (numpy array of floats):   Data matrix \n",
        "                                  each column corresponds to a different random variable \n",
        "     \n",
        "  Returns: \n",
        "    (numpy array of floats) : Data projected onto the new basis\n",
        "    (numpy array of floats) : Vector of eigenvalues\n",
        "    (numpy array of floats) : Corresponding matrix of eigenvectors \n",
        "    \n",
        "  \"\"\"\n",
        "  X = X - np.mean(X,0)\n",
        "  cov_matrix = get_sample_cov_matrix(X)\n",
        "  evals, evectors = np.linalg.eig(cov_matrix)\n",
        "  evals, evectors = sort_evals_descending(evals,evectors)\n",
        "  score = change_of_basis(X,evectors)\n",
        "  return score, evectors, evals\n",
        "\n",
        "def plot_eigenvalues(evals):\n",
        "  \"\"\"\n",
        "  Plots eigenvalues.\n",
        "  \n",
        "  Args:\n",
        "     (numpy array of floats) : Vector of eigenvalues\n",
        "     \n",
        "  Returns: \n",
        "    Nothing.\n",
        "    \n",
        "  \"\"\"\n",
        "  plt.figure()\n",
        "  plt.plot(np.arange(1,len(evals)+1),evals,'o-k')\n",
        "  plt.xlabel('Component')\n",
        "  plt.ylabel('Eigenvalue')\n",
        "  plt.title('Scree plot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jFNyCJ5ChXQ",
        "colab_type": "text"
      },
      "source": [
        "# Perform PCA on MNIST dataset.\n",
        "The MNIST dataset consists of a 70,000 images of individual handwritten digits. Each image is a 28x28 pixel grayscale image. For convenience, each 28x28 pixel image is often unravelled into a single 784 (=28*28) element vector, so that the whole dataset is represented as a 70,000 x 784 matrix. Each row represents a different image, and each column represents a different pixel.\n",
        " \n",
        "Enter the following cell to load the MNIST dataset and plot the first nine images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4TNMebrBDSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml(name = 'mnist_784')\n",
        "X = mnist.data\n",
        "plot_MNIST_sample(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxtBZtgXHIAT",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The MNIST dataset has an extrinsic dimensionality of 784, much higher than the 2-dimensional examples used in the previous tutorials! To make sense of this data, we'll use dimensionality reduction. But first, we need to determine the intrinsic dimensionality $K$ of the data. One way to do this is to look for an \"elbow\" in the scree plot, to determine which eigenvalues are signficant.\n",
        "\n",
        "#### Exercise\n",
        "In this exercise you will examine the scree plot in the MNIST dataset.\n",
        "\n",
        "**Suggestions**\n",
        "* Perform PCA on the dataset and examine the scree plot. \n",
        "* When do the eigenvalues appear (by eye) to reach zero? (Hint: use `plt.xlim` to zoom into a section of the plot).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kiAFD9KOG8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(pca)\n",
        "help(plot_eigenvalues)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zgeszJSHVr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################\n",
        "## Insert your code here to:\n",
        "##                perform PCA \n",
        "##                plot the eigenvalues\n",
        "################################################################### \n",
        "\n",
        "# score, evectors, evals = ...YOUR CODE HERE to perform PCA\n",
        "# plot_eigenvalues(evals)\n",
        "# YOUR CODE HERE to limit the x-axis for zooming"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAM5vUWJBpiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to_remove solution\n",
        "score, evectors, evals = pca(X)\n",
        "\n",
        "with plt.xkcd():\n",
        "  plot_eigenvalues(evals)\n",
        "  plt.xlim([0,100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ccOz9ePZPGMz"
      },
      "source": [
        "# Calculate the variance explained.\n",
        "The scree plot suggests that most of the eigenvalues are near zero, with fewer than 100 having large values. Another common way to determine the intrinsic dimensionality is by considering the   variance explained. This can be examined with a cumulative plot of the fraction of the total variance explained by the top $K$ components, i.e.:\n",
        "\\begin{equation}\n",
        "\\text{var explained} = \\frac{\\sum_{i=1}^K \\lambda_i}{\\sum_{i=1}^N \\lambda_i}\n",
        "\\end{equation}\n",
        "The intrinsic dimensionality is often quantified by the $K$ necessary to explain a large proportion of the total variance of the data (often a defined threshold, e.g., 90%).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W30pzQPIwZ0",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise\n",
        "In this exercise you will plot the explained variance.\n",
        "\n",
        "**Suggestions**\n",
        "* Fill in the function below to calculate the fraction variance explained as a function of the number of principal componenets. **Hint:** use `np.cumsum`.\n",
        "* Plot the variance explained using `plot_variance_explained`.\n",
        "* How many principal components are required to explain 90% of the variance?\n",
        "* How does the intrinsic dimensionality of this dataset compare to its extrinsic dimensionality?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnQt-y4_WwVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(plot_variance_explained)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEVRB7fCVcOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_variance_explained(evals):\n",
        "  \"\"\"\n",
        "  Calculates variance explained from the eigenvalues.\n",
        "  \n",
        "  Args:\n",
        "     evals (numpy array of floats) : Vector of eigenvalues\n",
        "     \n",
        "  Returns: \n",
        "    (numpy array of floats) : Vector of variance explained\n",
        "    \n",
        "  \"\"\"\n",
        "  ###################################################################\n",
        "  ## Insert your code here to:\n",
        "  ##                cumulatively sum the eigenvalues\n",
        "  ##                normalize by the sum of eigenvalues\n",
        "\n",
        "  #uncomment once you've filled in the function\n",
        "  raise NotImplementedError(\"Student excercise: calculate explaine variance!\")\n",
        "  ################################################################### \n",
        "  return variance_explained\n",
        "\n",
        "###################################################################\n",
        "## Insert your code here to:\n",
        "##                calculate and plot the variance explained \n",
        "################################################################### \n",
        "# variance_explained = ...\n",
        "# plot_variance_explained(variance_explained)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HhFNTajH55u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to_remove solution\n",
        "\n",
        "def get_variance_explained(evals):\n",
        "  \"\"\"\n",
        "  Plots eigenvalues.\n",
        "  \n",
        "  Args:\n",
        "     (numpy array of floats) : Vector of eigenvalues\n",
        "     \n",
        "  Returns: \n",
        "    Nothing.\n",
        "    \n",
        "  \"\"\"\n",
        "  return np.cumsum(evals)/np.sum(evals)\n",
        "  \n",
        "variance_explained = get_variance_explained(evals)\n",
        "\n",
        "with plt.xkcd():\n",
        "  plot_variance_explained(variance_explained)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lVO2rHv0kDi",
        "colab_type": "text"
      },
      "source": [
        "# Reconstruct data with different numbers of PCs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIi0fq2d0Z60",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Video: Geometric view of data\n",
        "from IPython.display import YouTubeVideo\n",
        "video = YouTubeVideo(id=\"A_a7_hMhjfc\", width=854, height=480, fs=1)\n",
        "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "video\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dhA1ioJJlrtw"
      },
      "source": [
        "Now we have seen that the top 100 or so principal components of the data can explain most of the variance. We can use this fact to perform *dimensionality reduction*, i.e., by storing the data using only 100 components rather than the samples of all 784 pixels. Remarkably, we will be able to reconstruct much of the structure of the data using only the top 100 components. To see this, recall that to perform PCA we projected the data $\\bf X$ onto the eigenvectors of the covariance matrix:\n",
        "\\begin{equation}\n",
        "\\bf S = X W\n",
        "\\end{equation}\n",
        "Since $\\bf W$ is an orthogonal matrix, ${\\bf W}^{-1} = {\\bf W}^T$. So by multiplying by ${\\bf W}^T$ on each side we can rewrite this equation as  \n",
        "\\begin{equation}\n",
        "{\\bf X = S W}^T.\n",
        "\\end{equation}\n",
        "This now gives us a way to reconstruct the data matrix from the scores and loadings. To reconstruct the data from a low-dimensional approximation, we just have to truncate these matrices.  Let's call ${\\bf S}_{1:K}$ and ${\\bf W}_{1:K}$ as keeping only the first $K$ columns of this matrix. Then our reconstruction is:\n",
        "\\begin{equation}\n",
        "{\\bf \\hat X = S}_{1:K} ({\\bf W}_{1:K})^T.\n",
        "\\end{equation}\n",
        "\n",
        "#### Exercise\n",
        "Fill in the function below to reconstruct the data using different numbers of principal components. \n",
        "\n",
        "**Suggestions**\n",
        "* Fill in the following function to reconstruct the data based on the weights and scores. Don't forget to add the mean!\n",
        "* Make sure your function works by reconstructing the data with all $K=784$ components. They two images should look identical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mozpTVpMniYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(plot_MNIST_reconstruction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS1c_mSLIdMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reconstruct_data(score,evectors,X_mean,K):\n",
        "  \"\"\"\n",
        "  Reconstruct the data based on the top K components.\n",
        "  \n",
        "  Args:\n",
        "     score (numpy array of floats) : Score matrix\n",
        "     evectors (numpy array of floats) : Matrix of eigenvectors\n",
        "     X_mean (numpy array of floats) : Vector corresponding to data mean\n",
        "     K (scalar) : Number of components to include\n",
        "     \n",
        "  Returns: \n",
        "     (numpy array of floats) : Matrix of reconstructed data \n",
        "    \n",
        "  \"\"\"\n",
        "  ###################################################################\n",
        "  ## Insert your code here to:\n",
        "  ##                Reconstruct the data from the score and eigenvectors\n",
        "  ##                Don't forget to add the mean!!\n",
        "\n",
        "  #X_reconstructed =  Your code here \n",
        "  #uncomment once you've filled in the function\n",
        "  raise NotImplementedError(\"Student excercise: finish reconstructing data function!\")\n",
        "  ################################################################### \n",
        "  return X_reconstructed\n",
        "\n",
        "K = 784\n",
        "\n",
        "## Uncomment below to to:\n",
        "##                Reconstruct the data based on all components\n",
        "##                Plot the data and reconstruction\n",
        "# X_mean = ...\n",
        "# X_reconstructed = ...\n",
        "# plot_MNIST_reconstruction(X ,X_reconstructed)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5q8yvs6TJAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to_remove solution\n",
        "\n",
        "def reconstruct_data(score,evectors,X_mean,K):\n",
        "  \"\"\"\n",
        "  Reconstruct the data based on the top K components.\n",
        "  \n",
        "  Args:\n",
        "     score (numpy array of floats) : Score matrix\n",
        "     evectors (numpy array of floats) : Matrix of eigenvectors\n",
        "     X_mean (numpy array of floats) : Vector corresponding to data mean\n",
        "     K (scalar) : Number of components to include\n",
        "     \n",
        "  Returns: \n",
        "     (numpy array of floats) : Matrix of reconstructed data \n",
        "    \n",
        "  \"\"\"\n",
        "  X_reconstructed = np.matmul(score[:,:K],evectors[:,:K].T) + X_mean\n",
        "  return X_reconstructed\n",
        "\n",
        "K = 784\n",
        "\n",
        "with plt.xkcd():\n",
        "  X_mean = np.mean(X,0) \n",
        "  X_reconstructed = reconstruct_data(score,evectors,X_mean,K)\n",
        "  plot_MNIST_reconstruction(X ,X_reconstructed)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHxJHV4BrRHi",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise:\n",
        "Now run the code below and experiment with the slider to reconstruct the data matrix using different numbers of principal components.\n",
        "\n",
        "**Questions:**\n",
        "* How many principal components are necessary to reconstruct the numbers (by eye)? How does this relate to the intrinsic dimensionality of the data?\n",
        "* Do you see any information in the data with only a single principal component?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZGFzhXqlvmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### MAKE SURE TO RUN THIS CELL VIA THE PLAY BUTTON TO ENABLE SLIDERS ########\n",
        "\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def refresh(K = 100):\n",
        "  X_reconstructed = reconstruct_data(score,evectors,X_mean,K)\n",
        "  plot_MNIST_reconstruction(X ,X_reconstructed)\n",
        "  plt.title('Reconstructed, K={}'.format(K))\n",
        "\n",
        "_ = widgets.interact(refresh, \n",
        "  K = (1, 784, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnmqJqd3nue7",
        "colab_type": "text"
      },
      "source": [
        "#### Exercise:\n",
        "Next, let's take a closer look at the first principal component by visualizing its corresponding weights. \n",
        "\n",
        "**Questions**\n",
        "* Enter `plot_MNIST_weights` to visualize the weights of the first basis vector.\n",
        "* What structure do you see? Which pixels have a strong positive weighting? Which have a strong negative weighting? What kinds of images would this basis vector differentiate?\n",
        "* Try visualizing the second and third basis vectors. Do you see any structure? What about the 100th basis vector? 500th? 700th?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZghlYuowoaAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(plot_MNIST_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7BkraA4IDR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################\n",
        "## Insert your code here to:\n",
        "##                Plot the weights of the first principal component\n",
        "\n",
        "#plot_MNIST_weights(Your code here)\n",
        "################################################################### "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPYX_kK9nvBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to_remove solution\n",
        "with plt.xkcd():\n",
        "  plot_MNIST_weights(evectors[:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4o207yNk0c-I"
      },
      "source": [
        "# (Optional Exploration): Examine denoising using PCA.\n",
        "   \n",
        "Finally, we will test how PCA can be used to denoise data. We will add salt-and-pepper noise to the original data and see how that affects the eigenvalues. To do this, we'll use the function `add_noise`, starting with adding noise to 20% of the pixels.\n",
        "The we'll Perform PCA and plot the variance explained. How many principal components are required to explain 90% of the variance? How does this compare to the original data?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVWrn-mn5m4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################\n",
        "## Here we:\n",
        "##                Add noise to the data\n",
        "##                Plot noise-corrupted data\n",
        "##                Perform PCA on the noisy data\n",
        "##                Calculate and plot the variance explained\n",
        "################################################################### \n",
        "X_noisy = add_noise(X,.2)\n",
        "score_noisy, evectors_noisy, evals_noisy = pca(X_noisy)\n",
        "variance_explained_noisy = get_variance_explained(evals_noisy)\n",
        "\n",
        "with plt.xkcd():\n",
        "  plot_MNIST_sample(X_noisy)\n",
        "  plot_variance_explained(variance_explained_noisy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWojBrz2xbjC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "To denoise the data, we can simply project it onto the basis found with the original dataset (`evectors`, not `evectors_noisy`). Then, by taking the top K components of this projection, we have a guess for where the sample should lie in the K-dimensional latent space. We can then reconstruct the data as normal, using the top 50 components. You should play around with the amount of noise and K to build intuition.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB5QiPn-3Pag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################################################\n",
        "## Here we:\n",
        "##                Subtract the mean of the noise-corrupted data\n",
        "##                Project onto the original basis vectors evectors\n",
        "##                Reconstruct the data using the top 50 components\n",
        "##                Plot the result\n",
        "################################################################### \n",
        "\n",
        "X_noisy_mean = np.mean(X_noisy,0)\n",
        "projX_noisy = np.matmul(X_noisy-X_noisy_mean,evectors)\n",
        "X_reconstructed = reconstruct_data(projX_noisy,evectors,X_noisy_mean,50)\n",
        "\n",
        "with plt.xkcd():\n",
        "  plot_MNIST_reconstruction(X_noisy,X_reconstructed)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}