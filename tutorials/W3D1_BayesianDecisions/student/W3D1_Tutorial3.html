
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Bonus Tutorial:Fitting to data &#8212; Neuromatch Computational Neuroscience</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Outro" href="../W3D1_Outro.html" />
    <link rel="prev" title="Tutorial 2: Bayesian inference and decisions with continuous hidden state" href="W3D1_Tutorial2.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      <img src="../../../_static/nma-logo-square-4xp.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Neuromatch Computational Neuroscience</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../intro.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Pre-reqs Refresher
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">
   Python Workshop 1 (W0D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D1_PythonWorkshop1/student/W0D1_Tutorial1.html">
     Tutorial: LIF Neuron - Part I
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">
   Python Workshop 2 (W0D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D2_PythonWorkshop2/student/W0D2_Tutorial1.html">
     Tutorial 1: LIF Neuron Part II
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D3_LinearAlgebra/chapter_title.html">
   Linear Algebra (W0D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial1.html">
     Tutorial 1: Vectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial2.html">
     Tutorial 2: Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial3.html">
     Bonus Tutorial: Discrete Dynamical Systems
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D4_Calculus/chapter_title.html">
   Calculus (W0D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial1.html">
     Tutorial 1: Basics of Differential and Integral Calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial2.html">
     Tutorial 2: Differential Equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial3.html">
     Tutorial 3: Numerical Methods
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D5_Statistics/chapter_title.html">
   Statistics (W0D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial1.html">
     Neuromatch Academy: Precourse Week, Day 5, Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial2.html">
     Tutorial 2: Statistical Inference
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Intro to Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D1_ModelTypes/chapter_title.html">
   Model Types (W1D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/W1D1_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial1.html">
     Tutorial 1: “What” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial2.html">
     Tutorial 2: “How” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial3.html">
     Tutorial 3: “Why” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/W1D1_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D2_ModelingPractice/chapter_title.html">
   Modeling Practice (W1D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_ModelingPractice/W1D2_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_ModelingPractice/student/W1D2_Tutorial1.html">
     Tutorial: Framing the Question
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_ModelingPractice/W1D2_Outro.html">
     Outro
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D3_ModelFitting/chapter_title.html">
   Model Fitting (W1D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/W1D3_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial1.html">
     Tutorial 1: Linear regression with MSE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial2.html">
     Tutorial 2: Linear regression with MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial3.html">
     Tutorial 3: Confidence intervals and bootstrapping
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial4.html">
     Tutorial 4: Multiple linear regression and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial5.html">
     Tutorial 5: Model Selection: Bias-variance trade-off
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial6.html">
     Tutorial 6: Model Selection: Cross-validation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/W1D3_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/chapter_title.html">
   Generalized Linear Models (W1D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/W1D4_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/student/W1D4_Tutorial1.html">
     Tutorial 1: GLMs for Encoding
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/student/W1D4_Tutorial2.html">
     Tutorial 2: Classifiers and regularizers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/W1D4_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D5_DimensionalityReduction/chapter_title.html">
   Dimensionality Reduction (W1D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/W1D5_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial1.html">
     Tutorial 1: Geometric view of data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial2.html">
     Tutorial 2: Principal Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial3.html">
     Tutorial 3: Dimensionality Reduction &amp; Reconstruction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial4.html">
     Tutorial 4:  Nonlinear Dimensionality Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/W1D5_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D1_DeepLearning/chapter_title.html">
   Deep Learning (W2D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/W2D1_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial3.html">
     Tutorial 2: Building and Evaluating Normative Encoding Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/W2D1_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D2_LinearSystems/chapter_title.html">
   Linear Systems (W2D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/W2D2_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial1.html">
     Tutorial 1: Linear dynamical systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial2.html">
     Tutorial 2: Markov Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial3.html">
     Tutorial 3: Combining determinism and stochasticity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial4.html">
     Tutorial 4: Autoregressive models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/W2D2_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/chapter_title.html">
   Biological Neuron Models (W2D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/W2D3_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial1.html">
     Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial2.html">
     Tutorial 2: Effects of Input Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial3.html">
     Tutorial 3: Synaptic transmission - Models of static and dynamic synapses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial4.html">
     Tutorial 4: Spike-timing dependent plasticity (STDP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/W2D3_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D4_DynamicNetworks/chapter_title.html">
   Dynamic Networks (W2D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/W2D4_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial1.html">
     Tutorial 1: Neural Rate Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial2.html">
     Tutorial 2: Wilson-Cowan Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/W2D4_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Stochastic Processes
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../chapter_title.html">
   Bayesian Decisions (W3D1)
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../W3D1_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="W3D1_Tutorial1.html">
     Tutorial 1: Bayes with a binary hidden state
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="W3D1_Tutorial2.html">
     Tutorial 2: Bayesian inference and decisions with continuous hidden state
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Bonus Tutorial:Fitting to data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../W3D1_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D2_HiddenDynamics/chapter_title.html">
   Hidden Dynamics (W3D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/W3D2_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial1.html">
     Tutorial 1: Sequential Probability Ratio Test
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial2.html">
     Tutorial 2: Hidden Markov Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial3.html">
     Tutorial 3: 1D Kalman Filter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial4.html">
     Tutorial 4: 2D Kalman Filter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/W3D2_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D3_OptimalControl/chapter_title.html">
   Optimal Control (W3D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/W3D3_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial1.html">
     Tutorial 1: Optimal Control for Discrete States
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial2.html">
     Tutorial 2: Optimal Control for Continuous State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/W3D3_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D4_ReinforcementLearning/chapter_title.html">
   Reinforcement Learning (W3D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/W3D4_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial4.html">
     Tutorial 4: From Reinforcement Learning to Planning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/W3D4_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D5_NetworkCausality/chapter_title.html">
   Network Causality (W3D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/W3D5_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial1.html">
     Tutorial 1: Interventions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial2.html">
     Tutorial 2: Correlations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial3.html">
     Tutorial 3: Simultaneous fitting/regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial4.html">
     Tutorial 4: Instrumental Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/W3D5_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial3.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/NeuromatchAcademy/course_content/blob/master/book/tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial3.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Bonus Tutorial:Fitting to data
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial objectives
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-1-likelihood-array">
   Section 1: Likelihood array
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-2-causal-mixture-of-gaussian-prior">
   Section 2: Causal mixture of Gaussian prior
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-2-implement-the-prior-array">
     Exercise 2: Implement the prior array
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-3-bayes-rule-and-posterior-array">
   Section 3: Bayes rule and Posterior array
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-3-calculate-the-posterior-as-a-function-of-the-hypothetical-stimulus-x">
     Exercise 3: Calculate the posterior as a function of the hypothetical stimulus x
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-4-estimating-the-position-hat-x">
   Section 4: Estimating the position
   <span class="math notranslate nohighlight">
    \(\hat x\)
   </span>
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-4-calculate-the-estimated-response-as-a-function-of-the-hypothetical-stimulus-x">
     Exercise 4: Calculate the estimated response as a function of the hypothetical stimulus x
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-5-probabilities-of-encoded-stimuli">
   Section 5: Probabilities of encoded stimuli
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-6-normalization-and-expected-estimate-distribution">
   Section 6: Normalization and expected estimate distribution
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generate-some-data">
   Generate some data
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-8-summary">
   Section 8: Summary
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/master/tutorials/W3D1_BayesianDecisions/student/W3D1_Tutorial3.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<div class="section" id="bonus-tutorial-fitting-to-data">
<h1>Bonus Tutorial:Fitting to data<a class="headerlink" href="#bonus-tutorial-fitting-to-data" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 3, Day 1: Bayesian Decisions</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Vincent Valton, Konrad Kording</p>
<p><strong>Content reviewers:</strong> Matt Krause, Jesse Livezey, Karolina Stosio, Saeed Salehi, Michael Waskom</p>
</div>
<hr class="docutils" />
<div class="section" id="tutorial-objectives">
<h1>Tutorial objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p>In the first two tutorials, we learned about Bayesian models and decisions more intuitively, using demos. In this notebook, we will dive into using math and code to fit Bayesian models to data.</p>
<p>We’ll have a look at computing all the necessary steps to perform model inversion (estimate the model parameters such as <span class="math notranslate nohighlight">\(p_{common}\)</span> that generated data similar to that of a participant). We will describe all the steps of the generative model first, and in the last exercise we will use all these steps to estimate the parameter <span class="math notranslate nohighlight">\(p_{common}\)</span> of a single participant using simulated data.</p>
<p>The generative model will be a Bayesian model we saw in Tutorial 2: a mixture of Gaussian prior  and a Gaussian likelihood.
Steps:</p>
<ul class="simple">
<li><p>First, we’ll create the prior, likelihood, posterior, etc in a form that will make it easier for us to visualise what is being computed and estimated at each step of the generative model:</p>
<ol class="simple">
<li><p>Creating a mixture of Gaussian prior for multiple possible stimulus inputs</p></li>
<li><p>Generating the likelihood for multiple possible stimulus inputs</p></li>
<li><p>Estimating our posterior as a function of the stimulus input</p></li>
<li><p>Estimating a participant response given the posterior</p></li>
</ol>
</li>
<li><p>Next, we’ll perform the model inversion/fitting:
5. Create an distribution for the input as a function of possible inputs
6. Marginalization
7. Generate some data using the generative model provided
8. Perform model inversion (model fitting) using the generated data and see if you recover the orignal parameters.</p></li>
</ul>
</div>
<hr class="docutils" />
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<p>Please execute the cell below to initialize the notebook environment</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Figure Settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/NeuromatchAcademy/course-content/NMA2020/nma.mplstyle&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper Functions</span>

<span class="k">def</span> <span class="nf">my_gaussian</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a Gaussian estimated at points `x_points`, with parameters: `mu` and `sigma`</span>

<span class="sd">    Args :</span>
<span class="sd">      x_points (numpy arrays of floats)- points at which the gaussian is evaluated</span>
<span class="sd">      mu (scalar) - mean of the Gaussian</span>
<span class="sd">      sigma (scalar) - std of the gaussian</span>

<span class="sd">    Returns:</span>
<span class="sd">      Gaussian evaluated at `x`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">x_points</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">p</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">moments_myfunc</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">function</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  DO NOT EDIT THIS FUNCTION !!!</span>

<span class="sd">  Returns the mean, median and mode of an arbitrary function</span>

<span class="sd">  Args :</span>
<span class="sd">    x_points (numpy array of floats) - x-axis values</span>
<span class="sd">    function (numpy array of floats) - y-axis values of the function evaluated at `x_points`</span>

<span class="sd">  Returns:</span>
<span class="sd">    (tuple of 3 scalars): mean, median, mode</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1"># Calc mode of arbitrary function</span>
  <span class="n">mode</span> <span class="o">=</span> <span class="n">x_points</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">function</span><span class="p">)]</span>

  <span class="c1"># Calc mean of arbitrary function</span>
  <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x_points</span> <span class="o">*</span> <span class="n">function</span><span class="p">)</span>

  <span class="c1"># Calc median of arbitrary function</span>
  <span class="n">cdf_function</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x_points</span><span class="p">)</span>
  <span class="n">accumulator</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">accumulator</span> <span class="o">=</span> <span class="n">accumulator</span> <span class="o">+</span> <span class="n">function</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">cdf_function</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">accumulator</span>
  <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">cdf_function</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">))</span>
  <span class="n">median</span> <span class="o">=</span> <span class="n">x_points</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

  <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">median</span><span class="p">,</span> <span class="n">mode</span>

<span class="k">def</span> <span class="nf">plot_myarray</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">xlabel</span><span class="p">,</span> <span class="n">ylabel</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Plot an array with labels.</span>

<span class="sd">  Args :</span>
<span class="sd">    array (numpy array of floats)</span>
<span class="sd">    xlabel (string) - label of x-axis</span>
<span class="sd">    ylabel (string) - label of y-axis</span>
<span class="sd">    title  (string) - title of plot</span>

<span class="sd">  Returns:</span>
<span class="sd">    None</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
  <span class="n">colormap</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">8</span><span class="p">])</span>
  <span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">colormap</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
  <span class="n">cbar</span><span class="o">.</span><span class="n">set_label</span><span class="p">(</span><span class="s1">&#39;probability&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
  <span class="k">return</span> <span class="kc">None</span>

<span class="k">def</span> <span class="nf">plot_my_bayes_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
  <span class="sd">&quot;&quot;&quot;Pretty-print a simple Bayes Model (ex 7), defined as a function:</span>

<span class="sd">  Args:</span>
<span class="sd">    - model: function that takes a single parameter value and returns</span>
<span class="sd">             the negative log-likelihood of the model, given that parameter</span>
<span class="sd">  Returns:</span>
<span class="sd">    None, draws plot</span>
<span class="sd">    &quot;&quot;&quot;</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mf">0.07</span><span class="p">)</span>

  <span class="c1"># Plot neg-LogLikelihood for different values of alpha</span>
  <span class="n">alpha_tries</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
  <span class="n">nll</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">alpha_tries</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i_try</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">alpha_tries</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">nll</span><span class="p">[</span><span class="n">i_try</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">alpha_tries</span><span class="p">[</span><span class="n">i_try</span><span class="p">]]))</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alpha_tries</span><span class="p">,</span> <span class="n">nll</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;p_independent value&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;negative log-likelihood&#39;</span><span class="p">)</span>

  <span class="c1"># Mark minima</span>
  <span class="n">ix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">nll</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">alpha_tries</span><span class="p">[</span><span class="n">ix</span><span class="p">],</span> <span class="n">nll</span><span class="p">[</span><span class="n">ix</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">144</span><span class="p">)</span>

  <span class="c1">#plt.axvline(alpha_tries[np.argmin(nll)])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Sample Output&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

  <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">plot_simulated_behavior</span><span class="p">(</span><span class="n">true_stim</span><span class="p">,</span> <span class="n">behaviour</span><span class="p">):</span>
  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_facecolor</span><span class="p">(</span><span class="s1">&#39;xkcd:light grey&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">true_stim</span><span class="p">,</span> <span class="n">true_stim</span> <span class="o">-</span> <span class="n">behaviour</span><span class="p">,</span> <span class="s1">&#39;-k&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Position of true visual stimulus (cm)&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Participant deviation from true stimulus (cm)&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Participant behavior&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

  <span class="k">return</span> <span class="kc">None</span>
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 1: Intro</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s1">&#39;YSKDhnbjKmA&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtube.com/watch?v=&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="Generative model" src="https://github.com/vincentvalton/figures_NMA_W2D1_T3/blob/master/Drawing%20Generative%20Model%20W2T3.png?raw=true" /></p>
<p>Here is a graphical representation of the generative model:</p>
<ol class="simple">
<li><p>We present a stimulus <span class="math notranslate nohighlight">\(x\)</span> to participants.</p></li>
<li><p>The brain encodes this true stimulus <span class="math notranslate nohighlight">\(x\)</span> noisily (this is the brain’s representation of the true visual stimulus: <span class="math notranslate nohighlight">\(p(\tilde x|x)\)</span>.</p></li>
<li><p>The brain then combine this brain encoded stimulus (likelihood: <span class="math notranslate nohighlight">\(p(\tilde x|x)\)</span>) with prior information (the prior: <span class="math notranslate nohighlight">\(p(x)\)</span>) to make up the brain’s estimated position of the true visual stimulus, the posterior: <span class="math notranslate nohighlight">\(p(x|\tilde x)\)</span>.</p></li>
<li><p>This brain’s estimated stimulus position: <span class="math notranslate nohighlight">\(p(x|\tilde x)\)</span>, is then used to make a response:  <span class="math notranslate nohighlight">\(\hat x\)</span>, which is the participant’s noisy estimate of the stimulus position (the participant’s percept).</p></li>
</ol>
<p>Typically the response <span class="math notranslate nohighlight">\(\hat x\)</span> also includes some motor noise (noise due to the hand/arm move being not 100% accurate), but we’ll ignore it in this tutorial and assume there is no motor noise.</p>
<p>We will use the same experimental setup as in <a class="reference external" href="https://colab.research.google.com/drive/15pbgrfGjSKbUQoX51RdcNe3UXb4R5RRx#scrollTo=tF5caxVGYURh">tutorial 2</a> but with slightly different probabilities. This time, participants are told that they need to estimate the sound location of a puppet that is hidden behind a curtain. The participants are told to use auditory information and are also informed that the sound could come from 2 possible causes: a common cause (95% of the time it comes from the puppet hidden behind the curtain at position 0), or an independent cause (5% of the time the sound comes from loud-speakers at more distant locations).</p>
</div>
<hr class="docutils" />
<div class="section" id="section-1-likelihood-array">
<h1>Section 1: Likelihood array<a class="headerlink" href="#section-1-likelihood-array" title="Permalink to this headline">¶</a></h1>
<p>First, we want to create a likelihood, but for the sake of visualization (and to consider all possible brain encodings) we will create multiple likelihoods <span class="math notranslate nohighlight">\(f(x)=p(\tilde x|x)\)</span> (one for each potential encoded stimulus: <span class="math notranslate nohighlight">\(\tilde x\)</span>). We will then be able to visualize the likelihood as a function of hypothesized true stimulus positions: <span class="math notranslate nohighlight">\(x\)</span> on the x-axis and encoded position <span class="math notranslate nohighlight">\(\tilde x\)</span> on the y-axis.</p>
<p>Using the equation for the <code class="docutils literal notranslate"><span class="pre">my_gaussian</span></code> and the values in <code class="docutils literal notranslate"><span class="pre">hypothetical_stim</span></code>:</p>
<ul class="simple">
<li><p>Create a Gaussian likelihood with mean varying from <code class="docutils literal notranslate"><span class="pre">hypothetical_stim</span></code>, keeping <span class="math notranslate nohighlight">\(\sigma_{likelihood}\)</span> constant at 1.</p></li>
<li><p>Each likelihood will have a different mean and thus a different row-likelihood of your 2D array, such that you end up with a likelihood array made up of 1,000 row-Gaussians with different means. (<em>Hint</em>: <code class="docutils literal notranslate"><span class="pre">np.tile</span></code> won’t work here. You may need a for-loop).</p></li>
<li><p>Plot the array using the function <code class="docutils literal notranslate"><span class="pre">plot_myarray()</span></code> already pre-written and commented-out in your script</p></li>
</ul>
<p>###Exercise 1. Implement the auditory likelihood as a function of true stimulus position</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">hypothetical_stim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_likelihood_array</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">stim_array</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>

    <span class="c1"># initializing likelihood_array</span>
    <span class="n">likelihood_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">stim_array</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_points</span><span class="p">)))</span>

    <span class="c1"># looping over stimulus array</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stim_array</span><span class="p">)):</span>
        <span class="c1">########################################################################</span>
        <span class="c1">## Insert your code here to:</span>
        <span class="c1">##      - Generate a likelihood array using `my_gaussian` function,</span>
        <span class="c1">##        with std=1, and varying the mean using `stim_array` values.</span>
        <span class="c1">## remove the raise below to test your function</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;You need to complete the function!&quot;</span><span class="p">)</span>
        <span class="c1">########################################################################</span>
        <span class="n">likelihood_array</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="o">...</span>

    <span class="k">return</span> <span class="n">likelihood_array</span>

<span class="c1"># Uncomment following lines to test your code</span>
<span class="c1"># likelihood_array = compute_likelihood_array(x, hypothetical_stim)</span>
<span class="c1"># plot_myarray(likelihood_array,</span>
<span class="c1">#             &#39;$x$ : Potential true stimulus $x$&#39;,</span>
<span class="c1">#             &#39;Possible brain encoding $\~x$&#39;,</span>
<span class="c1">#             &#39;Likelihood as a function of $\~x$ : $p(\~x | x)$&#39;)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D1_BayesianDecisions/solutions/W3D1_Tutorial3_Solution_5883eb88.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=557 height=414 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D1_BayesianDecisions/static/W3D1_Tutorial3_Solution_5883eb88_0.png>
</div>
<hr class="docutils" />
<div class="section" id="section-2-causal-mixture-of-gaussian-prior">
<h1>Section 2: Causal mixture of Gaussian prior<a class="headerlink" href="#section-2-causal-mixture-of-gaussian-prior" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 2: Prior array</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s1">&#39;F0IYpUicXu4&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtube.com/watch?v=&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>As in Tutorial 2, we want to create a prior that will describe the participants’ prior knowledge that, 95% of the time sounds come from a common position around the puppet, while during the remaining 5% of the time, they arise from another independent position. We will embody this information into a prior using a mixture of Gaussians. For visualization reasons, we will create a prior that has the same shape (form) as the likelihood array we created in the previous exercise. That is, we want to create a mixture of Gaussian prior as a function the the brain encoded stimulus <span class="math notranslate nohighlight">\(\tilde x\)</span>. Since the prior does not change as a function of <span class="math notranslate nohighlight">\(\tilde x\)</span> it will be identical for each row of the prior 2D array.</p>
<p>Using the equation for the Gaussian <code class="docutils literal notranslate"><span class="pre">my_gaussian</span></code>:</p>
<ul class="simple">
<li><p>Generate a Gaussian <span class="math notranslate nohighlight">\(Common\)</span> with mean 0 and standard deviation 0.5</p></li>
<li><p>Generate another Gaussian <span class="math notranslate nohighlight">\(Independent\)</span> with mean 0 and standard deviation 10</p></li>
<li><p>Combine the two Gaussians (Common + Independent) to make a new prior by mixing the two Gaussians with mixing parameter <span class="math notranslate nohighlight">\(p_{independent}\)</span> = 0.05. Make it such that the peakier Gaussian has 95% of the weight (don’t forget to normalize afterwards)</p></li>
<li><p>This will be the first row of your prior 2D array</p></li>
<li><p>Now repeat this for varying brain encodings <span class="math notranslate nohighlight">\(\tilde x\)</span>. Since the prior does not depend on <span class="math notranslate nohighlight">\(\tilde x\)</span> you can just repeat the prior for each <span class="math notranslate nohighlight">\(\tilde x\)</span> (hint: use np.tile) that row prior to make an array of 1,000 (i.e. <code class="docutils literal notranslate"><span class="pre">hypothetical_stim.shape[0]</span></code>)  row-priors.</p></li>
<li><p>Plot the matrix using the function <code class="docutils literal notranslate"><span class="pre">plot_myarray()</span></code> already pre-written and commented-out in your script</p></li>
</ul>
<div class="section" id="exercise-2-implement-the-prior-array">
<h2>Exercise 2: Implement the prior array<a class="headerlink" href="#exercise-2-implement-the-prior-array" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">calculate_prior_array</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">stim_array</span><span class="p">,</span> <span class="n">p_indep</span><span class="p">,</span>
                          <span class="n">prior_mean_common</span><span class="o">=</span><span class="mf">.0</span><span class="p">,</span> <span class="n">prior_sigma_common</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span>
                          <span class="n">prior_mean_indep</span><span class="o">=</span><span class="mf">.0</span><span class="p">,</span> <span class="n">prior_sigma_indep</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        &#39;common&#39; stands for common</span>
<span class="sd">        &#39;indep&#39; stands for independent</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">prior_common</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">prior_mean_common</span><span class="p">,</span> <span class="n">prior_sigma_common</span><span class="p">)</span>
    <span class="n">prior_indep</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">prior_mean_indep</span><span class="p">,</span> <span class="n">prior_sigma_indep</span><span class="p">)</span>

    <span class="c1">############################################################################</span>
    <span class="c1">## Insert your code here to:</span>
    <span class="c1">##      - Create a mixture of gaussian priors from &#39;prior_common&#39;</span>
    <span class="c1">##        and &#39;prior_indep&#39; with mixing parameter &#39;p_indep&#39;</span>
    <span class="c1">##      - normalize</span>
    <span class="c1">##      - repeat the prior array and reshape it to make a 2D array</span>
    <span class="c1">##        of 1000 rows of priors (Hint: use np.tile() and np.reshape())</span>
    <span class="c1">## remove the raise below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;You need to complete the function!&quot;</span><span class="p">)</span>
    <span class="c1">############################################################################</span>

    <span class="n">prior_mixed</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">prior_mixed</span> <span class="o">/=</span> <span class="o">...</span>  <span class="c1"># normalize</span>

    <span class="n">prior_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="o">...</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">prior_array</span>

<span class="n">p_independent</span><span class="o">=</span><span class="mf">.05</span>
<span class="c1"># Uncomment following lines, once the task is complete.</span>
<span class="c1"># prior_array = calculate_prior_array(x, hypothetical_stim, p_independent)</span>
<span class="c1"># plot_myarray(prior_array,</span>
<span class="c1">#              &#39;Hypothesized position $x$&#39;, &#39;Brain encoded position $\~x$&#39;,</span>
<span class="c1">#              &#39;Prior as a fcn of $\~x$ : $p(x|\~x)$&#39;)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D1_BayesianDecisions/solutions/W3D1_Tutorial3_Solution_dddc3e14.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=555 height=413 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D1_BayesianDecisions/static/W3D1_Tutorial3_Solution_dddc3e14_0.png>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-3-bayes-rule-and-posterior-array">
<h1>Section 3: Bayes rule and Posterior array<a class="headerlink" href="#section-3-bayes-rule-and-posterior-array" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 3: Posterior array</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s1">&#39;HpOzXZUKFJc&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtube.com/watch?v=&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>We now want to calcualte the posterior using <em>Bayes Rule</em>. Since we have already created a likelihood and a prior for each brain encoded position <span class="math notranslate nohighlight">\(\tilde x\)</span>, all we need to do is to multiply them row-wise. That is, each row of the posterior array will be the posterior resulting from the multiplication of the prior and likelihood of the same equivalent row.</p>
<p>Mathematically:</p>
<div class="amsmath math notranslate nohighlight" id="equation-14fd02d6-772d-42c9-b045-63c7007fbf4a">
<span class="eqno">(167)<a class="headerlink" href="#equation-14fd02d6-772d-42c9-b045-63c7007fbf4a" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
    Posterior\left[i, :\right] \propto Likelihood\left[i, :\right] \odot Prior\left[i, :\right]
\end{eqnarray}\]</div>
<p>where <span class="math notranslate nohighlight">\(\odot\)</span> represents the <a class="reference external" href="https://en.wikipedia.org/wiki/Hadamard_product_(matrices)">Hadamard Product</a> (i.e., elementwise multiplication) of the corresponding prior and likelihood row vectors <code class="docutils literal notranslate"><span class="pre">i</span></code> from each matrix.</p>
<p>Follow these steps to build the posterior as a function of the brain encoded stimulus <span class="math notranslate nohighlight">\(\tilde x\)</span>:</p>
<ul class="simple">
<li><p>For each row of the prior and likelihood (i.e. each possible brain encoding <span class="math notranslate nohighlight">\(\tilde x\)</span>), fill in the posterior matrix so that every row of the posterior array represents the posterior density for a different brain encode  <span class="math notranslate nohighlight">\(\tilde x\)</span>.</p></li>
<li><p>Plot the array using the function <code class="docutils literal notranslate"><span class="pre">plot_myarray()</span></code> already pre-written and commented-out in your script</p></li>
</ul>
<p>Optional:</p>
<ul class="simple">
<li><p>Do you need to operate on one element–or even one row–at a time? NumPy operations can often process an entire matrix in a single “vectorized” operation. This approach is often much faster and much easier to read than an element-by-element calculation.  Try to write a vectorized version that calculates the posterior without using any for-loops. <em>Hint</em>: look at <code class="docutils literal notranslate"><span class="pre">np.sum</span></code> and its keyword arguments.</p></li>
</ul>
<div class="section" id="exercise-3-calculate-the-posterior-as-a-function-of-the-hypothetical-stimulus-x">
<h2>Exercise 3: Calculate the posterior as a function of the hypothetical stimulus x<a class="headerlink" href="#exercise-3-calculate-the-posterior-as-a-function-of-the-hypothetical-stimulus-x" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_posterior_array</span><span class="p">(</span><span class="n">prior_array</span><span class="p">,</span> <span class="n">likelihood_array</span><span class="p">):</span>

    <span class="c1">############################################################################</span>
    <span class="c1">## Insert your code here to:</span>
    <span class="c1">##      - calculate the &#39;posterior_array&#39; from the given</span>
    <span class="c1">##        &#39;prior_array&#39;, &#39;likelihood_array&#39;</span>
    <span class="c1">##      - normalize</span>
    <span class="c1">## remove the raise below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;You need to complete the function!&quot;</span><span class="p">)</span>
    <span class="c1">############################################################################</span>
    <span class="n">posterior_array</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">posterior_array</span> <span class="o">/=</span> <span class="o">...</span>  <span class="c1"># normalize each row separately</span>

    <span class="k">return</span> <span class="n">posterior_array</span>

<span class="c1"># Uncomment following lines, once the task is complete.</span>
<span class="c1"># posterior_array = calculate_posterior_array(prior_array, likelihood_array)</span>
<span class="c1"># plot_myarray(posterior_array,</span>
<span class="c1">#              &#39;Hypothesized Position $x$&#39;,</span>
<span class="c1">#              &#39;Brain encoded Stimulus $\~x$&#39;,</span>
<span class="c1">#              &#39;Posterior as a fcn of $\~x$ : $p(x | \~x)$&#39;)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D1_BayesianDecisions/solutions/W3D1_Tutorial3_Solution_3b290b41.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=555 height=413 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D1_BayesianDecisions/static/W3D1_Tutorial3_Solution_3b290b41_0.png>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-4-estimating-the-position-hat-x">
<h1>Section 4: Estimating the position <span class="math notranslate nohighlight">\(\hat x\)</span><a class="headerlink" href="#section-4-estimating-the-position-hat-x" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 4: Binary decision matrix</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s1">&#39;gy3GmlssHgQ&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtube.com/watch?v=&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we have a posterior distribution (for each possible brain encoding <span class="math notranslate nohighlight">\(\tilde x\)</span>)that represents the brain’s estimated stimulus position: <span class="math notranslate nohighlight">\(p(x|\tilde x)\)</span>, we want to make an estimate (response) of the sound location <span class="math notranslate nohighlight">\(\hat x\)</span> using the posterior distribution. This would represent the subject’s estimate if their (for us as experimentalist unobservable) brain encoding took on each possible value.</p>
<p>This effectively encodes the <em>decision</em> that a participant would make for a given brain encoding <span class="math notranslate nohighlight">\(\tilde x\)</span>. In this exercise, we make the assumptions that participants take the mean of the posterior (decision rule) as a response estimate for the sound location (use the function <code class="docutils literal notranslate"><span class="pre">moments_myfunc()</span></code> provided to calculate the mean of the posterior).</p>
<p>Using this knowledge, we will now represent <span class="math notranslate nohighlight">\(\hat x\)</span> as a function of the encoded stimulus <span class="math notranslate nohighlight">\(\tilde x\)</span>. This will result in a 2D binary decision array. To do so, we will scan the posterior matrix (i.e. row-wise), and set the array cell value to 1 at the mean of the row-wise posterior.</p>
<p><strong>Suggestions</strong></p>
<ul class="simple">
<li><p>For each brain encoding <span class="math notranslate nohighlight">\(\tilde x\)</span> (row of the posterior array), calculate the mean of the posterior, and set the corresponding cell of the binary decision array to 1. (e.g., if the mean of the posterior is at position 0, then set the cell with x_column == 0 to 1).</p></li>
<li><p>Plot the matrix using the function <code class="docutils literal notranslate"><span class="pre">plot_myarray()</span></code> already pre-written and commented-out in your script</p></li>
</ul>
<div class="section" id="exercise-4-calculate-the-estimated-response-as-a-function-of-the-hypothetical-stimulus-x">
<h2>Exercise 4: Calculate the estimated response as a function of the hypothetical stimulus x<a class="headerlink" href="#exercise-4-calculate-the-estimated-response-as-a-function-of-the-hypothetical-stimulus-x" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_binary_decision_array</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">posterior_array</span><span class="p">):</span>

    <span class="n">binary_decision_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">posterior_array</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">posterior_array</span><span class="p">)):</span>

        <span class="c1">########################################################################</span>
        <span class="c1">## Insert your code here to:</span>
        <span class="c1">##      - For each hypothetical stimulus x (row of posterior),</span>
        <span class="c1">##        calculate the mean of the posterior using the povided function</span>
        <span class="c1">##        `moments_myfunc()`, and set the corresponding cell of the</span>
        <span class="c1">##        Binary Decision array to 1.</span>
        <span class="c1">##        Hint: you can run &#39;help(moments_myfunc)&#39; to see the docstring</span>
        <span class="c1">## remove the raise below to test your function</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;You need to complete the function!&quot;</span><span class="p">)</span>
        <span class="c1">########################################################################</span>
        <span class="c1"># calculate mean of posterior using &#39;moments_myfunc&#39;</span>
        <span class="n">mean</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="o">...</span>
        <span class="c1"># find the postion of mean in x_points (closest position)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="o">...</span>
        <span class="n">binary_decision_array</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">binary_decision_array</span>

<span class="c1"># Uncomment following lines, once the task is complete.</span>
<span class="c1"># binary_decision_array = calculate_binary_decision_array(x, posterior_array)</span>
<span class="c1"># plot_myarray(binary_decision_array,</span>
<span class="c1">#              &#39;Chosen position $\hat x$&#39;, &#39;Brain-encoded Stimulus $\~ x$&#39;,</span>
<span class="c1">#              &#39;Sample Binary Decision Array&#39;)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D1_BayesianDecisions/solutions/W3D1_Tutorial3_Solution_0cd39fa7.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=547 height=413 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D1_BayesianDecisions/static/W3D1_Tutorial3_Solution_0cd39fa7_0.png>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-5-probabilities-of-encoded-stimuli">
<h1>Section 5: Probabilities of encoded stimuli<a class="headerlink" href="#section-5-probabilities-of-encoded-stimuli" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 5: Input array</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s1">&#39;C1d1n_Si83o&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtube.com/watch?v=&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>Because we as experimentalists can not know the encoding <span class="math notranslate nohighlight">\(\tilde x\)</span> of the stimulus <span class="math notranslate nohighlight">\(x\)</span> that we do know, we had to compute the binary decision array for each possible encoding.</p>
<p>First however, we need to calculate how likely each possible encoding is given the true stimulus. That is, we will now create a Gaussian centered around the true presented stimulus, with <span class="math notranslate nohighlight">\(\sigma = 1\)</span>, and repeat that gaussian distribution across as a function of potentially encoded values <span class="math notranslate nohighlight">\(\tilde x\)</span>. That is, we want to make a <em>column</em> gaussian centered around the true presented stimulus, and repeat this <em>column</em> Gaussian across all hypothetical stimulus values <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>This, effectively encodes the distribution of the brain encoded stimulus (one single simulus, which we as experimentalists know) and enable us to link the true stimulus <span class="math notranslate nohighlight">\(x\)</span>, to potential encodings <span class="math notranslate nohighlight">\(\tilde x\)</span>.</p>
<p><strong>Suggestions</strong></p>
<p>For this exercise, we will assume the true stimulus is presented at direction 2.5</p>
<ul class="simple">
<li><p>Create a Gaussian likelihood with <span class="math notranslate nohighlight">\(\mu = 2.5\)</span> and <span class="math notranslate nohighlight">\(\sigma = 1.0\)</span></p></li>
<li><p>Make this the first column of your array and repeat that <em>column</em> to fill in the true presented stimulus input as a function of hypothetical stimulus locations.</p></li>
<li><p>Plot the array using the function <code class="docutils literal notranslate"><span class="pre">plot_myarray()</span></code> already pre-written and commented-out in your script</p></li>
</ul>
<p>###Exercise 5: Generate an input as a function of hypothetical stimulus x</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_input_array</span><span class="p">(</span><span class="n">x_points</span><span class="p">,</span> <span class="n">stim_array</span><span class="p">,</span> <span class="n">posterior_array</span><span class="p">,</span>
                         <span class="n">mean</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>

    <span class="n">input_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">posterior_array</span><span class="p">)</span>

    <span class="c1">########################################################################</span>
    <span class="c1">## Insert your code here to:</span>
    <span class="c1">##      - Generate a gaussian centered on the true stimulus 2.5</span>
    <span class="c1">##        and sigma = 1. for each column</span>
    <span class="c1">## remove the raise below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;You need to complete the function!&quot;</span><span class="p">)</span>
    <span class="c1">########################################################################</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_points</span><span class="p">)):</span>
        <span class="n">input_array</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span>

    <span class="k">return</span> <span class="n">input_array</span>

<span class="c1"># Uncomment following lines, once the task is complete.</span>
<span class="c1"># input_array = generate_input_array(x, hypothetical_stim, posterior_array)</span>
<span class="c1"># plot_myarray(input_array,</span>
<span class="c1">#              &#39;Hypothetical Stimulus $x$&#39;, &#39;$\~x$&#39;,</span>
<span class="c1">#              &#39;Sample Distribution over Encodings:\n $p(\~x | x = 2.5)$&#39;)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D1_BayesianDecisions/solutions/W3D1_Tutorial3_Solution_f61fa492.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=557 height=413 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D1_BayesianDecisions/static/W3D1_Tutorial3_Solution_f61fa492_0.png>
</div>
<hr class="docutils" />
<div class="section" id="section-6-normalization-and-expected-estimate-distribution">
<h1>Section 6: Normalization and expected estimate distribution<a class="headerlink" href="#section-6-normalization-and-expected-estimate-distribution" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 6: Marginalization</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s1">&#39;5alwtNS4CGw&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtube.com/watch?v=&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we have a true stimulus <span class="math notranslate nohighlight">\(x\)</span> and a way to link it to potential encodings, we will be able to calculate the distribution of encodings and ultimately estimates. To integrate over all possible hypothetical values of <span class="math notranslate nohighlight">\(\tilde x\)</span> we marginalize, that is, we first compute the dot-product from the true presented stimulus and our binary decision array and then sum over x.</p>
<p>Mathematically, this means that we want to compute:</p>
<div class="amsmath math notranslate nohighlight" id="equation-8a97085b-6be4-4f2d-9477-53bf28705a09">
<span class="eqno">(168)<a class="headerlink" href="#equation-8a97085b-6be4-4f2d-9477-53bf28705a09" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
    Marginalization Array = Input Array \odot Binary Decision Array
\end{eqnarray}\]</div>
<div class="amsmath math notranslate nohighlight" id="equation-6eb1cad6-0ab7-4d3e-9661-401f41cf301e">
<span class="eqno">(169)<a class="headerlink" href="#equation-6eb1cad6-0ab7-4d3e-9661-401f41cf301e" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
    Marginal = \int_{\tilde x} Marginalization Array
\end{eqnarray}\]</div>
<p>Since we are performing integration over discrete values using arrays for visualization purposes, the integration reduces to a simple sum over <span class="math notranslate nohighlight">\(\tilde x\)</span>.</p>
<p><strong>Suggestions</strong></p>
<ul class="simple">
<li><p>For each row of the input and binary arrays, calculate product of the two and fill in the 2D marginal array.</p></li>
<li><p>Plot the result using the function <code class="docutils literal notranslate"><span class="pre">plot_myarray()</span></code> already pre-written and commented-out in your script</p></li>
<li><p>Calculate and plot the marginal over <code class="docutils literal notranslate"><span class="pre">x</span></code> using the code snippet commented out in your script</p>
<ul>
<li><p>Note how the limitations of numerical integration create artifacts on your marginal</p></li>
</ul>
</li>
</ul>
<p>###Exercise 6: Implement the marginalization matrix</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_marginalization</span><span class="p">(</span><span class="n">input_array</span><span class="p">,</span> <span class="n">binary_decision_array</span><span class="p">):</span>

    <span class="c1">############################################################################</span>
    <span class="c1">## Insert your code here to:</span>
    <span class="c1">##  - Compute &#39;marginalization_array&#39; by multiplying pointwise the Binary</span>
    <span class="c1">##    decision array over hypothetical stimuli and the Input array</span>
    <span class="c1">##  - Compute &#39;marginal&#39; from the &#39;marginalization_array&#39; by summing over x</span>
    <span class="c1">##    (hint: use np.sum() and only marginalize along the columns)</span>
    <span class="c1">## remove the raise below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;You need to complete the function!&quot;</span><span class="p">)</span>
    <span class="c1">############################################################################</span>

    <span class="n">marginalization_array</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">marginal</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># note axis</span>
    <span class="n">marginal</span> <span class="o">/=</span> <span class="o">...</span> <span class="c1"># normalize</span>

    <span class="k">return</span> <span class="n">marginalization_array</span><span class="p">,</span> <span class="n">marginal</span>

<span class="c1"># Uncomment following lines, once the task is complete.</span>
<span class="c1"># marginalization_array, marginal = my_marginalization(input_array, binary_decision_array)</span>
<span class="c1"># plot_myarray(marginalization_array, &#39;estimated $\hat x$&#39;, &#39;$\~x$&#39;, &#39;Marginalization array: $p(\^x | \~x)$&#39;)</span>
<span class="c1"># plt.figure()</span>
<span class="c1"># plt.plot(x, marginal)</span>
<span class="c1"># plt.xlabel(&#39;$\^x$&#39;)</span>
<span class="c1"># plt.ylabel(&#39;probability&#39;)</span>
<span class="c1"># plt.show()</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D1_BayesianDecisions/solutions/W3D1_Tutorial3_Solution_3560aec0.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=553 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D1_BayesianDecisions/static/W3D1_Tutorial3_Solution_3560aec0_0.png>
<img alt='Solution hint' align='left' width=560 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D1_BayesianDecisions/static/W3D1_Tutorial3_Solution_3560aec0_1.png>
</div>
<hr class="docutils" />
<div class="section" id="generate-some-data">
<h1>Generate some data<a class="headerlink" href="#generate-some-data" title="Permalink to this headline">¶</a></h1>
<p>We have seen how to calculate the posterior and marginalize to remove <span class="math notranslate nohighlight">\(\tilde x\)</span> and get <span class="math notranslate nohighlight">\(p(\hat{x} \mid x)\)</span>. Next, we will generate some artificial data for a single participant using the <code class="docutils literal notranslate"><span class="pre">generate_data()</span></code> function provided, and mixing parameter <span class="math notranslate nohighlight">\(p_{independent} = 0.1\)</span>.</p>
<p>Our goal in the next exercise will be to recover that parameter. These parameter recovery experiments are a powerful method for planning and debugging Bayesian analyses–if you cannot recover the given parameters, something has gone wrong! Note that this value for <span class="math notranslate nohighlight">\(p_{independent}\)</span> is not quite the same as our prior, which used <span class="math notranslate nohighlight">\(p_{independent} = 0.05.\)</span> This lets us test out the complete model.</p>
<p>Please run the code below to generate some synthetic data.  You do not need to edit anything, but check that the plot below matches what you would expect from the video.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title</span>
<span class="c1">#@markdown #### Run the &#39;generate_data&#39; function (this cell)</span>
<span class="k">def</span> <span class="nf">generate_data</span><span class="p">(</span><span class="n">x_stim</span><span class="p">,</span> <span class="n">p_independent</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  DO NOT EDIT THIS FUNCTION !!!</span>

<span class="sd">  Returns generated data using the mixture of Gaussian prior with mixture</span>
<span class="sd">  parameter `p_independent`</span>

<span class="sd">  Args :</span>
<span class="sd">    x_stim (numpy array of floats) - x values at which stimuli are presented</span>
<span class="sd">    p_independent (scalar) - mixture component for the Mixture of Gaussian prior</span>

<span class="sd">  Returns:</span>
<span class="sd">    (numpy array of floats): x_hat response of participant for each stimulus</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span>
  <span class="n">x_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x_stim</span><span class="p">)</span>

  <span class="n">prior_mean</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">prior_sigma1</span> <span class="o">=</span> <span class="mf">.5</span>
  <span class="n">prior_sigma2</span> <span class="o">=</span> <span class="mi">3</span>
  <span class="n">prior1</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_sigma1</span><span class="p">)</span>
  <span class="n">prior2</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">,</span> <span class="n">prior_sigma2</span><span class="p">)</span>

  <span class="n">prior_combined</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p_independent</span><span class="p">)</span> <span class="o">*</span> <span class="n">prior1</span> <span class="o">+</span> <span class="p">(</span><span class="n">p_independent</span> <span class="o">*</span> <span class="n">prior2</span><span class="p">)</span>
  <span class="n">prior_combined</span> <span class="o">=</span> <span class="n">prior_combined</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">prior_combined</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">i_stim</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x_stim</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">likelihood_mean</span> <span class="o">=</span> <span class="n">x_stim</span><span class="p">[</span><span class="n">i_stim</span><span class="p">]</span>
    <span class="n">likelihood_sigma</span>  <span class="o">=</span> <span class="mi">1</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">likelihood_mean</span><span class="p">,</span> <span class="n">likelihood_sigma</span><span class="p">)</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">likelihood</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">likelihood</span><span class="p">)</span>

    <span class="n">posterior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">prior_combined</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">posterior</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>

    <span class="c1"># Assumes participant takes posterior mean as &#39;action&#39;</span>
    <span class="n">x_hat</span><span class="p">[</span><span class="n">i_stim</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">posterior</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">x_hat</span>

<span class="c1"># Generate data for a single participant</span>
<span class="n">true_stim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.5</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>
                      <span class="mf">2.5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="n">behaviour</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="n">true_stim</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">)</span>

<span class="n">plot_simulated_behavior</span><span class="p">(</span><span class="n">true_stim</span><span class="p">,</span> <span class="n">behaviour</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p>#Section 7: Model fitting</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 7: Log likelihood</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s1">&#39;jbYauFpyZhs&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtube.com/watch?v=&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we have generated some data, we will attempt to recover the parameter <span class="math notranslate nohighlight">\(p_{independent}\)</span> that was used to generate it.</p>
<p>We have provided you with an incomplete function called <code class="docutils literal notranslate"><span class="pre">my_Bayes_model_mse()</span></code> that needs to be completed to perform the same computations you have performed in the previous exercises but over all the participant’s trial, as opposed to a single trial.</p>
<p>The likelihood has already been constructed; since it depends  only on the hypothetical stimuli, it will not change. However, we will have to implement the prior matrix, since it depends on <span class="math notranslate nohighlight">\(p_{independent}\)</span>. We will therefore have to recompute the posterior, input and the marginal in order to get <span class="math notranslate nohighlight">\(p(\hat{x} \mid x)\)</span>.</p>
<p>Using <span class="math notranslate nohighlight">\(p(\hat{x} \mid x)\)</span>, we will then compute the negative log-likelihood for each trial and find the value of <span class="math notranslate nohighlight">\(p_{independent}\)</span> that minimizes the negative log-likelihood (i.e. maximises the log-likelihood.  See the model fitting tutorial from W1D3 for a refresher).</p>
<p>In this experiment, we assume that trials are independent from one another. This is a common assumption–and it’s often even true! It allows us to define negative log-likelihood as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-44eff9d9-c061-418e-83aa-6c365b817a9d">
<span class="eqno">(170)<a class="headerlink" href="#equation-44eff9d9-c061-418e-83aa-6c365b817a9d" title="Permalink to this equation">¶</a></span>\[\begin{eqnarray}
    -LL = - \sum_i \log p(\hat{x}_i \mid x_i)
\end{eqnarray}\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{x}_i\)</span> is the participant’s response for trial <span class="math notranslate nohighlight">\(i\)</span>, with presented stimulus <span class="math notranslate nohighlight">\(x_i\)</span></p>
<ul class="simple">
<li><p>Complete the function <code class="docutils literal notranslate"><span class="pre">my_Bayes_model_mse</span></code>, we’ve already pre-completed the function to give you the prior, posterior, and input arrays on each trial</p></li>
<li><p>Compute the marginalization array as well as the marginal on each trial</p></li>
<li><p>Compute the negative log likelihood using the marginal and the participant’s response</p></li>
<li><p>Using the code snippet commented out in your script to loop over possible values of <span class="math notranslate nohighlight">\(p_{independent}\)</span></p></li>
</ul>
<p>###Exercise 7: Fitting a model to generated data</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_Bayes_model_mse</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function fits the Bayesian model from Tutorial 4</span>

<span class="sd">    Args :</span>
<span class="sd">        params (list of positive floats):  parameters used by the model</span>
<span class="sd">        (params[0]  = posterior scaling)</span>

<span class="sd">    Returns :</span>
<span class="sd">        (scalar) negative log-likelihood :sum of log probabilities</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Create the prior array</span>
    <span class="n">p_independent</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">prior_array</span> <span class="o">=</span> <span class="n">calculate_prior_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>
                                        <span class="n">hypothetical_stim</span><span class="p">,</span>
                                        <span class="n">p_independent</span><span class="p">,</span>
                                        <span class="n">prior_sigma_indep</span><span class="o">=</span> <span class="mf">3.</span><span class="p">)</span>

    <span class="c1"># Create posterior array</span>
    <span class="n">posterior_array</span> <span class="o">=</span> <span class="n">calculate_posterior_array</span><span class="p">(</span><span class="n">prior_array</span><span class="p">,</span> <span class="n">likelihood_array</span><span class="p">)</span>

    <span class="c1"># Create Binary decision array</span>
    <span class="n">binary_decision_array</span> <span class="o">=</span> <span class="n">calculate_binary_decision_array</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">posterior_array</span><span class="p">)</span>

    <span class="c1"># we will use trial_ll (trial log likelihood) to register each trial</span>
    <span class="n">trial_ll</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">true_stim</span><span class="p">)</span>

    <span class="c1"># Loop over stimuli</span>
    <span class="k">for</span> <span class="n">i_stim</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">true_stim</span><span class="p">)):</span>

        <span class="c1"># create the input array with true_stim as mean</span>
        <span class="n">input_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">posterior_array</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
            <span class="n">input_array</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">my_gaussian</span><span class="p">(</span><span class="n">hypothetical_stim</span><span class="p">,</span> <span class="n">true_stim</span><span class="p">[</span><span class="n">i_stim</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">input_array</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_array</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">input_array</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span>

        <span class="c1"># calculate the marginalizations</span>
        <span class="n">marginalization_array</span><span class="p">,</span> <span class="n">marginal</span> <span class="o">=</span> <span class="n">my_marginalization</span><span class="p">(</span><span class="n">input_array</span><span class="p">,</span>
                                                    <span class="n">binary_decision_array</span><span class="p">)</span>

        <span class="n">action</span> <span class="o">=</span> <span class="n">behaviour</span><span class="p">[</span><span class="n">i_stim</span><span class="p">]</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">action</span><span class="p">))</span>

        <span class="c1">########################################################################</span>
        <span class="c1">## Insert your code here to:</span>
        <span class="c1">##      - Compute the log likelihood of the participant</span>
        <span class="c1">## remove the raise below to test your function</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;You need to complete the function!&quot;</span><span class="p">)</span>
        <span class="c1">########################################################################</span>

        <span class="c1"># Get the marginal likelihood corresponding to the action</span>
        <span class="n">marginal_nonzero</span> <span class="o">=</span> <span class="o">...</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>  <span class="c1"># avoid log(0)</span>
        <span class="n">trial_ll</span><span class="p">[</span><span class="n">i_stim</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">marginal_nonzero</span><span class="p">)</span>

    <span class="n">neg_ll</span> <span class="o">=</span> <span class="o">-</span> <span class="n">trial_ll</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">neg_ll</span>

<span class="c1"># Uncomment following lines, once the task is complete.</span>
<span class="c1"># plot_my_bayes_model(my_Bayes_model_mse)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D1_BayesianDecisions/solutions/W3D1_Tutorial3_Solution_fe350657.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=559 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D1_BayesianDecisions/static/W3D1_Tutorial3_Solution_fe350657_0.png>
</div>
<div class="section" id="section-8-summary">
<h1>Section 8: Summary<a class="headerlink" href="#section-8-summary" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 8: Outro</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s1">&#39;F5JfqJonz20&#39;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtube.com/watch?v=&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>Congratuations! You found <span class="math notranslate nohighlight">\(p_{independent}\)</span>, the parameter that describes how much weight subjects assign to the same-cause vs. independent-cause origins of a sound. In the preceeding notebooks, we went through the entire Bayesian analysis pipeline:</p>
<ul class="simple">
<li><p>developing a model</p></li>
<li><p>simulating data, and</p></li>
<li><p>using Bayes’ Rule and marginalization to recover a hidden parameter from the data</p></li>
</ul>
<p>This example was simple, but the same princples can be used to analyze datasets with many hidden variables and complex priors and likelihoods. Bayes’ Rule will also play a cruical role in many of the other techniques you will see later this week.</p>
<hr class="docutils" />
<p>If you’re still intrigued as to why we decided to use the mean of the posterior as a decision rule for a response <span class="math notranslate nohighlight">\(\hat{x}\)</span>, we have an extra Bonus Tutorial 4 which goes through the most common decision rules and how these rules correspond to minimizing different cost functions.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W3D1_BayesianDecisions/student"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="W3D1_Tutorial2.html" title="previous page">Tutorial 2: Bayesian inference and decisions with continuous hidden state</a>
    <a class='right-next' id="next-link" href="../W3D1_Outro.html" title="next page">Outro</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Neuromatch<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>