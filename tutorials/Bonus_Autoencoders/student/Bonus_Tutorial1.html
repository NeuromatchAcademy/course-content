
<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="Docutils 0.18.1: http://docutils.sourceforge.net/" name="generator"/>
<title>Tutorial 1: Intro to Autoencoders — Neuromatch Academy: Computational Neuroscience</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../../../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/styles/sphinx-book-theme.css?digest=4ec06e9971c5264fbd345897d5258098f11cc577" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css">
<link href="../../../_static/custom.css" rel="stylesheet" type="text/css">
<link href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94" rel="preload"/>
<link as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script src="../../../_static/scripts/sphinx-book-theme.js?digest=8bf782fb4ee92b3d3646425e50f299c4e1fd152d"></script>
<script>let toggleHintShow = 'Click to show';</script>
<script>let toggleHintHide = 'Click to hide';</script>
<script>let toggleOpenOnPrint = 'true';</script>
<script src="../../../_static/togglebutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
<script src="../../../_static/design-tabs.js"></script>
<script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
<script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/Bonus_Autoencoders/student/Bonus_Tutorial1';</script>
<link href="../../../_static/nma-logo-square-4xp.png" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index">
<link href="../../../search.html" rel="search" title="Search"/>
<link href="Bonus_Tutorial2.html" rel="next" title="Tutorial 2: Autoencoder extensions"/>
<link href="Bonus_Intro.html" rel="prev" title="Intro"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</link></link></link></link></link></link></link></link></link></head>
<body data-default-mode="" data-offset="180" data-spy="scroll" data-target="#bd-toc-nav">
<a class="skip-link" href="#main-content">Skip to main content</a>
<input class="sidebar-toggle" id="__primary" name="__primary" type="checkbox"/>
<label class="overlay overlay-primary" for="__primary"></label>
<input class="sidebar-toggle" id="__secondary" name="__secondary" type="checkbox"/>
<label class="overlay overlay-secondary" for="__secondary"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
</div>
<nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
<label class="sidebar-toggle primary-toggle" for="__primary">
<span class="fa-solid fa-bars"></span>
</label>
<div id="navbar-start">
<a class="navbar-brand logo" href="../../intro.html">
<img alt="Logo image" class="logo__image only-light" src="../../../_static/nma-logo-square-4xp.png"/>
<img alt="Logo image" class="logo__image only-dark" src="../../../_static/nma-logo-square-4xp.png"/>
</a>
</div>
<div class="col-lg-9 navbar-header-items">
<div class="mr-auto" id="navbar-center">
<div class="navbar-center-item">
<nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
        Site Navigation
    </p>
<ul class="navbar-nav" id="navbar-main-elements">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Schedule/schedule_intro.html">
                        Schedule
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../prereqs/ComputationalNeuroscience.html">
                        Prerequisites and preparatory materials for NMA Computational Neuroscience
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D0_NeuroVideoSeries/chapter_title.html">
                        Neuro Video Series (W0D0)
                      </a>
</li>
<div class="nav-item dropdown">
<button aria-expanded="false" aria-haspopup="true" class="btn dropdown-toggle nav-item" data-toggle="dropdown" type="button">
                    More
                </button>
<div class="dropdown-menu">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">
                        Python Workshop 1 (W0D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">
                        Python Workshop 2 (W0D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D3_LinearAlgebra/chapter_title.html">
                        Linear Algebra (W0D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D4_Calculus/chapter_title.html">
                        Calculus (W0D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D5_Statistics/chapter_title.html">
                        Statistics (W0D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D1_ModelTypes/chapter_title.html">
                        Model Types (W1D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D1_ModelingPractice/chapter_title.html">
                        Modeling Practice (W2D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D2_ModelFitting/chapter_title.html">
                        Model Fitting (W1D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D3_GeneralizedLinearModels/chapter_title.html">
                        Generalized Linear Models (W1D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D4_DimensionalityReduction/chapter_title.html">
                        Dimensionality Reduction (W1D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D5_DeepLearning/chapter_title.html">
                        Deep Learning (W1D5)
                      </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../chapter_title.html">
                        Autoencoders (Bonus)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Module_WrapUps/MachineLearning.html">
                        Machine Learning Wrap-Up
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D2_LinearSystems/chapter_title.html">
                        Linear Systems (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D3_BiologicalNeuronModels/chapter_title.html">
                        Biological Neuron Models (W2D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D4_DynamicNetworks/chapter_title.html">
                        Dynamic Networks (W2D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Module_WrapUps/DynamicalSystems.html">
                        Dynamical Systems Wrap-Up
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W3D1_BayesianDecisions/chapter_title.html">
                        Bayesian Decisions (W3D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W3D2_HiddenDynamics/chapter_title.html">
                        Hidden Dynamics (W3D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W3D3_OptimalControl/chapter_title.html">
                        Optimal Control (W3D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W3D4_ReinforcementLearning/chapter_title.html">
                        Reinforcement Learning (W3D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W3D5_NetworkCausality/chapter_title.html">
                        Network Causality (W3D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Module_WrapUps/StochasticProcesses.html">
                        Stochastic Processes Wrap-Up
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_guidance.html">
                        Daily guide for projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/modelingsteps/intro.html">
                        Modeling Step-by-Step Guide
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/datasets_overview.html">
                        Datasets and Project Templates
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_2020_highlights.html">
                        Projects 2020
                      </a>
</li>
</div>
</div>
</ul>
</nav>
</div>
</div>
<div id="navbar-end">
<div class="navbar-end-item navbar-persistent--container">
<button aria-label="Search" class="btn btn-sm navbar-btn search-button search-button__button" data-toggle="tooltip" title="Search">
<i class="fa-solid fa-magnifying-glass"></i>
</button>
</div>
<div class="navbar-end-item">
<button aria-label="light/dark" class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" data-toggle="tooltip" title="light/dark">
<span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
<span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
<span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
</div>
<div class="navbar-end-item">
<ul aria-label="Icon Links" class="navbar-nav" id="navbar-icon-links">
</ul>
</div>
</div>
</div>
<div class="navbar-persistent--mobile">
<button aria-label="Search" class="btn btn-sm navbar-btn search-button search-button__button" data-toggle="tooltip" title="Search">
<i class="fa-solid fa-magnifying-glass"></i>
</button>
</div>
<label class="sidebar-toggle secondary-toggle" for="__secondary">
<span class="fa-solid fa-outdent"></span>
</label>
</div>
</nav>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-center-item">
<nav class="navbar-nav">
<p aria-label="Site Navigation" aria-level="1" class="sidebar-header-items__title" role="heading">
        Site Navigation
    </p>
<ul class="navbar-nav" id="navbar-main-elements">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Schedule/schedule_intro.html">
                        Schedule
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/tech_intro.html">
                        Technical Help
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../TechnicalHelp/Links_Policy.html">
                        Quick links and policies
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../prereqs/ComputationalNeuroscience.html">
                        Prerequisites and preparatory materials for NMA Computational Neuroscience
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D0_NeuroVideoSeries/chapter_title.html">
                        Neuro Video Series (W0D0)
                      </a>
</li>
<div class="nav-item dropdown">
<button aria-expanded="false" aria-haspopup="true" class="btn dropdown-toggle nav-item" data-toggle="dropdown" type="button">
                    More
                </button>
<div class="dropdown-menu">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">
                        Python Workshop 1 (W0D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">
                        Python Workshop 2 (W0D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D3_LinearAlgebra/chapter_title.html">
                        Linear Algebra (W0D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D4_Calculus/chapter_title.html">
                        Calculus (W0D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W0D5_Statistics/chapter_title.html">
                        Statistics (W0D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D1_ModelTypes/chapter_title.html">
                        Model Types (W1D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D1_ModelingPractice/chapter_title.html">
                        Modeling Practice (W2D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D2_ModelFitting/chapter_title.html">
                        Model Fitting (W1D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D3_GeneralizedLinearModels/chapter_title.html">
                        Generalized Linear Models (W1D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D4_DimensionalityReduction/chapter_title.html">
                        Dimensionality Reduction (W1D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W1D5_DeepLearning/chapter_title.html">
                        Deep Learning (W1D5)
                      </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../chapter_title.html">
                        Autoencoders (Bonus)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Module_WrapUps/MachineLearning.html">
                        Machine Learning Wrap-Up
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D2_LinearSystems/chapter_title.html">
                        Linear Systems (W2D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D3_BiologicalNeuronModels/chapter_title.html">
                        Biological Neuron Models (W2D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W2D4_DynamicNetworks/chapter_title.html">
                        Dynamic Networks (W2D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Module_WrapUps/DynamicalSystems.html">
                        Dynamical Systems Wrap-Up
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W3D1_BayesianDecisions/chapter_title.html">
                        Bayesian Decisions (W3D1)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W3D2_HiddenDynamics/chapter_title.html">
                        Hidden Dynamics (W3D2)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W3D3_OptimalControl/chapter_title.html">
                        Optimal Control (W3D3)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W3D4_ReinforcementLearning/chapter_title.html">
                        Reinforcement Learning (W3D4)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../W3D5_NetworkCausality/chapter_title.html">
                        Network Causality (W3D5)
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../Module_WrapUps/StochasticProcesses.html">
                        Stochastic Processes Wrap-Up
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/README.html">
                        Introduction
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_guidance.html">
                        Daily guide for projects
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/modelingsteps/intro.html">
                        Modeling Step-by-Step Guide
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/datasets_overview.html">
                        Datasets and Project Templates
                      </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../../projects/docs/project_2020_highlights.html">
                        Projects 2020
                      </a>
</li>
</div>
</div>
</ul>
</nav>
</div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-end-item">
<button aria-label="light/dark" class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" data-toggle="tooltip" title="light/dark">
<span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
<span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
<span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
</div>
<div class="navbar-end-item">
<ul aria-label="Icon Links" class="navbar-nav" id="navbar-icon-links">
</ul>
</div>
</div>
</div>
<div class="sidebar-start-items sidebar-primary__section">
<div class="sidebar-start-items__item">
<a class="navbar-brand logo" href="../../intro.html">
<img alt="Logo image" class="logo__image only-light" src="../../../_static/nma-logo-square-4xp.png"/>
<img alt="Logo image" class="logo__image only-dark" src="../../../_static/nma-logo-square-4xp.png"/>
</a>
</div>
<div class="sidebar-start-items__item">
<form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search this book..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="sidebar-start-items__item"><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item navbar-nav active">
<ul class="nav bd-sidenav bd-sidenav__home-link">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
                    Introduction
                </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Schedule/schedule_intro.html">Schedule</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/daily_schedules.html">General schedule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/shared_calendars.html">Shared calendars</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Schedule/timezone_widget.html">Timezone widget</a></li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../TechnicalHelp/tech_intro.html">Technical Help</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">Using jupyterbook</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">Using Google Colab</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">Using Kaggle</a></li>
</ul>
</input></li>
<li class="toctree-l2"><a class="reference internal" href="../../TechnicalHelp/Discord.html">Using discord</a></li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../TechnicalHelp/Links_Policy.html">Quick links and policies</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../prereqs/ComputationalNeuroscience.html">Prerequisites and preparatory materials for NMA Computational Neuroscience</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Pre-reqs Refresher</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/chapter_title.html">Neuro Video Series (W0D0)</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial1.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial2.html">Human Psychophysics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial3.html">Behavioral Readout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial4.html">Live in Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial5.html">Brain Signals: Spiking Activity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial6.html">Brain Signals: LFP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial7.html">Brain Signals: EEG &amp; MEG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial8.html">Brain Signals: fMRI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial9.html">Brain Signals: Calcium Imaging</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial10.html">Stimulus Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial11.html">Neurotransmitters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial12.html">Neurons to Consciousness</a></li>
</ul>
</input></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">Python Workshop 1 (W0D1)</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D1_PythonWorkshop1/student/W0D1_Tutorial1.html">Tutorial: LIF Neuron Part I</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">Python Workshop 2 (W0D2)</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D2_PythonWorkshop2/student/W0D2_Tutorial1.html">Tutorial 1: LIF Neuron Part II</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D3_LinearAlgebra/chapter_title.html">Linear Algebra (W0D3)</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial1.html">Tutorial 1: Vectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial2.html">Tutorial 2: Matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial3.html">Bonus Tutorial: Discrete Dynamical Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D4_Calculus/chapter_title.html">Calculus (W0D4)</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial1.html">Tutorial 1: Differentiation and Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial2.html">Tutorial 2: Differential Equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial3.html">Tutorial 3: Numerical Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D4_Calculus/student/W0D4_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W0D5_Statistics/chapter_title.html">Statistics (W0D5)</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial1.html">Tutorial 1: Probability Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial2.html">Tutorial 2: Statistical Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W0D5_Statistics/student/W0D5_DaySummary.html">Day Summary</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Intro to Modeling</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D1_ModelTypes/chapter_title.html">Model Types (W1D1)</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial1.html">Tutorial 1: “What” models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial2.html">Tutorial 2: “How” models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial3.html">Tutorial 3: “Why” models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial4.html">Tutorial 4: Model Discussions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_ModelTypes/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D1_ModelingPractice/chapter_title.html">Modeling Practice (W2D1)</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_ModelingPractice/student/W2D1_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_ModelingPractice/student/W2D1_Tutorial1.html">Tutorial 1: Framing the Question</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_ModelingPractice/student/W2D1_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D1_ModelingPractice/student/W2D1_DaySummary.html">Day Summary</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Machine Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D2_ModelFitting/chapter_title.html">Model Fitting (W1D2)</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ModelFitting/student/W1D2_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ModelFitting/student/W1D2_Tutorial1.html">Tutorial 1: Linear regression with MSE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ModelFitting/student/W1D2_Tutorial2.html">Tutorial 2: Linear regression with MLE</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ModelFitting/student/W1D2_Tutorial3.html">Tutorial 3: Confidence intervals and bootstrapping</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ModelFitting/student/W1D2_Tutorial4.html">Tutorial 4: Multiple linear regression and polynomial regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ModelFitting/student/W1D2_Tutorial5.html">Tutorial 5: Model Selection: Bias-variance trade-off</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ModelFitting/student/W1D2_Tutorial6.html">Tutorial 6: Model Selection: Cross-validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ModelFitting/student/W1D2_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ModelFitting/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D2_ModelFitting/student/W1D2_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D3_GeneralizedLinearModels/chapter_title.html">Generalized Linear Models (W1D3)</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_GeneralizedLinearModels/student/W1D3_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_GeneralizedLinearModels/student/W1D3_Tutorial1.html">Tutorial 1: GLMs for Encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_GeneralizedLinearModels/student/W1D3_Tutorial2.html">Tutorial 2: Classifiers and regularizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_GeneralizedLinearModels/student/W1D3_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_GeneralizedLinearModels/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D3_GeneralizedLinearModels/student/W1D3_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D4_DimensionalityReduction/chapter_title.html">Dimensionality Reduction (W1D4)</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D4_DimensionalityReduction/student/W1D4_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D4_DimensionalityReduction/student/W1D4_Tutorial1.html">Tutorial 1: Geometric view of data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D4_DimensionalityReduction/student/W1D4_Tutorial2.html">Tutorial 2: Principal Component Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D4_DimensionalityReduction/student/W1D4_Tutorial3.html">Tutorial 3: Dimensionality Reduction &amp; Reconstruction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D4_DimensionalityReduction/student/W1D4_Tutorial4.html">Tutorial 4:  Nonlinear Dimensionality Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D4_DimensionalityReduction/student/W1D4_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D4_DimensionalityReduction/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D4_DimensionalityReduction/student/W1D4_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W1D5_DeepLearning/chapter_title.html">Deep Learning (W1D5)</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_DeepLearning/student/W1D5_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_DeepLearning/student/W1D5_Tutorial1.html">Tutorial 1: Decoding Neural Responses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_DeepLearning/student/W1D5_Tutorial2.html">Tutorial 2: Convolutional Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_DeepLearning/student/W1D5_Tutorial3.html">Tutorial 3: Building and Evaluating Normative Encoding Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_DeepLearning/student/W1D5_Tutorial4.html">Bonus Tutorial: Diving Deeper into Decoding &amp; Encoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_DeepLearning/student/W1D5_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_DeepLearning/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W1D5_DeepLearning/student/W1D5_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../chapter_title.html">Autoencoders (Bonus)</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Bonus_Intro.html">Intro</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Tutorial 1: Intro to Autoencoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="Bonus_Tutorial2.html">Tutorial 2: Autoencoder extensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="Bonus_Tutorial3.html">Tutorial 3: Autoencoders applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="Bonus_Outro.html">Outro</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../Module_WrapUps/MachineLearning.html">Machine Learning Wrap-Up</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Dynamical Systems</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D2_LinearSystems/chapter_title.html">Linear Systems (W2D2)</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial1.html">Tutorial 1: Linear dynamical systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial2.html">Tutorial 2: Markov Processes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial3.html">Tutorial 3: Combining determinism and stochasticity</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial4.html">Tutorial 4: Autoregressive models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_LinearSystems/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D3_BiologicalNeuronModels/chapter_title.html">Biological Neuron Models (W2D3)</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial1.html">Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial2.html">Tutorial 2: Effects of Input Correlation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial3.html">Tutorial 3: Synaptic transmission - Models of static and dynamic synapses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial4.html">Bonus Tutorial: Spike-timing dependent plasticity (STDP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_BiologicalNeuronModels/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W2D4_DynamicNetworks/chapter_title.html">Dynamic Networks (W2D4)</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial1.html">Tutorial 1: Neural Rate Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial2.html">Tutorial 2: Wilson-Cowan Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial3.html">Bonus Tutorial: Extending the Wilson-Cowan Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_DynamicNetworks/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../Module_WrapUps/DynamicalSystems.html">Dynamical Systems Wrap-Up</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Stochastic Processes</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W3D1_BayesianDecisions/chapter_title.html">Bayesian Decisions (W3D1)</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial1.html">Tutorial 1: Bayes with a binary hidden state</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial2.html">Tutorial 2: Bayesian inference and decisions with continuous hidden state</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial3.html">Bonus Tutorial: Fitting to data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D1_BayesianDecisions/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W3D2_HiddenDynamics/chapter_title.html">Hidden Dynamics (W3D2)</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial1.html">Tutorial 1: Sequential Probability Ratio Test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial2.html">Tutorial 2: Hidden Markov Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial3.html">Tutorial 3: The Kalman Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial4.html">Bonus Tutorial 4: The Kalman Filter, part 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial5.html">Bonus Tutorial 5: Expectation Maximization for spiking neurons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D2_HiddenDynamics/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W3D3_OptimalControl/chapter_title.html">Optimal Control (W3D3)</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial1.html">Tutorial 1: Optimal Control for Discrete States</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial2.html">Tutorial 2: Optimal Control for Continuous State</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D3_OptimalControl/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W3D4_ReinforcementLearning/chapter_title.html">Reinforcement Learning (W3D4)</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial1.html">Tutorial 1: Learning to Predict</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial2.html">Tutorial 2: Learning to Act: Multi-Armed Bandits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial3.html">Tutorial 3: Learning to Act: Q-Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial4.html">Tutorial 4: Model-Based Reinforcement Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D4_ReinforcementLearning/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../W3D5_NetworkCausality/chapter_title.html">Network Causality (W3D5)</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Intro.html">Intro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial1.html">Tutorial 1: Interventions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial2.html">Tutorial 2: Correlations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial3.html">Tutorial 3: Simultaneous fitting/regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial4.html">Tutorial 4: Instrumental Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Outro.html">Outro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D5_NetworkCausality/further_reading.html">Suggested further readings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_DaySummary.html">Day Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../Module_WrapUps/StochasticProcesses.html">Stochastic Processes Wrap-Up</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Project Booklet</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects/docs/project_guidance.html">Daily guide for projects</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../projects/modelingsteps/intro.html">Modeling Step-by-Step Guide</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-25"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through4.html">Modeling Steps 1 - 4</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through10.html">Modeling Steps 5 - 10</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModel.html">Example Model Project: the Train Illusion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProject.html">Example Data Project: the Train Illusion</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../projects/docs/datasets_overview.html">Datasets and Project Templates</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-26"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../projects/docs/neurons.html">Neurons</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-27"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../projects/neurons/README.html">Guide to choosing a Neurons dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../projects/neurons/neurons_videos.html">Overview videos</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../projects/docs/fMRI.html">fMRI</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-28"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../projects/fMRI/README.html">Guide to choosing an FMRI dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../projects/fMRI/fMRI_videos.html">Overview videos</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../projects/docs/ECoG.html">ECoG</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-29"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../projects/ECoG/README.html">Guide to choosing an EEG/ECoG/LFP dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../projects/ECoG/ECoG_videos.html">Overview videos</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../projects/docs/behavior_and_theory.html">Behavior and Theory</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-30"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../projects/behavior_and_theory/README.html">Guide to choosing a Behavior And Theory dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../projects/behavior_and_theory/behavior_and_theory_videos.html">Overview videos</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../projects/docs/project_2020_highlights.html">Projects 2020</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-31"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/docs/projects_2020/neurons.html">Neurons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/docs/projects_2020/theory.html">Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/docs/projects_2020/behavior.html">Behavior</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/docs/projects_2020/fMRI.html">fMRI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../projects/docs/projects_2020/eeg.html">EEG</a></li>
</ul>
</li>
</ul>
</div>
</nav>
</div>
</div>
<div class="sidebar-end-items sidebar-primary__section">
<div class="sidebar-end-items__item">
</div>
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content">
<div class="sbt-scroll-pixel-helper"></div>
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article">
<div class="col py-1 d-flex header-article-main">
<div class="header-article__left">
<label class="sidebar-toggle primary-toggle btn btn-sm" data-placement="right" data-toggle="tooltip" for="__primary" title="Toggle primary sidebar">
<span class="fa-solid fa-bars"></span>
</label>
</div>
<div class="header-article__right">
<div class="dropdown dropdown-launch-buttons">
<button aria-expanded="false" aria-label="Launch interactive content" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-rocket"></i>
</button>
<ul class="dropdown-menu">
</ul>
</div>
<button class="btn btn-sm" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode">
<span class="btn__icon-container">
<i class="fas fa-expand"></i>
</span>
</button>
<div class="dropdown dropdown-repository-buttons">
<button aria-expanded="false" aria-label="Source repositories" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fab fa-github"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/course-content" target="_blank" title="Source repository">
<span class="btn__icon-container">
<i class="fab fa-github"></i>
</span>
<span class="btn__text-container">repository</span>
</a>

<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="https://github.com/NeuromatchAcademy/course-content/issues/new?title=Issue%20on%20page%20%2Ftutorials/Bonus_Autoencoders/student/Bonus_Tutorial1.html&amp;body=Your%20issue%20content%20here." target="_blank" title="Open an issue">
<span class="btn__icon-container">
<i class="fas fa-lightbulb"></i>
</span>
<span class="btn__text-container">open issue</span>
</a>

</li></li></ul>
</div>
<div class="dropdown dropdown-download-buttons">
<button aria-expanded="false" aria-label="Download this page" class="btn dropdown-toggle" data-bs-toggle="dropdown" type="button">
<i class="fas fa-download"></i>
</button>
<ul class="dropdown-menu">
<li><a class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" href="../../../_sources/tutorials/Bonus_Autoencoders/student/Bonus_Tutorial1.ipynb" target="_blank" title="Download source file">
<span class="btn__icon-container">
<i class="fas fa-file"></i>
</span>
<span class="btn__text-container">.ipynb</span>
</a>

<li>
<button class="btn btn-sm dropdown-item" data-placement="left" data-toggle="tooltip" onclick="printPdf(this)" title="Print to PDF">
<span class="btn__icon-container">
<i class="fas fa-file-pdf"></i>
</span>
<span class="btn__text-container">.pdf</span>
</button>

</li></li></ul>
</div>
<label class="sidebar-toggle secondary-toggle btn btn-sm" data-placement="left" data-toggle="tooltip" for="__secondary" title="Toggle secondary sidebar">
<span class="fa-solid fa-list"></span>
</label>
</div>
</div>
</div>
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 1: Intro to Autoencoders</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 1: Intro to Autoencoders
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#internal-representations-and-autoencoders">
     Internal representations and autoencoders
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-and-import-feedback-gadget">
     Install and import feedback gadget
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-0-introduction">
   Section 0: Introduction
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-intro">
     Video 1: Intro
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#submit-your-feedback">
     Submit your feedback
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-introduction-to-autoencoders">
   Section 1: Introduction to autoencoders
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-autoencoders">
     Video 2: Autoencoders
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
     Submit your feedback
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-the-mnist-dataset">
   Section 2: The MNIST dataset
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-1-download-and-prepare-mnist-dataset">
     Section 2.1: Download  and prepare MNIST dataset
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#visualize-samples">
     Visualize samples
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-latent-space-visualization">
   Section 3: Latent space visualization
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-1-mnist-with-pca">
     Section 3.1: MNIST with PCA
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-visualize-pca-latent-space-2d">
     Coding Exercise 1: Visualize PCA latent space (2D)
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
</a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id3">
       Submit your feedback
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-2-qualitative-analysis-pca">
     Section 3.2: Qualitative analysis PCA
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-ann-autoencoder">
   Section 4: ANN autoencoder
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#design-ann-autoencoder-32d">
     Design ANN autoencoder (32D)
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-design-ann-autoencoder">
       Coding Exercise 2: Design ANN autoencoder
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id4">
         Submit your feedback
        </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#train-autoencoder-32d">
     Train autoencoder (32D)
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#choose-the-loss-function">
     Choose the loss function
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#design-ann-autoencoder-2d">
     Design ANN autoencoder (2D)
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#train-the-autoencoder-2d">
     Train the autoencoder (2D)
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#expressive-power-in-2d">
     Expressive power in 2D
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-wrap-up">
     Video 3: Wrap-up
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id5">
     Submit your feedback
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus">
   Bonus
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#failure-mode-with-relu-units-in-2d">
     Failure mode with ReLU units in 2D
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-coding-exercise-3-choosing-weight-initialization">
       Bonus Coding Exercise 3: Choosing weight initialization
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id6">
         Submit your feedback
        </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#choose-the-activation-function">
     Choose the activation function
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#qualitative-analysis-nmf">
     Qualitative analysis NMF
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<article class="bd-article" role="main">
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/main/tutorials/Bonus_Autoencoders/Bonus_Tutorial1.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a>   <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/Bonus_Autoencoders/Bonus_Tutorial1.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-1-intro-to-autoencoders">
<h1>Tutorial 1: Intro to Autoencoders<a class="headerlink" href="#tutorial-1-intro-to-autoencoders" title="Permalink to this heading">#</a></h1>
<p><strong>Bonus Day: Autoencoders</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Marco Brigham and the <a class="reference external" href="https://www.ccnss.org/">CCNSS</a> team (2014-2018)</p>
<p><strong>Content reviewers:</strong> Itzel Olivos, Karen Schroeder, Karolina Stosio, Kshitij Dwivedi, Spiros Chavlis, Michael Waskom</p>
<p><strong>Production editors:</strong> Spiros Chavlis</p>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this heading">#</a></h1>
<section id="internal-representations-and-autoencoders">
<h2>Internal representations and autoencoders<a class="headerlink" href="#internal-representations-and-autoencoders" title="Permalink to this heading">#</a></h2>
<p>How can simple algorithms capture relevant aspects of data and build robust models of the world?</p>
<p>Autoencoders are a family of artificial neural networks (ANNs) that learn internal representations through auxiliary tasks, i.e., <em>learning by doing</em>.</p>
<p>The primary task is to reconstruct output images based on a compressed representation of the inputs. This task teaches the network which details to throw away while still producing images that are similar to the inputs.</p>
<p> </p>
<p>A fictitious <em>MNIST cognitive task</em> bundles more elaborate tasks such as removing noise from images, guessing occluded parts, and recovering original image orientation. We use the handwritten digits from the MNIST dataset since it is easier to identify similar images or issues with reconstructions than in other types of data, such as spiking data time series.</p>
<p> </p>
<p><img alt="MNIST cognitive task" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/mnist_task.png"/></p>
<p> </p>
<p>The beauty of autoencoders is the possibility to see these internal representations. The bottleneck layer enforces data compression by having fewer units than input and output layers. Further limiting this layer to two or three units enables us to see how the autoencoder is organizing the data internally in two or three-dimensional <em>latent space</em>.</p>
<p> </p>
<p>Our roadmap is the following: learn about typical elements of autoencoder architecture in Tutorial 1 (this tutorial), how to extend their performance in Tutorial 2, and use them to solve the MNIST cognitive task in Tutorial 3.</p>
<p> </p>
<p>In this tutorial, you will:</p>
<ul class="simple">
<li><p>Get acquainted with latent space visualizations and apply them to <em>Principal Component Analysis (PCA)</em> and <em>Non-negative Matrix Factorization (NMF)</em></p></li>
<li><p>Build and train a single hidden layer ANN autoencoder</p></li>
<li><p>Inspect the representational power of autoencoders with latent spaces of different dimensions</p></li>
</ul>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h1>
<section id="install-and-import-feedback-gadget">
<h2>Install and import feedback gadget<a class="headerlink" href="#install-and-import-feedback-gadget" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install and import feedback gadget</span>

<span class="o">!</span>pip3<span class="w"> </span>install<span class="w"> </span>vibecheck<span class="w"> </span>datatops<span class="w"> </span>--quiet

<span class="kn">from</span><span class="w"> </span><span class="nn">vibecheck</span><span class="w"> </span><span class="kn">import</span> <span class="n">DatatopsContentReviewContainer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">content_review</span><span class="p">(</span><span class="n">notebook_section</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">DatatopsContentReviewContainer</span><span class="p">(</span>
        <span class="s2">""</span><span class="p">,</span>  <span class="c1"># No text prompt</span>
        <span class="n">notebook_section</span><span class="p">,</span>
        <span class="p">{</span>
            <span class="s2">"url"</span><span class="p">:</span> <span class="s2">"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab"</span><span class="p">,</span>
            <span class="s2">"name"</span><span class="p">:</span> <span class="s2">"neuromatch_cn"</span><span class="p">,</span>
            <span class="s2">"user_key"</span><span class="p">:</span> <span class="s2">"y1x3mpx5"</span><span class="p">,</span>
        <span class="p">},</span>
    <span class="p">)</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>


<span class="n">feedback_prefix</span> <span class="o">=</span> <span class="s2">"Bonus_Autoencoders_T1"</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">decomposition</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_openml</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="figure-settings">
<h2>Figure settings<a class="headerlink" href="#figure-settings" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure settings</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">'matplotlib.font_manager'</span><span class="p">)</span><span class="o">.</span><span class="n">disabled</span> <span class="o">=</span> <span class="kc">True</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/NMA2020/nma.mplstyle"</span><span class="p">)</span>
<span class="n">fig_w</span><span class="p">,</span> <span class="n">fig_h</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">'figure.figsize'</span><span class="p">]</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper functions</span>


<span class="k">def</span><span class="w"> </span><span class="nf">downloadMNIST</span><span class="p">():</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Download MNIST dataset and transform it to torch.Tensor</span>

<span class="sd">  Args:</span>
<span class="sd">    None</span>

<span class="sd">  Returns:</span>
<span class="sd">    x_train : training images (torch.Tensor) (60000, 28, 28)</span>
<span class="sd">    x_test  : test images (torch.Tensor) (10000, 28, 28)</span>
<span class="sd">    y_train : training labels (torch.Tensor) (60000, )</span>
<span class="sd">    y_train : test labels (torch.Tensor) (10000, )</span>
<span class="sd">  """</span>
  <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="s1">'mnist_784'</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="c1"># Trunk the data</span>
  <span class="n">n_train</span> <span class="o">=</span> <span class="mi">60000</span>
  <span class="n">n_test</span> <span class="o">=</span> <span class="mi">10000</span>

  <span class="n">train_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_train</span><span class="p">)</span>
  <span class="n">test_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_train</span> <span class="o">+</span> <span class="n">n_test</span><span class="p">)</span>

  <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
  <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">test_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>

  <span class="c1"># Transform np.ndarrays to torch.Tensor</span>
  <span class="n">x_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span>
                                        <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span>
                                         <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
  <span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span>
                                       <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span>
                                        <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

  <span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>
  <span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>

  <span class="k">return</span> <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">init_weights_kaiming_uniform</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Initializes weights from linear PyTorch layer</span>
<span class="sd">  with kaiming uniform distribution.</span>

<span class="sd">  Args:</span>
<span class="sd">    layer (torch.Module)</span>
<span class="sd">        Pytorch layer</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>
  <span class="c1"># check for linear PyTorch layer</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
    <span class="c1"># initialize weights with kaiming uniform distribution</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">init_weights_kaiming_normal</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Initializes weights from linear PyTorch layer</span>
<span class="sd">  with kaiming normal distribution.</span>

<span class="sd">  Args:</span>
<span class="sd">    layer (torch.Module)</span>
<span class="sd">        Pytorch layer</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>
  <span class="c1"># check for linear PyTorch layer</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
    <span class="c1"># initialize weights with kaiming normal distribution</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">get_layer_weights</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Retrieves learnable parameters from PyTorch layer.</span>

<span class="sd">  Args:</span>
<span class="sd">    layer (torch.Module)</span>
<span class="sd">        Pytorch layer</span>

<span class="sd">  Returns:</span>
<span class="sd">    list with learnable parameters</span>
<span class="sd">  """</span>
  <span class="c1"># initialize output list</span>
  <span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="c1"># check whether layer has learnable parameters</span>
  <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="c1"># copy numpy array representation of each set of learnable parameters</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
      <span class="n">weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

  <span class="k">return</span> <span class="n">weights</span>


<span class="k">def</span><span class="w"> </span><span class="nf">eval_mse</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Evaluates Mean Square Error (MSE) between y_pred and y_true</span>

<span class="sd">  Args:</span>
<span class="sd">    y_pred (torch.Tensor)</span>
<span class="sd">        prediction samples</span>

<span class="sd">    v (numpy array of floats)</span>
<span class="sd">        ground truth samples</span>

<span class="sd">  Returns:</span>
<span class="sd">    MSE(y_pred, y_true)</span>
<span class="sd">  """</span>

  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>

  <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">eval_bce</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Evaluates Binary Cross-Entropy (BCE) between y_pred and y_true</span>

<span class="sd">  Args:</span>
<span class="sd">    y_pred (torch.Tensor)</span>
<span class="sd">        prediction samples</span>

<span class="sd">    v (numpy array of floats)</span>
<span class="sd">        ground truth samples</span>

<span class="sd">  Returns:</span>
<span class="sd">    BCE(y_pred, y_true)</span>
<span class="sd">  """</span>

  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>

  <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">plot_weights_ab</span><span class="p">(</span><span class="n">encoder_w_a</span><span class="p">,</span> <span class="n">encoder_w_b</span><span class="p">,</span> <span class="n">decoder_w_a</span><span class="p">,</span> <span class="n">decoder_w_b</span><span class="p">,</span>
                    <span class="n">label_a</span><span class="o">=</span><span class="s1">'init'</span><span class="p">,</span> <span class="n">label_b</span><span class="o">=</span><span class="s1">'train'</span><span class="p">,</span>
                    <span class="n">bins_encoder</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">bins_decoder</span><span class="o">=</span><span class="mf">1.5</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Plots row of histograms with encoder and decoder weights</span>
<span class="sd">  between two training checkpoints.</span>

<span class="sd">  Args:</span>
<span class="sd">    encoder_w_a (iterable)</span>
<span class="sd">        encoder weights at checkpoint a</span>

<span class="sd">    encoder_w_b (iterable)</span>
<span class="sd">        encoder weights at checkpoint b</span>

<span class="sd">    decoder_w_a (iterable)</span>
<span class="sd">        decoder weights at checkpoint a</span>

<span class="sd">    decoder_w_b (iterable)</span>
<span class="sd">        decoder weights at checkpoint b</span>

<span class="sd">    label_a (string)</span>
<span class="sd">        label for checkpoint a</span>

<span class="sd">    label_b (string)</span>
<span class="sd">        label for checkpoint b</span>

<span class="sd">    bins_encoder (float)</span>
<span class="sd">        norm of extreme values for encoder bins</span>

<span class="sd">    bins_decoder (float)</span>
<span class="sd">        norm of extreme values for decoder bins</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">fig_w</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">,</span> <span class="n">fig_h</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">))</span>

  <span class="c1"># plot encoder weights</span>
  <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">bins_encoder</span><span class="p">,</span> <span class="n">bins_encoder</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Encoder weights to unit 0'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">encoder_w_a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label_a</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">encoder_w_b</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label_b</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Encoder weights to unit 1'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">encoder_w_a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label_a</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">encoder_w_b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label_b</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

  <span class="c1"># plot decoder weights</span>
  <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">bins_decoder</span><span class="p">,</span> <span class="n">bins_decoder</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Decoder weights from unit 0'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">decoder_w_a</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label_a</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">decoder_w_b</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label_b</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">224</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Decoder weights from unit 1'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">decoder_w_a</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label_a</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">decoder_w_b</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label_b</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">plot_row</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">show_n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">image_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Plots rows of images from list of iterables (iterables: list, numpy array</span>
<span class="sd">  or torch.Tensor). Also accepts single iterable.</span>
<span class="sd">  Randomly selects images in each list element if item count &gt; show_n.</span>

<span class="sd">  Args:</span>
<span class="sd">    images (iterable or list of iterables)</span>
<span class="sd">        single iterable with images, or list of iterables</span>

<span class="sd">    show_n (integer)</span>
<span class="sd">        maximum number of images per row</span>

<span class="sd">    image_shape (tuple or list)</span>
<span class="sd">        original shape of image if vectorized form</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">images</span><span class="p">]</span>

  <span class="k">for</span> <span class="n">items_idx</span><span class="p">,</span> <span class="n">items</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">images</span><span class="p">):</span>

    <span class="n">items</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">items</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">items</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">show_n</span><span class="p">:</span>
      <span class="n">selected</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">),</span> <span class="n">show_n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="n">items</span> <span class="o">=</span> <span class="n">items</span><span class="p">[</span><span class="n">selected</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">image_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">items</span> <span class="o">=</span> <span class="n">items</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">image_shape</span><span class="p">))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">image_idx</span><span class="p">,</span> <span class="n">image</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">items</span><span class="p">):</span>

      <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">),</span> <span class="n">image_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">vmax</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>

      <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">xy_lim</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Return arguments for plt.xlim and plt.ylim calculated from minimum</span>
<span class="sd">  and maximum of x.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        data to be plotted</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="n">x_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">x_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="n">x_min</span> <span class="o">=</span> <span class="n">x_min</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.05</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>
  <span class="n">x_max</span> <span class="o">=</span> <span class="n">x_max</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.05</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>

  <span class="k">return</span> <span class="p">[</span><span class="n">x_min</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_max</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">x_min</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x_max</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>


<span class="k">def</span><span class="w"> </span><span class="nf">plot_generative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">decoder_fn</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">n_row</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Plots images reconstructed by decoder_fn from a 2D grid in</span>
<span class="sd">  latent space that is determined by minimum and maximum values in x.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        2D coordinates in latent space</span>

<span class="sd">    decoder_fn (integer)</span>
<span class="sd">        function returning vectorized images from 2D latent space coordinates</span>

<span class="sd">    image_shape (tuple or list)</span>
<span class="sd">        original shape of image</span>

<span class="sd">    n_row</span>
<span class="sd">        number of rows in grid</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="n">xlim</span><span class="p">,</span> <span class="n">ylim</span> <span class="o">=</span> <span class="n">xy_lim</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

  <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">xlim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">xlim</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">n_row</span>
  <span class="n">grid</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ylim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">dx</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">ylim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">dx</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_row</span><span class="p">),</span>
          <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xlim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">dx</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">xlim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">dx</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_row</span><span class="p">)]</span>

  <span class="n">canvas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">n_row</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_row</span><span class="p">))</span>

  <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'gray'</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">latent_y</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">latent_x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>

      <span class="n">latent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">latent_x</span><span class="p">,</span> <span class="n">latent_y</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
      <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
          <span class="n">x_decoded</span> <span class="o">=</span> <span class="n">decoder_fn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">latent</span><span class="p">))</span>

      <span class="n">x_decoded</span> <span class="o">=</span> <span class="n">x_decoded</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">image_shape</span><span class="p">)</span>

      <span class="n">canvas</span><span class="p">[</span><span class="n">j</span><span class="o">*</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
             <span class="n">i</span><span class="o">*</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">x_decoded</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">canvas</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">canvas</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">vmax</span><span class="o">=</span><span class="n">canvas</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">plot_latent</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">show_n</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xy_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Plots digit class of each sample in 2D latent space coordinates.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        2D coordinates in latent space</span>

<span class="sd">    y (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        digit class of each sample</span>

<span class="sd">    n_row (integer)</span>
<span class="sd">        number of samples</span>

<span class="sd">    fontdict (dictionary)</span>
<span class="sd">        optional style option for plt.text</span>

<span class="sd">    xy_labels (list)</span>
<span class="sd">        optional list with [xlabel, ylabel]</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="k">if</span> <span class="n">fontdict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">fontdict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'weight'</span><span class="p">:</span> <span class="s1">'bold'</span><span class="p">,</span> <span class="s1">'size'</span><span class="p">:</span> <span class="mi">12</span><span class="p">}</span>

  <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'tab10'</span><span class="p">)</span>

  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">show_n</span><span class="p">:</span>
    <span class="n">selected</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">show_n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">selected</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">selected</span><span class="p">]</span>

  <span class="k">for</span> <span class="n">my_x</span><span class="p">,</span> <span class="n">my_y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">my_x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">my_x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">my_y</span><span class="p">)),</span>
             <span class="n">color</span><span class="o">=</span><span class="n">cmap</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">my_y</span><span class="p">)</span> <span class="o">/</span> <span class="mf">10.</span><span class="p">),</span>
             <span class="n">fontdict</span><span class="o">=</span><span class="n">fontdict</span><span class="p">,</span>
             <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span>
             <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span>
             <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">xy_labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">xy_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'$Z_1$'</span><span class="p">,</span> <span class="s1">'$Z_2$'</span><span class="p">]</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">xy_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">xy_labels</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

  <span class="n">xlim</span><span class="p">,</span> <span class="n">ylim</span> <span class="o">=</span> <span class="n">xy_lim</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xlim</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ylim</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">plot_latent_generative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">decoder_fn</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                           <span class="n">xy_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Two horizontal subplots generated with encoder map and decoder grid.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        2D coordinates in latent space</span>

<span class="sd">    y (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        digit class of each sample</span>

<span class="sd">    decoder_fn (integer)</span>
<span class="sd">        function returning vectorized images from 2D latent space coordinates</span>

<span class="sd">    image_shape (tuple or list)</span>
<span class="sd">        original shape of image</span>

<span class="sd">    title (string)</span>
<span class="sd">        plot title</span>

<span class="sd">    xy_labels (list)</span>
<span class="sd">        optional list with [xlabel, ylabel]</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

  <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>

  <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Encoder map'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
  <span class="n">plot_latent</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">xy_labels</span><span class="o">=</span><span class="n">xy_labels</span><span class="p">)</span>

  <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Decoder grid'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
  <span class="n">plot_generative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">decoder_fn</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">plot_latent_ab</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">selected_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">title_a</span><span class="o">=</span><span class="s1">'Before'</span><span class="p">,</span> <span class="n">title_b</span><span class="o">=</span><span class="s1">'After'</span><span class="p">,</span> <span class="n">show_n</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Two horizontal subplots with encoder maps.</span>

<span class="sd">  Args:</span>
<span class="sd">    x1 (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        2D coordinates in latent space (left plot)</span>

<span class="sd">    x2 (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        digit class of each sample (right plot)</span>

<span class="sd">    y (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        digit class of each sample</span>

<span class="sd">    selected_idx (list of integers)</span>
<span class="sd">        indexes of elements to be plotted</span>

<span class="sd">    show_n (integer)</span>
<span class="sd">        maximum number of samples in each plot</span>

<span class="sd">    s2 (boolean)</span>
<span class="sd">        convert 3D coordinates (x, y, z) to spherical coordinates (theta, phi)</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="n">fontdict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'weight'</span><span class="p">:</span> <span class="s1">'bold'</span><span class="p">,</span> <span class="s1">'size'</span><span class="p">:</span> <span class="mi">12</span><span class="p">}</span>

  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">show_n</span><span class="p">:</span>

    <span class="k">if</span> <span class="n">selected_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">selected_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x1</span><span class="p">),</span> <span class="n">show_n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">x1</span> <span class="o">=</span> <span class="n">x1</span><span class="p">[</span><span class="n">selected_idx</span><span class="p">]</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">x2</span><span class="p">[</span><span class="n">selected_idx</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">selected_idx</span><span class="p">]</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

  <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title_a</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
  <span class="n">plot_latent</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="n">fontdict</span><span class="p">)</span>

  <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title_b</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
  <span class="n">plot_latent</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="n">fontdict</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">runSGD</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">input_train</span><span class="p">,</span> <span class="n">input_test</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">'bce'</span><span class="p">,</span>
           <span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  Trains autoencoder network with stochastic gradient descent with Adam</span>
<span class="sd">  optimizer and loss criterion. Train samples are shuffled, and loss is</span>
<span class="sd">  displayed at the end of each opoch for both MSE and BCE. Plots training loss</span>
<span class="sd">  at each minibatch (maximum of 500 randomly selected values).</span>

<span class="sd">  Args:</span>
<span class="sd">    net (torch network)</span>
<span class="sd">        ANN object (nn.Module)</span>

<span class="sd">    input_train (torch.Tensor)</span>
<span class="sd">        vectorized input images from train set</span>

<span class="sd">    input_test (torch.Tensor)</span>
<span class="sd">        vectorized input images from test set</span>

<span class="sd">    criterion (string)</span>
<span class="sd">        train loss: 'bce' or 'mse'</span>

<span class="sd">    n_epochs (boolean)</span>
<span class="sd">        number of full iterations of training data</span>

<span class="sd">    batch_size (integer)</span>
<span class="sd">        number of element in mini-batches</span>

<span class="sd">    verbose (boolean)</span>
<span class="sd">        whether to print final loss</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="c1"># Initialize loss function</span>
  <span class="k">if</span> <span class="n">criterion</span> <span class="o">==</span> <span class="s1">'mse'</span><span class="p">:</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
  <span class="k">elif</span> <span class="n">criterion</span> <span class="o">==</span> <span class="s1">'bce'</span><span class="p">:</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Please specify either "mse" or "bce" for loss criterion'</span><span class="p">)</span>

  <span class="c1"># Initialize SGD optimizer</span>
  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

  <span class="c1"># Placeholder for loss</span>
  <span class="n">track_loss</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="nb">print</span><span class="p">(</span><span class="s1">'Epoch'</span><span class="p">,</span> <span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'Loss train'</span><span class="p">,</span> <span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'Loss test'</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>

    <span class="n">shuffle_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_train</span><span class="p">))</span>
    <span class="n">batches</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">input_train</span><span class="p">[</span><span class="n">shuffle_idx</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batches</span><span class="p">:</span>

      <span class="n">output_train</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

      <span class="c1"># Keep track of loss at each epoch</span>
      <span class="n">track_loss</span> <span class="o">+=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">)]</span>

    <span class="n">loss_epoch</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s1"> / </span><span class="si">{</span><span class="n">n_epochs</span><span class="si">}</span><span class="s1">'</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="n">output_train</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_train</span><span class="p">)</span>
      <span class="n">loss_train</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span> <span class="n">input_train</span><span class="p">)</span>
      <span class="n">loss_epoch</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">loss_train</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">'</span>

      <span class="n">output_test</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>
      <span class="n">loss_test</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output_test</span><span class="p">,</span> <span class="n">input_test</span><span class="p">)</span>
      <span class="n">loss_epoch</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\t\t</span><span class="s1"> </span><span class="si">{</span><span class="n">loss_test</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">'</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">loss_epoch</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
    <span class="c1"># Print final loss</span>
    <span class="n">loss_mse</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">MSE</span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_mse</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span><span class="w"> </span><span class="n">input_train</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
    <span class="n">loss_mse</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\t\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_mse</span><span class="p">(</span><span class="n">output_test</span><span class="p">,</span><span class="w"> </span><span class="n">input_test</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">loss_mse</span><span class="p">)</span>

    <span class="n">loss_bce</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'BCE</span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_bce</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span><span class="w"> </span><span class="n">input_train</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
    <span class="n">loss_bce</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\t\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_bce</span><span class="p">(</span><span class="n">output_test</span><span class="p">,</span><span class="w"> </span><span class="n">input_test</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">loss_bce</span><span class="p">)</span>

  <span class="c1"># Plot loss</span>
  <span class="n">step</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">track_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">500</span><span class="p">))</span>
  <span class="n">x_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">track_loss</span><span class="p">),</span> <span class="n">step</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">track_loss</span><span class="p">[::</span><span class="n">step</span><span class="p">],</span> <span class="s1">'C0'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Iterations'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-0-introduction">
<h1>Section 0: Introduction<a class="headerlink" href="#section-0-introduction" title="Permalink to this heading">#</a></h1>
<section id="video-1-intro">
<h2>Video 1: Intro<a class="headerlink" href="#video-1-intro" title="Permalink to this heading">#</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</section>
<section id="submit-your-feedback">
<h2>Submit your feedback<a class="headerlink" href="#submit-your-feedback" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_Intro_Video"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-1-introduction-to-autoencoders">
<h1>Section 1: Introduction to autoencoders<a class="headerlink" href="#section-1-introduction-to-autoencoders" title="Permalink to this heading">#</a></h1>
<section id="video-2-autoencoders">
<h2>Video 2: Autoencoders<a class="headerlink" href="#video-2-autoencoders" title="Permalink to this heading">#</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</section>
<section id="id1">
<h2>Submit your feedback<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_Autoencoders_Video"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<p>This tutorial introduces typical elements of autoencoders, that learn low dimensional representations of data through an auxiliary task of compression and decompression. In general, these networks are characterized by an equal number of input and output units and a <em>bottleneck layer</em> with fewer units.</p>
<p><img alt="Single hidden layer ANN autoencoder" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/ae-ann-1h.png"/></p>
<p>Autoencoder architectures have <em>encoder</em> and <em>decoder</em> components:</p>
<ul class="simple">
<li><p>The encoder network compresses high dimensional inputs into lower-dimensional coordinates of the <em>bottleneck layer</em></p></li>
<li><p>The <em>decoder</em> expands <em>bottleneck layer</em> coordinates back to the original dimensionality</p></li>
</ul>
<p>Each input presented to the autoencoder maps to a coordinate in the bottleneck layer that spans the lower-dimensional <em>latent space</em>.</p>
<br/>
<p>Differences between inputs and outputs trigger the backpropagation of loss to adjust weights and better compress/decompress data.  Autoencoders are examples of models that automatically build internal representations of the world and use them to predict unseen data.</p>
<p>We’ll use fully-connected AAN architectures due to their lower computational requirements. The inputs to ANNs are <em>vectorized</em> versions of the images (i.e., stretched as a line).</p>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-2-the-mnist-dataset">
<h1>Section 2: The MNIST dataset<a class="headerlink" href="#section-2-the-mnist-dataset" title="Permalink to this heading">#</a></h1>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/MNIST_database">MNIST dataset</a> contains handwritten digits in square images of 28x28 pixels of grayscale levels. There are 60,000 training images and 10,000 testing images from different writers.</p>
<p>Get acquainted with the data by inspecting data type, shape, and visualizing samples with the function <code class="docutils literal notranslate"><span class="pre">plot_row</span></code>.</p>
<p><strong>Helper function:</strong> <code class="docutils literal notranslate"><span class="pre">plot_row</span></code></p>
<p>Please uncomment the line below to inspect this function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># help(plot_row)</span>
</pre></div>
</div>
</div>
</div>
<section id="section-2-1-download-and-prepare-mnist-dataset">
<h2>Section 2.1: Download  and prepare MNIST dataset<a class="headerlink" href="#section-2-1-download-and-prepare-mnist-dataset" title="Permalink to this heading">#</a></h2>
<p>We use the helper function <code class="docutils literal notranslate"><span class="pre">downloadMNIST</span></code> to download the dataset, transform it into <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code> and assign train and test datasets to (<code class="docutils literal notranslate"><span class="pre">x_train</span></code>, <code class="docutils literal notranslate"><span class="pre">y_train</span></code>) and (<code class="docutils literal notranslate"><span class="pre">x_test</span></code>, <code class="docutils literal notranslate"><span class="pre">y_test</span></code>), respectively.</p>
<p>(<code class="docutils literal notranslate"><span class="pre">x_train</span></code>, <code class="docutils literal notranslate"><span class="pre">x_test</span></code>) contain images and (<code class="docutils literal notranslate"><span class="pre">y_train</span></code>, <code class="docutils literal notranslate"><span class="pre">y_test</span></code>) contain labels from <code class="docutils literal notranslate"><span class="pre">0</span></code> to <code class="docutils literal notranslate"><span class="pre">9</span></code>.</p>
<p>The original pixel values are integers between <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">255</span></code>. We rescale them between <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>, a more favorable range for training the autoencoders in this tutorial.</p>
<p>The images are <em>vectorized</em>, i.e., stretched as a line. We reshape training and testing images to <em>vectorized</em> versions with the method <code class="docutils literal notranslate"><span class="pre">.reshape</span></code> and store them in variable <code class="docutils literal notranslate"><span class="pre">input_train</span></code> and <code class="docutils literal notranslate"><span class="pre">input_test</span></code>, respectively. The variable <code class="docutils literal notranslate"><span class="pre">image_shape</span></code> stores the shape of the images, and <code class="docutils literal notranslate"><span class="pre">input_size</span></code> stores the size of the <em>vectorized</em> versions.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell below</p></li>
</ul>
<p><strong>Questions:</strong></p>
<ul class="simple">
<li><p>What are the shape and numeric representations of <code class="docutils literal notranslate"><span class="pre">x_train</span></code> and <code class="docutils literal notranslate"><span class="pre">input_train</span></code>?</p></li>
<li><p>What is the image shape?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download MNIST</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">downloadMNIST</span><span class="p">()</span>

<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mi">255</span>

<span class="n">image_shape</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

<span class="n">input_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">input_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_size</span><span class="p">])</span>
<span class="n">input_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_size</span><span class="p">])</span>

<span class="n">test_selected_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="mi">10</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">train_selected_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span> <span class="mi">10</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'shape x_train </span><span class="se">\t\t</span><span class="s1"> </span><span class="si">{</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'shape x_test </span><span class="se">\t\t</span><span class="s1"> </span><span class="si">{</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'shape image </span><span class="se">\t\t</span><span class="s1"> </span><span class="si">{</span><span class="n">image_shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'shape input_train </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">input_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'shape input_test </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">input_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualize-samples">
<h2>Visualize samples<a class="headerlink" href="#visualize-samples" title="Permalink to this heading">#</a></h2>
<p>The variables <code class="docutils literal notranslate"><span class="pre">train_selected_idx</span></code> and <code class="docutils literal notranslate"><span class="pre">test_selected_idx</span></code> store 10 random indexes from the train and test data.</p>
<p>We use the function <code class="docutils literal notranslate"><span class="pre">np.random.choice</span></code> to select 10 indexes from <code class="docutils literal notranslate"><span class="pre">x_train</span></code> and <code class="docutils literal notranslate"><span class="pre">y_train</span></code> without replacement (<code class="docutils literal notranslate"><span class="pre">replacement=False</span></code>).</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cells below</p></li>
<li><p>The first cell display different samples each time, the second cell always displays the same samples</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># top row: random images from test set</span>
<span class="c1"># bottom row: images selected with test_selected_idx</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">x_test</span><span class="p">,</span> <span class="n">x_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-3-latent-space-visualization">
<h1>Section 3: Latent space visualization<a class="headerlink" href="#section-3-latent-space-visualization" title="Permalink to this heading">#</a></h1>
<p>This section introduces tools for visualization of latent space and applies them to <em>Principal Component Analysis (PCA)</em>, already introduced in tutorial <em>W1D5 Dimensionality reduction</em>. Please see the exercise in the <em>Bonus</em> section for <em>Non-negative Matrix Factorization (NMF)</em>.</p>
<br/>
<p>The plotting function <code class="docutils literal notranslate"><span class="pre">plot_latent_generative</span></code> helps visualize the encoding of inputs from high dimension into 2D latent space, and decoding back to the original dimension. This function produces two plots:</p>
<ul class="simple">
<li><p><strong>Encoder map</strong> shows the mapping from input images to coordinates <span class="math notranslate nohighlight">\((z_1, z_2)\)</span> in latent space, with overlaid digit labels</p></li>
<li><p><strong>Decoder grid</strong> shows reconstructions from a grid of latent space coordinates <span class="math notranslate nohighlight">\((z_1, z_2)\)</span></p></li>
</ul>
<br/>
<p><img alt="Latent space visualization" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/latent_space_plots_noaxis.png"/></p>
<p>The latent space representation is a new coordinate system <span class="math notranslate nohighlight">\((z_1, z_2)\)</span> that hopefully captures relevant structure from high-dimensional data. The coordinates of each input only matter relative to those of other inputs, i.e., we often care about separability between different classes of digits rather than their location.</p>
<br/>
<p>The encoder map provides direct insight into the organization of latent space. Keep in mind that latent space only contains coordinates <span class="math notranslate nohighlight">\((z_1, z_2)\)</span>. We overlay additional information such as digit labels for insight into the latent space structure.</p>
<p>The plot on the left is the raw latent space representation corresponding to the plot on the right with digit labels overlaid.</p>
<p><img alt="Raw latent space visualization" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/latent_space_plots_nolabel.png"/></p>
<section id="section-3-1-mnist-with-pca">
<h2>Section 3.1: MNIST with PCA<a class="headerlink" href="#section-3-1-mnist-with-pca" title="Permalink to this heading">#</a></h2>
</section>
<section id="coding-exercise-1-visualize-pca-latent-space-2d">
<h2>Coding Exercise 1: Visualize PCA latent space (2D)<a class="headerlink" href="#coding-exercise-1-visualize-pca-latent-space-2d" title="Permalink to this heading">#</a></h2>
<p>The tutorial <em>W1D5 Dimensionality reduction</em> introduced PCA decomposition. The case of two principal components (PCA1 and PCA2) generates a latent space in 2D.</p>
<p><img alt="Latent space visualization PCA" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/latent_space_plots_pca.png"/></p>
<p>In tutorial W1D5, PCA decomposition was implemented directly and also by using module <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition">sklearn.decomposition</a> from the package <a class="reference external" href="https://scikit-learn.org">scikit-learn</a>. This module includes several matrix decomposition algorithms that are useful as dimensionality reduction techniques.</p>
<p>Their usage is very straightforward, as shown by this example for truncated SVD:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">svd</span> <span class="o">=</span> <span class="n">decomposition</span><span class="o">.</span><span class="n">TruncatedSVD</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">svd</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">input_train</span><span class="p">)</span>

<span class="n">svd_latent_train</span> <span class="o">=</span> <span class="n">svd</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">input_train</span><span class="p">)</span>
<span class="n">svd_latent_test</span> <span class="o">=</span> <span class="n">svd</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">svd_reconstruction_train</span> <span class="o">=</span> <span class="n">svd</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">svd_latent_train</span><span class="p">)</span>
<span class="n">svd_reconstruction_test</span> <span class="o">=</span> <span class="n">svd</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">svd_latent_test</span><span class="p">)</span>
</pre></div>
</div>
<p>in this exercise, we’ll use <code class="docutils literal notranslate"><span class="pre">decomposition.PCA</span></code> (docs <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html">here</a>) for PCA decomposition.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Initialize <code class="docutils literal notranslate"><span class="pre">decomposition.PCA</span></code> in 2 dimensions</p></li>
<li><p>Fit <code class="docutils literal notranslate"><span class="pre">input_train</span></code> with <code class="docutils literal notranslate"><span class="pre">.fit</span></code> method of <code class="docutils literal notranslate"><span class="pre">decomposition.PCA</span></code></p></li>
<li><p>Obtain latent space representation of <code class="docutils literal notranslate"><span class="pre">input_test</span></code></p></li>
<li><p>Visualize latent space with <code class="docutils literal notranslate"><span class="pre">plot_latent_generative</span></code></p></li>
</ul>
<p><strong>Helper function:</strong> <code class="docutils literal notranslate"><span class="pre">plot_latent_generative</span></code></p>
<p>Please uncomment the line below to inspect this function.</p>
<section id="id2">
<h3><a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>Execute this cell to inspect <code class="docutils literal notranslate"><span class="pre">plot_latent_generative</span></code>!</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title</span>

<span class="c1"># @markdown Execute this cell to inspect `plot_latent_generative`!</span>
<span class="n">help</span><span class="p">(</span><span class="n">plot_latent_generative</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">####################################################</span>
<span class="c1">## TODO for students: perform PCA and visualize latent space and reconstruction</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Complete the make_design_matrix function"</span><span class="p">)</span>
<span class="c1">#####################################################################</span>
<span class="c1"># create the model</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">decomposition</span><span class="o">.</span><span class="n">PCA</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="c1"># fit the model on training data</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="c1"># transformation on 2D space</span>
<span class="n">pca_latent_test</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

<span class="n">plot_latent_generative</span><span class="p">(</span><span class="n">pca_latent_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">,</span>
                       <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/main/tutorials/Bonus_Autoencoders/solutions/Bonus_Tutorial1_Solution_c05ddd88.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/Bonus_Autoencoders/static/Bonus_Tutorial1_Solution_c05ddd88_1.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/Bonus_Autoencoders/static/Bonus_Tutorial1_Solution_c05ddd88_1.png" style="width: 1132.0px; height: 575.0px;"/></a>
</section>
<section id="id3">
<h3>Submit your feedback<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_Visualize_PCA_latent_space_Exercise"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="section-3-2-qualitative-analysis-pca">
<h2>Section 3.2: Qualitative analysis PCA<a class="headerlink" href="#section-3-2-qualitative-analysis-pca" title="Permalink to this heading">#</a></h2>
<p>The encoder map shows how well the encoder is distinguishing between digit classes. We see that digits <code class="docutils literal notranslate"><span class="pre">1</span></code> and <code class="docutils literal notranslate"><span class="pre">0</span></code> are in opposite regions of the first principal component axis, and similarly for digits <code class="docutils literal notranslate"><span class="pre">9</span></code> and <code class="docutils literal notranslate"><span class="pre">3</span></code> for the second principal component.</p>
<p>The decoder grid indicates how well the decoder is recovering images from latent space coordinates. Overall, digits <code class="docutils literal notranslate"><span class="pre">1</span></code>, <code class="docutils literal notranslate"><span class="pre">0</span></code>, and <code class="docutils literal notranslate"><span class="pre">9</span></code> are the most recognizable.</p>
<p>Let’s inspect the principal components to understand these observations better. The principal components are available as <code class="docutils literal notranslate"><span class="pre">pca.components_</span></code> and shown below.</p>
<p><img alt="principal components" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/pca-components.png"/></p>
<p>Notice that the first principal component encodes digit <code class="docutils literal notranslate"><span class="pre">0</span></code> with positive values (in white) and digit <code class="docutils literal notranslate"><span class="pre">1</span></code> in negative values (in black). The colormap encodes the minimum values in black and maximum values in white, and we know their signs by looking at coordinates in the first principal component axis for digits <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
<br/>
<p>The first principal component axis encodes the “thickness” of the digits: thin digits on the left and tick digits on the right.</p>
<p>Similarly, the second principal component encodes digit <code class="docutils literal notranslate"><span class="pre">9</span></code> with positive values (in white) and digit <code class="docutils literal notranslate"><span class="pre">3</span></code> with negative values (in black).</p>
<p>The second principal component axis is encoding, well, another aspect besides “thickness” of digits (why?).</p>
<p>The reconstruction grid also shows that digits <code class="docutils literal notranslate"><span class="pre">4</span></code> and <code class="docutils literal notranslate"><span class="pre">7</span></code> are indistinguishable from digit <code class="docutils literal notranslate"><span class="pre">9</span></code> and similarly for digits <code class="docutils literal notranslate"><span class="pre">2</span></code> and <code class="docutils literal notranslate"><span class="pre">3</span></code>.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell(s) below</p></li>
<li><p>Plot reconstruction samples a few times to get a visual feel of the digit confusions (use keyword <code class="docutils literal notranslate"><span class="pre">image_shape</span></code> to visualize the vectorized images).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pca_components</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">components_</span>

<span class="n">plot_row</span><span class="p">(</span><span class="n">pca_components</span><span class="p">,</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pca_output_test</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">pca_latent_test</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test</span><span class="p">,</span> <span class="n">pca_output_test</span><span class="p">],</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="section-4-ann-autoencoder">
<h1>Section 4: ANN autoencoder<a class="headerlink" href="#section-4-ann-autoencoder" title="Permalink to this heading">#</a></h1>
<p>Let’s implement a <em>shallow</em> ANN autoencoder with a single hidden layer.</p>
<p><img alt="Single hidden layer ANN autoencoder" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/ae-ann-1h.png"/></p>
<section id="design-ann-autoencoder-32d">
<h2>Design ANN autoencoder (32D)<a class="headerlink" href="#design-ann-autoencoder-32d" title="Permalink to this heading">#</a></h2>
<p>Here we introduce a technique for quickly building Pytorch models best suited for the initial exploration phase of your research project.</p>
<p>The object-oriented programming (OOP) presented in tutorial W3D4 is your top choice after better understanding the model’s architecture and components.</p>
<p>Using this concise technique, a network equivalent to <code class="docutils literal notranslate"><span class="pre">DeepNetReLU</span></code> from W3D4 tutorial 1 is defined as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_input</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">),</span>
                      <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                      <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_output</span><span class="p">))</span>
</pre></div>
</div>
<p>Designing and training efficient neural networks currently requires some thought, experience, and testing for choosing between available options, such as the number of hidden layers, loss function, optimizer function, mini-batch size, etc. Choosing these hyper-parameters may soon become more of an engineering process with our increasing analytical understanding of these systems and their learning dynamics.</p>
<p>The references below are great to learn more about neural network design and best practices:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://neuralnetworksanddeeplearning.com">Neural Networks and Deep Learning</a> by Michael Nielsen is an excellent reference for beginners</p></li>
<li><p><a class="reference external" href="http://www.deeplearningbook.org">Deep Learning</a> by Ian Goodfellow, Yoshua Bengio, and Aaron Courville provides in-depth and extensive coverage</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1803.09820">A disciplined approach to neural network hyper-parameters: Part 1 – learning rate, batch size, momentum, and weight decay</a> by L. Smith covers efficient ways to set hyper-parameters</p></li>
</ul>
<section id="coding-exercise-2-design-ann-autoencoder">
<h3>Coding Exercise 2: Design ANN autoencoder<a class="headerlink" href="#coding-exercise-2-design-ann-autoencoder" title="Permalink to this heading">#</a></h3>
<p>We will use a rectifier <a class="reference external" href="https://icml.cc/Conferences/2010/papers/432.pdf">ReLU</a> units in the bottleneck layer with <code class="docutils literal notranslate"><span class="pre">encoding_dim=32</span></code> units, and sigmoid units in the output layer. You can read more about activation functions <a class="reference external" href="https://en.wikipedia.org/wiki/Activation_function">here</a> and rectifiers <a class="reference external" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">here</a>.</p>
<p><img alt="ReLU unit" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/relu.png"/></p>
<p><img alt="Single hidden layer ANN autoencoder" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/sigmoid.png"/></p>
<p>We rescaled images to values between <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code> for compatibility with sigmoid units in the output (why?). Such mapping is without loss of generality since any (finite) range can map a one-to-one correspondence to values between <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
<p>Both ReLU and sigmoid units provide non-linear computation to the encoder and decoder components. The sigmoid units, additionally, ensure output values to be in the same range as the inputs. These units could be swapped by ReLU, in which case output values would sometimes be negative or greater than 1. The sigmoid units of the decoder enforce a numerical constraint that expresses our <em>domain knowledge</em> of the data.</p>
<p><strong>Instructions</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code> defines and initializes an ANN with layer sizes (<code class="docutils literal notranslate"><span class="pre">input_shape,</span> <span class="pre">encoding_dim,</span> <span class="pre">input_shape</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code> defines a linear layer with the size of the inputs and outputs as arguments</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nn.ReLU</span></code> and <code class="docutils literal notranslate"><span class="pre">nn.Sigmoid</span></code> encode ReLU and sigmoid units</p></li>
<li><p>Visualize the initial output using <code class="docutils literal notranslate"><span class="pre">plot_row</span></code> with input and output images</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="c1">######################################################################</span>
<span class="c1">## TODO for students: add linear and sigmoid layers</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Complete the make_design_matrix function"</span><span class="p">)</span>
<span class="c1">#####################################################################</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">encoding_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="c1"># insert your code here to add the layer</span>
    <span class="c1"># nn.Linear(...),</span>
    <span class="c1"># insert the activation function</span>
    <span class="c1"># ....</span>
    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Model structure </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>SAMPLE OUTPUT</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Sequential</span><span class="p">(</span>
  <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="n">ReLU</span><span class="p">()</span>
  <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="p">(</span><span class="mi">3</span><span class="p">):</span> <span class="n">Sigmoid</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/main/tutorials/Bonus_Autoencoders/solutions/Bonus_Tutorial1_Solution_e7182519.py"><em>Click for solution</em></a></p>
<section id="id4">
<h4>Submit your feedback<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h4>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_Design_ANN_autoencoder_Exercise"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">output_test</span><span class="p">],</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="train-autoencoder-32d">
<h2>Train autoencoder (32D)<a class="headerlink" href="#train-autoencoder-32d" title="Permalink to this heading">#</a></h2>
<p>The function <code class="docutils literal notranslate"><span class="pre">runSGD</span></code> trains the autoencoder with stochastic gradient descent using Adam optimizer (<code class="docutils literal notranslate"><span class="pre">optim.Adam</span></code>) and provides a choice between Mean Square Errors (MSE  with <code class="docutils literal notranslate"><span class="pre">nn.MSELoss</span></code>) and Binary Cross-entropy (BCE with <code class="docutils literal notranslate"><span class="pre">nn.BCELoss</span></code>).</p>
<p>The figures below illustrate these losses, where <span class="math notranslate nohighlight">\(\hat{Y}\)</span> is the output value, and <span class="math notranslate nohighlight">\(Y\)</span> is the target value.</p>
<p><img alt="MSE loss" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/mse.png"/></p>
<p><img alt="BCE loss" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/bce.png"/></p>
<p>Train the network for <code class="docutils literal notranslate"><span class="pre">n_epochs=10</span></code> epochs and <code class="docutils literal notranslate"><span class="pre">batch_size=64</span></code> with <code class="docutils literal notranslate"><span class="pre">runSGD</span></code> and MSE loss, and visualize a few reconstructed samples.</p>
<p>Please execute the cells below to construct and train the model!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">encoding_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
    <span class="p">)</span>

<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_train</span><span class="p">,</span> <span class="n">input_test</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">'mse'</span><span class="p">,</span>
       <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span> <span class="n">output_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">]],</span>
         <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="choose-the-loss-function">
<h2>Choose the loss function<a class="headerlink" href="#choose-the-loss-function" title="Permalink to this heading">#</a></h2>
<p>The loss function determines what the network is optimizing during training, and this translates to the visual aspect of reconstructed images.</p>
<p>For example, isolated black pixels in the middle of white regions are very unlikely and look noisy. The network can prioritize avoiding such scenarios by maximally penalizing white pixels that turn out black and vice-versa.</p>
<p>The figure below compares MSE with BCE with a target pixel value <span class="math notranslate nohighlight">\(Y=1\)</span>, and the output ranging from <span class="math notranslate nohighlight">\(\hat{Y}\in [0, 1]\)</span>. The MSE loss has a gentle quadratic rise in this range. Notice how BCE loss dramatically increases for dark pixels <span class="math notranslate nohighlight">\(\hat{Y}\)</span> lower than 0.4.</p>
<p><img alt="bce vs. MSE loss" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/bce-mse.png"/></p>
<p>Let’s look at their derivatives <span class="math notranslate nohighlight">\(d\,\text{Loss}/d\,\hat{Y}\)</span> to make this comparison more objective. The derivative of MSE loss is linear with slope <span class="math notranslate nohighlight">\(-2\)</span>, whereas BCE takes off as <span class="math notranslate nohighlight">\(1/\hat{Y}\)</span> for dark pixel values (why?).</p>
<p><img alt="bce vs. MSE loss" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/bce-mse-dloss.png"/></p>
<p>We reduced the plotting range to <span class="math notranslate nohighlight">\([0.05, 1]\)</span> to share the same y-axis scale for both loss functions (why?).</p>
<p>Let’s switch to BCE loss and verify the effects of maximally penalizing white pixels that turn out black and vice-versa. The visual differences between losses will be subtle since the network is converging well in both cases.</p>
<p><strong>Look for isolated white/black pixel areas in MSE loss reconstructions.</strong></p>
<p>We will first retrain under MSE loss for <code class="docutils literal notranslate"><span class="pre">2</span></code> epochs to accentuate differences, and similarly under BCE loss.</p>
<p>Please execute the cells below to train with MSE and BCE, respectively.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">encoding_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
    <span class="p">)</span>

<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_train</span><span class="p">,</span> <span class="n">input_test</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">'mse'</span><span class="p">,</span>
       <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span> <span class="n">output_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">]],</span>
         <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">encoding_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
    <span class="p">)</span>

<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_train</span><span class="p">,</span> <span class="n">input_test</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">'bce'</span><span class="p">,</span>
       <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span> <span class="n">output_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">]],</span>
         <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="design-ann-autoencoder-2d">
<h2>Design ANN autoencoder (2D)<a class="headerlink" href="#design-ann-autoencoder-2d" title="Permalink to this heading">#</a></h2>
<p>Reducing the number of bottleneck units to <code class="docutils literal notranslate"><span class="pre">encoding_size=2</span></code> generates a 2D latent space as for PCA before. The coordinates <span class="math notranslate nohighlight">\((z_1, z_2)\)</span>  of the encoder map represent unit activations in the bottleneck layer.</p>
<br/>
<p><img alt="encoder map for autoencoder" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/latent_space_plots_ae.png"/></p>
<br/>
<p>The <code class="docutils literal notranslate"><span class="pre">encoder</span></code> component provides (<span class="math notranslate nohighlight">\(z_1, z_2\)</span>) coordinates in latent space, and the <code class="docutils literal notranslate"><span class="pre">decoder</span></code> component generates image reconstructions from (<span class="math notranslate nohighlight">\(z_1, z_2\)</span>). Specifying a sequence of layers from the autoencoder network defines these sub-networks.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="n">n</span><span class="p">:]</span>
</pre></div>
</div>
<p>This architecture works well with a bottleneck layer with 32 units but fails to converge with two units.  Check the exercises in <em>Bonus</em> section to understand this failure more and two options to address it: better weight initialization and changing the activation function.</p>
<p>Here we opt for <a class="reference external" href="https://arxiv.org/abs/1502.01852">PReLU units</a> in the bottleneck layer to add negative activations with a learnable parameter. This change affords additional wiggle room for the autoencoder to model data with only two units in the bottleneck layer.</p>
<p><img alt="PreLU unit" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/prelu.png"/></p>
<p><strong>Instructions</strong></p>
<ul class="simple">
<li><p>Please execute the cells below:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">encoding_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
    <span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Autoencoder </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Encoder </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">encoder</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Decoder </span><span class="se">\n\n</span><span class="s1"> </span><span class="si">{</span><span class="n">decoder</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-the-autoencoder-2d">
<h2>Train the autoencoder (2D)<a class="headerlink" href="#train-the-autoencoder-2d" title="Permalink to this heading">#</a></h2>
<p>Train the network for <code class="docutils literal notranslate"><span class="pre">n_epochs=10</span></code> epochs and <code class="docutils literal notranslate"><span class="pre">batch_size=64</span></code> with <code class="docutils literal notranslate"><span class="pre">runSGD</span></code> and BCE loss, and visualize latent space.</p>
<p>Please execute the cells below to train the autoencoder!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># train the autoencoder</span>
<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_train</span><span class="p">,</span> <span class="n">input_test</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">'bce'</span><span class="p">,</span>
       <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">latent_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_latent_generative</span><span class="p">(</span><span class="n">latent_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span>
                       <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="expressive-power-in-2d">
<h2>Expressive power in 2D<a class="headerlink" href="#expressive-power-in-2d" title="Permalink to this heading">#</a></h2>
<p>The latent space representation of shallow autoencoder with a 2D bottleneck is similar to that of PCA. How can this linear dimensionality reduction technique be comparable to our non-linear autoencoder?</p>
<p>Training an autoencoder with linear activation functions under MSE loss is <a class="reference external" href="https://arxiv.org/abs/1804.10253">very similar to performing PCA</a>. Using piece-wise linear units, sigmoidal output unit, and BCE loss doesn’t seem to change this behavior qualitatively. The network lacks capacity in terms of learnable parameters to make good use of its non-linear operations and capture non-linear aspects of the data.</p>
<p>The similarity between representations is apparent when plotting decoder maps side-by-side. Look for classes of digits that cluster successfully, and those still mixing with others.</p>
<p>Execute the cell below for a PCA vs. Autoencoder (2D) comparison!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_latent_ab</span><span class="p">(</span><span class="n">pca_latent_test</span><span class="p">,</span> <span class="n">latent_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span>
               <span class="n">title_a</span><span class="o">=</span><span class="s1">'PCA'</span><span class="p">,</span> <span class="n">title_b</span><span class="o">=</span><span class="s1">'Autoencoder (2D)'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">#</a></h1>
<p>In this tutorial, we got comfortable with the basic techniques to create and visualize low-dimensional representations and build shallow autoencoders.</p>
<p><strong>We saw that PCA and shallow autoencoder have similar expressive power in 2D latent space, despite the autoencoder’s non-linear character.</strong></p>
<p>The shallow autoencoder lacks learnable parameters to take advantage of non-linear operations in encoding/decoding and capture non-linear patterns in data.</p>
<p>The next tutorial extends the autoencoder architecture to learn richer internal representations of data required for tackling the MNIST cognitive task.</p>
<section id="video-3-wrap-up">
<h2>Video 3: Wrap-up<a class="headerlink" href="#video-3-wrap-up" title="Permalink to this heading">#</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</section>
<section id="id5">
<h2>Submit your feedback<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h2>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_WrapUp_Video"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<hr class="docutils"/>
<section class="tex2jax_ignore mathjax_ignore" id="bonus">
<h1>Bonus<a class="headerlink" href="#bonus" title="Permalink to this heading">#</a></h1>
<section id="failure-mode-with-relu-units-in-2d">
<h2>Failure mode with ReLU units in 2D<a class="headerlink" href="#failure-mode-with-relu-units-in-2d" title="Permalink to this heading">#</a></h2>
<p>An architecture with two units in the bottleneck layer, ReLU units, and default weight initialization may fail to converge, depending on the minibatch sequence, choice of the optimizer, etc. To illustrate this failure mode, we first set the random number generators (RNGs) to reproduce an example of failed convergence:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>Afterward, we set the RNGs to reproduce an example of successful convergence:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p> </p>
<p>Train the network for <code class="docutils literal notranslate"><span class="pre">n_epochs=10</span></code> epochs and <code class="docutils literal notranslate"><span class="pre">batch_size=64</span></code> and check the encoder map and reconstruction grid in each case.</p>
<p>We then activate our x-ray vision and check the distribution of weights in encoder and decoder components. Recall that encoder maps input pixels to bottleneck units (encoder weights <code class="docutils literal notranslate"><span class="pre">shape=(2,</span> <span class="pre">784)</span></code>), and decoder maps bottleneck units to output pixels (decoder weights <code class="docutils literal notranslate"><span class="pre">shape=(784,</span> <span class="pre">2)</span></code>).</p>
<p>Network models often initialize with random weights close to 0. The default weight initialization for linear layers in Pytorch is sampled from a uniform distribution <code class="docutils literal notranslate"><span class="pre">[-limit,</span> <span class="pre">limit]</span></code> with <code class="docutils literal notranslate"><span class="pre">limit=1/sqrt(fan_in)</span></code>, where <code class="docutils literal notranslate"><span class="pre">fan_in</span></code> is the number of input units in the weight tensor.</p>
<p>We compare the distribution of weights on network initialization to that after training. Weights that fail to learn during training keep to their initial distribution. On the other hand, weights that are adjusted by SGD during training are likely to have a change in distribution.</p>
<p>Encoder weights may even acquire a bell-shaped form. This effect may be related to the following: SGD adds a sequence of positive and negative increments to each initial weight. The Central Limit Theorem (CLT) would predict a gaussian histogram if increments were independent in sequences and between sequences. The deviation from gaussianity is a measure of the inter-dependency of SGD increments.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cells below</p></li>
<li><p>Start with <code class="docutils literal notranslate"><span class="pre">torch.manual_seed</span> <span class="pre">=</span> <span class="pre">0</span></code> for an example of failed convergence</p></li>
<li><p>Check encoder mapping collapsed into a single axis</p></li>
<li><p>Verify collapsed dimension corresponds to unchanged weights</p></li>
<li><p>Change <code class="docutils literal notranslate"><span class="pre">torch.manual_seed</span> <span class="pre">=</span> <span class="pre">1</span></code> for an example of successful convergence</p></li>
<li><p>Run <code class="docutils literal notranslate"><span class="pre">help(get_layer_weights)</span></code> for additional details on retrieving learnable parameters (weights and biases)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># set PyTorch RNG seed</span>
<span class="n">torch_seed</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># reset RNG for weight initialization</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">torch_seed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">encoding_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
    <span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>

<span class="c1"># retrieve weights and biases from the encoder before training</span>
<span class="n">encoder_w_init</span><span class="p">,</span> <span class="n">encoder_b_init</span> <span class="o">=</span> <span class="n">get_layer_weights</span><span class="p">(</span><span class="n">encoder</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">decoder_w_init</span><span class="p">,</span> <span class="n">decoder_b_init</span> <span class="o">=</span> <span class="n">get_layer_weights</span><span class="p">(</span><span class="n">decoder</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># reset RNG for minibatch sequence</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">torch_seed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># train the autoencoder</span>
<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_train</span><span class="p">,</span> <span class="n">input_test</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">'bce'</span><span class="p">,</span>
       <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="c1"># retrieve weights and biases from the encoder after training</span>
<span class="n">encoder_w_train</span><span class="p">,</span> <span class="n">encoder_b_train</span> <span class="o">=</span> <span class="n">get_layer_weights</span><span class="p">(</span><span class="n">encoder</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">decoder_w_train</span><span class="p">,</span> <span class="n">decoder_b_train</span> <span class="o">=</span> <span class="n">get_layer_weights</span><span class="p">(</span><span class="n">decoder</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">latent_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_latent_generative</span><span class="p">(</span><span class="n">latent_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span> <span class="n">output_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">]],</span>
         <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_weights_ab</span><span class="p">(</span><span class="n">encoder_w_init</span><span class="p">,</span> <span class="n">encoder_w_train</span><span class="p">,</span> <span class="n">decoder_w_init</span><span class="p">,</span>
                <span class="n">decoder_w_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="bonus-coding-exercise-3-choosing-weight-initialization">
<h3>Bonus Coding Exercise 3: Choosing weight initialization<a class="headerlink" href="#bonus-coding-exercise-3-choosing-weight-initialization" title="Permalink to this heading">#</a></h3>
<p>An improved weight initialization for ReLU units avoids the failure mode from the previous exercise. A popular choice for rectifier units is <em>Kaiming uniform</em>: sampling from uniform distribution <span class="math notranslate nohighlight">\(\mathcal{U}(-limit, limit)\)</span> with <span class="math notranslate nohighlight">\(limit=\sqrt{6/fan\_in}\)</span>, where <span class="math notranslate nohighlight">\(fan\_in\)</span> is the number of input units in the weight tensor (see the relevant <a class="reference external" href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf">article</a> for details). Example of resetting all autoencoder weights to Kaiming uniform:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights_kaiming_uniform</span><span class="p">)</span>
</pre></div>
</div>
<p>An alternative is to sample from a gaussian distribution <span class="math notranslate nohighlight">\(\mathcal{N}(\mu, \sigma^2)\)</span> with <span class="math notranslate nohighlight">\(\mu=0\)</span> and <span class="math notranslate nohighlight">\(\sigma=1/\sqrt{fan\_in}\)</span>. Example for resetting all but the two last autoencoder layers to Kaiming normal:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights_kaiming_normal</span><span class="p">)</span>
</pre></div>
</div>
<p>For more information on weight initialization, the references below are a good starting point:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">Efficient Backprop</a></p></li>
<li><p><a class="reference external" href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">Understanding the difficulty of training deep feedforward neural networks</a></p></li>
<li><p><a class="reference external" href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf">Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification</a></p></li>
</ul>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Reset encoder weights with <code class="docutils literal notranslate"><span class="pre">init_weights_kaiming_uniform</span></code></p></li>
<li><p>Compare with resetting with <code class="docutils literal notranslate"><span class="pre">init_weights_kaiming_normal</span></code></p></li>
<li><p>See <code class="docutils literal notranslate"><span class="pre">help(init_weights_kaiming_uniform)</span></code> and <code class="docutils literal notranslate"><span class="pre">help(init_weights_kaiming_normal)</span></code> for additional details</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># set PyTorch RNG seed</span>
<span class="n">torch_seed</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">encoding_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
    <span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>

<span class="c1"># reset RNGs for weight initialization</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">torch_seed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1">######################################################################</span>
<span class="c1">## TODO for students: reset encoder weights and biases</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Complete the code below"</span><span class="p">)</span>
<span class="c1">#####################################################################</span>
<span class="c1"># reset encoder weights and biases</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

<span class="c1"># retrieve weights and biases from the encoder before training</span>
<span class="n">encoder_w_init</span><span class="p">,</span> <span class="n">encoder_b_init</span> <span class="o">=</span> <span class="n">get_layer_weights</span><span class="p">(</span><span class="n">encoder</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">decoder_w_init</span><span class="p">,</span> <span class="n">decoder_b_init</span> <span class="o">=</span> <span class="n">get_layer_weights</span><span class="p">(</span><span class="n">decoder</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># reset RNGs for minibatch sequence</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">torch_seed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># train the autoencoder</span>
<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_train</span><span class="p">,</span> <span class="n">input_test</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">'bce'</span><span class="p">,</span>
       <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="c1"># retrieve weights and biases from the encoder after training</span>
<span class="n">encoder_w_train</span><span class="p">,</span> <span class="n">encoder_b_train</span> <span class="o">=</span> <span class="n">get_layer_weights</span><span class="p">(</span><span class="n">encoder</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">decoder_w_train</span><span class="p">,</span> <span class="n">decoder_b_train</span> <span class="o">=</span> <span class="n">get_layer_weights</span><span class="p">(</span><span class="n">decoder</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/main/tutorials/Bonus_Autoencoders/solutions/Bonus_Tutorial1_Solution_9d6c1017.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/Bonus_Autoencoders/static/Bonus_Tutorial1_Solution_9d6c1017_11.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/tutorials/Bonus_Autoencoders/static/Bonus_Tutorial1_Solution_9d6c1017_11.png" style="width: 775.0px; height: 575.0px;"/></a>
<section id="id6">
<h4>Submit your feedback<a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h4>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Submit your feedback</span>
<span class="n">content_review</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">feedback_prefix</span><span class="si">}</span><span class="s2">_Choosing_weight_initialization_Bonus_Exercise"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">latent_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_latent_generative</span><span class="p">(</span><span class="n">latent_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span>
                       <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span> <span class="n">output_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">]],</span>
         <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_weights_ab</span><span class="p">(</span><span class="n">encoder_w_init</span><span class="p">,</span> <span class="n">encoder_w_train</span><span class="p">,</span> <span class="n">decoder_w_init</span><span class="p">,</span>
                <span class="n">decoder_w_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="choose-the-activation-function">
<h2>Choose the activation function<a class="headerlink" href="#choose-the-activation-function" title="Permalink to this heading">#</a></h2>
<p>An alternative to specific weight initialization is to choose an activation unit that performs better in this context. We will use <a class="reference external" href="https://arxiv.org/abs/1502.01852">PReLU</a> units in the bottleneck layer, which adds a learnable parameter for negative activations.</p>
<p>This change affords a little bit more of wiggle room for the autoencoder to model data compared to ReLU units.</p>
<p><img alt="PreLU unit" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/prelu.png"/></p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cells below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># set PyTorch RNG seed</span>
<span class="n">torch_seed</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># reset RNGs for weight initialization</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">torch_seed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">encoding_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoding_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
    <span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>

<span class="c1"># retrieve weights and biases from the encoder before training</span>
<span class="n">encoder_w_init</span><span class="p">,</span> <span class="n">encoder_b_init</span> <span class="o">=</span> <span class="n">get_layer_weights</span><span class="p">(</span><span class="n">encoder</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">decoder_w_init</span><span class="p">,</span> <span class="n">decoder_b_init</span> <span class="o">=</span> <span class="n">get_layer_weights</span><span class="p">(</span><span class="n">decoder</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># reset RNGs for minibatch sequence</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">torch_seed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># train the autoencoder</span>
<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_train</span><span class="p">,</span> <span class="n">input_test</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">'bce'</span><span class="p">,</span>
       <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="c1"># retrieve weights and biases from the encoder after training</span>
<span class="n">encoder_w_train</span><span class="p">,</span> <span class="n">encoder_b_train</span> <span class="o">=</span> <span class="n">get_layer_weights</span><span class="p">(</span><span class="n">encoder</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">decoder_w_train</span><span class="p">,</span> <span class="n">decoder_b_train</span> <span class="o">=</span> <span class="n">get_layer_weights</span><span class="p">(</span><span class="n">decoder</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">latent_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_latent_generative</span><span class="p">(</span><span class="n">latent_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_weights_ab</span><span class="p">(</span><span class="n">encoder_w_init</span><span class="p">,</span> <span class="n">encoder_w_train</span><span class="p">,</span> <span class="n">decoder_w_init</span><span class="p">,</span>
                <span class="n">decoder_w_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="qualitative-analysis-nmf">
<h2>Qualitative analysis NMF<a class="headerlink" href="#qualitative-analysis-nmf" title="Permalink to this heading">#</a></h2>
<p>We proceed with <em>non-negative matrix factorization (NMF)</em> using <code class="docutils literal notranslate"><span class="pre">sk.decomposition.NMF</span></code> (docs <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html">here</a>).</p>
<p>A product of positive matrices <span class="math notranslate nohighlight">\(W\)</span> and <span class="math notranslate nohighlight">\(H\)</span> approximates data matrix <span class="math notranslate nohighlight">\(X\)</span>, i.e., <span class="math notranslate nohighlight">\(X \approx W H\)</span>.</p>
<p>The columns of <span class="math notranslate nohighlight">\(W\)</span> play the same role as the principal components in PCA.</p>
<p>Digit classes <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code> are the furthest apart in latent space and better clustered.</p>
<p>Looking at the first component, we see that images gradually resemble digit class <code class="docutils literal notranslate"><span class="pre">0</span></code>. A mix between digits classes <code class="docutils literal notranslate"><span class="pre">1</span></code> and <code class="docutils literal notranslate"><span class="pre">9</span></code> in the second component shows a similar progression.</p>
<p>That data is shifted by <code class="docutils literal notranslate"><span class="pre">0.5</span></code> to avoid failure modes near <code class="docutils literal notranslate"><span class="pre">0</span></code> - this is probably related to our scaling choice. Try it without shifting by <code class="docutils literal notranslate"><span class="pre">0.5</span></code>.</p>
<p>The parameter <code class="docutils literal notranslate"><span class="pre">init='random'</span></code> scales the initial non-negative random matrices and often provides better results - try it as well!</p>
<p>Please execute the cells below, to run NMF.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nmf</span> <span class="o">=</span> <span class="n">decomposition</span><span class="o">.</span><span class="n">NMF</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">'random'</span><span class="p">)</span>

<span class="n">nmf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">input_train</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="n">nmf_latent_test</span> <span class="o">=</span> <span class="n">nmf</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">input_test</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="n">plot_latent_generative</span><span class="p">(</span><span class="n">nmf_latent_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">nmf</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">,</span>
                       <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nmf_components</span> <span class="o">=</span> <span class="n">nmf</span><span class="o">.</span><span class="n">components_</span>

<span class="n">plot_row</span><span class="p">(</span><span class="n">nmf_components</span><span class="p">,</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nmf_output_test</span> <span class="o">=</span> <span class="n">nmf</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">nmf_latent_test</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test</span><span class="p">,</span> <span class="n">nmf_output_test</span><span class="p">],</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tutorials/Bonus_Autoencoders/student"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</article>
<footer class="bd-footer-article">
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="Bonus_Intro.html" id="prev-link" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Intro</p>
</div>
</a>
<a class="right-next" href="Bonus_Tutorial2.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Tutorial 2: Autoencoder extensions</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="toc-item">
<div class="tocsection onthispage">
<i class="fa-solid fa-list"></i> On this page
</div>
<nav class="page-toc" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 1: Intro to Autoencoders
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#internal-representations-and-autoencoders">
     Internal representations and autoencoders
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-and-import-feedback-gadget">
     Install and import feedback gadget
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-0-introduction">
   Section 0: Introduction
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-intro">
     Video 1: Intro
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#submit-your-feedback">
     Submit your feedback
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-introduction-to-autoencoders">
   Section 1: Introduction to autoencoders
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-autoencoders">
     Video 2: Autoencoders
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
     Submit your feedback
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-the-mnist-dataset">
   Section 2: The MNIST dataset
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-1-download-and-prepare-mnist-dataset">
     Section 2.1: Download  and prepare MNIST dataset
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#visualize-samples">
     Visualize samples
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-latent-space-visualization">
   Section 3: Latent space visualization
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-1-mnist-with-pca">
     Section 3.1: MNIST with PCA
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-visualize-pca-latent-space-2d">
     Coding Exercise 1: Visualize PCA latent space (2D)
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
</a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id3">
       Submit your feedback
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-2-qualitative-analysis-pca">
     Section 3.2: Qualitative analysis PCA
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-ann-autoencoder">
   Section 4: ANN autoencoder
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#design-ann-autoencoder-32d">
     Design ANN autoencoder (32D)
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-design-ann-autoencoder">
       Coding Exercise 2: Design ANN autoencoder
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id4">
         Submit your feedback
        </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#train-autoencoder-32d">
     Train autoencoder (32D)
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#choose-the-loss-function">
     Choose the loss function
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#design-ann-autoencoder-2d">
     Design ANN autoencoder (2D)
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#train-the-autoencoder-2d">
     Train the autoencoder (2D)
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#expressive-power-in-2d">
     Expressive power in 2D
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-wrap-up">
     Video 3: Wrap-up
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#id5">
     Submit your feedback
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus">
   Bonus
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#failure-mode-with-relu-units-in-2d">
     Failure mode with ReLU units in 2D
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-coding-exercise-3-choosing-weight-initialization">
       Bonus Coding Exercise 3: Choosing weight initialization
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id6">
         Submit your feedback
        </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#choose-the-activation-function">
     Choose the activation function
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#qualitative-analysis-nmf">
     Qualitative analysis NMF
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<footer class="bd-footer-content">
<div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
<div class="footer-item">
<p class="component-author">
By Neuromatch
</p>
</div>
<div class="footer-item">
</div>
<div class="footer-item">
<p class="last-updated">
Last updated on None.<br/>
</p>
</div>
<div class="footer-item">
<div class="extra_footer">
<div>
<a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
<a href="https://opensource.org/licenses/BSD-3-Clause"><img src="https://camo.githubusercontent.com/9b9ea65d95c9ef878afa1987df65731d47681336/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f736561626f726e2e737667"/></a>
The contents of this repository are shared under the <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Software elements are additionally licensed under the <a href="https://opensource.org/licenses/BSD-3-Clause">BSD (3-Clause) License</a>.
</div>
</div>
</div>
</div>
</div>
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>
</body>
</html>