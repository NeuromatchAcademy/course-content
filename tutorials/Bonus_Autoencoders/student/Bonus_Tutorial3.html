
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 3: Autoencoders applications — Neuromatch Academy: Computational Neuroscience</title>
<link href="../../../_static/css/theme.css" rel="stylesheet"/>
<link href="../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-book-theme.css?digest=84ace793992934648b4de8eed757e5a2" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<link as="script" href="../../../_static/js/index.be7d3bbb2ef33a8344ce.js" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script src="../../../_static/sphinx-book-theme.9d8b4a8b9bb19db25eeaddc40d639ba2.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
<script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<link href="../../../_static/nma-logo-square-4xp.jpg" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="../Bonus_Outro.html" rel="next" title="Outro"/>
<link href="Bonus_Tutorial2.html" rel="prev" title="Tutorial 2: Autoencoder extensions"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="None" name="docsearch:language"/>
<!-- Google Analytics -->
</link></link></link></link></link></link></head>
<body data-offset="80" data-spy="scroll" data-target="#bd-toc-nav">
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<!-- Checkboxes to toggle the left sidebar -->
<input aria-label="Toggle navigation sidebar" class="sidebar-toggle" id="__navigation" name="__navigation" type="checkbox"/>
<label class="overlay" for="__navigation">
<div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<div class="col-12 col-md-3 bd-sidebar site-navigation" id="site-navigation">
<div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
<img alt="logo" class="logo" src="../../../_static/nma-logo-square-4xp.jpg"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Computational Neuroscience</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
   Introduction
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox">
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using discord
    </a>
</li>
</ul>
</input></li>
</ul>
<p class="caption">
<span class="caption-text">
  Pre-reqs Refresher
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/chapter_title.html">
   Neuro Video Series (W0D0)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial1.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial2.html">
     Human Psychophysics
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial3.html">
     Behavioral Readout
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial4.html">
     Live in Lab
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial5.html">
     Brain Signals: Spiking Activity
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial6.html">
     Brain Signals: LFP
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial7.html">
     Brain Signals: EEG &amp; MEG
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial8.html">
     Brain Signals: fMRI
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial9.html">
     Brain Signals: Calcium Imaging
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial10.html">
     Stimulus Representation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial11.html">
     Neurotransmitters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D0_NeuroVideoSeries/student/W0D0_Tutorial12.html">
     Neurons to Consciousness
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">
   Python Workshop 1 (W0D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D1_PythonWorkshop1/student/W0D1_Tutorial1.html">
     Tutorial: LIF Neuron Part I
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">
   Python Workshop 2 (W0D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D2_PythonWorkshop2/student/W0D2_Tutorial1.html">
     Tutorial 1: LIF Neuron Part II
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D3_LinearAlgebra/chapter_title.html">
   Linear Algebra (W0D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial1.html">
     Tutorial 1: Vectors
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial2.html">
     Tutorial 2: Matrices
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial3.html">
     Bonus Tutorial: Discrete Dynamical Systems
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D3_LinearAlgebra/W0D3_Outro.html">
     Outro
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D4_Calculus/chapter_title.html">
   Calculus (W0D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial1.html">
     Tutorial 1: Differentiation and Integration
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial2.html">
     Tutorial 2: Differential Equations
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial3.html">
     Tutorial 3: Numerical Methods
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W0D5_Statistics/chapter_title.html">
   Statistics (W0D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial1.html">
     Tutorial 1: Probability Distributions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial2.html">
     Tutorial 2: Statistical Inference
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W0D5_Statistics/W0D5_Outro.html">
     Outro
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Intro to Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_ModelTypes/chapter_title.html">
   Model Types (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/W1D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial1.html">
     Tutorial 1: “What” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial2.html">
     Tutorial 2: “How” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial3.html">
     Tutorial 3: “Why” models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial4.html">
     Tutorial 4: Model Dicussions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/W1D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_ModelTypes/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_ModelingPractice/chapter_title.html">
   Modeling Practice (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelingPractice/W1D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelingPractice/student/W1D2_Tutorial1.html">
     Tutorial 1: Framing the Question
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_ModelingPractice/W1D2_Outro.html">
     Outro
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_ModelFitting/chapter_title.html">
   Model Fitting (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/W1D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial1.html">
     Tutorial 1: Linear regression with MSE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial2.html">
     Tutorial 2: Linear regression with MLE
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial3.html">
     Tutorial 3: Confidence intervals and bootstrapping
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial4.html">
     Tutorial 4: Multiple linear regression and polynomial regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial5.html">
     Tutorial 5: Model Selection: Bias-variance trade-off
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial6.html">
     Tutorial 6: Model Selection: Cross-validation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/W1D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_ModelFitting/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/chapter_title.html">
   Generalized Linear Models (W1D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/W1D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/student/W1D4_Tutorial1.html">
     Tutorial 1: GLMs for Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/student/W1D4_Tutorial2.html">
     Tutorial 2: Classifiers and regularizers
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/W1D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_GeneralizedLinearModels/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/chapter_title.html">
   Dimensionality Reduction (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/W1D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial1.html">
     Tutorial 1: Geometric view of data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial2.html">
     Tutorial 2: Principal Component Analysis
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial3.html">
     Tutorial 3: Dimensionality Reduction &amp; Reconstruction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial4.html">
     Tutorial 4:  Nonlinear Dimensionality Reduction
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/W1D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_DimensionalityReduction/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_DeepLearning/chapter_title.html">
   Deep Learning (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/W2D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial3.html">
     Tutorial 3: Building and Evaluating Normative Encoding Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial4.html">
     Bonus Tutorial: Diving Deeper into Decoding &amp; Encoding
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/W2D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_DeepLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Autoencoders (Bonus)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2">
<a class="reference internal" href="../Bonus_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="Bonus_Tutorial1.html">
     Tutorial 1: Intro to Autoencoders
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="Bonus_Tutorial2.html">
     Tutorial 2: Autoencoder extensions
    </a>
</li>
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 3: Autoencoders applications
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../Bonus_Outro.html">
     Outro
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/MachineLearning.html">
   Machine Learning Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_LinearSystems/chapter_title.html">
   Linear Systems (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/W2D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial1.html">
     Tutorial 1: Linear dynamical systems
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial2.html">
     Tutorial 2: Markov Processes
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial3.html">
     Tutorial 3: Combining determinism and stochasticity
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial4.html">
     Tutorial 4: Autoregressive models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/W2D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_LinearSystems/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/chapter_title.html">
   Biological Neuron Models (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/W2D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial1.html">
     Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial2.html">
     Tutorial 2: Effects of Input Correlation
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial3.html">
     Tutorial 3: Synaptic transmission - Models of static and dynamic synapses
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial4.html">
     Bonus Tutorial: Spike-timing dependent plasticity (STDP)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/W2D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_BiologicalNeuronModels/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_DynamicNetworks/chapter_title.html">
   Dynamic Networks (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/W2D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial1.html">
     Tutorial 1: Neural Rate Models
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial2.html">
     Tutorial 2: Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial3.html">
     Bonus Tutorial: Extending the Wilson-Cowan Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/W2D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_DynamicNetworks/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/DynamicalSystems.html">
   Dynamical Systems Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Stochastic Processes
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_BayesianDecisions/chapter_title.html">
   Bayesian Decisions (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/W3D1_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial1.html">
     Tutorial 1: Bayes with a binary hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial2.html">
     Tutorial 2: Bayesian inference and decisions with continuous hidden state
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial3.html">
     Bonus Tutorial : Fitting to data
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/W3D1_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_BayesianDecisions/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_HiddenDynamics/chapter_title.html">
   Hidden Dynamics (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/W3D2_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial1.html">
     Tutorial 1: Sequential Probability Ratio Test
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial2.html">
     Tutorial 2: Hidden Markov Model
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial3.html">
     Tutorial 3: The Kalman Filter
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial4.html">
     Bonus Tutorial 4: The Kalman Filter, part 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial5.html">
     Bonus Tutorial 5: Expectation Maximization for spiking neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/W3D2_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_HiddenDynamics/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_OptimalControl/chapter_title.html">
   Optimal Control (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/W3D3_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial1.html">
     Tutorial 1: Optimal Control for Discrete States
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial2.html">
     Tutorial 2: Optimal Control for Continuous State
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/W3D3_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_OptimalControl/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/chapter_title.html">
   Reinforcement Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/W3D4_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial4.html">
     Tutorial 4: From Reinforcement Learning to Planning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/W3D4_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ReinforcementLearning/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D5_NetworkCausality/chapter_title.html">
   Network Causality (W3D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
<label for="toctree-checkbox-24">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/W3D5_Intro.html">
     Intro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial1.html">
     Tutorial 1: Interventions
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial2.html">
     Tutorial 2: Correlations
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial3.html">
     Tutorial 3: Simultaneous fitting/regression
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial4.html">
     Tutorial 4: Instrumental Variables
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/W3D5_Outro.html">
     Outro
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D5_NetworkCausality/further_reading.html">
     Suggested further readings
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/StochasticProcesses.html">
   Stochastic Processes Wrap-Up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction to projects
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
<label for="toctree-checkbox-25">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through4.html">
     Modeling Steps 1 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through10.html">
     Modeling Steps 5 - 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModel.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProject.html">
     Example Data Project: the Train Illusion
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/datasets_overview.html">
   Datasets
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
<label for="toctree-checkbox-26">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/neurons.html">
     Neurons
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
<label for="toctree-checkbox-27">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/neurons/neurons_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/fMRI.html">
     fMRI
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
<label for="toctree-checkbox-28">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/fMRI/fMRI_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/ECoG.html">
     ECoG
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
<label for="toctree-checkbox-29">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ECoG/ECoG_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/behavior.html">
     Behavior
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
<label for="toctree-checkbox-30">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/README.html">
       Guide
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/behavior/behavior_videos.html">
       Overview videos
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/docs/theory.html">
     Theory
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
<label for="toctree-checkbox-31">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/theory/README.html">
       Guide
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_templates.html">
   Project Templates
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/project_2020_highlights.html">
   Projects 2020
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/>
<label for="toctree-checkbox-32">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/neurons.html">
     Neurons
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/theory.html">
     Theory
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/behavior.html">
     Behavior
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/fMRI.html">
     fMRI
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/docs/projects_2020/eeg.html">
     EEG
    </a>
</li>
</ul>
</li>
</ul>
</div>
</nav> <!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
<!-- This is an invisible pixel that we watch to see if we've scrolled. -->
<div class="sbt-scroll-pixel-helper"></div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
<div class="topbar container-xl fixed-top">
<div class="topbar-contents row">
<div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
<div class="col pl-md-4 topbar-main">
<div class="topbar-left">
<label class="nav-toggle-button" for="__navigation">
<div class="visually-hidden">Toggle navigation</div>
<i class="fas fa-bars"></i>
</label>
</div>
<div class="dropdown-buttons-trigger">
<button aria-label="Download this page" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fas fa-download"></i></button>
<div class="dropdown-buttons">
<!-- ipynb file if we had a myst markdown file -->
<!-- Download raw file -->
<a class="dropdown-buttons" href="../../../_sources/tutorials/Bonus_Autoencoders/student/Bonus_Tutorial3.ipynb"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Download source file" type="button">.ipynb</button></a>
<!-- Download PDF via print -->
<button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" id="download-print" onclick="printPdf(this)" title="Print to PDF" type="button">.pdf</button>
</div>
</div>
<!-- Source interaction buttons -->
<div class="dropdown-buttons-trigger">
<button aria-label="Connect with source repository" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fab fa-github"></i></button>
<div class="dropdown-buttons sourcebuttons">
<a class="repository-button" href="https://github.com/NeuromatchAcademy/course-content"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Source repository" type="button"><i class="fab fa-github"></i>repository</button></a>
<a class="issues-button" href="https://github.com/NeuromatchAcademy/course-content/issues/new?title=Issue%20on%20page%20%2Ftutorials/Bonus_Autoencoders/student/Bonus_Tutorial3.html&amp;body=Your%20issue%20content%20here."><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Open an issue" type="button"><i class="fas fa-lightbulb"></i>open issue</button></a>
</div>
</div>
<!-- Full screen (wrap in <a> to have style consistency -->
<a class="full-screen-button"><button aria-label="Fullscreen mode" class="btn btn-secondary topbarbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode" type="button"><i class="fas fa-expand"></i></button></a>
<!-- Launch buttons -->
</div>
<!-- Table of contents -->
<div class="d-none d-md-block col-md-2 bd-toc show noprint">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
            </div>
<nav aria-label="Page" id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 3: Autoencoders applications
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#autoencoder-applications">
     Autoencoder applications
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-applications">
     Video 1: Applications
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-download-and-prepare-mnist-dataset">
   Section 1: Download  and prepare MNIST dataset
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-download-a-pre-trained-model">
   Section 2: Download a pre-trained model
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-applications-of-autoencoders">
   Section 3: Applications of autoencoders
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#application-1-image-noise">
     Application 1 - Image noise
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#reconstructions-before-fine-tuning">
       Reconstructions before fine-tuning
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#latent-space-before-fine-tuning">
       Latent space before fine-tuning
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#fine-tuning-the-autoencoder-with-noisy-images">
       Fine-tuning the autoencoder with noisy images
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#global-latent-space-shift">
       Global latent space shift
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#application-2-image-occlusion">
     Application 2 - Image occlusion
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#before-fine-tuning">
       Before fine-tuning
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#after-fine-tuning">
       After fine-tuning
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#application-3-image-rotation">
     Application 3 - Image rotation
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
       Before fine-tuning
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
       After fine-tuning
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#application-4-what-would-digit-6-look-like-if-we-had-never-seen-it-before">
     Application 4 - What would digit “6” look like if we had never seen it before?
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-1-removing-the-most-dominant-digit-classes">
       Exercise 1: Removing the most dominant digit classes
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-anns-same-but-different">
   Section 4: ANNs? Same but different!
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-wrap-up">
     Video 2: Wrap-up
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="row" id="main-content">
<div class="col-12 col-md-9 pl-md-3 pr-md-0">
<!-- Table of contents that is only displayed when printing the page -->
<div class="onlyprint" id="jb-print-docs-body">
<h1>Tutorial 3: Autoencoders applications</h1>
<!-- Table of contents -->
<div id="print-main-content">
<div id="jb-print-toc">
<div>
<h2> Contents </h2>
</div>
<nav aria-label="Page">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 3: Autoencoders applications
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#autoencoder-applications">
     Autoencoder applications
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-applications">
     Video 1: Applications
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-download-and-prepare-mnist-dataset">
   Section 1: Download  and prepare MNIST dataset
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-download-a-pre-trained-model">
   Section 2: Download a pre-trained model
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-applications-of-autoencoders">
   Section 3: Applications of autoencoders
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#application-1-image-noise">
     Application 1 - Image noise
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#reconstructions-before-fine-tuning">
       Reconstructions before fine-tuning
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#latent-space-before-fine-tuning">
       Latent space before fine-tuning
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#fine-tuning-the-autoencoder-with-noisy-images">
       Fine-tuning the autoencoder with noisy images
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#global-latent-space-shift">
       Global latent space shift
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#application-2-image-occlusion">
     Application 2 - Image occlusion
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#before-fine-tuning">
       Before fine-tuning
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#after-fine-tuning">
       After fine-tuning
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#application-3-image-rotation">
     Application 3 - Image rotation
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
       Before fine-tuning
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
       After fine-tuning
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#application-4-what-would-digit-6-look-like-if-we-had-never-seen-it-before">
     Application 4 - What would digit “6” look like if we had never seen it before?
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-1-removing-the-most-dominant-digit-classes">
       Exercise 1: Removing the most dominant digit classes
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-anns-same-but-different">
   Section 4: ANNs? Same but different!
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-wrap-up">
     Video 2: Wrap-up
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/master/tutorials/Bonus_Autoencoders/Bonus_Tutorial3.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<div class="section" id="tutorial-3-autoencoders-applications">
<h1>Tutorial 3: Autoencoders applications<a class="headerlink" href="#tutorial-3-autoencoders-applications" title="Permalink to this headline">¶</a></h1>
<p><strong>Bonus Day: Autoencoders</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Marco Brigham and the <a class="reference external" href="https://www.ccnss.org/">CCNSS</a> team (2014-2018)</p>
<p><strong>Content reviewers:</strong> Itzel Olivos, Karen Schroeder, Karolina Stosio, Kshitij Dwivedi, Spiros Chavlis, Michael Waskom</p>
</div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<div class="section" id="autoencoder-applications">
<h2>Autoencoder applications<a class="headerlink" href="#autoencoder-applications" title="Permalink to this headline">¶</a></h2>
<p>How do autoencoders with rich internal representations perform on the MNIST cognitive task?</p>
<p>How do autoencoders perceive unseen digit classes?</p>
<p>How does ANN image encoding differ from human vision?</p>
<p>We are equipped with tools and techniques to answer these questions, and hopefully, many others you may encounter in your research!</p>
<p> </p>
<p><img alt="MNIST cognitive task" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/mnist_task.png"/></p>
<p> </p>
<p>In this tutorial, you will:</p>
<ul class="simple">
<li><p>Analyze how autoencoders perceive transformed data (added noise, occluded parts, and rotations), and how that evolves with short re-train sessions</p></li>
<li><p>Use autoencoders to visualize unseen digit classes</p></li>
<li><p>Understand visual encoding for fully connected ANN autoencoders</p></li>
</ul>
</div>
<div class="section" id="video-1-applications">
<h2>Video 1: Applications<a class="headerlink" href="#video-1-applications" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "15f8988027704188857c9d371dcb2f61"}
</script></div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<p>Please execute the cell(s) below to initialize the notebook environment.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">ndimage</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure settings</span>

<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/NMA2020/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper functions</span>


<span class="k">def</span> <span class="nf">downloadMNIST</span><span class="p">():</span>
  <span class="sd">"""</span>
<span class="sd">  Download MNIST dataset and transform it to torch.Tensor</span>

<span class="sd">  Args:</span>
<span class="sd">    None</span>

<span class="sd">  Returns:</span>
<span class="sd">    x_train : training images (torch.Tensor) (60000, 28, 28)</span>
<span class="sd">    x_test  : test images (torch.Tensor) (10000, 28, 28)</span>
<span class="sd">    y_train : training labels (torch.Tensor) (60000, )</span>
<span class="sd">    y_train : test labels (torch.Tensor) (10000, )</span>
<span class="sd">  """</span>
  <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="s1">'mnist_784'</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="c1"># Trunk the data</span>
  <span class="n">n_train</span> <span class="o">=</span> <span class="mi">60000</span>
  <span class="n">n_test</span> <span class="o">=</span> <span class="mi">10000</span>

  <span class="n">train_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_train</span><span class="p">)</span>
  <span class="n">test_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_train</span> <span class="o">+</span> <span class="n">n_test</span><span class="p">)</span>

  <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
  <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">test_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>

  <span class="c1"># Transform np.ndarrays to torch.Tensor</span>
  <span class="n">x_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span>
                                        <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span>
                                         <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
  <span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span>
                                       <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span>
                                        <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

  <span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>
  <span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>

  <span class="k">return</span> <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">init_weights_kaiming_uniform</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Initializes weights from linear PyTorch layer</span>
<span class="sd">  with kaiming uniform distribution.</span>

<span class="sd">  Args:</span>
<span class="sd">    layer (torch.Module)</span>
<span class="sd">        Pytorch layer</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>
  <span class="c1"># check for linear PyTorch layer</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
    <span class="c1"># initialize weights with kaiming uniform distribution</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">init_weights_kaiming_normal</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Initializes weights from linear PyTorch layer</span>
<span class="sd">  with kaiming normal distribution.</span>

<span class="sd">  Args:</span>
<span class="sd">    layer (torch.Module)</span>
<span class="sd">        Pytorch layer</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>
  <span class="c1"># check for linear PyTorch layer</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
    <span class="c1"># initialize weights with kaiming normal distribution</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_layer_weights</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Retrieves learnable parameters from PyTorch layer.</span>

<span class="sd">  Args:</span>
<span class="sd">    layer (torch.Module)</span>
<span class="sd">        Pytorch layer</span>

<span class="sd">  Returns:</span>
<span class="sd">    list with learnable parameters</span>
<span class="sd">  """</span>
  <span class="c1"># initialize output list</span>
  <span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="c1"># check whether layer has learnable parameters</span>
  <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="c1"># copy numpy array representation of each set of learnable parameters</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
      <span class="n">weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

  <span class="k">return</span> <span class="n">weights</span>


<span class="k">def</span> <span class="nf">eval_mse</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Evaluates mean square error (MSE) between y_pred and y_true</span>

<span class="sd">  Args:</span>
<span class="sd">    y_pred (torch.Tensor)</span>
<span class="sd">        prediction samples</span>

<span class="sd">    v (numpy array of floats)</span>
<span class="sd">        ground truth samples</span>

<span class="sd">  Returns:</span>
<span class="sd">    MSE(y_pred, y_true)</span>
<span class="sd">  """</span>

  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>

  <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">eval_bce</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Evaluates binary cross-entropy (BCE) between y_pred and y_true</span>

<span class="sd">  Args:</span>
<span class="sd">    y_pred (torch.Tensor)</span>
<span class="sd">        prediction samples</span>

<span class="sd">    v (numpy array of floats)</span>
<span class="sd">        ground truth samples</span>

<span class="sd">  Returns:</span>
<span class="sd">    BCE(y_pred, y_true)</span>
<span class="sd">  """</span>

  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>

  <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_row</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">show_n</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">image_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Plots rows of images from list of iterables (iterables: list, numpy array</span>
<span class="sd">  or torch.Tensor). Also accepts single iterable.</span>
<span class="sd">  Randomly selects images in each list element if item count &gt; show_n.</span>

<span class="sd">  Args:</span>
<span class="sd">    images (iterable or list of iterables)</span>
<span class="sd">        single iterable with images, or list of iterables</span>

<span class="sd">    show_n (integer)</span>
<span class="sd">        maximum number of images per row</span>

<span class="sd">    image_shape (tuple or list)</span>
<span class="sd">        original shape of image if vectorized form</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">images</span><span class="p">]</span>

  <span class="k">for</span> <span class="n">items_idx</span><span class="p">,</span> <span class="n">items</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">images</span><span class="p">):</span>

    <span class="n">items</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">items</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">items</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">items</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">items</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">show_n</span><span class="p">:</span>
      <span class="n">selected</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">),</span> <span class="n">show_n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="n">items</span> <span class="o">=</span> <span class="n">items</span><span class="p">[</span><span class="n">selected</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">image_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">items</span> <span class="o">=</span> <span class="n">items</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">image_shape</span><span class="p">))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">image_idx</span><span class="p">,</span> <span class="n">image</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">items</span><span class="p">):</span>

      <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">),</span> <span class="n">image_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">vmax</span><span class="o">=</span><span class="n">image</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">to_s2</span><span class="p">(</span><span class="n">u</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Projects 3D coordinates to spherical coordinates (theta, phi) surface of</span>
<span class="sd">  unit sphere S2.</span>
<span class="sd">  theta: [0, pi]</span>
<span class="sd">  phi: [-pi, pi]</span>

<span class="sd">  Args:</span>
<span class="sd">    u (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        3D coordinates</span>

<span class="sd">  Returns:</span>
<span class="sd">    Sperical coordinates (theta, phi) on surface of unit sphere S2.</span>
<span class="sd">  """</span>

  <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">u</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">u</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">u</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>
  <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">z</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
  <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arccos</span><span class="p">(</span><span class="n">z</span> <span class="o">/</span> <span class="n">r</span><span class="p">)</span>
  <span class="n">phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arctan2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">theta</span><span class="p">,</span> <span class="n">phi</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>


<span class="k">def</span> <span class="nf">to_u3</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Converts from 2D coordinates on surface of unit sphere S2 to 3D coordinates</span>
<span class="sd">  (on surface of S2), i.e. (theta, phi) ---&gt; (1, theta, phi).</span>

<span class="sd">  Args:</span>
<span class="sd">    s (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        2D coordinates on unit sphere S_2</span>

<span class="sd">  Returns:</span>
<span class="sd">    3D coordinates on surface of unit sphere S_2</span>
<span class="sd">  """</span>

  <span class="n">theta</span><span class="p">,</span> <span class="n">phi</span> <span class="o">=</span> <span class="p">(</span><span class="n">s</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">s</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">phi</span><span class="p">)</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>


<span class="k">def</span> <span class="nf">xy_lim</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Return arguments for plt.xlim and plt.ylim calculated from minimum</span>
<span class="sd">  and maximum of x.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        data to be plotted</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>
  <span class="n">x_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">x_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="n">x_min</span> <span class="o">=</span> <span class="n">x_min</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.05</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>
  <span class="n">x_max</span> <span class="o">=</span> <span class="n">x_max</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.05</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span>

  <span class="k">return</span> <span class="p">[</span><span class="n">x_min</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_max</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">x_min</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x_max</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>


<span class="k">def</span> <span class="nf">plot_generative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">decoder_fn</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">n_row</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Plots images reconstructed by decoder_fn from a 2D grid in</span>
<span class="sd">  latent space that is determined by minimum and maximum values in x.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        2D or 3D coordinates in latent space</span>

<span class="sd">    decoder_fn (integer)</span>
<span class="sd">        function returning vectorized images from 2D latent space coordinates</span>

<span class="sd">    image_shape (tuple or list)</span>
<span class="sd">        original shape of image</span>

<span class="sd">    n_row (integer)</span>
<span class="sd">        number of rows in grid</span>

<span class="sd">    s2 (boolean)</span>
<span class="sd">        convert 3D coordinates (x, y, z) to spherical coordinates (theta, phi)</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="k">if</span> <span class="n">s2</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">to_s2</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

  <span class="n">xlim</span><span class="p">,</span> <span class="n">ylim</span> <span class="o">=</span> <span class="n">xy_lim</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

  <span class="n">dx</span> <span class="o">=</span> <span class="p">(</span><span class="n">xlim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">xlim</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="n">n_row</span>
  <span class="n">grid</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ylim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">dx</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">ylim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">dx</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_row</span><span class="p">),</span>
          <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xlim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">dx</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">xlim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">dx</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_row</span><span class="p">)]</span>

  <span class="n">canvas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_row</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_row</span><span class="p">))</span>

  <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'gray'</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">latent_y</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">latent_x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>

      <span class="n">latent</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">latent_x</span><span class="p">,</span> <span class="n">latent_y</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">s2</span><span class="p">:</span>
        <span class="n">latent</span> <span class="o">=</span> <span class="n">to_u3</span><span class="p">(</span><span class="n">latent</span><span class="p">)</span>

      <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">x_decoded</span> <span class="o">=</span> <span class="n">decoder_fn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">latent</span><span class="p">))</span>

      <span class="n">x_decoded</span> <span class="o">=</span> <span class="n">x_decoded</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">image_shape</span><span class="p">)</span>

      <span class="n">canvas</span><span class="p">[</span><span class="n">j</span> <span class="o">*</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
             <span class="n">i</span> <span class="o">*</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">x_decoded</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">canvas</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="n">canvas</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">vmax</span><span class="o">=</span><span class="n">canvas</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_latent</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">show_n</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xy_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Plots digit class of each sample in 2D latent space coordinates.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        2D coordinates in latent space</span>

<span class="sd">    y (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        digit class of each sample</span>

<span class="sd">    n_row (integer)</span>
<span class="sd">        number of samples</span>

<span class="sd">    s2 (boolean)</span>
<span class="sd">        convert 3D coordinates (x, y, z) to spherical coordinates (theta, phi)</span>

<span class="sd">    fontdict (dictionary)</span>
<span class="sd">        style option for plt.text</span>

<span class="sd">    xy_labels (list)</span>
<span class="sd">        optional list with [xlabel, ylabel]</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="k">if</span> <span class="n">fontdict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">fontdict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'weight'</span><span class="p">:</span> <span class="s1">'bold'</span><span class="p">,</span> <span class="s1">'size'</span><span class="p">:</span> <span class="mi">12</span><span class="p">}</span>

  <span class="k">if</span> <span class="n">s2</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">to_s2</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

  <span class="n">cmap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">'tab10'</span><span class="p">)</span>

  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">show_n</span><span class="p">:</span>
    <span class="n">selected</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">show_n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">selected</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">selected</span><span class="p">]</span>

  <span class="k">for</span> <span class="n">my_x</span><span class="p">,</span> <span class="n">my_y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">my_x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">my_x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">my_y</span><span class="p">)),</span>
             <span class="n">color</span><span class="o">=</span><span class="n">cmap</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">my_y</span><span class="p">)</span> <span class="o">/</span> <span class="mf">10.</span><span class="p">),</span>
             <span class="n">fontdict</span><span class="o">=</span><span class="n">fontdict</span><span class="p">,</span>
             <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span>
             <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span>
             <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

  <span class="n">xlim</span><span class="p">,</span> <span class="n">ylim</span> <span class="o">=</span> <span class="n">xy_lim</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xlim</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ylim</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">s2</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">xy_labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">xy_labels</span> <span class="o">=</span> <span class="p">[</span><span class="sa">r</span><span class="s1">'$\varphi$'</span><span class="p">,</span> <span class="sa">r</span><span class="s1">'$\theta$'</span><span class="p">]</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">6</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">6</span><span class="p">),</span>
               <span class="p">[</span><span class="s1">'0'</span><span class="p">,</span> <span class="s1">'$\pi/6$'</span><span class="p">,</span> <span class="s1">'$\pi/3$'</span><span class="p">,</span> <span class="s1">'$\pi/2$'</span><span class="p">,</span>
                <span class="s1">'$2\pi/3$'</span><span class="p">,</span> <span class="s1">'$5\pi/6$'</span><span class="p">,</span> <span class="s1">'$\pi$'</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">3</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">3</span><span class="p">),</span>
               <span class="p">[</span><span class="s1">'$-\pi$'</span><span class="p">,</span> <span class="s1">'$-2\pi/3$'</span><span class="p">,</span> <span class="s1">'$-\pi/3$'</span><span class="p">,</span> <span class="s1">'0'</span><span class="p">,</span>
                <span class="s1">'$\pi/3$'</span><span class="p">,</span> <span class="s1">'$2\pi/3$'</span><span class="p">,</span> <span class="s1">'$\pi$'</span><span class="p">])</span>

  <span class="k">if</span> <span class="n">xy_labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">xy_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'$Z_1$'</span><span class="p">,</span> <span class="s1">'$Z_2$'</span><span class="p">]</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">xy_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">xy_labels</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">plot_latent_generative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">decoder_fn</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                           <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xy_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Two horizontal subplots generated with encoder map and decoder grid.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        2D coordinates in latent space</span>

<span class="sd">    y (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        digit class of each sample</span>

<span class="sd">    decoder_fn (integer)</span>
<span class="sd">        function returning vectorized images from 2D latent space coordinates</span>

<span class="sd">    image_shape (tuple or list)</span>
<span class="sd">        original shape of image</span>

<span class="sd">    s2 (boolean)</span>
<span class="sd">        convert 3D coordinates (x, y, z) to spherical coordinates (theta, phi)</span>

<span class="sd">    title (string)</span>
<span class="sd">        plot title</span>

<span class="sd">    xy_labels (list)</span>
<span class="sd">        optional list with [xlabel, ylabel]</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

  <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>

  <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Encoder map'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
  <span class="n">plot_latent</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">,</span> <span class="n">xy_labels</span><span class="o">=</span><span class="n">xy_labels</span><span class="p">)</span>

  <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Decoder grid'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
  <span class="n">plot_generative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">decoder_fn</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_latent_ab</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">selected_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">title_a</span><span class="o">=</span><span class="s1">'Before'</span><span class="p">,</span> <span class="n">title_b</span><span class="o">=</span><span class="s1">'After'</span><span class="p">,</span> <span class="n">show_n</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Two horizontal subplots with encoder maps.</span>

<span class="sd">  Args:</span>
<span class="sd">    x1 (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        2D coordinates in latent space (left plot)</span>

<span class="sd">    x2 (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        digit class of each sample (right plot)</span>

<span class="sd">    y (list, numpy array or torch.Tensor of floats)</span>
<span class="sd">        digit class of each sample</span>

<span class="sd">    selected_idx (list of integers)</span>
<span class="sd">        indexes of elements to be plotted</span>

<span class="sd">    show_n (integer)</span>
<span class="sd">        maximum number of samples in each plot</span>

<span class="sd">    s2 (boolean)</span>
<span class="sd">        convert 3D coordinates (x, y, z) to spherical coordinates (theta, phi)</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="n">fontdict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'weight'</span><span class="p">:</span> <span class="s1">'bold'</span><span class="p">,</span> <span class="s1">'size'</span><span class="p">:</span> <span class="mi">12</span><span class="p">}</span>

  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">show_n</span><span class="p">:</span>

    <span class="k">if</span> <span class="n">selected_idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">selected_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x1</span><span class="p">),</span> <span class="n">show_n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">x1</span> <span class="o">=</span> <span class="n">x1</span><span class="p">[</span><span class="n">selected_idx</span><span class="p">]</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">x2</span><span class="p">[</span><span class="n">selected_idx</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">selected_idx</span><span class="p">]</span>

  <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">])</span>

  <span class="k">if</span> <span class="n">s2</span><span class="p">:</span>
    <span class="n">xlim</span><span class="p">,</span> <span class="n">ylim</span> <span class="o">=</span> <span class="n">xy_lim</span><span class="p">(</span><span class="n">to_s2</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>

  <span class="k">else</span><span class="p">:</span>
    <span class="n">xlim</span><span class="p">,</span> <span class="n">ylim</span> <span class="o">=</span> <span class="n">xy_lim</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

  <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title_a</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
  <span class="n">plot_latent</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="n">fontdict</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xlim</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ylim</span><span class="p">)</span>

  <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title_b</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.05</span><span class="p">)</span>
  <span class="n">plot_latent</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="n">fontdict</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xlim</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ylim</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">runSGD</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">input_train</span><span class="p">,</span> <span class="n">input_test</span><span class="p">,</span> <span class="n">out_train</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out_test</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
           <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">'bce'</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
           <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Trains autoencoder network with stochastic gradient descent with</span>
<span class="sd">  optimizer and loss criterion. Train samples are shuffled, and loss is</span>
<span class="sd">  displayed at the end of each opoch for both MSE and BCE. Plots training loss</span>
<span class="sd">  at each minibatch (maximum of 500 randomly selected values).</span>

<span class="sd">  Args:</span>
<span class="sd">    net (torch network)</span>
<span class="sd">        ANN network (nn.Module)</span>

<span class="sd">    input_train (torch.Tensor)</span>
<span class="sd">        vectorized input images from train set</span>

<span class="sd">    input_test (torch.Tensor)</span>
<span class="sd">        vectorized input images from test set</span>

<span class="sd">    criterion (string)</span>
<span class="sd">        train loss: 'bce' or 'mse'</span>

<span class="sd">    out_train (torch.Tensor)</span>
<span class="sd">        optional target images from train set</span>

<span class="sd">    out_test (torch.Tensor)</span>
<span class="sd">        optional target images from test set</span>

<span class="sd">    optimizer (torch optimizer)</span>
<span class="sd">        optional target images from train set</span>

<span class="sd">    criterion (string)</span>
<span class="sd">        train loss: 'bce' or 'mse'</span>

<span class="sd">    n_epochs (boolean)</span>
<span class="sd">        number of full iterations of training data</span>

<span class="sd">    batch_size (integer)</span>
<span class="sd">        number of element in mini-batches</span>

<span class="sd">    verbose (boolean)</span>
<span class="sd">        whether to print final loss</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="k">if</span> <span class="n">out_train</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">out_test</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">different_output</span> <span class="o">=</span> <span class="kc">True</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">different_output</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="c1"># Initialize loss function</span>
  <span class="k">if</span> <span class="n">criterion</span> <span class="o">==</span> <span class="s1">'mse'</span><span class="p">:</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
  <span class="k">elif</span> <span class="n">criterion</span> <span class="o">==</span> <span class="s1">'bce'</span><span class="p">:</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Please specify either "mse" or "bce" for loss criterion'</span><span class="p">)</span>

  <span class="c1"># Initialize SGD optimizer</span>
  <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

  <span class="c1"># Placeholder for loss</span>
  <span class="n">track_loss</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="nb">print</span><span class="p">(</span><span class="s1">'Epoch'</span><span class="p">,</span> <span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'Loss train'</span><span class="p">,</span> <span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">,</span> <span class="s1">'Loss test'</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>

    <span class="n">shuffle_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_train</span><span class="p">))</span>
    <span class="n">batches</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">input_train</span><span class="p">[</span><span class="n">shuffle_idx</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">different_output</span><span class="p">:</span>
      <span class="n">batches_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">out_train</span><span class="p">[</span><span class="n">shuffle_idx</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batches</span><span class="p">):</span>

      <span class="n">output_train</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">different_output</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span> <span class="n">batches_out</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">])</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>

      <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

      <span class="c1"># Keep track of loss at each epoch</span>
      <span class="n">track_loss</span> <span class="o">+=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">)]</span>

    <span class="n">loss_epoch</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">n_epochs</span><span class="si">}</span><span class="s1">'</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
      <span class="n">output_train</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_train</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">different_output</span><span class="p">:</span>
        <span class="n">loss_train</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span> <span class="n">out_train</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">loss_train</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span> <span class="n">input_train</span><span class="p">)</span>

      <span class="n">loss_epoch</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">loss_train</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">'</span>

      <span class="n">output_test</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">different_output</span><span class="p">:</span>
        <span class="n">loss_test</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output_test</span><span class="p">,</span> <span class="n">out_test</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">loss_test</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">output_test</span><span class="p">,</span> <span class="n">input_test</span><span class="p">)</span>

      <span class="n">loss_epoch</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\t\t</span><span class="s1"> </span><span class="si">{</span><span class="n">loss_test</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">'</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">loss_epoch</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
    <span class="c1"># Print loss</span>
    <span class="k">if</span> <span class="n">different_output</span><span class="p">:</span>
      <span class="n">loss_mse</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">MSE</span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_mse</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span> <span class="n">out_train</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
      <span class="n">loss_mse</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\t\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_mse</span><span class="p">(</span><span class="n">output_test</span><span class="p">,</span> <span class="n">out_test</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">loss_mse</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\n</span><span class="s1">MSE</span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_mse</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span> <span class="n">input_train</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
      <span class="n">loss_mse</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\t\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_mse</span><span class="p">(</span><span class="n">output_test</span><span class="p">,</span> <span class="n">input_test</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">loss_mse</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">different_output</span><span class="p">:</span>
      <span class="n">loss_bce</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'BCE</span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_bce</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span> <span class="n">out_train</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
      <span class="n">loss_bce</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\t\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_bce</span><span class="p">(</span><span class="n">output_test</span><span class="p">,</span> <span class="n">out_test</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">loss_bce</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'BCE</span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_bce</span><span class="p">(</span><span class="n">output_train</span><span class="p">,</span> <span class="n">input_train</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
      <span class="n">loss_bce</span> <span class="o">+=</span> <span class="sa">f</span><span class="s1">'</span><span class="se">\t\t</span><span class="s1"> </span><span class="si">{</span><span class="n">eval_bce</span><span class="p">(</span><span class="n">output_test</span><span class="p">,</span> <span class="n">input_test</span><span class="p">)</span><span class="si">:</span><span class="s1">0.4f</span><span class="si">}</span><span class="s1">'</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">loss_bce</span><span class="p">)</span>

  <span class="c1"># Plot loss</span>
  <span class="n">step</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">track_loss</span><span class="p">)</span><span class="o">/</span><span class="mi">500</span><span class="p">))</span>
  <span class="n">x_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">track_loss</span><span class="p">),</span> <span class="n">step</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">track_loss</span><span class="p">[::</span><span class="n">step</span><span class="p">],</span> <span class="s1">'C0'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Iterations'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">image_occlusion</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Randomly selects on quadrant of images and sets to zeros.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (torch.Tensor of floats)</span>
<span class="sd">        vectorized images</span>

<span class="sd">    image_shape (tuple or list)</span>
<span class="sd">        original shape of image</span>

<span class="sd">  Returns:</span>
<span class="sd">    torch.Tensor.</span>
<span class="sd">  """</span>

  <span class="n">selection</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

  <span class="n">my_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
  <span class="n">my_x</span> <span class="o">=</span> <span class="n">my_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

  <span class="n">my_x</span><span class="p">[</span><span class="n">selection</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:</span><span class="nb">int</span><span class="p">(</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="p">:</span><span class="nb">int</span><span class="p">(</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">my_x</span><span class="p">[</span><span class="n">selection</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="p">):,</span> <span class="p">:</span><span class="nb">int</span><span class="p">(</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">my_x</span><span class="p">[</span><span class="n">selection</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="p">:</span><span class="nb">int</span><span class="p">(</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="p">):]</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="n">my_x</span><span class="p">[</span><span class="n">selection</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="p">):,</span> <span class="nb">int</span><span class="p">(</span><span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span><span class="p">):]</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="n">my_x</span> <span class="o">=</span> <span class="n">my_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">my_x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">image_rotation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">deg</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Randomly rotates images by +- deg degrees.</span>

<span class="sd">  Args:</span>
<span class="sd">    x (torch.Tensor of floats)</span>
<span class="sd">        vectorized images</span>

<span class="sd">    deg (integer)</span>
<span class="sd">        rotation range</span>

<span class="sd">    image_shape (tuple or list)</span>
<span class="sd">        original shape of image</span>

<span class="sd">  Returns:</span>
<span class="sd">    torch.Tensor.</span>
<span class="sd">  """</span>

  <span class="n">my_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
  <span class="n">my_x</span> <span class="o">=</span> <span class="n">my_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">image_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

  <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">my_x</span><span class="p">):</span>
    <span class="n">my_deg</span> <span class="o">=</span> <span class="n">deg</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">-</span> <span class="n">deg</span>
    <span class="n">my_x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">ndimage</span><span class="o">.</span><span class="n">rotate</span><span class="p">(</span><span class="n">my_x</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">my_deg</span><span class="p">,</span>
                               <span class="n">reshape</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">prefilter</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

  <span class="n">my_x</span> <span class="o">=</span> <span class="n">my_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">my_x</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">AutoencoderClass</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Deep autoencoder network object (nn.Module) with optional L2 normalization</span>
<span class="sd">  of activations in bottleneck layer.</span>

<span class="sd">  Args:</span>
<span class="sd">    input_size (integer)</span>
<span class="sd">        size of input samples</span>

<span class="sd">    s2 (boolean)</span>
<span class="sd">        whether to L2 normalize activatinos in bottleneck layer</span>

<span class="sd">  Returns:</span>
<span class="sd">    Autoencoder object inherited from nn.Module class.</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">s2</span> <span class="o">=</span> <span class="n">s2</span>

    <span class="k">if</span> <span class="n">s2</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">encoding_size</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">enc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc1_f</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc2_f</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoding_size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc3_f</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoding_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec1_f</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoding_size</span> <span class="o">*</span> <span class="mi">32</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec2_f</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec3_f</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">encoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Encoder component.</span>
<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc1_f</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc2_f</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc3_f</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc3</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">s2</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span>

  <span class="k">def</span> <span class="nf">decoder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Decoder component.</span>
<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec1_f</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dec1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec2_f</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dec2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec3_f</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dec3</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">x</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Forward pass.</span>
<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Saves a PyTorch checkpoint.</span>

<span class="sd">  Args:</span>
<span class="sd">    net (torch network)</span>
<span class="sd">        ANN network (nn.Module)</span>

<span class="sd">    optimizer (torch optimizer)</span>
<span class="sd">        optimizer for SGD</span>

<span class="sd">    filename (string)</span>
<span class="sd">        filename (without extension)</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s1">'model_state_dict'</span><span class="p">:</span> <span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
              <span class="s1">'optimizer_state_dict'</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()},</span>
             <span class="n">filename</span><span class="o">+</span><span class="s1">'.pt'</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">load_checkpoint</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Loads a PyTorch checkpoint from URL is local file not present.</span>

<span class="sd">  Args:</span>
<span class="sd">    url (string)</span>
<span class="sd">        URL location of PyTorch checkpoint</span>

<span class="sd">    filename (string)</span>
<span class="sd">        filename (without extension)</span>

<span class="sd">  Returns:</span>
<span class="sd">    PyTorch checkpoint of saved model.</span>
<span class="sd">  """</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">filename</span><span class="o">+</span><span class="s1">'.pt'</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="sa">f</span><span class="s2">"wget </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">.pt"</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename</span><span class="o">+</span><span class="s1">'.pt'</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">reset_checkpoint</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Resets PyTorch model to checkpoint.</span>

<span class="sd">  Args:</span>
<span class="sd">    net (torch network)</span>
<span class="sd">        ANN network (nn.Module)</span>

<span class="sd">    optimizer (torch optimizer)</span>
<span class="sd">        optimizer for SGD</span>

<span class="sd">    checkpoint (torch checkpoint)</span>
<span class="sd">        checkpoint of saved model</span>

<span class="sd">  Returns:</span>
<span class="sd">    Nothing.</span>
<span class="sd">  """</span>

  <span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'model_state_dict'</span><span class="p">])</span>
  <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'optimizer_state_dict'</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-download-and-prepare-mnist-dataset">
<h1>Section 1: Download  and prepare MNIST dataset<a class="headerlink" href="#section-1-download-and-prepare-mnist-dataset" title="Permalink to this headline">¶</a></h1>
<p>We use the helper function <code class="docutils literal notranslate"><span class="pre">downloadMNIST</span></code> to download the dataset and transform it into <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code> and assign train and test sets to (<code class="docutils literal notranslate"><span class="pre">x_train</span></code>, <code class="docutils literal notranslate"><span class="pre">y_train</span></code>) and (<code class="docutils literal notranslate"><span class="pre">x_test</span></code>, <code class="docutils literal notranslate"><span class="pre">y_test</span></code>).</p>
<p>The variable <code class="docutils literal notranslate"><span class="pre">input_size</span></code> stores the length of <em>vectorized</em> versions of the images <code class="docutils literal notranslate"><span class="pre">input_train</span></code> and <code class="docutils literal notranslate"><span class="pre">input_test</span></code> for training and test images.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download MNIST</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">downloadMNIST</span><span class="p">()</span>

<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mi">255</span>

<span class="n">image_shape</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

<span class="n">input_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">input_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_size</span><span class="p">])</span>
<span class="n">input_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_size</span><span class="p">])</span>

<span class="n">test_selected_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="mi">10</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">train_selected_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span> <span class="mi">10</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">test_subset_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="mi">500</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'shape image </span><span class="se">\t\t</span><span class="s1"> </span><span class="si">{</span><span class="n">image_shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'shape input_train </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">input_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'shape input_test </span><span class="se">\t</span><span class="s1"> </span><span class="si">{</span><span class="n">input_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>shape image 		 torch.Size([28, 28])
shape input_train 	 torch.Size([60000, 784])
shape input_test 	 torch.Size([10000, 784])
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-download-a-pre-trained-model">
<h1>Section 2: Download a pre-trained model<a class="headerlink" href="#section-2-download-a-pre-trained-model" title="Permalink to this headline">¶</a></h1>
<p>The class <code class="docutils literal notranslate"><span class="pre">AutoencoderClass</span></code> implements the autoencoder architectures introduced in the previous tutorial. The design of this class follows the object-oriented programming (OOP) style from tutorial W3D4. Setting the boolean parameter <code class="docutils literal notranslate"><span class="pre">s2=True</span></code> specifies the model with projection onto the <span class="math notranslate nohighlight">\(S_2\)</span> sphere.</p>
<p>We trained both models for <code class="docutils literal notranslate"><span class="pre">n_epochs=25</span></code> and saved the weights to avoid a lengthy initial training period - these will be our reference model states.</p>
<p>Experiments are run from the identical initial conditions by resetting the autoencoder to the reference state at the beginning of each exercise.</p>
<p>The mechanism for loading and storing models from PyTorch is the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="ow">or</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoencoderClass</span><span class="p">()</span>

<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span><span class="s1">'model_state_dict'</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'optimizer_state_dict'</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()},</span>
           <span class="n">filename_path</span><span class="p">)</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filename_path</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'model_state_dict'</span><span class="p">])</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'optimizer_state_dict'</span><span class="p">])</span>
</pre></div>
</div>
<p>See additional <a class="reference external" href="https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html">PyTorch instructions</a>, and when to use <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code> and <code class="docutils literal notranslate"><span class="pre">model.train()</span></code> for more complex models.</p>
<p>We provide the functions <code class="docutils literal notranslate"><span class="pre">save_checkpoint</span></code>, <code class="docutils literal notranslate"><span class="pre">load_checkpoint</span></code>, and <code class="docutils literal notranslate"><span class="pre">reset_checkpoint</span></code> to implement the steps above and download pre-trained weights from the GitHub repo.</p>
<p>If downloading from GitHub fails, please uncomment the 3rd cell bellow to train the model for <code class="docutils literal notranslate"><span class="pre">n_epochs=10</span></code> and save it locally.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell(s) below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">root</span> <span class="o">=</span> <span class="s1">'https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders'</span>
<span class="n">filename</span> <span class="o">=</span> <span class="s1">'ae_6h_prelu_bce_adam_25e_32b'</span>
<span class="n">url</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
<span class="n">s2</span> <span class="o">=</span> <span class="kc">True</span>

<span class="k">if</span> <span class="n">s2</span><span class="p">:</span>
  <span class="n">filename</span> <span class="o">+=</span> <span class="s1">'_s2'</span>
  <span class="n">url</span> <span class="o">+=</span> <span class="s1">'_s2'</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoencoderClass</span><span class="p">(</span><span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encoder</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decoder</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'model_state_dict'</span><span class="p">])</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'optimizer_state_dict'</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--2022-01-25 22:11:01--  https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/ae_6h_prelu_bce_adam_25e_32b_s2.pt
Resolving github.com (github.com)... 140.82.114.4
Connecting to github.com (github.com)|140.82.114.4|:443... connected.
HTTP request sent, awaiting response... 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>302 Found
Location: https://raw.githubusercontent.com/mpbrigham/colaboratory-figures/master/nma/autoencoders/ae_6h_prelu_bce_adam_25e_32b_s2.pt [following]
--2022-01-25 22:11:01--  https://raw.githubusercontent.com/mpbrigham/colaboratory-figures/master/nma/autoencoders/ae_6h_prelu_bce_adam_25e_32b_s2.pt
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.
HTTP request sent, awaiting response... 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>200 OK
Length: 8313616 (7.9M) [application/octet-stream]
Saving to: ‘ae_6h_prelu_bce_adam_25e_32b_s2.pt’

     0K .......... .......... .......... .......... ..........  0% 9.83M 1s
    50K .......... .......... .......... .......... ..........  1% 8.87M 1s
   100K .......... .......... .......... .......... ..........  1% 67.9M 1s
   150K .......... .......... .......... .......... ..........  2% 11.2M 1s
   200K .......... .......... .......... .......... ..........  3% 45.0M 1s
   250K .......... .......... .......... .......... ..........  3% 98.7M 0s
   300K .......... .......... .......... .......... ..........  4% 61.2M 0s
   350K .......... .......... .......... .......... ..........  4% 14.1M 0s
   400K .......... .......... .......... .......... ..........  5%  286M 0s
   450K .......... .......... .......... .......... ..........  6%  142M 0s
   500K .......... .......... .......... .......... ..........  6%  307M 0s
   550K .......... .......... .......... .......... ..........  7% 81.7M 0s
   600K .......... .......... .......... .......... ..........  8% 79.6M 0s
   650K .......... .......... .......... .......... ..........  8%  127M 0s
   700K .......... .......... .......... .......... ..........  9%  141M 0s
   750K .......... .......... .......... .......... ..........  9% 19.2M 0s
   800K .......... .......... .......... .......... .......... 10% 60.6M 0s
   850K .......... .......... .......... .......... .......... 11% 72.1M 0s
   900K .......... .......... .......... .......... .......... 11% 40.4M 0s
   950K .......... .......... .......... .......... .......... 12% 75.1M 0s
  1000K .......... .......... .......... .......... .......... 12% 68.3M 0s
  1050K .......... .......... .......... .......... .......... 13% 96.6M 0s
  1100K .......... .......... .......... .......... .......... 14% 67.8M 0s
  1150K .......... .......... .......... .......... .......... 14% 75.1M 0s
  1200K .......... .......... .......... .......... .......... 15% 51.5M 0s
  1250K .......... .......... .......... .......... .......... 16% 85.7M 0s
  1300K .......... .......... .......... .......... .......... 16% 58.0M 0s
  1350K .......... .......... .......... .......... .......... 17% 82.2M 0s
  1400K .......... .......... .......... .......... .......... 17%  334M 0s
  1450K .......... .......... .......... .......... .......... 18%  149M 0s
  1500K .......... .......... .......... .......... .......... 19%  108M 0s
  1550K .......... .......... .......... .......... .......... 19% 88.7M 0s
  1600K .......... .......... .......... .......... .......... 20%  142M 0s
  1650K .......... .......... .......... .......... .......... 20%  153M 0s
  1700K .......... .......... .......... .......... .......... 21% 93.4M 0s
  1750K .......... .......... .......... .......... .......... 22% 91.5M 0s
  1800K .......... .......... .......... .......... .......... 22%  130M 0s
  1850K .......... .......... .......... .......... .......... 23% 86.9M 0s
  1900K .......... .......... .......... .......... .......... 24% 94.9M 0s
  1950K .......... .......... .......... .......... .......... 24%  131M 0s
  2000K .......... .......... .......... .......... .......... 25% 95.1M 0s
  2050K .......... .......... .......... .......... .......... 25%  147M 0s
  2100K .......... .......... .......... .......... .......... 26% 93.5M 0s
  2150K .......... .......... .......... .......... .......... 27% 89.3M 0s
  2200K .......... .......... .......... .......... .......... 27%  128M 0s
  2250K .......... .......... .......... .......... .......... 28%  335M 0s
  2300K .......... .......... .......... .......... .......... 28% 89.7M 0s
  2350K .......... .......... .......... .......... .......... 29% 80.0M 0s
  2400K .......... .......... .......... .......... .......... 30% 87.4M 0s
  2450K .......... .......... .......... .......... .......... 30% 85.7M 0s
  2500K .......... .......... .......... .......... .......... 31% 82.1M 0s
  2550K .......... .......... .......... .......... .......... 32% 91.7M 0s
  2600K .......... .......... .......... .......... .......... 32%  102M 0s
  2650K .......... .......... .......... .......... .......... 33% 79.1M 0s
  2700K .......... .......... .......... .......... .......... 33%  147M 0s
  2750K .......... .......... .......... .......... .......... 34%  116M 0s
  2800K .......... .......... .......... .......... .......... 35%  109M 0s
  2850K .......... .......... .......... .......... .......... 35% 88.9M 0s
  2900K .......... .......... .......... .......... .......... 36% 89.7M 0s
  2950K .......... .......... .......... .......... .......... 36%  104M 0s
  3000K .......... .......... .......... .......... .......... 37%  114M 0s
  3050K .......... .......... .......... .......... .......... 38% 88.0M 0s
  3100K .......... .......... .......... .......... .......... 38%  102M 0s
  3150K .......... .......... .......... .......... .......... 39%  102M 0s
  3200K .......... .......... .......... .......... .......... 40%  113M 0s
  3250K .......... .......... .......... .......... .......... 40% 96.1M 0s
  3300K .......... .......... .......... .......... .......... 41% 91.4M 0s
  3350K .......... .......... .......... .......... .......... 41%  111M 0s
  3400K .......... .......... .......... .......... .......... 42% 87.3M 0s
  3450K .......... .......... .......... .......... .......... 43%  137M 0s
  3500K .......... .......... .......... .......... .......... 43%  111M 0s
  3550K .......... .......... .......... .......... .......... 44% 99.7M 0s
  3600K .......... .......... .......... .......... .......... 44%  103M 0s
  3650K .......... .......... .......... .......... .......... 45%  101M 0s
  3700K .......... .......... .......... .......... .......... 46%  131M 0s
  3750K .......... .......... .......... .......... .......... 46% 87.9M 0s
  3800K .......... .......... .......... .......... .......... 47%  135M 0s
  3850K .......... .......... .......... .......... .......... 48%  109M 0s
  3900K .......... .......... .......... .......... .......... 48%  138M 0s
  3950K .......... .......... .......... .......... .......... 49%  107M 0s
  4000K .......... .......... .......... .......... .......... 49% 99.1M 0s
  4050K .......... .......... .......... .......... .......... 50%  102M 0s
  4100K .......... .......... .......... .......... .......... 51%  107M 0s
  4150K .......... .......... .......... .......... .......... 51%  100M 0s
  4200K .......... .......... .......... .......... .......... 52% 89.2M 0s
  4250K .......... .......... .......... .......... .......... 52%  116M 0s
  4300K .......... .......... .......... .......... .......... 53%  118M 0s
  4350K .......... .......... .......... .......... .......... 54%  108M 0s
  4400K .......... .......... .......... .......... .......... 54% 80.7M 0s
  4450K .......... .......... .......... .......... .......... 55%  130M 0s
  4500K .......... .......... .......... .......... .......... 56%  126M 0s
  4550K .......... .......... .......... .......... .......... 56%  120M 0s
  4600K .......... .......... .......... .......... .......... 57% 77.1M 0s
  4650K .......... .......... .......... .......... .......... 57%  114M 0s
  4700K .......... .......... .......... .......... .......... 58% 99.1M 0s
  4750K .......... .......... .......... .......... .......... 59%  126M 0s
  4800K .......... .......... .......... .......... .......... 59%  103M 0s
  4850K .......... .......... .......... .......... .......... 60%  107M 0s
  4900K .......... .......... .......... .......... .......... 60%  124M 0s
  4950K .......... .......... .......... .......... .......... 61%  135M 0s
  5000K .......... .......... .......... .......... .......... 62%  116M 0s
  5050K .......... .......... .......... .......... .......... 62%  123M 0s
  5100K .......... .......... .......... .......... .......... 63%  106M 0s
  5150K .......... .......... .......... .......... .......... 64%  104M 0s
  5200K .......... .......... .......... .......... .......... 64%  128M 0s
  5250K .......... .......... .......... .......... .......... 65%  112M 0s
  5300K .......... .......... .......... .......... .......... 65%  134M 0s
  5350K .......... .......... .......... .......... .......... 66%  141M 0s
  5400K .......... .......... .......... .......... .......... 67%  111M 0s
  5450K .......... .......... .......... .......... .......... 67%  123M 0s
  5500K .......... .......... .......... .......... .......... 68%  140M 0s
  5550K .......... .......... .......... .......... .......... 68%  131M 0s
  5600K .......... .......... .......... .......... .......... 69%  136M 0s
  5650K .......... .......... .......... .......... .......... 70%  141M 0s
  5700K .......... .......... .......... .......... .......... 70%  108M 0s
  5750K .......... .......... .......... .......... .......... 71%  136M 0s
  5800K .......... .......... .......... .......... .......... 72%  130M 0s
  5850K .......... .......... .......... .......... .......... 72%  134M 0s
  5900K .......... .......... .......... .......... .......... 73%  122M 0s
  5950K .......... .......... .......... .......... .......... 73%  132M 0s
  6000K .......... .......... .......... .......... .......... 74%  133M 0s
  6050K .......... .......... .......... .......... .......... 75%  121M 0s
  6100K .......... .......... .......... .......... .......... 75%  139M 0s
  6150K .......... .......... .......... .......... .......... 76%  133M 0s
  6200K .......... .......... .......... .......... .......... 76%  119M 0s
  6250K .......... .......... .......... .......... .......... 77%  116M 0s
  6300K .......... .......... .......... .......... .......... 78%  140M 0s
  6350K .......... .......... .......... .......... .......... 78%  105M 0s
  6400K .......... .......... .......... .......... .......... 79%  128M 0s
  6450K .......... .......... .......... .......... .......... 80%  142M 0s
  6500K .......... .......... .......... .......... .......... 80%  141M 0s
  6550K .......... .......... .......... .......... .......... 81%  115M 0s
  6600K .......... .......... .......... .......... .......... 81%  132M 0s
  6650K .......... .......... .......... .......... .......... 82%  121M 0s
  6700K .......... .......... .......... .......... .......... 83%  129M 0s
  6750K .......... .......... .......... .......... .......... 83%  129M 0s
  6800K .......... .......... .......... .......... .......... 84%  146M 0s
  6850K .......... .......... .......... .......... .......... 84%  121M 0s
  6900K .......... .......... .......... .......... .......... 85%  136M 0s
  6950K .......... .......... .......... .......... .......... 86%  132M 0s
  7000K .......... .......... .......... .......... .......... 86%  121M 0s
  7050K .......... .......... .......... .......... .......... 87%  128M 0s
  7100K .......... .......... .......... .......... .......... 88%  127M 0s
  7150K .......... .......... .......... .......... .......... 88%  138M 0s
  7200K .......... .......... .......... .......... .......... 89%  120M 0s
  7250K .......... .......... .......... .......... .......... 89%  128M 0s
  7300K .......... .......... .......... .......... .......... 90%  129M 0s
  7350K .......... .......... .......... .......... .......... 91%  137M 0s
  7400K .......... .......... .......... .......... .......... 91%  109M 0s
  7450K .......... .......... .......... .......... .......... 92%  137M 0s
  7500K .......... .......... .......... .......... .......... 92%  130M 0s
  7550K .......... .......... .......... .......... .......... 93%  121M 0s
  7600K .......... .......... .......... .......... .......... 94%  136M 0s
  7650K .......... .......... .......... .......... .......... 94%  124M 0s
  7700K .......... .......... .......... .......... .......... 95%  124M 0s
  7750K .......... .......... .......... .......... .......... 96%  135M 0s
  7800K .......... .......... .......... .......... .......... 96%  144M 0s
  7850K .......... .......... .......... .......... .......... 97%  125M 0s
  7900K .......... .......... .......... .......... .......... 97%  126M 0s
  7950K .......... .......... .......... .......... .......... 98%  136M 0s
  8000K .......... .......... .......... .......... .......... 99%  142M 0s
  8050K .......... .......... .......... .......... .......... 99%  114M 0s
  8100K .......... ........                                   100% 88.3M=0.09s

2022-01-25 22:11:01 (85.6 MB/s) - ‘ae_6h_prelu_bce_adam_25e_32b_s2.pt’ saved [8313616/8313616]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Please uncomment and execute this cell if download of</span>
<span class="c1"># pre-trained weights fail</span>

<span class="c1"># model = AutoencoderClass(s2=s2)</span>
<span class="c1"># encoder = model.encoder</span>
<span class="c1"># decoder = model.decoder</span>
<span class="c1"># n_epochs = 10</span>
<span class="c1"># batch_size = 128</span>
<span class="c1"># runSGD(model, input_train, input_test,</span>
<span class="c1">#        n_epochs=n_epochs, batch_size=batch_size)</span>
<span class="c1"># save_checkpoint(model, optimizer, filename)</span>
<span class="c1"># checkpoint = load_checkpoint(url, filename)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>
  <span class="n">latent_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span> <span class="n">output_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">]],</span>
         <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">plot_latent_generative</span><span class="p">(</span><span class="n">latent_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span>
                       <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/Bonus_Tutorial3_17_0.png" src="../../../_images/Bonus_Tutorial3_17_0.png"/>
<img alt="../../../_images/Bonus_Tutorial3_17_1.png" src="../../../_images/Bonus_Tutorial3_17_1.png"/>
<img alt="../../../_images/Bonus_Tutorial3_17_2.png" src="../../../_images/Bonus_Tutorial3_17_2.png"/>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-3-applications-of-autoencoders">
<h1>Section 3: Applications of autoencoders<a class="headerlink" href="#section-3-applications-of-autoencoders" title="Permalink to this headline">¶</a></h1>
<div class="section" id="application-1-image-noise">
<h2>Application 1 - Image noise<a class="headerlink" href="#application-1-image-noise" title="Permalink to this headline">¶</a></h2>
<p>Removing noise added to images is often showcased in dimensionality reduction techniques. The tutorial  <em>W1D5 Dimensionality reduction</em> illustrated this capability with PCA.</p>
<p>We first observe that autoencoders trained with noise-free images output noise-free images when receiving noisy images as input.  However, the reconstructed images will be different from the original images (without noise) since the added noise maps to different coordinates in latent space.</p>
<p>The ability to map noise-free and noisy versions to similar regions in latent space is known as <em>robustness</em> or <em>invariance</em> to noise. How can we build such functionality into the autoencoder?</p>
<p>The solution is to train the autoencoder with noise-free and noisy versions mapping to the noise-free version. A faster alternative is to re-train the autoencoder for few epochs with noisy images. These short training sessions fine-tune the weights to map noisy images to their noise-free versions from similar latent space coordinates.</p>
<p>Let’s start by resetting to the reference state of the autoencoder.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cells below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reset_checkpoint</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">latent_test_ref</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="reconstructions-before-fine-tuning">
<h3>Reconstructions before fine-tuning<a class="headerlink" href="#reconstructions-before-fine-tuning" title="Permalink to this headline">¶</a></h3>
<p>Let’s verify that an autoencoder trained on clean images will output clean images from noisy inputs. We visualize this by plotting three rows:</p>
<ul class="simple">
<li><p>Top row with noisy images inputs</p></li>
<li><p>Middle row with reconstructions of noisy images</p></li>
<li><p>Bottom row with reconstructions of the original images (noise-free)</p></li>
</ul>
<p><img alt="Noise task" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/applications_noise.png"/></p>
<p>The bottom row helps identify samples with reconstruction issues before adding noise. This row shows the baseline reconstruction quality for these samples rather than the original images. (Why?)</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell(s) below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">noise_factor</span> <span class="o">=</span> <span class="mf">0.4</span>

<span class="n">input_train_noisy</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_train</span>
                     <span class="o">+</span> <span class="n">noise_factor</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">input_train</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">input_train_noisy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">input_train_noisy</span><span class="p">,</span> <span class="n">input_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span>
                            <span class="n">input_train</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">input_test_noisy</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_test</span>
                    <span class="o">+</span> <span class="n">noise_factor</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">input_test</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">input_test_noisy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">input_test_noisy</span><span class="p">,</span> <span class="n">input_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span>
                           <span class="n">input_test</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output_test_noisy</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test_noisy</span><span class="p">)</span>
  <span class="n">latent_test_noisy</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test_noisy</span><span class="p">)</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test_noisy</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span>
          <span class="n">output_test_noisy</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span>
          <span class="n">output_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">]],</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/Bonus_Tutorial3_23_0.png" src="../../../_images/Bonus_Tutorial3_23_0.png"/>
<img alt="../../../_images/Bonus_Tutorial3_23_1.png" src="../../../_images/Bonus_Tutorial3_23_1.png"/>
<img alt="../../../_images/Bonus_Tutorial3_23_2.png" src="../../../_images/Bonus_Tutorial3_23_2.png"/>
</div>
</div>
</div>
<div class="section" id="latent-space-before-fine-tuning">
<h3>Latent space before fine-tuning<a class="headerlink" href="#latent-space-before-fine-tuning" title="Permalink to this headline">¶</a></h3>
<p>We investigate the origin of reconstruction errors by looking at how adding noise to input affects latent space coordinates. The decoder interprets significant coordinate changes as different digits.</p>
<p>The function <code class="docutils literal notranslate"><span class="pre">plot_latent_ab</span></code> compares latent space coordinates for the same set of samples between two conditions.  Here, we display coordinates for the ten samples from the previous cell before and after adding noise:</p>
<ul class="simple">
<li><p>The left plot shows the coordinates of the original samples (noise-free)</p></li>
<li><p>The plot on the right shows the new coordinates after adding noise</p></li>
</ul>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_latent_ab</span><span class="p">(</span><span class="n">latent_test</span><span class="p">,</span> <span class="n">latent_test_noisy</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">test_selected_idx</span><span class="p">,</span>
               <span class="n">title_a</span><span class="o">=</span><span class="s1">'Before noise'</span><span class="p">,</span> <span class="n">title_b</span><span class="o">=</span><span class="s1">'After noise'</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/Bonus_Tutorial3_25_0.png" src="../../../_images/Bonus_Tutorial3_25_0.png"/>
</div>
</div>
</div>
<div class="section" id="fine-tuning-the-autoencoder-with-noisy-images">
<h3>Fine-tuning the autoencoder with noisy images<a class="headerlink" href="#fine-tuning-the-autoencoder-with-noisy-images" title="Permalink to this headline">¶</a></h3>
<p>Let’s re-train the autoencoder with noisy images on the input and original (noise-free) images on the output, and regenerate the previous plots.</p>
<p>We now see that both noisy and noise-free images match similar locations in latent space. The network denoises the input with a latent-space representation that is more robust to noise.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell(s) below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_train_noisy</span><span class="p">,</span> <span class="n">input_test_noisy</span><span class="p">,</span>
       <span class="n">out_train</span><span class="o">=</span><span class="n">input_train</span><span class="p">,</span> <span class="n">out_test</span><span class="o">=</span><span class="n">input_test</span><span class="p">,</span>
       <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 	 Loss train 	 Loss test
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1/3	 0.1748		 0.1759
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2/3	 0.1730		 0.1742
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3/3	 0.1718		 0.1730
</pre></div>
</div>
<img alt="../../../_images/Bonus_Tutorial3_27_4.png" src="../../../_images/Bonus_Tutorial3_27_4.png"/>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output_test_noisy</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test_noisy</span><span class="p">)</span>
  <span class="n">latent_test_noisy</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test_noisy</span><span class="p">)</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test_noisy</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span>
          <span class="n">output_test_noisy</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span>
          <span class="n">output_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">]],</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">plot_latent_ab</span><span class="p">(</span><span class="n">latent_test</span><span class="p">,</span> <span class="n">latent_test_noisy</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">test_selected_idx</span><span class="p">,</span>
               <span class="n">title_a</span><span class="o">=</span><span class="s1">'Before fine-tuning'</span><span class="p">,</span>
               <span class="n">title_b</span><span class="o">=</span><span class="s1">'After fine-tuning'</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/Bonus_Tutorial3_28_0.png" src="../../../_images/Bonus_Tutorial3_28_0.png"/>
<img alt="../../../_images/Bonus_Tutorial3_28_1.png" src="../../../_images/Bonus_Tutorial3_28_1.png"/>
<img alt="../../../_images/Bonus_Tutorial3_28_2.png" src="../../../_images/Bonus_Tutorial3_28_2.png"/>
<img alt="../../../_images/Bonus_Tutorial3_28_3.png" src="../../../_images/Bonus_Tutorial3_28_3.png"/>
</div>
</div>
</div>
<div class="section" id="global-latent-space-shift">
<h3>Global latent space shift<a class="headerlink" href="#global-latent-space-shift" title="Permalink to this headline">¶</a></h3>
<p>The new latent space representation is more robust to noise and may result in a better internal representation of the dataset. We verify this by inspecting the latent space with clean images before and after fine-tuning with noisy images.</p>
<p>Fine-tuning the network with noisy images causes a <em>domain shift</em> in the dataset, i.e., a change in the distribution of images since the dataset was initially composed of noise-free images. Depending on the task and the extent of changes during re-train,  (number of epochs, optimizer characteristics, etc.), the new latent space representation may become less well adapted to the original data as a side-effect. How could we address <em>domain shift</em> and improve both noisy and noise-free images?</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell(s) below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">latent_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_latent_ab</span><span class="p">(</span><span class="n">latent_test_ref</span><span class="p">,</span> <span class="n">latent_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">test_subset_idx</span><span class="p">,</span>
               <span class="n">title_a</span><span class="o">=</span><span class="s1">'Before fine-tuning'</span><span class="p">,</span>
               <span class="n">title_b</span><span class="o">=</span><span class="s1">'After fine-tuning'</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/Bonus_Tutorial3_30_0.png" src="../../../_images/Bonus_Tutorial3_30_0.png"/>
</div>
</div>
</div>
</div>
<div class="section" id="application-2-image-occlusion">
<h2>Application 2 - Image occlusion<a class="headerlink" href="#application-2-image-occlusion" title="Permalink to this headline">¶</a></h2>
<p>We now investigate the effects of image occlusion. Drawing from the previous exercise, we expect the autoencoder to reconstruct complete images since the train set does not contain occluded images (right?).</p>
<p>We visualize this by plotting three rows:</p>
<ul class="simple">
<li><p>Top row with occluded images</p></li>
<li><p>Middle row with reconstructions of occluded images</p></li>
<li><p>Bottom row with reconstructions of the original images</p></li>
</ul>
<p><img alt="Occlusion task" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/applications_occlusion.png"/></p>
<p>Similarly, we investigate the source of this issue by looking at the representation of partial images in latent space and how it adjusts after fine-tuning.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell(s) below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reset_checkpoint</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">latent_test_ref</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="before-fine-tuning">
<h3>Before fine-tuning<a class="headerlink" href="#before-fine-tuning" title="Permalink to this headline">¶</a></h3>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell(s) below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_train_mask</span> <span class="o">=</span> <span class="n">image_occlusion</span><span class="p">(</span><span class="n">input_train</span><span class="p">,</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
<span class="n">input_test_mask</span> <span class="o">=</span> <span class="n">image_occlusion</span><span class="p">(</span><span class="n">input_test</span><span class="p">,</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output_test_mask</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test_mask</span><span class="p">)</span>
  <span class="n">latent_test_mask</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test_mask</span><span class="p">)</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test_mask</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span>
          <span class="n">output_test_mask</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span>
          <span class="n">output_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">]],</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">plot_latent_ab</span><span class="p">(</span><span class="n">latent_test</span><span class="p">,</span> <span class="n">latent_test_mask</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">test_selected_idx</span><span class="p">,</span>
               <span class="n">title_a</span><span class="o">=</span><span class="s1">'Before occlusion'</span><span class="p">,</span> <span class="n">title_b</span><span class="o">=</span><span class="s1">'After occlusion'</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/Bonus_Tutorial3_35_0.png" src="../../../_images/Bonus_Tutorial3_35_0.png"/>
<img alt="../../../_images/Bonus_Tutorial3_35_1.png" src="../../../_images/Bonus_Tutorial3_35_1.png"/>
<img alt="../../../_images/Bonus_Tutorial3_35_2.png" src="../../../_images/Bonus_Tutorial3_35_2.png"/>
<img alt="../../../_images/Bonus_Tutorial3_35_3.png" src="../../../_images/Bonus_Tutorial3_35_3.png"/>
</div>
</div>
</div>
<div class="section" id="after-fine-tuning">
<h3>After fine-tuning<a class="headerlink" href="#after-fine-tuning" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_train_mask</span><span class="p">,</span> <span class="n">input_test_mask</span><span class="p">,</span>
       <span class="n">out_train</span><span class="o">=</span><span class="n">input_train</span><span class="p">,</span> <span class="n">out_test</span><span class="o">=</span><span class="n">input_test</span><span class="p">,</span>
       <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 	 Loss train 	 Loss test
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1/3	 0.1725		 0.1735
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2/3	 0.1710		 0.1721
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3/3	 0.1711		 0.1724
</pre></div>
</div>
<img alt="../../../_images/Bonus_Tutorial3_37_4.png" src="../../../_images/Bonus_Tutorial3_37_4.png"/>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output_test_mask</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test_mask</span><span class="p">)</span>
  <span class="n">latent_test_mask</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test_mask</span><span class="p">)</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test_mask</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span>
          <span class="n">output_test_mask</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span>
          <span class="n">output_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">]],</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">plot_latent_ab</span><span class="p">(</span><span class="n">latent_test</span><span class="p">,</span> <span class="n">latent_test_mask</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">test_selected_idx</span><span class="p">,</span>
               <span class="n">title_a</span><span class="o">=</span><span class="s1">'Before fine-tuning'</span><span class="p">,</span>
               <span class="n">title_b</span><span class="o">=</span><span class="s1">'After fine-tuning'</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/Bonus_Tutorial3_38_0.png" src="../../../_images/Bonus_Tutorial3_38_0.png"/>
<img alt="../../../_images/Bonus_Tutorial3_38_1.png" src="../../../_images/Bonus_Tutorial3_38_1.png"/>
<img alt="../../../_images/Bonus_Tutorial3_38_2.png" src="../../../_images/Bonus_Tutorial3_38_2.png"/>
<img alt="../../../_images/Bonus_Tutorial3_38_3.png" src="../../../_images/Bonus_Tutorial3_38_3.png"/>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">latent_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_latent_ab</span><span class="p">(</span><span class="n">latent_test_ref</span><span class="p">,</span> <span class="n">latent_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">test_subset_idx</span><span class="p">,</span>
               <span class="n">title_a</span><span class="o">=</span><span class="s1">'Before fine-tuning'</span><span class="p">,</span>
               <span class="n">title_b</span><span class="o">=</span><span class="s1">'After fine-tuning'</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/Bonus_Tutorial3_39_0.png" src="../../../_images/Bonus_Tutorial3_39_0.png"/>
</div>
</div>
</div>
</div>
<div class="section" id="application-3-image-rotation">
<h2>Application 3 - Image rotation<a class="headerlink" href="#application-3-image-rotation" title="Permalink to this headline">¶</a></h2>
<p>Finally, we look at the effect of image rotation in latent space coordinates. This task is arguably more challenging since it may require a complete re-write of image reconstruction.</p>
<p>We visualize this by plotting three rows:</p>
<ul class="simple">
<li><p>Top row with rotated images</p></li>
<li><p>Middle row with reconstructions of rotated images</p></li>
<li><p>Bottom row with reconstructions of the original images</p></li>
</ul>
<p><img alt="Rotation task" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/applications_rotation.png"/></p>
<p>We investigate the source of this issue by looking at the representation of rotated images in latent space and how it adjusts after fine-tuning.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell(s) below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reset_checkpoint</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">latent_test_ref</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id1">
<h3>Before fine-tuning<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell(s) below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_train_rotation</span> <span class="o">=</span> <span class="n">image_rotation</span><span class="p">(</span><span class="n">input_train</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
<span class="n">input_test_rotation</span> <span class="o">=</span> <span class="n">image_rotation</span><span class="p">(</span><span class="n">input_test</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output_test_rotation</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test_rotation</span><span class="p">)</span>
  <span class="n">latent_test_rotation</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test_rotation</span><span class="p">)</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test_rotation</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span>
          <span class="n">output_test_rotation</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span>
          <span class="n">output_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">]],</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">plot_latent_ab</span><span class="p">(</span><span class="n">latent_test</span><span class="p">,</span> <span class="n">latent_test_rotation</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">test_selected_idx</span><span class="p">,</span>
               <span class="n">title_a</span><span class="o">=</span><span class="s1">'Before rotation'</span><span class="p">,</span> <span class="n">title_b</span><span class="o">=</span><span class="s1">'After rotation'</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/Bonus_Tutorial3_44_0.png" src="../../../_images/Bonus_Tutorial3_44_0.png"/>
<img alt="../../../_images/Bonus_Tutorial3_44_1.png" src="../../../_images/Bonus_Tutorial3_44_1.png"/>
<img alt="../../../_images/Bonus_Tutorial3_44_2.png" src="../../../_images/Bonus_Tutorial3_44_2.png"/>
<img alt="../../../_images/Bonus_Tutorial3_44_3.png" src="../../../_images/Bonus_Tutorial3_44_3.png"/>
</div>
</div>
</div>
<div class="section" id="id2">
<h3>After fine-tuning<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell(s) below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_train_rotation</span><span class="p">,</span> <span class="n">input_test_rotation</span><span class="p">,</span>
       <span class="n">out_train</span><span class="o">=</span><span class="n">input_train</span><span class="p">,</span> <span class="n">out_test</span><span class="o">=</span><span class="n">input_test</span><span class="p">,</span>
       <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 	 Loss train 	 Loss test
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1/5	 0.2202		 0.2200
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2/5	 0.2131		 0.2133
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3/5	 0.2095		 0.2100
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_2393</span><span class="o">/</span><span class="mf">2310652347.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_train_rotation</span><span class="p">,</span> <span class="n">input_test_rotation</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>        <span class="n">out_train</span><span class="o">=</span><span class="n">input_train</span><span class="p">,</span> <span class="n">out_test</span><span class="o">=</span><span class="n">input_test</span><span class="p">,</span>
<span class="ne">----&gt; </span><span class="mi">8</span>        <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="nn">/tmp/ipykernel_2393/56036000.py</span> in <span class="ni">runSGD</span><span class="nt">(net, input_train, input_test, out_train, out_test, optimizer, criterion, n_epochs, batch_size, verbose)</span>
<span class="g g-Whitespace">    </span><span class="mi">580</span>       <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">581</span>       <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="ne">--&gt; </span><span class="mi">582</span>       <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">583</span> 
<span class="g g-Whitespace">    </span><span class="mi">584</span>       <span class="c1"># Keep track of loss at each epoch</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/torch/optim/optimizer.py</span> in <span class="ni">wrapper</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">86</span>                 <span class="n">profile_name</span> <span class="o">=</span> <span class="s2">"Optimizer.step#</span><span class="si">{}</span><span class="s2">.step"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">87</span>                 <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">record_function</span><span class="p">(</span><span class="n">profile_name</span><span class="p">):</span>
<span class="ne">---&gt; </span><span class="mi">88</span>                     <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">89</span>             <span class="k">return</span> <span class="n">wrapper</span>
<span class="g g-Whitespace">     </span><span class="mi">90</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/torch/autograd/grad_mode.py</span> in <span class="ni">decorate_context</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">26</span>         <span class="k">def</span> <span class="nf">decorate_context</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">27</span>             <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">():</span>
<span class="ne">---&gt; </span><span class="mi">28</span>                 <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">29</span>         <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">decorate_context</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">30</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/torch/optim/adam.py</span> in <span class="ni">step</span><span class="nt">(self, closure)</span>
<span class="g g-Whitespace">    </span><span class="mi">142</span>                    <span class="n">lr</span><span class="o">=</span><span class="n">group</span><span class="p">[</span><span class="s1">'lr'</span><span class="p">],</span>
<span class="g g-Whitespace">    </span><span class="mi">143</span>                    <span class="n">weight_decay</span><span class="o">=</span><span class="n">group</span><span class="p">[</span><span class="s1">'weight_decay'</span><span class="p">],</span>
<span class="ne">--&gt; </span><span class="mi">144</span>                    <span class="n">eps</span><span class="o">=</span><span class="n">group</span><span class="p">[</span><span class="s1">'eps'</span><span class="p">])</span>
<span class="g g-Whitespace">    </span><span class="mi">145</span>         <span class="k">return</span> <span class="n">loss</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/torch/optim/_functional.py</span> in <span class="ni">adam</span><span class="nt">(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)</span>
<span class="g g-Whitespace">     </span><span class="mi">84</span> 
<span class="g g-Whitespace">     </span><span class="mi">85</span>         <span class="c1"># Decay the first and second moment running average coefficient</span>
<span class="ne">---&gt; </span><span class="mi">86</span>         <span class="n">exp_avg</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">beta1</span><span class="p">)</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">87</span>         <span class="n">exp_avg_sq</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">beta2</span><span class="p">)</span><span class="o">.</span><span class="n">addcmul_</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">grad</span><span class="o">.</span><span class="n">conj</span><span class="p">(),</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">88</span>         <span class="k">if</span> <span class="n">amsgrad</span><span class="p">:</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output_test_rotation</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test_rotation</span><span class="p">)</span>
  <span class="n">latent_test_rotation</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test_rotation</span><span class="p">)</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test_rotation</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span>
          <span class="n">output_test_rotation</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span>
          <span class="n">output_test</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">]],</span> <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">plot_latent_ab</span><span class="p">(</span><span class="n">latent_test</span><span class="p">,</span> <span class="n">latent_test_rotation</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">test_selected_idx</span><span class="p">,</span>
               <span class="n">title_a</span><span class="o">=</span><span class="s1">'Before fine-tuning'</span><span class="p">,</span>
               <span class="n">title_b</span><span class="o">=</span><span class="s1">'After fine-tuning'</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">latent_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>

<span class="n">plot_latent_ab</span><span class="p">(</span><span class="n">latent_test_ref</span><span class="p">,</span> <span class="n">latent_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">test_subset_idx</span><span class="p">,</span>
               <span class="n">title_a</span><span class="o">=</span><span class="s1">'Before fine-tuning'</span><span class="p">,</span>
               <span class="n">title_b</span><span class="o">=</span><span class="s1">'After fine-tuning'</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="application-4-what-would-digit-6-look-like-if-we-had-never-seen-it-before">
<h2>Application 4 - What would digit “6” look like if we had never seen it before?<a class="headerlink" href="#application-4-what-would-digit-6-look-like-if-we-had-never-seen-it-before" title="Permalink to this headline">¶</a></h2>
<p>Before we start melting our brains with such an impossible task, let’s just ask the autoencoder to do it!</p>
<p>We train the autoencoder from scratch without digit class <code class="docutils literal notranslate"><span class="pre">6</span></code> and visualize reconstructions from digit <code class="docutils literal notranslate"><span class="pre">6</span></code>.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell(s) below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoencoderClass</span><span class="p">(</span><span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encoder</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decoder</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">missing</span> <span class="o">=</span> <span class="mi">6</span>

<span class="n">my_input_train</span> <span class="o">=</span> <span class="n">input_train</span><span class="p">[</span><span class="n">y_train</span> <span class="o">!=</span> <span class="n">missing</span><span class="p">]</span>
<span class="n">my_input_test</span> <span class="o">=</span> <span class="n">input_test</span><span class="p">[</span><span class="n">y_test</span> <span class="o">!=</span> <span class="n">missing</span><span class="p">]</span>
<span class="n">my_y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[</span><span class="n">y_test</span> <span class="o">!=</span> <span class="n">missing</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">my_input_train</span><span class="p">,</span> <span class="n">my_input_test</span><span class="p">,</span>
       <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>
  <span class="n">my_latent_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">my_input_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_row</span><span class="p">([</span><span class="n">input_test</span><span class="p">[</span><span class="n">y_test</span> <span class="o">==</span> <span class="mi">6</span><span class="p">],</span> <span class="n">output_test</span><span class="p">[</span><span class="n">y_test</span> <span class="o">==</span> <span class="mi">6</span><span class="p">]],</span>
         <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">plot_latent_generative</span><span class="p">(</span><span class="n">my_latent_test</span><span class="p">,</span> <span class="n">my_y_test</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span>
                       <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="exercise-1-removing-the-most-dominant-digit-classes">
<h3>Exercise 1: Removing the most dominant digit classes<a class="headerlink" href="#exercise-1-removing-the-most-dominant-digit-classes" title="Permalink to this headline">¶</a></h3>
<p>Digit classes <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code> are dominant in the sense that these occupy large areas of the decoder grid, compared to other digit classes that occupy very little generative space.</p>
<p>How will latent space change when removing the two most dominant digit classes? Will latent space re-distribute evenly among remaining classes or choose another two dominant classes?</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell(s) below</p></li>
<li><p>The intersection of two boolean arrays by condition is specified as <code class="docutils literal notranslate"><span class="pre">x[(cond_a)&amp;(cond_b)]</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoencoderClass</span><span class="p">(</span><span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encoder</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decoder</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">missing_a</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">missing_b</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1">#################################################</span>
<span class="c1">## TODO for students:</span>
<span class="c1">#################################################</span>
<span class="c1"># input train data</span>
<span class="c1"># my_input_train = ...</span>
<span class="c1"># input test data</span>
<span class="c1"># my_input_test = ...</span>
<span class="c1"># model</span>
<span class="c1"># my_y_test = ...</span>

<span class="c1"># Uncomment to test your code</span>
<span class="c1"># print(my_input_train.shape)</span>
<span class="c1"># print(my_input_test.shape)</span>
<span class="c1"># print(my_y_test.shape)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>SAMPLE OUTPUT</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">47335</span><span class="p">,</span> <span class="mi">784</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">7885</span><span class="p">,</span> <span class="mi">784</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">7885</span><span class="p">])</span>
</pre></div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/Bonus_Autoencoders/solutions/Bonus_Tutorial3_Solution_22e2c431.py"><em>Click for solution</em></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">my_input_train</span><span class="p">,</span> <span class="n">my_input_test</span><span class="p">,</span>
       <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">output_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test</span><span class="p">)</span>
  <span class="n">my_latent_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">my_input_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_row</span><span class="p">([</span><span class="n">input_test</span><span class="p">[</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">missing_a</span><span class="p">],</span> <span class="n">output_test</span><span class="p">[</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">missing_a</span><span class="p">]],</span>
         <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test</span><span class="p">[</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">missing_b</span><span class="p">],</span> <span class="n">output_test</span><span class="p">[</span><span class="n">y_test</span> <span class="o">==</span> <span class="n">missing_b</span><span class="p">]],</span>
         <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">plot_latent_generative</span><span class="p">(</span><span class="n">my_latent_test</span><span class="p">,</span> <span class="n">my_y_test</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span>
                       <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-4-anns-same-but-different">
<h1>Section 4: ANNs? Same but different!<a class="headerlink" href="#section-4-anns-same-but-different" title="Permalink to this headline">¶</a></h1>
<p>“Same same but different” is an expression used in some parts of Asia to express differences between supposedly similar subjects. In this exercise, we investigate a fundamental difference in how fully-connected ANNs process visual information compared to human vision.</p>
<p>The previous exercises showed ANN autoencoder performing cognitive tasks with relative ease. However, there is a crucial aspect of ANN processing already encoded in the vectorization of images. This network architecture completely ignores the relative position of pixels. To illustrate this, we show that learning proceeds just as well with shuffled pixel locations.</p>
<p>First, we obtain a reversible shuffle map stored in <code class="docutils literal notranslate"><span class="pre">shuffle_image_idx</span></code> used to shuffle image pixels randomly.</p>
<p> </p>
<p><img alt="mnist_pixel_shuffle" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/mnist_pixel_shuffle.png"/></p>
<p> </p>
<p>The unshuffled image set <code class="docutils literal notranslate"><span class="pre">input_shuffle</span></code> is recovered as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">input_shuffle</span><span class="p">[:,</span> <span class="n">shuffle_rev_image_idx</span><span class="p">]]</span>
</pre></div>
</div>
<p>First, we set up the reversible shuffle map and visualize a few images with shuffled and unshuffled pixels, followed by their noisy versions.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell(s) below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create forward and reverse indexes for pixel shuffling</span>
<span class="n">shuffle_image_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">input_size</span><span class="p">)</span>
<span class="n">shuffle_rev_image_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">shuffle_image_idx</span><span class="p">)</span>

<span class="c1"># shuffle pixel location</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">shuffle_image_idx</span><span class="p">)</span>

<span class="c1"># store reverse locations</span>
<span class="k">for</span> <span class="n">pos_idx</span><span class="p">,</span> <span class="n">pos</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">shuffle_image_idx</span><span class="p">):</span>
  <span class="n">shuffle_rev_image_idx</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">=</span> <span class="n">pos_idx</span>

<span class="c1"># shuffle train and test sets</span>
<span class="n">input_train_shuffle</span> <span class="o">=</span> <span class="n">input_train</span><span class="p">[:,</span> <span class="n">shuffle_image_idx</span><span class="p">]</span>
<span class="n">input_test_shuffle</span> <span class="o">=</span> <span class="n">input_test</span><span class="p">[:,</span> <span class="n">shuffle_image_idx</span><span class="p">]</span>

<span class="n">input_train_shuffle_noisy</span> <span class="o">=</span> <span class="n">input_train_noisy</span><span class="p">[:,</span> <span class="n">shuffle_image_idx</span><span class="p">]</span>
<span class="n">input_test_shuffle_noisy</span> <span class="o">=</span> <span class="n">input_test_noisy</span><span class="p">[:,</span> <span class="n">shuffle_image_idx</span><span class="p">]</span>

<span class="c1"># show samples with shuffled pixels</span>
<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test_shuffle</span><span class="p">,</span>
          <span class="n">input_test_shuffle</span><span class="p">[:,</span> <span class="n">shuffle_rev_image_idx</span><span class="p">]],</span>
         <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># show noisy samples with shuffled pixels</span>
<span class="n">plot_row</span><span class="p">([</span><span class="n">input_train_shuffle_noisy</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span>
          <span class="n">input_train_shuffle_noisy</span><span class="p">[:,</span> <span class="n">shuffle_rev_image_idx</span><span class="p">][</span><span class="n">test_selected_idx</span><span class="p">]],</span>
         <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We initialize and train the network in the denoising task with shuffled pixels.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoencoderClass</span><span class="p">(</span><span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encoder</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decoder</span>

<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>

<span class="c1"># train the model to denoise shuffled images</span>
<span class="n">runSGD</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_train_shuffle_noisy</span><span class="p">,</span> <span class="n">input_test_shuffle_noisy</span><span class="p">,</span>
       <span class="n">out_train</span><span class="o">=</span><span class="n">input_train_shuffle</span><span class="p">,</span> <span class="n">out_test</span><span class="o">=</span><span class="n">input_test_shuffle</span><span class="p">,</span>
       <span class="n">n_epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, visualize reconstructions and latent space representation with the trained model.</p>
<p>We visualize reconstructions by plotting three rows:</p>
<ul class="simple">
<li><p>Top row with shuffled noisy images</p></li>
<li><p>Middle row with reconstructions of shuffled denoised images</p></li>
<li><p>Bottom row with unshuffled reconstructions of denoised images</p></li>
</ul>
<p><img alt="mnist_pixel_shuffle denoised" src="https://github.com/mpbrigham/colaboratory-figures/raw/master/nma/autoencoders/applications_ann_denoise.png"/></p>
<p>We obtain the same organization in the encoder map as before. Sharing similar internal representations confirms the network to ignore the relative position of pixels. The decoder grid is different than before since it generates shuffled images.</p>
<p><strong>Instructions:</strong></p>
<ul class="simple">
<li><p>Please execute the cell below</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
  <span class="n">latent_test_shuffle_noisy</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">input_test_shuffle_noisy</span><span class="p">)</span>
  <span class="n">output_test_shuffle_noisy</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_test_shuffle_noisy</span><span class="p">)</span>

<span class="n">plot_row</span><span class="p">([</span><span class="n">input_test_shuffle_noisy</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span>
          <span class="n">output_test_shuffle_noisy</span><span class="p">[</span><span class="n">test_selected_idx</span><span class="p">],</span>
          <span class="n">output_test_shuffle_noisy</span><span class="p">[:,</span> <span class="n">shuffle_rev_image_idx</span><span class="p">][</span><span class="n">test_selected_idx</span><span class="p">]],</span>
         <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">)</span>

<span class="n">plot_latent_generative</span><span class="p">(</span><span class="n">latent_test_shuffle_noisy</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span>
                       <span class="n">image_shape</span><span class="o">=</span><span class="n">image_shape</span><span class="p">,</span> <span class="n">s2</span><span class="o">=</span><span class="n">s2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p>Hooray! You have finished the last Tutorial of NMA 2020!</p>
<p>We hope you’ve enjoyed these tutorials and learned about the usefulness of autoencoders to model rich and non-linear representations of data. We hope you may find them useful in your research, perhaps to model certain aspects of cognition or even extend them to biologically plausible architectures - autoencoders of spiking neurons, anyone?</p>
<p>These are the key take away messages from these tutorials:</p>
<p><strong>Autoencoders trained in <em>learning by doing</em> tasks such as compression/decompression, removing noise, etc. can uncover rich lower-dimensional structure embedded in structured images and other cognitively relevant data.</strong></p>
<p><strong>The data domain seen during training imprints a “cognitive bias” - you only see what you expect to see, which can only be similar to what you saw before.</strong></p>
<p>Such bias is related to the concept <a class="reference external" href="https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow"><em>What you see is all there is</em></a> coined by Daniel Kahneman in psychology.</p>
<p>For additional applications of autoencoders to neuroscience, check the spike sorting application in the outro video, and also see <a class="reference external" href="https://www.nature.com/articles/s41592-018-0109-9">here</a> how to replicate the input-output relationship of real networks of neurons with autoencoders.</p>
<div class="section" id="video-2-wrap-up">
<h2>Video 2: Wrap-up<a class="headerlink" href="#video-2-wrap-up" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/Bonus_Autoencoders/student"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
<!-- Previous / next buttons -->
<div class="prev-next-area">
<a class="left-prev" href="Bonus_Tutorial2.html" id="prev-link" title="previous page">
<i class="fas fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Tutorial 2: Autoencoder extensions</p>
</div>
</a>
<a class="right-next" href="../Bonus_Outro.html" id="next-link" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Outro</p>
</div>
<i class="fas fa-angle-right"></i>
</a>
</div>
</div>
</div>
<footer class="footer">
<p>
    
      By Neuromatch<br/>
    
        © Copyright 2021.<br/>
</p>
</footer>
</main>
</div>
</div>
<script src="../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
</body>
</html>