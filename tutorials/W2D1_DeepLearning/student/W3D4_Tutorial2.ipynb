{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/master/tutorials/W3D4_DeepLearning1/student/W3D4_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Neuromatch Academy: Week 3, Day 4, Tutorial 2\n",
    "# Deep Learning: Encoding Neural Responses\n",
    "\n",
    "**Content creators**: Jorge A. Menendez, Carsen Stringer \n",
    "\n",
    "**Content reviewers**: Roozbeh Farhoodi, Ella Batty, Kshitij Dwivedi, Spiros Chavlis, Michael Waskom\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "---\n",
    "#Tutorial Objectives\n",
    "\n",
    "In this tutorial, we'll use deep learning to build an encoding model from stimuli to neural activity. Specifically, we'll be looking at the activity of ~20,000 neurons in mouse primary visual cortex responding to oriented gratings recorded in [this study](https://www.biorxiv.org/content/10.1101/679324v2.abstract). \n",
    "\n",
    "Because the stimuli are 1D and the neurons respond with smooth tuning curves, we will model the neural responses as a 1D convolutional operation on the stimulus. \n",
    "\n",
    "In this tutorial, we will \n",
    "* Understand the basics of convolution\n",
    "* Build and train a convolutional neural network to predict neural responses using PyTorch\n",
    "* Visualize and analyze its internal representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "---\n",
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@title Figure settings\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@title Data retrieval and loading\n",
    "import hashlib\n",
    "import requests\n",
    "\n",
    "fname = \"W3D4_stringer_oribinned6_split.npz\"\n",
    "url = \"https://osf.io/p3aeb/download\"\n",
    "expected_md5 = \"b3f7245c6221234a676b71a1f43c3bb5\"\n",
    "\n",
    "if not os.path.isfile(fname):\n",
    "  try:\n",
    "    r = requests.get(url)\n",
    "  except requests.ConnectionError:\n",
    "    print(\"!!! Failed to download data !!!\")\n",
    "  else:\n",
    "    if r.status_code != requests.codes.ok:\n",
    "      print(\"!!! Failed to download data !!!\")\n",
    "    elif hashlib.md5(r.content).hexdigest() != expected_md5:\n",
    "      print(\"!!! Data download appears corrupted !!!\")\n",
    "    else:\n",
    "      with open(fname, \"wb\") as fid:\n",
    "        fid.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "#@title Helper Functions\n",
    "# Some helper functions\n",
    "def load_data_split(data_name=fname):\n",
    "  \"\"\"Load mouse V1 data from Stringer et al. (2019)\n",
    "\n",
    "  Data from study reported in this preprint:\n",
    "  https://www.biorxiv.org/content/10.1101/679324v2.abstract\n",
    "\n",
    "  These data comprise time-averaged responses of ~20,000 neurons\n",
    "  to ~4,000 stimulus gratings of different orientations, recorded\n",
    "  through Calcium imaginge. The responses have been normalized by\n",
    "  spontaneous levels of activity and then z-scored over stimuli, so\n",
    "  expect negative numbers. The repsonses were split into train and\n",
    "  test and then each set were averaged in bins of 6 degrees.\n",
    "\n",
    "  This function returns the relevant data (neural responses and\n",
    "  stimulus orientations) in a torch.Tensor of data type torch.float32\n",
    "  in order to match the default data type for nn.Parameters in\n",
    "  Google Colab.\n",
    "\n",
    "  It will hold out some of the trials when averaging to allow us to have test\n",
    "  tuning curves.\n",
    "\n",
    "  Args:\n",
    "    data_name (str): filename to load\n",
    "\n",
    "  Returns:\n",
    "    resp_train (torch.Tensor): n_stimuli x n_neurons matrix of neural responses,\n",
    "        each row contains the responses of each neuron to a given stimulus.\n",
    "        As mentioned above, neural \"response\" is actually an average over\n",
    "        responses to stimuli with similar angles falling within specified bins.\n",
    "    resp_test (torch.Tensor): n_stimuli x n_neurons matrix of neural responses,\n",
    "        each row contains the responses of each neuron to a given stimulus.\n",
    "        As mentioned above, neural \"response\" is actually an average over\n",
    "        responses to stimuli with similar angles falling within specified bins\n",
    "    stimuli: (torch.Tensor): n_stimuli x 1 column vector with orientation\n",
    "        of each stimulus, in degrees. This is actually the mean orientation\n",
    "        of all stimuli in each bin.\n",
    "\n",
    "  \"\"\"\n",
    "  with np.load(data_name) as dobj:\n",
    "    data = dict(**dobj)\n",
    "  resp_train = data['resp_train']\n",
    "  resp_test = data['resp_test']\n",
    "  stimuli = data['stimuli']\n",
    "\n",
    "  # Return as torch.Tensor\n",
    "  resp_train_tensor = torch.tensor(resp_train, dtype=torch.float32)\n",
    "  resp_test_tensor = torch.tensor(resp_test, dtype=torch.float32)\n",
    "  stimuli_tensor = torch.tensor(stimuli, dtype=torch.float32)\n",
    "\n",
    "  return resp_train_tensor, resp_test_tensor, stimuli_tensor\n",
    "\n",
    "\n",
    "def plot_tuning(ax, stimuli, respi_train, respi_test, neuron_index, linewidth=2):\n",
    "  \"\"\"Plot the tuning curve of a neuron\"\"\"\n",
    "\n",
    "  ax.plot(stimuli, respi_train, 'y', linewidth=linewidth)  # plot its responses as a function of stimulus orientation\n",
    "  ax.plot(stimuli, respi_test, 'm', linewidth=linewidth)  # plot its responses as a function of stimulus orientation\n",
    "  ax.set_title('neuron %i' % neuron_index)\n",
    "  ax.set_xlabel('stimulus orientation ($^o$)')\n",
    "  ax.set_ylabel('neural response')\n",
    "  ax.set_xticks(np.linspace(0, 360, 5))\n",
    "  ax.set_ylim([-0.5, 2.4])\n",
    "\n",
    "\n",
    "# from bayes day!\n",
    "def my_gaussian(x_points, mu, sigma):\n",
    "  \"\"\"\n",
    "  Returns normalized Gaussian estimated at points `x_points`, with parameters: mean `mu` and std `sigma`\n",
    "\n",
    "  Args:\n",
    "    x_points (numpy array of floats): points at which the gaussian is evaluated\n",
    "    mu (scalar): mean of the Gaussian\n",
    "    sigma (scalar): std of the gaussian\n",
    "\n",
    "  Returns:\n",
    "    (numpy array of floats) : un-normalized Gaussian (i.e. without constant) evaluated at `x`\n",
    "  \"\"\"\n",
    "  px = np.exp(- 1/2/sigma**2 * (mu - x_points) ** 2)\n",
    "  px = px / px.sum()\n",
    "  return px\n",
    "\n",
    "\n",
    "def plot_conv(pad, stimulus, filter, conv_out):\n",
    "  \"\"\" plot 1D convolution \"\"\"\n",
    "  # plot stimulus\n",
    "  ax = fig.add_subplot(1,3,1)\n",
    "  ax.plot(np.arange(0, 360), stimulus, 'k')\n",
    "  ax.set_title('stimulus')\n",
    "  ax.set_xlabel('orientation ($^o$)')\n",
    "  ax.set_ylabel('stimulus')\n",
    "\n",
    "  # plot convolutional filter\n",
    "  ax = fig.add_subplot(1,3,2)\n",
    "  ax.plot(np.arange(-pad, pad), filter)\n",
    "  ax.set_xlabel('orientation ($^o$)')\n",
    "  ax.set_ylabel('magnitude')\n",
    "  ax.set_title('convolutional filter')\n",
    "\n",
    "  # plot convolutional output\n",
    "  ax = fig.add_subplot(1,3,3)\n",
    "  n_units = (~np.isnan(conv_out)).sum()\n",
    "  ax.scatter(np.arange(0,n_units),\n",
    "             conv_out[~np.isnan(conv_out)], s=30,\n",
    "             cmap='hsv', c=np.arange(0,n_units))\n",
    "  ax.set_xlabel('convolutional unit')\n",
    "  ax.set_ylabel('activation')\n",
    "  ax.set_title('activations of\\nconvolutional units')\n",
    "\n",
    "\n",
    "def plot_example_activations(act):\n",
    "  \"\"\" plot activations act and corresponding stimulus\n",
    "  Args:\n",
    "        act: activations of convolutional layer (n_bins x conv_channels x n_bins)\n",
    "  \"\"\"\n",
    "  ns = [10,25,40]\n",
    "  fig, axs = plt.subplots(1,3,figsize=(12,4))\n",
    "  for k, (n, ax) in enumerate(zip(ns, axs.flatten())):\n",
    "    ax.plot(n * np.ones(2), [act.min()*1.15, act.max()*1.15], 'k', linewidth=4)\n",
    "    ax.plot(act[n].T, '.', linewidth=2)\n",
    "    ax.set_xlabel('convolutional unit')\n",
    "    ax.set_ylabel('activation')\n",
    "    ax.set_title('stim id %d'%n)\n",
    "    leg = ['chan%d'%i for i in range(act.shape[1])]\n",
    "    leg.insert(0, 'stim')\n",
    "    n_units = act.shape[0]\n",
    "    for k,s in enumerate(leg):\n",
    "      if k==0:\n",
    "        ax.text(((n+15)%n_units)/n_units, .9-k*.1, s, transform=ax.transAxes, color='k', ha='center')\n",
    "      else:\n",
    "        ax.text(((n+15)%n_units)/n_units, .9-k*.1, s, transform=ax.transAxes, color='C%d'%(k-1), ha='center')\n",
    "\n",
    "\n",
    "def train(net, custom_loss, train_data, train_labels,\n",
    "          test_data=None, test_labels=None,\n",
    "          learning_rate=10, n_iter=500, L2_penalty=0., L1_penalty=0.):\n",
    "  \"\"\"Run gradient descent for network without batches\n",
    "\n",
    "  Args:\n",
    "    net (nn.Module): deep network whose parameters to optimize with SGD\n",
    "    custom_loss: loss function for network\n",
    "    train_data: training data (n_train x input features)\n",
    "    train_labels: training labels (n_train x output features)\n",
    "    test_data: test data (n_train x input features)\n",
    "    test_labels: test labels (n_train x output features)\n",
    "    learning_rate (float): learning rate for gradient descent\n",
    "    n_epochs (int): number of epochs to run gradient descent\n",
    "    L2_penalty (float): magnitude of L2 penalty\n",
    "    L1_penalty (float): magnitude of L1 penalty\n",
    "\n",
    "  Returns:\n",
    "    train_loss: training loss across iterations\n",
    "    test_loss: testing loss across iterations\n",
    "\n",
    "  \"\"\"\n",
    "  optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.5) # Initialize PyTorch SGD optimizer\n",
    "  train_loss = np.nan * np.zeros(n_iter)  # Placeholder for train loss\n",
    "  test_loss = np.nan * np.zeros(n_iter)  # Placeholder for test loss\n",
    "\n",
    "  # Loop over epochs\n",
    "  for i in range(n_iter):\n",
    "    y_pred = net(train_data) # Forward pass: compute predicted y by passing train_data to the model.\n",
    "\n",
    "    if L2_penalty>0 or L1_penalty>0:\n",
    "      weights = net.out_layer.weight\n",
    "      loss = custom_loss(y_pred, train_labels, weights, L2_penalty, L1_penalty)\n",
    "    else:\n",
    "      loss = custom_loss(y_pred, train_labels)\n",
    "\n",
    "    ### Update parameters\n",
    "    optimizer.zero_grad() # zero out gradients\n",
    "    loss.backward() # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "    optimizer.step() # step parameters in gradient direction\n",
    "    train_loss[i] = loss.item()  # .item() transforms the tensor to a scalar and does .detach() for us\n",
    "\n",
    "    # Track progress\n",
    "    if (i+1) % (n_iter // 10) == 0 or i==0:\n",
    "      if test_data is not None and test_labels is not None:\n",
    "        y_pred = net(test_data)\n",
    "        if L2_penalty>0 or L1_penalty>0:\n",
    "          loss = custom_loss(y_pred, test_labels, weights, L2_penalty, L1_penalty)\n",
    "        else:\n",
    "          loss = custom_loss(y_pred, test_labels)\n",
    "        test_loss[i] = loss.item()\n",
    "        print(f'iteration {i+1}/{n_iter} | train loss: {train_loss[i]:.4f} | test loss: {test_loss[i]:.4f}')\n",
    "      else:\n",
    "        print(f'iteration {i+1}/{n_iter} | train loss: {train_loss[i]:.4f}')\n",
    "\n",
    "  return train_loss, test_loss\n",
    "\n",
    "\n",
    "def plot_pred_weights(y_pred, y_train, y_test, weights):\n",
    "  \"\"\" plot example neural response prediction + weights \"\"\"\n",
    "  fig = plt.figure(figsize=(12,4))\n",
    "  ax =fig.add_subplot(1,3,1)\n",
    "  ax.plot(y_train, 'y', linewidth=1)\n",
    "  ax.plot(y_test, 'm', linewidth=1)\n",
    "  ax.plot(y_pred, 'g', linestyle='-', linewidth=3)\n",
    "  ax.set_xlabel('stimulus bin')\n",
    "  ax.set_ylabel('response')\n",
    "  ax.text(0.1, 1.0, 'train', color='y', transform=ax.transAxes)\n",
    "  ax.text(0.1, 0.9, 'test', color='m', transform=ax.transAxes)\n",
    "  ax.text(0.1, 0.8, 'pred', color='g', transform=ax.transAxes)\n",
    "\n",
    "  ax=fig.add_subplot(1,3,2)\n",
    "  ax.plot(y_train, y_train, 'k', lw=1)\n",
    "  ax.scatter(y_train, y_pred, s=8, color='y')\n",
    "  ax.scatter(y_test, y_pred, s=8, color='m')\n",
    "  ax.set_xlabel('neural response')\n",
    "  ax.set_ylabel('predicted response', color='g')\n",
    "  ax.text(0.1, 1.0, 'train', color='y', transform=ax.transAxes)\n",
    "  ax.text(0.1, 0.9, 'test', color='m', transform=ax.transAxes)\n",
    "  plt.axis('square')\n",
    "\n",
    "  ### plot weights of fully-connected layer for first 300 neurons\n",
    "  plt.subplot(1,3,3)\n",
    "  plt.imshow(weights, aspect='auto', cmap='bwr', vmin=-0.01,vmax=0.01)\n",
    "  plt.title('out_layer weights')\n",
    "  plt.ylabel('neurons')\n",
    "  plt.xlabel('convolutional units')\n",
    "  plt.colorbar()\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def plot_prediction(ax, y_pred, y_test):\n",
    "  \"\"\" plot prediction of neural response + test neural response \"\"\"\n",
    "  ax.plot(y_test,color='m')\n",
    "  ax.plot(y_pred, 'g', linewidth=3)\n",
    "  ax.set_xlabel('stimulus bin')\n",
    "  ax.set_ylabel('response')\n",
    "\n",
    "\n",
    "def plot_training_curves(train_loss, test_loss):\n",
    "  f, ax = plt.subplots()\n",
    "  ax.plot(train_loss, 'y', label=\"Train loss\")\n",
    "  ax.plot(test_loss, '.', markersize=10, color='m', label=\"Test loss\")\n",
    "  ax.set(xlabel=\"Gradient descent iteration\", ylabel=\"Mean squared error\")\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "---\n",
    "# Section 1: Neural Tuning Curves\n",
    "\n",
    "In the next cell, we plot the turning curves of a random subset of neurons. We have binned the stimuli orientations more than in Tutorial 1. \n",
    "\n",
    "Rerun the cell to look at different example neurons and observe the diversity of tuning curves in the population. How can we fit these neural responses with an encoding model?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "colab_type": "code",
    "outputId": "477a3fec-5088-4b8d-b235-c07a962144df"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "#@markdown Execute this cell to load data and plot neural tuning curves\n",
    "\n",
    "### Load data and bin at 8 degrees\n",
    "# responses are split into test and train\n",
    "resp_train, resp_test, stimuli = load_data_split()\n",
    "n_stimuli, n_neurons = resp_train.shape\n",
    "print('resp_train contains averaged responses of %i neurons to %i binned stimuli' % (n_neurons, n_stimuli))\n",
    "#print(resp_train.shape)\n",
    "\n",
    "# also make stimuli into array of 0's and 1's\n",
    "n_bins = len(stimuli)\n",
    "stim_binary = torch.eye(n_bins, dtype=torch.float32)\n",
    "\n",
    "# Visualize tuning curves\n",
    "fig, axs = plt.subplots(3, 5, figsize=(15,7))\n",
    "for k, ax in enumerate(axs.flatten()):\n",
    "  neuron_index = np.random.choice(n_neurons)  # pick random neuron\n",
    "  plot_tuning(ax, stimuli, resp_train[:, neuron_index], resp_test[:, neuron_index], neuron_index, linewidth=2)\n",
    "  if k==0:\n",
    "    ax.text(1.0, 0.9, 'train', color='y', transform=ax.transAxes)\n",
    "    ax.text(1.0, 0.65, 'test', color='m', transform=ax.transAxes)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "---\n",
    "# Section 2: Introduction to convolutions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "outputId": "f445fbd3-c589-4f99-a8f8-53660f00a5a9"
   },
   "outputs": [],
   "source": [
    "#@title Video 1: Intro to convolutions\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"vPNu8CNg9i4\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Section 2.1: 1d convolution in numpy\n",
    "\n",
    "We provide an example function below, described in the video, which performs a 1D convolution of a stimulus input $s$ with **filter** $f$ of size $K$ (these filters are also called *kernels*). In particular, it computes:\n",
    "\n",
    "$$a_x = \\sum^{K/2}_{i=-K/2} f_i \\, s_{x-i}$$\n",
    "\n",
    "where $a_x$ is the convolutional output at position $x$.\n",
    "\n",
    "There is no exercise in this section but make sure you understand what is happening in the function below (i.e. what a convolution is). It can be helpful to write or draw this out on paper to clarify! You could even make your own short stimulus and filter and calculate what you think the convolutional output should be by hand, and then compare to the function output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def convolve1d(stimulus, f, pad, stride):\n",
    "  \"\"\" Pads stimulus and performs 1d convolution\n",
    "\n",
    "  Args:\n",
    "    stimulus (ndarray): the 1D input for the convolution\n",
    "    f (ndarray): the 1D filter for the convolution\n",
    "    pad (scalar): the amount of zero padding for the stimulus\n",
    "    stride (scalar): how far the filter moves every step\n",
    "\n",
    "  Returns:\n",
    "    (ndarray): convolutional output, same size as stimulus\n",
    "  \"\"\"\n",
    "\n",
    "  # Pad the stimulus\n",
    "  zero_pads = np.zeros(pad)\n",
    "  padded_stimulus = np.concatenate((zero_pads, stimulus, zero_pads))\n",
    "\n",
    "  # Initialize convolutional output\n",
    "  a = np.nan * np.zeros(360)\n",
    "\n",
    "  # Compute the convolution\n",
    "  for x in np.arange(0+pad, 360+pad, stride, int): # loop over positions x\n",
    "\n",
    "    # Compute element-wise multiplication between filter and stimulus\n",
    "    a[x - pad] = (f * padded_stimulus[x-pad : x+pad]).sum()\n",
    "\n",
    "  return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "outputId": "379c97e1-00e4-4f46-d62d-030b0fce90a5"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "#@markdown Execute this cell to call convolve1d with a Gaussian filter and plot results\n",
    "\n",
    "# Convolutional parameters\n",
    "K = 49 # size of convolutional filter\n",
    "stride = 1 # how often to compute the convolution along the stim axis\n",
    "pad = K // 2 # we will need to pad stimulus with zeros to perform convolution\n",
    "\n",
    "# Create stimulus\n",
    "ori = 135\n",
    "stimulus = np.zeros(360)\n",
    "stimulus[ori] = 1.0\n",
    "\n",
    "# Create Gaussian filter\n",
    "# we will use the code from W2D1 (bayes day) to create this!\n",
    "# mean of gaussian mu=0\n",
    "i = np.arange(-pad, pad)\n",
    "f = my_gaussian(i, 0.0, sigma=10)\n",
    "\n",
    "# Call function\n",
    "a = convolve1d(stimulus, f, pad, stride)\n",
    "\n",
    "# Plot results\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "plot_conv(pad, stimulus, f, a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Section 2.2: Convolutional layer\n",
    "\n",
    "You have just learned how to compute what is called a single convolutional **channel**: a single filter applied to the input resulting in several units, where the number of units depends on the *stride* you set.\n",
    "\n",
    "(Note if filter size *K* is odd and you set the *pad=K//2* and *stride=1* (as is the default above), you get a **channel** of units that is the same size as the input.)\n",
    "\n",
    "*Contemplation:* How does a neuron potentially combine those activation units and create the tuning curves they have? Will we need more than one convolutional filter to recreate all the responses we see?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "text"
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D4_DeepLearning1/solutions/W3D4_Tutorial2_Solution_185efdad.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Let's add more convolutional channels and implement this operation efficiently using pytorch. A *layer* of convolutional channels can be implemented with one line of code using the PyTorch class `nn.Conv1d()`, which requires the following arguments for initialization:\n",
    "  * $C^{in}$: the number of input channels\n",
    "  * $C^{out}$: the number of output channels (number of different convolutional filters)\n",
    "  * $K$: the size of the $C^{out}$ different convolutional filters\n",
    "  \n",
    "When you run the network, you can input a stimulus of arbitrary length ($H^{in}$), but it needs to be shaped as a 2D input $C^{in} \\times H^{in}$. In our case, $C^{in}=1$ because there is only one orientation input and $H^{in}$ is the number of stimulus bins $B$.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/NeuromatchAcademy/course-content/blob/master/tutorials/static/convolutional_layer.PNG?raw=true\" width=\"600\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class ConvolutionalLayer(nn.Module):\n",
    "  \"\"\"Deep network with one convolutional layer\n",
    "     Attributes: conv (nn.Conv1d): convolutional layer\n",
    "  \"\"\"\n",
    "  def __init__(self, c_in=1, c_out=8, K=9):\n",
    "    \"\"\"Initialize layer\n",
    "\n",
    "    Args:\n",
    "        c_in: number of input stimulus channels\n",
    "        c_out: number of output convolutional channels\n",
    "        K: size of each convolutional filter\n",
    "\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.conv = nn.Conv1d(c_in, c_out, kernel_size=K,\n",
    "                          padding=K//2, stride=1)\n",
    "\n",
    "  def forward(self, s):\n",
    "    \"\"\"Run stimulus through convolutional layer\n",
    "\n",
    "    Args:\n",
    "        s (torch.Tensor): n_stimuli x h tensor with stimuli\n",
    "\n",
    "    Returns:\n",
    "        (torch.Tensor): n_stimuli x c_out x h tensor with convolutional layer unit activations.\n",
    "\n",
    "    \"\"\"\n",
    "    s = s.unsqueeze(1)  # n_stimuli x 1 x h, add a singleton dimension for the single channel\n",
    "    a = self.conv(s)  # output of convolutional layer\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Exercise 1: 1D convolution in pytorch \n",
    "\n",
    "We will now run the convolutional layer on our stimulus. In particular, we will use the binary stimuli (`stim_binary`), which is a 60 x 60 tensor where each row contains the binary stimuli for one orientation (all zeros except for a one at that orientation). This tensor is size 60 instead of 360 because we have binned the orientations. Each row of this matrix is a different example orientation that we want to convolve - see cell below to visualize three rows of this tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "outputId": "a4adbbcd-12c5-4793-d9ed-deab66557feb"
   },
   "outputs": [],
   "source": [
    "# @markdown Execute this cell to visualize stim_binary\n",
    "row_inds = [10, 25, 40]\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "\n",
    "for j, row_ind in enumerate(row_inds):\n",
    "  ax = fig.add_subplot(1, 3, j+1)\n",
    "  ax.plot(np.arange(0, 60), stim_binary[row_ind,:], 'k')\n",
    "  ax.set_title('stim_binary row '+str(row_ind))\n",
    "  ax.set_xlabel('orientation bin')\n",
    "  ax.set_ylabel('stimulus')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "`nn.Conv1d` takes in a tensor of size $(N, C^{in}, H^{in}$) where $N$ is the number of examples, $C^{in}$ is the number of input channels, and $H^{in}$ is the number of stimulus bins $B$. Since our stimulus has only one input channel,  the `ConvolutionalLayer` class adds the $C^{in}$ dimension for us: we need to input an $(N, H^{in})$ stimulus, which `stim_binary` is!  \n",
    "\n",
    "\n",
    "We will plot the outputs of the convolution. `convout` is a tensor of size $(N, C^{out}, H^{in})$ where $N$ is the number of examples and $C^{out}$ are the number of convolutional channels. In the plot, the activations for a single channel are shown in one color. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Convolution layer parameters\n",
    "K = 9 # filter size, now that we've binned let's make this smaller than for the numpy conv\n",
    "conv_channels = 8 # how many convolutional channels to have in our layer\n",
    "\n",
    "convout = np.zeros(0) # assign convolutional activations to convout\n",
    "\n",
    "################################################################################\n",
    "## TODO for students: compute convolution activations from stim_binary using pytorch\n",
    "# Complete and uncomment\n",
    "################################################################################\n",
    "\n",
    "# Initialize conv layer\n",
    "# convLayer = ConvolutionalLayer(...)\n",
    "\n",
    "# Call conv layer on stimulus\n",
    "# convout = convLayer(...)\n",
    "# convout = convout.detach() # detach gradients\n",
    "# print(convout.shape) # can you identify what each of these dimensions are?\n",
    "\n",
    "# Plot results\n",
    "# plot_example_activations(convout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "text",
    "outputId": "158c9b20-a905-4e1b-eb11-16b898d4454c"
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D4_DeepLearning1/solutions/W3D4_Tutorial2_Solution_44e9267a.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=851 height=270 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D4_DeepLearning1/static/W3D4_Tutorial2_Solution_44e9267a_1.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Think!\n",
    "  - Why are the convolutional activations for a given channel the same for many units?\n",
    "  - What is the width of the non-constant activations (i.e. how many units in a given channel would differ from the constant)?\n",
    "  - How many weights does this convLayer have? \n",
    "  - How many would it have if it were a fully connected layer? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "text"
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D4_DeepLearning1/solutions/W3D4_Tutorial2_Solution_32703d8b.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "---\n",
    "# Section 3: Encoding model using convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "outputId": "f1b29908-9e8d-4654-814c-c13fa77d6f64"
   },
   "outputs": [],
   "source": [
    "#@title Video 2: Encoding model using convolutions\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"Me8X3Kro0EE\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Section 3.1: Convolutional layer & fully connected layer\n",
    "\n",
    "We will now build an encoding model by hooking this convolutional layer up to a fully connected layer, like the one that we used in Tutorial 1 (`nn.Linear`). We will use this model to predict neural responses.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/NeuromatchAcademy/course-content/blob/master/tutorials/static/conv_fc.PNG?raw=true\" width=\"800\" />\n",
    "</p>\n",
    "\n",
    "This linear layer will have weights $W^{out}$ and we will get an output vector $\\mathbf{y}$ of predicted neural responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Exercise 2: Implement encoding model \n",
    "\n",
    "In this exercise, you will create the encoding model described above. In particular, you will:\n",
    "\n",
    "* Add a fully connected layer to `__init__` method of network.\n",
    "* Add a fully connected layer to `forward` method of network.\n",
    "\n",
    "We will then train the network using the helper function `train`. Full training will take a few minutes: if you want to train for just a few steps to speed up the code while iterating on your code, you can decrease the `n_iter` input from 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class ConvFC(nn.Module):\n",
    "  \"\"\"Deep network with one convolutional layer + one fully connected layer\n",
    "\n",
    "  Attributes:\n",
    "    conv (nn.Conv1d): convolutional layer\n",
    "    dims (tuple): shape of convolutional layer output\n",
    "    out_layer (nn.Linear): linear layer\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, n_neurons, c_in=1, c_out=8, K=9, b=60):\n",
    "    \"\"\" initialize layer\n",
    "    Args:\n",
    "        c_in: number of input stimulus channels\n",
    "        c_out: number of convolutional channels\n",
    "        K: size of each convolutional filter\n",
    "        h: number of stimulus bins, n_bins\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.conv = nn.Conv1d(c_in, c_out, kernel_size=K, padding=K//2)\n",
    "    self.dims = (c_out, b)  # dimensions of conv layer output\n",
    "    M = np.prod(self.dims) # number of hidden units\n",
    "\n",
    "    ################################################################################\n",
    "    ## TO DO for students: add fully connected layer to network (self.out_layer)\n",
    "    # Fill out function and remove\n",
    "    raise NotImplementedError(\"Student exercise: add fully connected layer to initialize network\")\n",
    "    ################################################################################\n",
    "    self.out_layer = nn.Linear(M, ...)\n",
    "\n",
    "    nn.init.normal_(self.out_layer.weight, std=0.01) # initialize weights to be small\n",
    "\n",
    "  def forward(self, s):\n",
    "    \"\"\" Predict neural responses to stimuli s\n",
    "\n",
    "    Args:\n",
    "        s (torch.Tensor): p x L tensor with stimuli\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: p x N tensor with convolutional layer unit activations.\n",
    "\n",
    "    \"\"\"\n",
    "    s = s.unsqueeze(1)  # p x 1 x L, add a singleton dimension for the single channel\n",
    "    a = self.conv(s)  # output of convolutional layer\n",
    "    a = a.view(-1, np.prod(self.dims))  # flatten each convolutional layer output into a vector\n",
    "\n",
    "    ################################################################################\n",
    "    ## TO DO for students: add fully connected layer to forward pass of network (self.out_layer)\n",
    "    # Fill out function and remove\n",
    "    raise NotImplementedError(\"Student exercise: add fully connected layer to network\")\n",
    "    ################################################################################\n",
    "    y = ...\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "# Choose loss function\n",
    "MSE_loss = nn.MSELoss()\n",
    "\n",
    "## Initialize network\n",
    "# net = ConvFC(n_neurons)\n",
    "\n",
    "## Run GD on training set data\n",
    "## ** this time we are also providing the test data to estimate the test loss\n",
    "# train_loss, test_loss = train(net, MSE_loss, stim_binary, resp_train,\n",
    "#                               test_data=stim_binary, test_labels=resp_test,\n",
    "#                               n_iter=500, learning_rate=20)\n",
    "\n",
    "## Plot the training loss over iterations of GD\n",
    "# plot_training_curves(train_loss, test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "colab_type": "text",
    "outputId": "f2e0daf0-ae57-45b9-c82a-6ce98087a5e4"
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D4_DeepLearning1/solutions/W3D4_Tutorial2_Solution_fda4c007.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=558 height=414 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D4_DeepLearning1/static/W3D4_Tutorial2_Solution_fda4c007_11.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We trained this network to predict the neural responses -- see the yellow curve for the training loss. We also computed the test loss every 50 iterations. The training loss goes down throughout training but the testing loss doesn’t -- why is this? *We are overfitting to the NOISE in the training set.*\n",
    "\n",
    "Let’s look at a prediction for a single neuron (below). The yellow curve is the training data, the pink curve is the testing data and the prediction is in green. You can barely see the yellow curve because the prediction has fit so well to the training data. However, some of what it has fit is noise. \n",
    "\n",
    "If we look at the weight matrix, we see that the weights are all positive or negative. Did we expect this to happen? Or did we think that this tuning curve is the sum of only a few filters and positions?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "text"
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D4_DeepLearning1/solutions/W3D4_Tutorial2_Solution_5d5c2c4f.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "colab_type": "code",
    "outputId": "42817544-0db2-4aee-a81a-29938819d3c5"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "#@markdown Execute this cell to examine prediction for example neuron and see weights\n",
    "\n",
    "# Input stimuli to network\n",
    "y_pred = net(stim_binary)\n",
    "print('output shape: ', y_pred.shape) # what are the two dimensions of this network output?\n",
    "\n",
    "# Plot example neural response prediction and some fully-connected layer weights\n",
    "\n",
    "# Look at the weights of the out_layer of the network\n",
    "weights = net.out_layer.weight.detach()\n",
    "print('output weights shape: ', weights.shape) # what are these two dimensions of the fully connected layer weights?\n",
    "\n",
    "# Plot prediction + neuron + weights\n",
    "neuron_index = np.random.choice(n_neurons)\n",
    "plot_pred_weights(y_pred[:,neuron_index].detach(), resp_train[:,neuron_index],\n",
    "                  resp_test[:,neuron_index], weights[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "*Comprehension check*: what does each dimension of the output and output weights correspond to?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "text"
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D4_DeepLearning1/solutions/W3D4_Tutorial2_Solution_fa083d69.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We can reduce overfitting using L2 regularization as we learned on W1D4. \n",
    "\n",
    "Additionally there is another type of regularization you might want... If we think of a neuron as a sum of a few convolutional filters, we might expect the weight matrix of the fully-connected layer to be sparse. Therefore, we can also apply an L1 regularization penalty to enforce sparsity. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "---\n",
    "# (Bonus) Section 4: Regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "outputId": "a7a229ff-454c-4054-c73b-ff34035fea71"
   },
   "outputs": [],
   "source": [
    "#@title Video 3: Regularization\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"Qnn5OPHKo5w\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\n",
    "As discussed in the lecture, it is often important to incorporate regularization terms into the loss function to avoid overfitting. In particular, in this case, we want to use these terms to enforce sparsity in the output layer. \n",
    "\n",
    "Here we'll consider the classic L2 regularization penalty $\\mathcal{R}_{L2}$, which is the sum of squares of each weight in the network $\\sum_{ij} {\\mathbf{W}^{out}_{ij}}^2$ times a constant that we call `L2_penalty`.\n",
    "\n",
    "We will also add an L1 regularization penalty $\\mathcal{R}_{L1}$ to enforce sparsity of the weights, which is the sum of the absolute values of the weights $\\sum_{ij} |{\\mathbf{W}^{out}_{ij}}|$ times a constant that we call `L1_penalty`.\n",
    "\n",
    "We will add both of these to the loss function:\n",
    "\\begin{equation}\n",
    "    L = (y - \\tilde{y})^2 + \\mathcal{R}_{L2} + \\mathcal{R}_{L1}\n",
    "\\end{equation}\n",
    "\n",
    "The parameters `L2_penalty` and `L1_penalty` are inputs to the train function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### (Bonus) Exercise 3: Add regularization to training \n",
    "\n",
    "We will create a new loss function that adds L1 and L2 regularization. \n",
    "In particular, you will:\n",
    "* add L2 loss penalty to the weights \n",
    "* add L1 loss penalty to the weights\n",
    "\n",
    "\n",
    "We will then train the network using this loss function. Full training will take a few minutes: if you want to train for just a few steps to speed up the code while iterating on your code, you can decrease the n_iter input from 500. \n",
    "\n",
    "Hint: since we are using `torch` instead of `np`, we will use `torch.abs` instead of `np.absolute`. You can use `torch.sum` or `.sum()` to sum over a tensor.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def regularized_MSE_loss(output, target, weights=None, L2_penalty=0, L1_penalty=0):\n",
    "  \"\"\"loss function for MSE\n",
    "\n",
    "  Args:\n",
    "    output (torch.Tensor): output of network\n",
    "    target (torch.Tensor): neural response network is trying to predict\n",
    "    weights (torch.Tensor): fully-connected layer weights (net.out_layer.weight)\n",
    "    L2_penalty : scaling factor of sum of squared weights\n",
    "    L1_penalty : scalaing factor for sum of absolute weights\n",
    "\n",
    "  Returns:\n",
    "    (torch.Tensor) mean-squared error with L1 and L2 penalties added\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  loss_fn = nn.MSELoss()\n",
    "  loss = loss_fn(output, target)\n",
    "\n",
    "  ##############################################################################\n",
    "  # TO DO: add L1 and L2 regularization to the loss function and remove the error\n",
    "  raise NotImplementedError(\"Student exercise: complete regularized_MSE_loss\")\n",
    "  ##############################################################################\n",
    "\n",
    "  if weights is not None:\n",
    "    L2 = L2_penalty * ...\n",
    "    L1 = L1_penalty * ...\n",
    "    loss += L1 + L2\n",
    "\n",
    "  return loss\n",
    "\n",
    "# Initialize network\n",
    "net = ConvFC(n_neurons)\n",
    "\n",
    "# Uncomment below to test your function\n",
    "\n",
    "# Train network\n",
    "# train_loss, test_loss = train(net, regularized_MSE_loss, stim_binary, resp_train,\n",
    "#                               test_data=stim_binary, test_labels=resp_test,\n",
    "#                               learning_rate=10, n_iter=500,\n",
    "#                               L2_penalty=1e-4, L1_penalty=1e-6)\n",
    "\n",
    "# Plot the training loss over iterations of GD\n",
    "# plot_training_curves(train_loss, test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "colab_type": "text",
    "outputId": "d525e1c6-2d68-4315-9566-1daff87c96ca"
   },
   "source": [
    "[*Click for solution*](https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W3D4_DeepLearning1/solutions/W3D4_Tutorial2_Solution_c4027856.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=558 height=413 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W3D4_DeepLearning1/static/W3D4_Tutorial2_Solution_c4027856_11.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "If we now train the network with these regularization penalties we find that the train and test loss are similar throughout training: both continue decreasing.\n",
    "\n",
    "We will now look at the predictions after using the regularized loss function. We can see below that the prediction is much smoother than before! This is because the weight matrix is in fact sparser (zero is represented by white in this color map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "outputId": "15e6aedc-ade3-45a6-d844-88e3c05de82d"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "#@markdown Execute this cell to examine prediction for example neuron and see weights\n",
    "\n",
    "# Plot prediction + neuron + weights\n",
    "weights = net.out_layer.weight.detach()\n",
    "y_pred = net(stim_binary)\n",
    "neuron_index = np.random.choice(n_neurons)\n",
    "plot_pred_weights(y_pred[:,neuron_index].detach(), resp_train[:,neuron_index],\n",
    "                  resp_test[:,neuron_index], weights[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\n",
    "Now let's look at what the predictions look like for many neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "colab_type": "code",
    "outputId": "44be92e2-ea32-4bc2-e6ea-caf2e2c4fa9e"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "#@markdown Execute this cell to examine predictions for random subsets of neurons\n",
    "\n",
    "# Visualize tuning curves & plot neural predictions\n",
    "fig, axs = plt.subplots(2, 5, figsize=(15,6))\n",
    "for k, ax in enumerate(axs.flatten()):\n",
    "  ineur = np.random.choice(n_neurons)\n",
    "  plot_prediction(ax, y_pred[:,ineur].detach(), resp_test[:,ineur])\n",
    "  if k==0:\n",
    "    ax.text(.1, 1., 'test', color='m', transform=ax.transAxes)\n",
    "    ax.text(.1, .9, 'prediction', color='g', transform=ax.transAxes)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "In this notebook, we built and evaluated a neural network based encoding model to predict neural responses from stimuli. To do so we :\n",
    "* implemented a basic convolution filter\n",
    "* implemented and trained a convolutional neural network with multiple filters to predict neural responses using PyTorch\n",
    "* learned about and implemented L2/L1 regularization to avoid overfitting\n",
    "\n",
    "What can this tell us about the representation of oriented gratings in mouse visual cortex? Maybe we can think of interpreting each of the convolutional channels as a computation performed by a single group of neurons in thalamus, and each visual cortical neuron combines various groups of thalamic neurons. But we'd have to test hypotheses like these by, for instance, recording thalamic neurons.\n",
    "\n",
    "\n",
    "Tutorial 3 is bonus, although we recommend watching the videos if possible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "---\n",
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "outputId": "b2d2b3b3-b4d4-4828-bd06-d37918636e66"
   },
   "outputs": [],
   "source": [
    "#@title Video 4: Some practical advice for fitting neural networks\n",
    "from IPython.display import YouTubeVideo\n",
    "video = YouTubeVideo(id=\"eU74NFroIHk\", width=854, height=480, fs=1)\n",
    "print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Why CNN's?\n",
    "\n",
    "CNN models are particularly [well-suited](https://www.nature.com/articles/nn.4244) to modeling the visual system for a number of reasons:\n",
    "\n",
    "1. **Distributed computation**: like any other neural network, CNN's use distributed representations to compute -- much like the brain seems to do. Such models, therefore, provide us with a vocabulary with which to talk and think about such distributed representations. Because we know the exact function the model is built to perform (e.g. orientation discrimination), we can analyze its internal representations with respect to this function and begin to interpret why the representations look the way they do. Most importantly, we can then use these insights to analyze the structure of neural representations observed in recorded population activity. We can qualitatively and quantitatively compare the representations we see in the model and in a given population of real neurons to hopefully tease out the computations it performs.\n",
    "\n",
    "2. **Hierarchical architecture**: like in any other deep learning architecture, each layer of a deep CNN comprises a non-linear transformation of the previous layer. Thus, there is a natural hierarchy whereby layers closer to the network output represent increasingly more abstract information about the input image. For example, in a network trained to do object recognition, the early layers might represent information about edges in the image, whereas later layers closer to the output might represent various object categories. This resembles the [hierarchical structure of the visual system](https://pubmed.ncbi.nlm.nih.gov/1822724/), where [lower-level areas](https://www.jneurosci.org/content/25/46/10577.short) (e.g. retina, V1) represent visual features of the sensory input and [higher-level areas](https://www.sciencedirect.com/science/article/pii/S089662731200092X) (e.g. V4, IT) represent properties of objects in the visual scene. We can then naturally use a single CNN to model multiple visual areas, using early CNN layers to model lower-level visual areas and late CNN layers to model higher-level visual areas.\n",
    "  \n",
    "  Relative to fully connected networks, CNN's, in fact, have further hierarchical structure built-in through the max pooling layers. Recall that each output of a convolution + pooling block is the result of processing a local patch of the inputs to that block. If we stack such blocks in a sequence, then the outputs of each block will be sensitive to increasingly larger regions of the initial raw input to the network: an output from the first block is sensitive to a single patch of these inputs, corresponding to its \"receptive field\"; an output from the second block is sensitive to a patch of outputs from the first block, which together are sensitive to a larger patch of raw inputs comprising the union of their receptive fields. Receptive fields thus get larger for deeper layers (see [here](http://colah.github.io/posts/2014-07-Conv-Nets-Modular/) for a nice visual depiction of this). This resembles primate visual systems, where neurons in higher-level visual areas respond to stimuli in wider regions of the visual field than neurons in lower-level visual areas.\n",
    "\n",
    "3. **Convolutional layers**: through the weight sharing constraint, the outputs of each channel of a convolutional layer process different parts of the input image in exactly the same way. This architectural constraint effectively builds into the network the assumption that objects in the world typically look the same regardless of where they are in space. This is useful for modeling the visual system for two (largely separate) reasons:\n",
    "  * Firstly, this assumption is generally valid in mammalian visual systems, since mammals tend to view the same object from many perspectives. Two neurons at a similar hierarchy in the visual system with different receptive fields could thus end up receiving statistically similar synaptic inputs, so that the synaptic weights developed over time may end up being similar as well.\n",
    "  * Secondly, this architecture significantly improves object recognition ability. Object recognition was essentially an unsolved problem in machine learning until the [advent](https://en.wikipedia.org/wiki/AlexNet) of techniques for effectively training *deep* convolutional neural networks. Fully connected networks on their own can't achieve object recognition abilities anywhere close to human levels, making them bad models of human object recognition. Indeed, it is generally the case that [the better a neural network model is at object recognition, the closer the match between its representations and those observed in the brain](https://www.pnas.org/content/111/23/8619.short). That said, it is worth noting that our much simpler orientation discrimination task (in Tutorial 3) can be solved by relatively simple networks."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "W3D4_Tutorial2",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
