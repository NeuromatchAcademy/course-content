
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Tutorial 1: Basics of Differential and Integral Calculus &#8212; Neuromatch Computational Neuroscience</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Tutorial 2: Differential Equations" href="W0D4_Tutorial2.html" />
    <link rel="prev" title="Calculus" href="../chapter_title.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      <img src="../../../_static/nma-logo-square-4xp.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Neuromatch Computational Neuroscience</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../intro.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Pre-reqs Refresher
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D1_PythonWorkshop1/chapter_title.html">
   Python Workshop 1 (W0D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D1_PythonWorkshop1/student/W0D1_Tutorial1.html">
     Tutorial: LIF Neuron - Part I
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D2_PythonWorkshop2/chapter_title.html">
   Python Workshop 2 (W0D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D2_PythonWorkshop2/student/W0D2_Tutorial1.html">
     Tutorial 1: LIF Neuron Part II
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D3_LinearAlgebra/chapter_title.html">
   Linear Algebra (W0D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial1.html">
     Tutorial 1: Vectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial2.html">
     Tutorial 2: Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial3.html">
     Bonus Tutorial: Discrete Dynamical Systems
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../chapter_title.html">
   Calculus (W0D4)
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Tutorial 1: Basics of Differential and Integral Calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="W0D4_Tutorial2.html">
     Tutorial 2: Differential Equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="W0D4_Tutorial3.html">
     Tutorial 3: Numerical Methods
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D5_Statistics/chapter_title.html">
   Statistics (W0D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial1.html">
     Neuromatch Academy: Precourse Week, Day 5, Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial2.html">
     Tutorial 2: Statistical Inference
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Intro to Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D1_ModelTypes/chapter_title.html">
   Model Types (W1D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/W1D1_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial1.html">
     Tutorial 1: “What” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial2.html">
     Tutorial 2: “How” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial3.html">
     Tutorial 3: “Why” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/W1D1_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D2_ModelingPractice/chapter_title.html">
   Modeling Practice (W1D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_ModelingPractice/W1D2_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_ModelingPractice/student/W1D2_Tutorial1.html">
     Tutorial: Framing the Question
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_ModelingPractice/W1D2_Outro.html">
     Outro
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D3_ModelFitting/chapter_title.html">
   Model Fitting (W1D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/W1D3_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial1.html">
     Tutorial 1: Linear regression with MSE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial2.html">
     Tutorial 2: Linear regression with MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial3.html">
     Tutorial 3: Confidence intervals and bootstrapping
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial4.html">
     Tutorial 4: Multiple linear regression and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial5.html">
     Tutorial 5: Model Selection: Bias-variance trade-off
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial6.html">
     Tutorial 6: Model Selection: Cross-validation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/W1D3_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/chapter_title.html">
   Generalized Linear Models (W1D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/W1D4_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/student/W1D4_Tutorial1.html">
     Tutorial 1: GLMs for Encoding
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/student/W1D4_Tutorial2.html">
     Tutorial 2: Classifiers and regularizers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/W1D4_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D5_DimensionalityReduction/chapter_title.html">
   Dimensionality Reduction (W1D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/W1D5_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial1.html">
     Tutorial 1: Geometric view of data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial2.html">
     Tutorial 2: Principal Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial3.html">
     Tutorial 3: Dimensionality Reduction &amp; Reconstruction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial4.html">
     Tutorial 4:  Nonlinear Dimensionality Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/W1D5_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D1_DeepLearning/chapter_title.html">
   Deep Learning (W2D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/W2D1_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial3.html">
     Tutorial 2: Building and Evaluating Normative Encoding Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/W2D1_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D2_LinearSystems/chapter_title.html">
   Linear Systems (W2D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/W2D2_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial1.html">
     Tutorial 1: Linear dynamical systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial2.html">
     Tutorial 2: Markov Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial3.html">
     Tutorial 3: Combining determinism and stochasticity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial4.html">
     Tutorial 4: Autoregressive models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/W2D2_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/chapter_title.html">
   Biological Neuron Models (W2D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/W2D3_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial1.html">
     Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial2.html">
     Tutorial 2: Effects of Input Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial3.html">
     Tutorial 3: Synaptic transmission - Models of static and dynamic synapses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial4.html">
     Tutorial 4: Spike-timing dependent plasticity (STDP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/W2D3_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D4_DynamicNetworks/chapter_title.html">
   Dynamic Networks (W2D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/W2D4_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial1.html">
     Tutorial 1: Neural Rate Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial2.html">
     Tutorial 2: Wilson-Cowan Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/W2D4_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Stochastic Processes
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D1_BayesianDecisions/chapter_title.html">
   Bayesian Decisions (W3D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/W3D1_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial1.html">
     Tutorial 1: Bayes with a binary hidden state
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial2.html">
     Tutorial 2: Bayesian inference and decisions with continuous hidden state
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial3.html">
     Bonus Tutorial:Fitting to data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/W3D1_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D2_HiddenDynamics/chapter_title.html">
   Hidden Dynamics (W3D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/W3D2_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial1.html">
     Tutorial 1: Sequential Probability Ratio Test
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial2.html">
     Tutorial 2: Hidden Markov Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial3.html">
     Tutorial 3: 1D Kalman Filter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial4.html">
     Tutorial 4: 2D Kalman Filter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/W3D2_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D3_OptimalControl/chapter_title.html">
   Optimal Control (W3D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/W3D3_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial1.html">
     Tutorial 1: Optimal Control for Discrete States
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial2.html">
     Tutorial 2: Optimal Control for Continuous State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/W3D3_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D4_ReinforcementLearning/chapter_title.html">
   Reinforcement Learning (W3D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/W3D4_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial4.html">
     Tutorial 4: From Reinforcement Learning to Planning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/W3D4_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D5_NetworkCausality/chapter_title.html">
   Network Causality (W3D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/W3D5_Intro.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial1.html">
     Tutorial 1: Interventions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial2.html">
     Tutorial 2: Correlations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial3.html">
     Tutorial 3: Simultaneous fitting/regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial4.html">
     Tutorial 4: Instrumental Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/W3D5_Outro.html">
     Outro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/tutorials/W0D4_Calculus/student/W0D4_Tutorial1.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/NeuromatchAcademy/course_content/blob/master/book/tutorials/W0D4_Calculus/student/W0D4_Tutorial1.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Tutorial 1: Basics of Differential and Integral Calculus
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-1-what-is-differentiation-and-integration">
   Section 1: What is differentiation and integration?
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interactive-demo-1-geometrical-understanding">
     Interactive Demo 1: Geometrical understanding
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-2-analytical-numerical-differentiation">
   Section 2: Analytical &amp; Numerical Differentiation
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-2-1-analytical-differentiation">
     Section 2.1: Analytical Differentiation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#section-2-1-1-product-rule">
       Section 2.1.1: Product Rule
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#coding-exercise-2-1-1-derivative-of-the-postsynaptic-potential-alpha-function">
         Coding Exercise 2.1.1: Derivative of the postsynaptic potential alpha function
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#section-2-1-2-chain-rule">
       Section 2.1.2: Chain Rule
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#math-exercise-2-1-2-chain-rule">
         Math Exercise 2.1.2: Chain Rule
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#section-2-2-3-derivatives-in-python-using-sympy">
       Section 2.2.3: Derivatives in Python using Sympy
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-2-2-numerical-differentiation">
     Section 2.2: Numerical Differentiation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-demo-2-2-numerical-differentiation-of-the-sine-function">
       Interactive Demo 2.2: Numerical Differentiation of the Sine Function
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-2-3-transfer-function-and-gain-of-a-neuron">
     Section 2.3: Transfer Function and Gain of a Neuron
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coding-exercise-2-1-calculating-the-transfer-function-and-gain-of-a-neuron">
       Coding Exercise 2.1: Calculating the Transfer Function and Gain of a Neuron
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-3-functions-of-multiple-variables">
   Section 3: Functions of Multiple Variables
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-3-1-partial-derivatives">
     Section 3.1: Partial derivatives
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-demo-3-1-visualize-partial-derivatives">
       Interactive Demo 3.1: Visualize partial derivatives
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#section-3-2-numerical-calculation-of-partial-derivatives">
       Section 3.2: Numerical calculation of partial derivatives
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-4-numerical-integration">
   Section 4: Numerical Integration
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-4-1-demonstration-of-the-riemann-sum">
     Section 4.1: Demonstration of the Riemann Sum
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interactive-demo-4-1-riemann-sum-vs-analytical-integral-with-changing-step-size">
       Interactive Demo 4.1: Riemann Sum vs. Analytical Integral with changing step size
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-4-2-neural-applications-of-numerical-integration">
     Section 4.2: Neural Applications of Numerical Integration
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coding-exercise-4-2-calculating-charge-transfer-with-excitatory-input">
       Coding Exercise 4.2: Calculating Charge Transfer with Excitatory Input
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-5-integration-and-differentiation-as-filtering-operations">
   Section 5: Integration and Differentiation as Filtering Operations
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/master/tutorials/W0D4_Calculus/student/W0D4_Tutorial1.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<div class="section" id="tutorial-1-basics-of-differential-and-integral-calculus">
<h1>Tutorial 1: Basics of Differential and Integral Calculus<a class="headerlink" href="#tutorial-1-basics-of-differential-and-integral-calculus" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 0, Day 4: Calculus</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> John S Butler, Arvind Kumar with help from Ella Batty</p>
<p><strong>Content reviewers:</strong>  ??</p>
<p><strong>Production editors:</strong> Matthew McCann, Manisha Sinha</p>
</div>
<hr class="docutils" />
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we will cover aspects of differential calculus that will be frequently used in the main NMA course. We assume that you  have some familiarty with differential calculus, but may be a bit rusty or may not have done much practice.  Specifically the objectives of this tutorial are</p>
<ul class="simple">
<li><p>Get an intuitive understanding of derivative and integration operations</p></li>
<li><p>Learn to calculate the derivatives of 1- and 2-dimensional functions/signals numerically</p></li>
<li><p>Familiarize with the concept of neuron transfer function in 1- and 2-dimensions.</p></li>
<li><p>Familiarize with the idea of numerical integration using Riemann sum</p></li>
<li><p>Learn about the notion of eigenfunction</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 1: Why do we care about calculus?</span>
<span class="c1"># Insert the ID of the corresponding youtube video</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;781o_1hRtpk&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="o">!</span>pip install sympy --quiet

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.optimize</span> <span class="k">as</span> <span class="nn">opt</span>       <span class="c1"># import root-finding algorithm</span>
<span class="kn">import</span> <span class="nn">sympy</span> <span class="k">as</span> <span class="nn">sp</span>                 <span class="c1"># Python toolbox for symbolic maths</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span> <span class="c1"># Toolbox for rendring 3D figures</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits</span> <span class="kn">import</span> <span class="n">mplot3d</span>   <span class="c1"># Toolbox for rendring 3D figures</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure Settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>  <span class="c1"># interactive display</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="c1"># use NMA plot style</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle&quot;</span><span class="p">)</span>
<span class="n">my_layout</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Layout</span><span class="p">()</span>

<span class="n">fig_w</span><span class="p">,</span> <span class="n">fig_h</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span> <span class="mf">4.5</span>
<span class="n">my_fontsize</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">my_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;axes.labelsize&#39;</span><span class="p">:</span> <span class="n">my_fontsize</span><span class="p">,</span>
          <span class="s1">&#39;axes.titlesize&#39;</span><span class="p">:</span> <span class="n">my_fontsize</span><span class="p">,</span>
          <span class="s1">&#39;figure.figsize&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">fig_w</span><span class="p">,</span> <span class="n">fig_h</span><span class="p">],</span>
          <span class="s1">&#39;font.size&#39;</span><span class="p">:</span> <span class="n">my_fontsize</span><span class="p">,</span>
          <span class="s1">&#39;legend.fontsize&#39;</span><span class="p">:</span> <span class="n">my_fontsize</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span>
          <span class="s1">&#39;lines.markersize&#39;</span><span class="p">:</span> <span class="mf">8.</span><span class="p">,</span>
          <span class="s1">&#39;lines.linewidth&#39;</span><span class="p">:</span> <span class="mf">2.</span><span class="p">,</span>
          <span class="s1">&#39;xtick.labelsize&#39;</span><span class="p">:</span> <span class="n">my_fontsize</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span>
          <span class="s1">&#39;ytick.labelsize&#39;</span><span class="p">:</span> <span class="n">my_fontsize</span><span class="o">-</span><span class="mi">2</span><span class="p">}</span>

<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">my_params</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting Functions</span>
<span class="k">def</span> <span class="nf">move_sympyplot_to_axes</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="n">backend</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">backend</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">backend</span><span class="o">.</span><span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span>
    <span class="n">backend</span><span class="o">.</span><span class="n">process_series</span><span class="p">()</span>
    <span class="n">backend</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
    <span class="n">backend</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;bottom&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_position</span><span class="p">(</span><span class="s1">&#39;zero&#39;</span><span class="p">)</span>
    <span class="n">backend</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">backend</span><span class="o">.</span><span class="n">fig</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_functions</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">show_derivative</span><span class="p">,</span> <span class="n">show_integral</span><span class="p">):</span>

  <span class="c1"># For sympy we first define our symbolic variable</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">f</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s1">&#39;x y z t f&#39;</span><span class="p">)</span>

  <span class="c1"># We define our function</span>
  <span class="k">if</span> <span class="n">function</span> <span class="o">==</span> <span class="s1">&#39;Linear&#39;</span><span class="p">:</span>
    <span class="n">f</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">t</span>
    <span class="n">name</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;$-2t$&#39;</span>
  <span class="k">elif</span> <span class="n">function</span> <span class="o">==</span> <span class="s1">&#39;Parabolic&#39;</span><span class="p">:</span>
    <span class="n">f</span> <span class="o">=</span>  <span class="n">t</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">name</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;$t^2$&#39;</span>
  <span class="k">elif</span> <span class="n">function</span> <span class="o">==</span> <span class="s1">&#39;Exponential&#39;</span><span class="p">:</span>
    <span class="n">f</span> <span class="o">=</span>  <span class="n">sp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">name</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;$e^t$&#39;</span>
  <span class="k">elif</span> <span class="n">function</span> <span class="o">==</span> <span class="s1">&#39;Sine&#39;</span><span class="p">:</span>
    <span class="n">f</span> <span class="o">=</span>  <span class="n">sp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">name</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;$sin(t)$&#39;</span>
  <span class="k">elif</span> <span class="n">function</span> <span class="o">==</span> <span class="s1">&#39;Sigmoid&#39;</span><span class="p">:</span>
    <span class="n">f</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">sp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="mi">5</span><span class="p">)))</span>
    <span class="n">name</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;$\frac</span><span class="si">{1}</span><span class="s1">{1+e^{-(t-5)}}$&#39;</span>

  <span class="k">if</span> <span class="n">show_derivative</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">show_integral</span><span class="p">:</span>
    <span class="c1"># Calculate the derivative of sin(t) as a function of t</span>
    <span class="n">diff_f</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Derivative of&#39;</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="s1">&#39;is &#39;</span><span class="p">,</span> <span class="n">diff_f</span><span class="p">)</span>

    <span class="n">p1</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">diff_f</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">line_color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">line_color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Function&#39;</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Derivative&#39;</span>
    <span class="n">p1</span><span class="o">.</span><span class="n">legend</span><span class="o">=</span><span class="kc">True</span>
    <span class="n">p1</span><span class="o">.</span><span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;Function = &#39;</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
    <span class="n">p1</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
  <span class="k">elif</span> <span class="n">show_integral</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">show_derivative</span><span class="p">:</span>

    <span class="n">int_f</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">int_f</span> <span class="o">=</span> <span class="n">int_f</span> <span class="o">-</span> <span class="n">int_f</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Integral of&#39;</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="s1">&#39;is &#39;</span><span class="p">,</span> <span class="n">int_f</span><span class="p">)</span>


    <span class="n">p1</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">int_f</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">line_color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">line_color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Function&#39;</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Integral&#39;</span>
    <span class="n">p1</span><span class="o">.</span><span class="n">legend</span><span class="o">=</span><span class="kc">True</span>
    <span class="n">p1</span><span class="o">.</span><span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;Function = &#39;</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
    <span class="n">p1</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


  <span class="k">elif</span> <span class="n">show_integral</span> <span class="ow">and</span> <span class="n">show_derivative</span><span class="p">:</span>

    <span class="n">diff_f</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Derivative of&#39;</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="s1">&#39;is &#39;</span><span class="p">,</span> <span class="n">diff_f</span><span class="p">)</span>

    <span class="n">int_f</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">integrate</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">int_f</span> <span class="o">=</span> <span class="n">int_f</span> <span class="o">-</span> <span class="n">int_f</span><span class="o">.</span><span class="n">subs</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Integral of&#39;</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="s1">&#39;is &#39;</span><span class="p">,</span> <span class="n">int_f</span><span class="p">)</span>

    <span class="n">p1</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">diff_f</span><span class="p">,</span> <span class="n">int_f</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">line_color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">line_color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">line_color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Function&#39;</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Derivative&#39;</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Integral&#39;</span>
    <span class="n">p1</span><span class="o">.</span><span class="n">legend</span><span class="o">=</span><span class="kc">True</span>
    <span class="n">p1</span><span class="o">.</span><span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;Function = &#39;</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
    <span class="n">p1</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

  <span class="k">else</span><span class="p">:</span>

    <span class="n">p1</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">line_color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span>
    <span class="n">p1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Function&#39;</span>
    <span class="n">p1</span><span class="o">.</span><span class="n">legend</span><span class="o">=</span><span class="kc">True</span>
    <span class="n">p1</span><span class="o">.</span><span class="n">title</span> <span class="o">=</span> <span class="s1">&#39;Function = &#39;</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
    <span class="n">p1</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">plot_alpha_func</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">df_dt</span><span class="p">):</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Alpha function&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time (au)&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Voltage&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Alpha function (f(t))&#39;</span><span class="p">)</span>
  <span class="c1">#plt.legend()</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">df_dt</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Derivative&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Derivative of alpha function&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time (au)&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;df/dt&#39;</span><span class="p">)</span>
  <span class="c1">#plt.legend()</span>

<span class="k">def</span> <span class="nf">plot_rate_and_gain</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">gain</span><span class="p">):</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">I</span><span class="p">,</span><span class="n">rate</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Injected current (au)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Output firing rate (normalized)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Transfer function&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
    <span class="c1"># Uncomment to plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">I</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">gain</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Injected current (au)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Gain&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Gain&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_charge_transfer</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">PSP</span><span class="p">,</span> <span class="n">numerical_integral</span><span class="p">):</span>

  <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

  <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">PSP</span><span class="p">)</span>
  <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span> <span class="o">=</span> <span class="s1">&#39;t&#39;</span><span class="p">,</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">&#39;PSP&#39;</span><span class="p">)</span>

  <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">numerical_integral</span><span class="p">)</span>
  <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span> <span class="o">=</span> <span class="s1">&#39;t&#39;</span><span class="p">,</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">&#39;Charge Transferred&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-1-what-is-differentiation-and-integration">
<h1>Section 1: What is differentiation and integration?<a class="headerlink" href="#section-1-what-is-differentiation-and-integration" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 2: What is differentiation and integration?</span>
<span class="c1"># Insert the ID of the corresponding youtube video</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;eOyGG3m-7gA&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>Calculus is a part of mathematics concerned with <strong>continous change</strong>. There are two branches of calculus: differential calculus and integral calculus. Both of these concepts are useful not only in science, but also in daily life. We encounter differentiation and integration everywhere.</p>
<p>Differentiation of a function <span class="math notranslate nohighlight">\(f(t)\)</span> gives you the derivative of that function <span class="math notranslate nohighlight">\(\frac{d(f(t))}{dt}\)</span>. A derivative captures how sensitive a function is to slight changes in the input for different ranges of inputs. Geometrically, the derivative of a function at a certain input is the slope of the function at that input. For example, as you drive, the distance traveled changes continuously with time. If you take the derivative of the distance traveled with respect to time, you get the velocity of the vehicle at each point in time. The velocity tells you the rate of change of the distance traveled at different points in time. If you have slow velocity (a small derivative), the distance traveled doesn’t change much for small changes in time. A high velocity (big derivative) means that the distance traveled changes a lot for small changes in time.</p>
<p>The sign of the derivative of a function (or signal) tells whether the signal is increasing or decreasing. For a signal going through changes as a function of time, the derivative will become zero when the signal changes its direction of change (e.g. from increasing to decreasing). That is, at local minimum or maximum values, the slope of the signal will be zero. This property is used in optimizing problems. But we can also use it to find peaks in a signal.</p>
<p>Integration can be thought of as the reverse of differentation. If we integrate the velocity with respect to time, we can calculate the distance traveled. By integrating a function, we are basically trying to find functions that would have the original one as their derivative. When we integrate a function, our integral will have an added unknown scalar constant, <span class="math notranslate nohighlight">\(C\)</span>.
For example, if $<span class="math notranslate nohighlight">\( g(t) = 1.5t^2 + 4t - 1\)</span><span class="math notranslate nohighlight">\(, 
our integral function \)</span>f(t)<span class="math notranslate nohighlight">\( will be:
\)</span><span class="math notranslate nohighlight">\( f(t) = \int g(t) dt = 0.5t^3 + 2t^2 - t + C\)</span>$.</p>
<p>This constant exists because the derivative of a constant is 0 so we cannot know what the constant should be. This is an indefinite integral. If we compute a definite integral, that is the integral between two limits of the input, we will not have this unknown constant and the integral of a function will capture the area under the curve of that function between those two limits.</p>
<p>Some functions, when differentiated or integrated, equal a scalar times the same function. This is a similar idea to eigenvectors of a matrix being those that, when multipled by the matrix, equal a scalar times themselves, as you saw yesterday!</p>
<p>When</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\frac{d(f(t)}{dt} = a\cdot f(t), 
\end{align*}\]</div>
<p>we say that <span class="math notranslate nohighlight">\(f(t)\)</span> is an <strong>eigenfunction</strong> for derivative operator, where <span class="math notranslate nohighlight">\(a\)</span> is a scaling factor. Similarly, when</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\int f(t)dt = a\cdot f(t), 
\end{align*}\]</div>
<p>we say that <span class="math notranslate nohighlight">\(f(t)\)</span> is an <strong>eigenfunction</strong> for integral operator.</p>
<p>As you can imagine, working with eigenfunctions can make mathematical analysis easy.</p>
<div class="section" id="interactive-demo-1-geometrical-understanding">
<h2>Interactive Demo 1: Geometrical understanding<a class="headerlink" href="#interactive-demo-1-geometrical-understanding" title="Permalink to this headline">¶</a></h2>
<p>In the interactive demo below, you can pick different functions to examine in the drop down menu. You can then choose to show the derivative function and/or the integral function.</p>
<p>For the integral, we have chosen the unknown constant <span class="math notranslate nohighlight">\(C\)</span> so that the integral function at the left x-axis limit is 0 (f(t = -10) = 0). So the integral will reflect the area under the curve starting from that position.</p>
<p>For each function:</p>
<ul class="simple">
<li><p>Examine just the function first. Discuss and predict what the derivative and integral will look like. Remember that derivative = slope of function, integral = area under curve from t = -10 to that t.</p></li>
<li><p>Check the derivative - does it match your expectations?</p></li>
<li><p>Check the integral - does it match your expectations?</p></li>
<li><p>Identify whether the function is an eigenfunction for the derivative operator, an eigenfunction for the integral operator, or neither.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to enable the widget</span>
<span class="n">function_options</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Dropdown</span><span class="p">(</span>
    <span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Linear&#39;</span><span class="p">,</span> <span class="s1">&#39;Parabolic&#39;</span><span class="p">,</span> <span class="s1">&#39;Exponential&#39;</span><span class="p">,</span> <span class="s1">&#39;Sine&#39;</span><span class="p">,</span> <span class="s1">&#39;Sigmoid&#39;</span><span class="p">],</span>
    <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Function&#39;</span><span class="p">,</span>
    <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">derivative</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Checkbox</span><span class="p">(</span>
    <span class="n">value</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Show derivative&#39;</span><span class="p">,</span>
    <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">indent</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">integral</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Checkbox</span><span class="p">(</span>
    <span class="n">value</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Show integral&#39;</span><span class="p">,</span>
    <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">indent</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">on_value_change</span><span class="p">(</span><span class="n">change</span><span class="p">):</span>
    <span class="n">derivative</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">integral</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">function_options</span><span class="o">.</span><span class="n">observe</span><span class="p">(</span><span class="n">on_value_change</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="s1">&#39;value&#39;</span><span class="p">)</span>

<span class="n">interact</span><span class="p">(</span><span class="n">plot_functions</span><span class="p">,</span> <span class="n">function</span> <span class="o">=</span> <span class="n">function_options</span><span class="p">,</span> <span class="n">show_derivative</span> <span class="o">=</span> <span class="n">derivative</span><span class="p">,</span> <span class="n">show_integral</span> <span class="o">=</span> <span class="n">integral</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D4_Calculus/solutions/W0D4_Tutorial1_Solution_2ce1573c.py"><em>Click for solution</em></a></p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-2-analytical-numerical-differentiation">
<h1>Section 2: Analytical &amp; Numerical Differentiation<a class="headerlink" href="#section-2-analytical-numerical-differentiation" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 3: Analytical &amp; Numerical Differentiation</span>
<span class="c1"># Insert the ID of the corresponding youtube video</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;C7U8zgI5rdk&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>In this section, we will delve into how we actually find the derivative of a function, both analytically and numerically.</p>
<div class="section" id="section-2-1-analytical-differentiation">
<h2>Section 2.1: Analytical Differentiation<a class="headerlink" href="#section-2-1-analytical-differentiation" title="Permalink to this headline">¶</a></h2>
<p>When we find the derivative analytically, we are finding the exact formula for the derivative function.</p>
<p>To do this, instead of having to do some fancy math every time, we can often consult <a class="reference external" href="https://en.wikipedia.org/wiki/Differentiation_rules">an online resource</a> for a list of common derivatives, in this case our trusty friend Wikipedia.</p>
<p>If I told you to find the derivative of <span class="math notranslate nohighlight">\(f(t) = x^3\)</span>, you could consult that site and find in Section 2.1, that if <span class="math notranslate nohighlight">\(f(t) = x^r\)</span>, then <span class="math notranslate nohighlight">\(\frac{d(f(t))}{dt} = rx^{r-1}\)</span>. So you would be able to tell me that the derivative of <span class="math notranslate nohighlight">\(f(t) = x^3\)</span> is <span class="math notranslate nohighlight">\(\frac{d(f(t))}{dt} = 3x^{2}\)</span>.</p>
<p>This list of common derivatives often contains only very simple functions. Luckily, as we’ll see in the next two sections, we can often break the derivative of a complex function down into the derivatives of more simple components.</p>
<div class="section" id="section-2-1-1-product-rule">
<h3>Section 2.1.1: Product Rule<a class="headerlink" href="#section-2-1-1-product-rule" title="Permalink to this headline">¶</a></h3>
<p>Sometimes we encounter functions which are the product of two functions that both depend on the variable.
How do we take the derivative of such functions? For this we use the <a class="reference external" href="https://en.wikipedia.org/wiki/Product_rule">Product Rule</a>.</p>
<div class="amsmath math notranslate nohighlight" id="equation-86c1c75b-a9c5-4219-98ce-bc2814ed8acb">
<span class="eqno">(1)<a class="headerlink" href="#equation-86c1c75b-a9c5-4219-98ce-bc2814ed8acb" title="Permalink to this equation">¶</a></span>\[\begin{align}
f(t) = u(t)\cdot v(t)\\
\frac{d(f(t))}{dt} = v\cdot \frac{du}{dt} + u\cdot \frac{dv}{dt}\\
\end{align}\]</div>
<div class="section" id="coding-exercise-2-1-1-derivative-of-the-postsynaptic-potential-alpha-function">
<h4>Coding Exercise 2.1.1: Derivative of the postsynaptic potential alpha function<a class="headerlink" href="#coding-exercise-2-1-1-derivative-of-the-postsynaptic-potential-alpha-function" title="Permalink to this headline">¶</a></h4>
<p>Let’s use the product rule to get the derivative of the post-synaptic potential alpha function. As we saw in Video 3, the shape of the postsynaptic potential is given by the so called alpha function:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
f(t) = t \cdot exp(-\frac{t}{\tau})
\end{align*}\]</div>
<p>Here <span class="math notranslate nohighlight">\(f(t)\)</span> is a product of <span class="math notranslate nohighlight">\(t\)</span> and <span class="math notranslate nohighlight">\(exp(-\frac{t}{\tau})\)</span>. The variable <span class="math notranslate nohighlight">\(\tau\)</span> is the time constant of the synapse.</p>
<p>We have defined <span class="math notranslate nohighlight">\(u(t)\)</span> and <span class="math notranslate nohighlight">\(v(t)\)</span> in the code below, in terms of the variable <span class="math notranslate nohighlight">\(t\)</span> which is an array of time steps from 0 to 10. Define <span class="math notranslate nohighlight">\(\frac{du}{dt}\)</span> and <span class="math notranslate nohighlight">\(\frac{dv}{dt}\)</span>, the compute the full derivative of the alpha function using the product rule. You can always consult wikipedia to figure out <span class="math notranslate nohighlight">\(\frac{du}{dt}\)</span> and <span class="math notranslate nohighlight">\(\frac{dv}{dt}\)</span>!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define time, time constant</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">.1</span><span class="p">)</span>
<span class="n">tau</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="c1"># Compute alpha function</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">t</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">t</span><span class="o">/</span><span class="n">tau</span><span class="p">)</span>

<span class="c1"># Define u(t), v(t)</span>
<span class="n">u_t</span> <span class="o">=</span> <span class="n">t</span>
<span class="n">v_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">t</span><span class="o">/</span><span class="n">tau</span><span class="p">)</span>

<span class="c1"># Define du/dt, dv/dt</span>
<span class="n">du_dt</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">dv_dt</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># Define full derivative</span>
<span class="n">df_dt</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># Uncomment below to visualize</span>
<span class="c1">#plot_alpha_func(t, f, df_dt)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D4_Calculus/solutions/W0D4_Tutorial1_Solution_366c0574.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=843 height=303 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W0D4_Calculus/static/W0D4_Tutorial1_Solution_366c0574_0.png>
</div>
</div>
<div class="section" id="section-2-1-2-chain-rule">
<h3>Section 2.1.2: Chain Rule<a class="headerlink" href="#section-2-1-2-chain-rule" title="Permalink to this headline">¶</a></h3>
<p>Many times we encounter situations in which the variable <span class="math notranslate nohighlight">\(a\)</span> is changing with time (<span class="math notranslate nohighlight">\(t\)</span>) and affecting another variable <span class="math notranslate nohighlight">\(r\)</span>. How can we estimate the derivative of <span class="math notranslate nohighlight">\(r\)</span> with respect to <span class="math notranslate nohighlight">\(a\)</span> i.e. <span class="math notranslate nohighlight">\(\frac{dr}{da} = ?\)</span></p>
<p>To calculate <span class="math notranslate nohighlight">\(\frac{dr}{da}\)</span> we use the <a class="reference external" href="https://en.wikipedia.org/wiki/Chain_rule">Chain Rule</a>.</p>
<div class="amsmath math notranslate nohighlight" id="equation-18413bed-f428-43e9-ac43-50210915dc6c">
<span class="eqno">(2)<a class="headerlink" href="#equation-18413bed-f428-43e9-ac43-50210915dc6c" title="Permalink to this equation">¶</a></span>\[\begin{align}
\frac{dr}{da} = \frac{dr}{dt}\cdot\frac{dt}{da}
\end{align}\]</div>
<p>That is, we calculate the derivative of both variables with respect to time and divide the time derivative of <span class="math notranslate nohighlight">\(r\)</span> by that of time derivative of <span class="math notranslate nohighlight">\(a\)</span>.</p>
<p>We will step back from applications for a second: we can use this to simplify taking derivatives of complex functions, as you will see in the next exercise.</p>
<div class="section" id="math-exercise-2-1-2-chain-rule">
<h4>Math Exercise 2.1.2: Chain Rule<a class="headerlink" href="#math-exercise-2-1-2-chain-rule" title="Permalink to this headline">¶</a></h4>
<p>Let’s say that:
$<span class="math notranslate nohighlight">\( r(a) = e^{a^4 + 1} \)</span>$</p>
<p>What is <span class="math notranslate nohighlight">\(\frac{dr}{da}\)</span>? This is a more complex function so we can’t simply consult a table of common derivatives. Can you use the chain rule to help?</p>
<p>Hint: we didn’t define t but you could set t equal to the function in the exponent</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D4_Calculus/solutions/W0D4_Tutorial1_Solution_a0e42694.py"><em>Click for solution</em></a></p>
</div>
</div>
<div class="section" id="section-2-2-3-derivatives-in-python-using-sympy">
<h3>Section 2.2.3: Derivatives in Python using Sympy<a class="headerlink" href="#section-2-2-3-derivatives-in-python-using-sympy" title="Permalink to this headline">¶</a></h3>
<p>There is a useful Python library for getting the analytical derivatives of functions: Sympy. We actually used in Interactive Demo 1, under the hood.</p>
<p>See the following cell for an example of setting up a sympy function and finding the derivative.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># For sympy we first define our symbolic variables</span>
<span class="n">f</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s1">&#39;f, t&#39;</span><span class="p">)</span>

<span class="c1"># Function definition (sigmoid)</span>
<span class="n">f</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">sp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="mi">5</span><span class="p">)))</span>

<span class="c1"># Get the derivative</span>
<span class="n">diff_f</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="c1"># Print the resulting function</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Derivative of&#39;</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="s1">&#39;is &#39;</span><span class="p">,</span> <span class="n">diff_f</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="section-2-2-numerical-differentiation">
<h2>Section 2.2: Numerical Differentiation<a class="headerlink" href="#section-2-2-numerical-differentiation" title="Permalink to this headline">¶</a></h2>
<p>Formally, the derivative of a function <span class="math notranslate nohighlight">\(\mathcal{f}(x)\)</span> at any value <span class="math notranslate nohighlight">\(a\)</span> is given by the finite difference formula (FD):</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
FD = \frac{f(a+h) - f(a)}{h}
\end{align*}\]</div>
<p>As <span class="math notranslate nohighlight">\(h\rightarrow 0\)</span>, the FD approaches the actual value of the derivative. Let’s check this.</p>
<p><em>Note that the numerical estimate of the derivative will result
in a time series whose length is one short of the original time series.</em></p>
<div class="section" id="interactive-demo-2-2-numerical-differentiation-of-the-sine-function">
<h3>Interactive Demo 2.2: Numerical Differentiation of the Sine Function<a class="headerlink" href="#interactive-demo-2-2-numerical-differentiation-of-the-sine-function" title="Permalink to this headline">¶</a></h3>
<p>Below, we find the numerical derivative of the sine function for different values of <span class="math notranslate nohighlight">\(h\)</span>, and and compare the result the analytical solution.</p>
<ul class="simple">
<li><p>What values of h result in more accurate numerical derivatives?</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown *Execute this cell to enable the widget.*</span>
<span class="k">def</span> <span class="nf">numerical_derivative_demo</span><span class="p">(</span><span class="n">h</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">):</span>
  <span class="c1"># Now lets create a sequence of numbers which change according to the sine function</span>
  <span class="n">dt</span> <span class="o">=</span> <span class="mf">0.01</span>
  <span class="n">tx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">dt</span><span class="p">)</span>
  <span class="n">sine_fun</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>

  <span class="c1"># symbolic diffrentiation tells us that the derivative of sin(t) is cos(t)</span>
  <span class="n">cos_fun</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">tx</span><span class="p">)</span>

  <span class="c1"># Numerical derivative using difference formula</span>
  <span class="n">n_tx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="n">h</span><span class="p">)</span> <span class="c1"># create new time axis</span>
  <span class="n">n_sine_fun</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">n_tx</span><span class="p">)</span> <span class="c1"># calculate the sine function on the new time axis</span>
  <span class="n">sine_diff</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_sine_fun</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">n_sine_fun</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">h</span>

  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span> <span class="n">sine_fun</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;sine function&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span> <span class="n">cos_fun</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;analytical derivative of sine&#39;</span><span class="p">)</span>

  <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
    <span class="c1"># notice that numerical derivative will have one element less</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n_tx</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sine_diff</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;numerical derivative of sine&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time (au)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;f(x) or df(x)/dt&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper center&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">),</span>
              <span class="n">ncol</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">fancybox</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">numerical_derivative_demo</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">.02</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D4_Calculus/solutions/W0D4_Tutorial1_Solution_36cd3b93.py"><em>Click for solution</em></a></p>
</div>
</div>
<div class="section" id="section-2-3-transfer-function-and-gain-of-a-neuron">
<h2>Section 2.3: Transfer Function and Gain of a Neuron<a class="headerlink" href="#section-2-3-transfer-function-and-gain-of-a-neuron" title="Permalink to this headline">¶</a></h2>
<p>When we inject a constant current (DC) in a neuron, its firing rate changes as a function of strength of the injected current. This is called the <strong>input-output transfer function</strong> or just the <em>transfer function</em> or <em>I/O Curve</em> of the neuron. For most neurons this can be approximated by a sigmoid function e.g.</p>
<div class="amsmath math notranslate nohighlight" id="equation-cc80bb18-3af4-4209-9570-83d201ec91d0">
<span class="eqno">(3)<a class="headerlink" href="#equation-cc80bb18-3af4-4209-9570-83d201ec91d0" title="Permalink to this equation">¶</a></span>\[\begin{align}
rate(I) = \frac{1}{1+\text{e}^{-a*(I-\theta)}} - \frac{1}{exp(a*\theta)} + \eta
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(I\)</span> is injected current, <span class="math notranslate nohighlight">\(rate\)</span> is the neuron firing rate and <span class="math notranslate nohighlight">\(\eta\)</span> is noise (Gaussian noise with zero mean and <span class="math notranslate nohighlight">\(\sigma\)</span> standard deviation).</p>
<p><em>You will visit this equation in a different context in Week 3</em></p>
<div class="section" id="coding-exercise-2-1-calculating-the-transfer-function-and-gain-of-a-neuron">
<h3>Coding Exercise 2.1: Calculating the Transfer Function and Gain of a Neuron<a class="headerlink" href="#coding-exercise-2-1-calculating-the-transfer-function-and-gain-of-a-neuron" title="Permalink to this headline">¶</a></h3>
<p>The slope of a neurons input-output transfer function (<span class="math notranslate nohighlight">\(\frac{d(r(I)}{dI}\)</span>) is called the <strong>gain</strong> of the neuron, as it tells how the neuron output will change if the input is changed.</p>
<p>Estimate the gain of the following neuron transfer function using numerical differentiaton. We will use our timestep as h.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown *Execute this cell to enable the numerical differentiation function: `numerical_derivative`*</span>

<span class="k">def</span> <span class="nf">numerical_derivative</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
  <span class="sd">&#39;&#39;&#39;Numerical derivative calculation</span>
<span class="sd">    Args:</span>
<span class="sd">      x: array of number</span>
<span class="sd">      h: time step for differentiation</span>

<span class="sd">    Returns:</span>
<span class="sd">      Numerical derivative of f for a time step of h</span>
<span class="sd">  &#39;&#39;&#39;</span>

  <span class="n">dxdt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">dxdt</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="n">h</span>
  <span class="k">return</span> <span class="n">dxdt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_rate_and_gain</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">current_timestep</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot; Compute rate and gain of neuron based on parameters</span>

<span class="sd">  Args:</span>
<span class="sd">    I (ndarray): different possible values of the current</span>
<span class="sd">    a (scalar): parameter of the transfer function</span>
<span class="sd">    theta (scalar): parameter of the transfer function</span>
<span class="sd">    current_timestep (scalar): the time we&#39;re using to take steps</span>

<span class="sd">  Returns:</span>
<span class="sd">    (ndarray, ndarray): rate and gain for each possible value of I</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1">########################################################################</span>
  <span class="c1">## TODO for students: calculate the gain of the neural firing rate ##</span>
  <span class="c1">## Complete line of code and remove</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Calculate the gain&quot;</span><span class="p">)</span>
  <span class="c1">########################################################################</span>

  <span class="c1"># Compute rate</span>
  <span class="n">rate</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="p">(</span><span class="n">I</span><span class="o">-</span><span class="n">theta</span><span class="p">)))</span><span class="o">**-</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">a</span><span class="o">*</span><span class="n">theta</span><span class="p">))</span><span class="o">**-</span><span class="mi">1</span>

  <span class="c1"># Compute gain</span>
  <span class="n">gain</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">rate</span><span class="p">,</span> <span class="n">gain</span>


<span class="n">current_timestep</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">I</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">current_timestep</span><span class="p">)</span>

<span class="c1"># Neuron transfer function</span>
<span class="n">a</span> <span class="o">=</span> <span class="mf">1.2</span>     <span class="c1"># You can change this value</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mi">5</span> <span class="c1"># You can change this value</span>

<span class="c1"># Compute rate and gain</span>
<span class="n">rate</span><span class="p">,</span> <span class="n">gain</span> <span class="o">=</span> <span class="n">compute_rate_and_gain</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">current_timestep</span><span class="p">)</span>

<span class="c1"># Visualize rate and gain</span>
<span class="n">plot_rate_and_gain</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">gain</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D4_Calculus/solutions/W0D4_Tutorial1_Solution_9fc5d678.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=843 height=303 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W0D4_Calculus/static/W0D4_Tutorial1_Solution_9fc5d678_0.png>
<p>The slope of the transfer function tells us in which range of inputs the neuron is most sensitive to changes in its input. Change the parameters of the neuron transfer function (i.e. <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(\theta\)</span>) and see if you can predict the value of <span class="math notranslate nohighlight">\(I\)</span> for which the neuron has maximal slope and which parameter determines the peak value of the gain.</p>
</div>
</div>
</div>
<div class="section" id="section-3-functions-of-multiple-variables">
<h1>Section 3: Functions of Multiple Variables<a class="headerlink" href="#section-3-functions-of-multiple-variables" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 4: Functions of Multiple Variables</span>
<span class="c1"># Insert the ID of the corresponding youtube video</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;rLsLOWsNOGw&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>In the previous section, you looked at function of single variable <span class="math notranslate nohighlight">\(t\)</span> or <span class="math notranslate nohighlight">\(x\)</span>. In most cases, we encounter functions of multiple variables. For example, in the brain, the firing rate of a neuron is a function of both excitatory and inhibitory input rates. In the following, we will look into how to calculate derivatives of such functions.</p>
<p>First, let’s create a function of two variables. We take the example of a neuron driven by excitatory and inhibitory inputs. Because this is for illustrative purposes, we will not go in the details of the numerical range of the input and output variables.</p>
<p>In the function below, we assume that the firing rate of a neuron increases motonotically with an increase in excitation and decreases monotonically with an increase in inhibition. The inhibition is modelled as a subtraction. Like for the 1-dimensional transfer function, here we assume that we can approximate the transfer function as a sigmoid function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to visualize the neuron firing rate surface</span>
<span class="k">def</span> <span class="nf">sigmoid_function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">theta</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Population activation function.</span>

<span class="sd">    Expects:</span>
<span class="sd">    x     : the population input</span>
<span class="sd">    a     : the gain of the function</span>
<span class="sd">    theta : the threshold of the function</span>

<span class="sd">    Returns:</span>
<span class="sd">    the population activation response F(x) for input x</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># add the expression of f = F(x)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">a</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">theta</span><span class="p">)))</span><span class="o">**-</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">a</span><span class="o">*</span><span class="n">theta</span><span class="p">))</span><span class="o">**-</span><span class="mi">1</span>

    <span class="k">return</span> <span class="n">f</span>

<span class="c1"># Neuron Transfer function</span>
<span class="n">step_size</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">exc_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="n">step_size</span><span class="p">)</span>
<span class="n">inh_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="n">step_size</span><span class="p">)</span>
<span class="n">exc_a</span> <span class="o">=</span> <span class="mf">1.2</span>
<span class="n">exc_theta</span> <span class="o">=</span> <span class="mf">2.4</span>
<span class="n">inh_a</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">inh_theta</span> <span class="o">=</span> <span class="mf">4.</span>

<span class="n">rate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">exc_input</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">inh_input</span><span class="p">)))</span>

<span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">exc_input</span><span class="p">)):</span>
  <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inh_input</span><span class="p">)):</span>
    <span class="n">rate</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span><span class="n">jj</span><span class="p">]</span> <span class="o">=</span> <span class="n">sigmoid_function</span><span class="p">(</span><span class="n">exc_input</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span><span class="n">exc_a</span><span class="p">,</span><span class="n">exc_theta</span><span class="p">)</span> <span class="o">-</span> <span class="n">sigmoid_function</span><span class="p">(</span><span class="n">inh_input</span><span class="p">[</span><span class="n">jj</span><span class="p">],</span><span class="n">inh_a</span><span class="p">,</span><span class="n">inh_theta</span><span class="p">)</span><span class="o">*</span><span class="mf">0.5</span>

<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">exc_input</span><span class="p">,</span> <span class="n">inh_input</span><span class="p">)</span>
  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
  <span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">lg_txt</span> <span class="o">=</span> <span class="s1">&#39;Inhibition = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">inh_input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">exc_input</span><span class="p">,</span><span class="n">rate</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="n">lg_txt</span><span class="p">)</span>
  <span class="n">lg_txt</span> <span class="o">=</span> <span class="s1">&#39;Inhibition = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">inh_input</span><span class="p">[</span><span class="mi">20</span><span class="p">])</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">exc_input</span><span class="p">,</span><span class="n">rate</span><span class="p">[:,</span><span class="mi">20</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="n">lg_txt</span><span class="p">)</span>
  <span class="n">lg_txt</span> <span class="o">=</span> <span class="s1">&#39;Inhibition = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">inh_input</span><span class="p">[</span><span class="mi">40</span><span class="p">])</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">exc_input</span><span class="p">,</span><span class="n">rate</span><span class="p">[:,</span><span class="mi">40</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="n">lg_txt</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Excitatory input (au)&#39;</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Neuron output rate (au)&#39;</span><span class="p">);</span>

  <span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
  <span class="n">lg_txt</span> <span class="o">=</span> <span class="s1">&#39;Excitation = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">exc_input</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">inh_input</span><span class="p">,</span><span class="n">rate</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span><span class="n">label</span><span class="o">=</span><span class="n">lg_txt</span><span class="p">)</span>
  <span class="n">lg_txt</span> <span class="o">=</span> <span class="s1">&#39;Excitation = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">exc_input</span><span class="p">[</span><span class="mi">20</span><span class="p">])</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">inh_input</span><span class="p">,</span><span class="n">rate</span><span class="p">[</span><span class="mi">20</span><span class="p">,:],</span><span class="n">label</span><span class="o">=</span><span class="n">lg_txt</span><span class="p">)</span>
  <span class="n">lg_txt</span> <span class="o">=</span> <span class="s1">&#39;Excitation = &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">exc_input</span><span class="p">[</span><span class="mi">40</span><span class="p">])</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">inh_input</span><span class="p">,</span><span class="n">rate</span><span class="p">[</span><span class="mi">40</span><span class="p">,:],</span><span class="n">label</span><span class="o">=</span><span class="n">lg_txt</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Inhibitory input (au)&#39;</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Neuron output rate (au)&#39;</span><span class="p">);</span>

  <span class="n">ax3</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
  <span class="n">surf</span><span class="o">=</span> <span class="n">ax3</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">rstride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cstride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                  <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
  <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Inhibitory input (au)&#39;</span><span class="p">)</span>
  <span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Excitatory input (au)&#39;</span><span class="p">)</span>
  <span class="n">ax3</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">&#39;Neuron output rate (au)&#39;</span><span class="p">);</span>
  <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">surf</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In the <strong>Top-Left</strong> plot, we see how the neuron output rate increases as a function of excitatory input (e.g. the blue trace). However, as we increase inhibition, expectedly the neuron output decreases and the curve is shifted downwards. This constant shift in the curve suggests that the effect of inhibition is subtractive, and the amount of subtraction does not depend on the neuron output.</p>
<p>We can alternatively see how the neuron output changes with respect to inhibition and study how excitation affects that. This is visualized in the <strong>Top-Right</strong> plot.</p>
<p>This type of plotting is very intuitive, but it becomes very tedious to visualize when there are larger numbers of lines to be plotted. A nice solution to this visualization problem is to render the data as color, as surfaces, or both.</p>
<p>This is what we have done in the plot on the bottom. The colormap on the right shows the output of the neuron as a function of inhibitory input and excitatory input. The output rate is shown both as height along the z-axis and as the color. Blue means low firing rate and yellow means high firing rate (see the color bar).</p>
<p>In the above plot, the output rate of the neuron goes below zero. This is of course not physiological. In models, we either choose the operating point such that the output does not go below zero, or else we clamp the neuron output to zero if it goes below zero. You will learn about it more in Week 3.</p>
<div class="section" id="section-3-1-partial-derivatives">
<h2>Section 3.1: Partial derivatives<a class="headerlink" href="#section-3-1-partial-derivatives" title="Permalink to this headline">¶</a></h2>
<p>The above function is like a surface and when we are thinking of the derivative of the surface we can make a physical analogy.</p>
<p>Consider putting a ball on this surface. In which direction the ball will move?</p>
<p>The movement along one of the directions (along the x-axis) will be determined by inhibitory input and in the other direction (along y-axis) it will be determined by excitatory inputs. The effective movement direction will be the vector sum of the two (perhaps you recall vector sum from yesterday).</p>
<p>That is, we can calculate the derivative of the surface for the inhibitory input and then for the excitatory inputs.</p>
<p>When we take the derrivative of a multivariable function with respect to one of the variables it is called the <strong>partial derivative</strong>. For example if we have a function:</p>
<div class="amsmath math notranslate nohighlight" id="equation-0c8ed9bb-54b0-41a3-8642-cb2e0ac1f065">
<span class="eqno">(4)<a class="headerlink" href="#equation-0c8ed9bb-54b0-41a3-8642-cb2e0ac1f065" title="Permalink to this equation">¶</a></span>\[\begin{align}
f(x,y) = x^2 + 2xy + y^2
\end{align}\]</div>
<p>The we can define the partial derivatives as</p>
<div class="amsmath math notranslate nohighlight" id="equation-dd903d1f-fd34-4644-8e5f-1f5804d3bffd">
<span class="eqno">(5)<a class="headerlink" href="#equation-dd903d1f-fd34-4644-8e5f-1f5804d3bffd" title="Permalink to this equation">¶</a></span>\[\begin{align}
\frac{\partial(f(x,y))}{\partial x} = 2x + 2y + 0 \\\\
\frac{\partial(f(x,y))}{\partial y} = 0 + 2x + 2y
\end{align}\]</div>
<p>In the above, the derivative of the last term (<span class="math notranslate nohighlight">\(y^2\)</span>) with respect to <span class="math notranslate nohighlight">\(x\)</span> is zero because it does not change with respect to <span class="math notranslate nohighlight">\(x\)</span>. Similarly, the derivative of <span class="math notranslate nohighlight">\(x^2\)</span> with respect to <span class="math notranslate nohighlight">\(y\)</span> is also zero.</p>
<div class="section" id="interactive-demo-3-1-visualize-partial-derivatives">
<h3>Interactive Demo 3.1: Visualize partial derivatives<a class="headerlink" href="#interactive-demo-3-1-visualize-partial-derivatives" title="Permalink to this headline">¶</a></h3>
<p>In the demo below, you can input any function of x and y and then visualize both the function and partial derivatives.</p>
<p>We visualized the 2-dimensional function as a surface plot in which the values of the function are rendered as color. Yellow represents a high value and blue represents a low value. The height of the surface also shows the numerical value of the function. The first plot is that of our function. And the two bottom plots are the derivative surfaces with respect to <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> variables.</p>
<ol class="simple">
<li><p>Ensure you understand how the plots relate to each other - if not, review the above material</p></li>
<li><p>Can you come up with a function where the partial derivative with respect to x will be a linear plane and the derivative with respect to y will be more curvy?</p></li>
<li><p>What happens to the partial derivatives if there are no terms involving multiplying x and y together?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this widget to enable the demo</span>

<span class="c1"># Let&#39;s use sympy to calculate Partial derivatives of a function of 2-variables</span>
<span class="nd">@interact</span><span class="p">(</span><span class="n">f2d_string</span> <span class="o">=</span> <span class="s1">&#39;x**2 + 2*x*y + y**2&#39;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">plot_partial_derivs</span><span class="p">(</span><span class="n">f2d_string</span><span class="p">):</span>
  <span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">symbols</span><span class="p">(</span><span class="s1">&#39;f, x, y&#39;</span><span class="p">)</span>

  <span class="n">f2d</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">f2d_string</span><span class="p">)</span>
  <span class="n">f2d_dx</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">f2d</span><span class="p">,</span><span class="n">x</span><span class="p">)</span>
  <span class="n">f2d_dy</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">f2d</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Partial derivative of &#39;</span><span class="p">,</span> <span class="n">f2d</span><span class="p">,</span> <span class="s1">&#39;with respect to x is&#39;</span><span class="p">,</span> <span class="n">f2d_dx</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Partial derivative of &#39;</span><span class="p">,</span> <span class="n">f2d</span><span class="p">,</span> <span class="s1">&#39;with respect to y is&#39;</span><span class="p">,</span> <span class="n">f2d_dy</span><span class="p">)</span>

  <span class="n">p1</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">plotting</span><span class="o">.</span><span class="n">plot3d</span><span class="p">(</span><span class="n">f2d</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span><span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">zlabel</span><span class="o">=</span><span class="s1">&#39;f(x,y)&#39;</span><span class="p">,</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Our function&#39;</span><span class="p">)</span>

  <span class="n">p2</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">plotting</span><span class="o">.</span><span class="n">plot3d</span><span class="p">(</span><span class="n">f2d_dx</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span><span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">zlabel</span><span class="o">=</span><span class="s1">&#39;df(x,y)/dx&#39;</span><span class="p">,</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Derivative w.r.t. x&#39;</span><span class="p">)</span>

  <span class="n">p3</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">plotting</span><span class="o">.</span><span class="n">plot3d</span><span class="p">(</span><span class="n">f2d_dy</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span><span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">zlabel</span><span class="o">=</span><span class="s1">&#39;df(x,y)/dy&#39;</span><span class="p">,</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Derivative w.r.t. y&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D4_Calculus/solutions/W0D4_Tutorial1_Solution_5deca1d0.py"><em>Click for solution</em></a></p>
</div>
<div class="section" id="section-3-2-numerical-calculation-of-partial-derivatives">
<h3>Section 3.2: Numerical calculation of partial derivatives<a class="headerlink" href="#section-3-2-numerical-calculation-of-partial-derivatives" title="Permalink to this headline">¶</a></h3>
<p>Now that you have an intuition about multivariable functions and partial derivatives we can go back to the neuron transfer function we evaluated earlier.
To evaluate the partial derivatives we can use the same numerical differentiation as before but now we apply it to each row and column separately.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to visualize the transfer function</span>
<span class="c1"># Neuron Transfer Function</span>
<span class="n">step_size</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">exc_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="n">step_size</span><span class="p">)</span>
<span class="n">inh_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="n">step_size</span><span class="p">)</span>
<span class="n">exc_a</span> <span class="o">=</span> <span class="mf">1.2</span>
<span class="n">exc_theta</span> <span class="o">=</span> <span class="mf">2.4</span>
<span class="n">inh_a</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">inh_theta</span> <span class="o">=</span> <span class="mf">4.</span>

<span class="n">rate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">exc_input</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">inh_input</span><span class="p">)))</span>
<span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">exc_input</span><span class="p">)):</span>
  <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inh_input</span><span class="p">)):</span>
    <span class="n">rate</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span><span class="n">jj</span><span class="p">]</span> <span class="o">=</span> <span class="n">sigmoid_function</span><span class="p">(</span><span class="n">exc_input</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span><span class="n">exc_a</span><span class="p">,</span><span class="n">exc_theta</span><span class="p">)</span> <span class="o">-</span> <span class="n">sigmoid_function</span><span class="p">(</span><span class="n">inh_input</span><span class="p">[</span><span class="n">jj</span><span class="p">],</span><span class="n">inh_a</span><span class="p">,</span><span class="n">inh_theta</span><span class="p">)</span><span class="o">*</span><span class="mf">0.5</span>

<span class="c1"># Derivative with respect to excitatory input rate</span>
<span class="n">rate_de</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">exc_input</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">inh_input</span><span class="p">)))</span><span class="c1"># this will have one row less than the rate matrix</span>
<span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inh_input</span><span class="p">)):</span>
  <span class="n">rate_de</span><span class="p">[:,</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">rate</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span><span class="n">ii</span><span class="p">]</span> <span class="o">-</span> <span class="n">rate</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">ii</span><span class="p">])</span><span class="o">/</span><span class="n">step_size</span>

<span class="c1"># Derivative with respect to inhibitory input rate</span>
<span class="n">rate_di</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">exc_input</span><span class="p">),</span><span class="nb">len</span><span class="p">(</span><span class="n">inh_input</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="c1"># this will have one column less than the rate matrix</span>
<span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">exc_input</span><span class="p">)):</span>
  <span class="n">rate_di</span><span class="p">[</span><span class="n">ii</span><span class="p">,:]</span> <span class="o">=</span> <span class="p">(</span><span class="n">rate</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">rate</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="n">step_size</span>

<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
  <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">exc_input</span><span class="p">,</span> <span class="n">inh_input</span><span class="p">)</span>
  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
  <span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
  <span class="n">surf1</span> <span class="o">=</span> <span class="n">ax1</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">rstride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cstride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Inhibitory input (au)&#39;</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Excitatory input (au)&#39;</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">&#39;Neuron output rate (au)&#39;</span><span class="p">)</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Rate as a function of Exc. and Inh&#39;</span><span class="p">);</span>
  <span class="n">ax1</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
  <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">surf1</span><span class="p">)</span>

  <span class="n">Xde</span><span class="p">,</span> <span class="n">Yde</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">exc_input</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">inh_input</span><span class="p">)</span>
  <span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
  <span class="n">surf2</span> <span class="o">=</span> <span class="n">ax2</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">Yde</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Xde</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">rate_de</span><span class="p">,</span> <span class="n">rstride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cstride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Inhibitory input (au)&#39;</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Excitatory input (au)&#39;</span><span class="p">)</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">&#39;Neuron output rate (au)&#39;</span><span class="p">);</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Derivative wrt Excitation&#39;</span><span class="p">);</span>
  <span class="n">ax2</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
  <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">surf2</span><span class="p">)</span>

  <span class="n">Xdi</span><span class="p">,</span> <span class="n">Ydi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">exc_input</span><span class="p">,</span> <span class="n">inh_input</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
  <span class="n">ax3</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
  <span class="n">surf3</span> <span class="o">=</span> <span class="n">ax3</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">Ydi</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">Xdi</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">rate_di</span><span class="p">,</span> <span class="n">rstride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cstride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
  <span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Inhibitory input (au)&#39;</span><span class="p">)</span>
  <span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Excitatory input (au)&#39;</span><span class="p">)</span>
  <span class="n">ax3</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">&#39;Neuron output rate (au)&#39;</span><span class="p">);</span>
  <span class="n">ax3</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Derivative wrt Inhibition&#39;</span><span class="p">);</span>
  <span class="n">ax3</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="o">-</span><span class="mi">115</span><span class="p">)</span>
  <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">surf3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Is this what you expeced? Vary the inputs and see if your intuitions are correct. Change the time varying variable and test your intuitions.</p>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-4-numerical-integration">
<h1>Section 4: Numerical Integration<a class="headerlink" href="#section-4-numerical-integration" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 5: Numerical Integration</span>
<span class="c1"># Insert the ID of the corresponding youtube video</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;sj_83_811j0&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>Geometrically, integration is the area under the curve. This interpretation gives two formal ways to calculate the integral of a function numerically.</p>
<p><strong><a class="reference external" href="https://en.wikipedia.org/wiki/Riemann_sum">Riemann sum</a></strong>:
If we wish to integrate a function <span class="math notranslate nohighlight">\(f(t)\)</span> with respect to <span class="math notranslate nohighlight">\(t\)</span>, then first we divide the function into <span class="math notranslate nohighlight">\(n\)</span> intervals of size <span class="math notranslate nohighlight">\(dt = a-b\)</span>, where <span class="math notranslate nohighlight">\(a\)</span> is the starting of the interval. Thus, each interval gives a rectangle with height <span class="math notranslate nohighlight">\(f(a)\)</span> and width <span class="math notranslate nohighlight">\(dt\)</span>. By summing the area of all the rectangles, we can approximate the area under the curve. As the size <span class="math notranslate nohighlight">\(dt\)</span> approaches to zero, our estimate of the integral approcahes the analytical calculation. Essentially, the Riemann sum is cutting the region under the curve in vertical stripes, calculating area of the each stripe and summing them up.</p>
<p><strong><a class="reference external" href="https://en.wikipedia.org/wiki/Lebesgue_integral">Lebesgue integral</a></strong>: In the Lebesgue integral, we divide the area under the curve into horizontal stripes. That is, instead of the independent variable, the range of the function <span class="math notranslate nohighlight">\(f(t)\)</span> is divided into small intervals.</p>
<div class="section" id="section-4-1-demonstration-of-the-riemann-sum">
<h2>Section 4.1: Demonstration of the Riemann Sum<a class="headerlink" href="#section-4-1-demonstration-of-the-riemann-sum" title="Permalink to this headline">¶</a></h2>
<div class="section" id="interactive-demo-4-1-riemann-sum-vs-analytical-integral-with-changing-step-size">
<h3>Interactive Demo 4.1: Riemann Sum vs. Analytical Integral with changing step size<a class="headerlink" href="#interactive-demo-4-1-riemann-sum-vs-analytical-integral-with-changing-step-size" title="Permalink to this headline">¶</a></h3>
<p>Below, we will compare numerical integration using the Riemann Sum with the analytical solution. You can change the interval size <span class="math notranslate nohighlight">\(dt\)</span> using the slider.</p>
<ol class="simple">
<li><p>What values of dt result in the best numerical integration?</p></li>
<li><p>What is the downside of choosing that value of dt?</p></li>
<li><p>With large dt, why are we underestimating the integral (as opposed to overestimating?</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Run this cell to enable the widget!</span>
<span class="k">def</span> <span class="nf">riemann_sum_demo</span><span class="p">(</span><span class="n">dt</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">):</span>
  <span class="n">step_size</span> <span class="o">=</span> <span class="mf">0.1</span>
  <span class="n">min_val</span> <span class="o">=</span> <span class="mf">0.</span>
  <span class="n">max_val</span> <span class="o">=</span> <span class="mf">10.</span>
  <span class="n">tx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">min_val</span><span class="p">,</span> <span class="n">max_val</span><span class="p">,</span> <span class="n">step_size</span><span class="p">)</span>

  <span class="c1"># Our function</span>
  <span class="n">ftn</span> <span class="o">=</span> <span class="n">tx</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">tx</span> <span class="o">+</span> <span class="mi">1</span>
  <span class="c1"># And the integral analytical formula calculates using sympy</span>
  <span class="n">int_ftn</span> <span class="o">=</span> <span class="n">tx</span><span class="o">**</span><span class="mi">3</span><span class="o">/</span><span class="mi">3</span> <span class="o">-</span> <span class="n">tx</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="mi">2</span> <span class="o">+</span> <span class="n">tx</span>

  <span class="c1"># Numerical integration of f(t) using Riemann Sum</span>
  <span class="n">n</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">max_val</span><span class="o">-</span><span class="n">min_val</span><span class="p">)</span><span class="o">/</span><span class="n">dt</span><span class="p">)</span>
  <span class="n">r_tx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
  <span class="n">fun_value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">min_val</span><span class="o">+</span><span class="n">ii</span><span class="o">*</span><span class="n">dt</span>
    <span class="n">fun_value</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">a</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">r_tx</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">;</span>

  <span class="c1"># Riemann sum is just cumulative sum of the fun_value multiplied by the</span>
  <span class="n">r_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">fun_value</span><span class="p">)</span><span class="o">*</span><span class="n">dt</span>
  <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">xkcd</span><span class="p">():</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">ftn</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Function&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
      <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">r_tx</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span> <span class="n">r_tx</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span> <span class="n">r_tx</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">+</span><span class="n">dt</span><span class="p">,</span> <span class="n">r_tx</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">+</span><span class="n">dt</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">fun_value</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span> <span class="n">fun_value</span><span class="p">[</span><span class="n">ii</span><span class="p">],</span> <span class="mi">0</span><span class="p">]</span> <span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time (au)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;f(t)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;f(t)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">int_ftn</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Analytical&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r_tx</span><span class="o">+</span><span class="n">dt</span><span class="p">,</span><span class="n">r_sum</span><span class="p">,</span><span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Riemann Sum&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time (au)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;int(f(t))&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Integral of f(t)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="n">_</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">riemann_sum_demo</span><span class="p">,</span> <span class="n">dt</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">.02</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D4_Calculus/solutions/W0D4_Tutorial1_Solution_fd942e45.py"><em>Click for solution</em></a></p>
<p>There are more advanced methods of numerical integration, such as Rungga-Kutta. In any case, the Riemann sum is the basis of Euler’s method of integration for solving ordinary differential equations - something you will do in a later tutorial today.</p>
<p>See Bonus Section 1 to work through some examples of neural applications of numerical integration.</p>
</div>
</div>
<div class="section" id="section-4-2-neural-applications-of-numerical-integration">
<h2>Section 4.2: Neural Applications of Numerical Integration<a class="headerlink" href="#section-4-2-neural-applications-of-numerical-integration" title="Permalink to this headline">¶</a></h2>
<div class="section" id="coding-exercise-4-2-calculating-charge-transfer-with-excitatory-input">
<h3>Coding Exercise 4.2: Calculating Charge Transfer with Excitatory Input<a class="headerlink" href="#coding-exercise-4-2-calculating-charge-transfer-with-excitatory-input" title="Permalink to this headline">¶</a></h3>
<p>An incoming spike elicits a change in the post-synaptic membrane potential which can be captured by the following function</p>
<div class="amsmath math notranslate nohighlight" id="equation-20a6ef49-c133-4a40-bcbc-fbe116f25bac">
<span class="eqno">(6)<a class="headerlink" href="#equation-20a6ef49-c133-4a40-bcbc-fbe116f25bac" title="Permalink to this equation">¶</a></span>\[\begin{align}
PSP(t) = J\times t\times exp\big(-\frac{t-t_{sp}}{\tau_{s}}\big)
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(J\)</span> is the synaptic amplitude, <span class="math notranslate nohighlight">\(t_{sp}\)</span> is the spike time and <span class="math notranslate nohighlight">\(\tau_s\)</span> is the synaptic time constant.</p>
<p>Estimate the total charge transfered to the postsynaptic neuron during an PSP with amplitude <span class="math notranslate nohighlight">\(J=1.0\)</span>, <span class="math notranslate nohighlight">\(\tau_s = 1.0\)</span> and <span class="math notranslate nohighlight">\(t_{sp} = 1.\)</span> (that is the spike occured at 1ms). The total charge will be the integral of the PSP function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set up parameters</span>
<span class="n">J</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">tau_s</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">t_sp</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">dt</span> <span class="o">=</span> <span class="mf">.1</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">dt</span><span class="p">)</span>

<span class="c1"># Code PSP formula</span>
<span class="n">PSP</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># Compute numerical integral</span>
<span class="c1"># We already have PSP at every time step (height of rectangles). We need to</span>
<span class="c1">#.  multiply by width of rectangles (dt) to get areas</span>
<span class="n">rectangle_areas</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># Cumulatively sum rectangles (hint: use np.cumsum)</span>
<span class="n">numerical_integral</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># Visualize</span>
<span class="c1"># plot_charge_transfer(t, PSP, numerical_integral)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W0D4_Calculus/solutions/W0D4_Tutorial1_Solution_200c1e98.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=843 height=303 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W0D4_Calculus/static/W0D4_Tutorial1_Solution_200c1e98_0.png>
<p>You can see from the figure that the total charge transferred is a little over 2.5.</p>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-5-integration-and-differentiation-as-filtering-operations">
<h1>Section 5: Integration and Differentiation as Filtering Operations<a class="headerlink" href="#section-5-integration-and-differentiation-as-filtering-operations" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 6: Filtering Operations</span>
<span class="c1"># Insert the ID of the corresponding youtube video</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;TQ0t-S3__OA&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>In the above, we used the notions that geometrically integration is the area under the curve and differentiation is the slope of the curve. There is another interpretation of these two operations.</p>
<p>As we calculate the derivative of a function, we take the difference of adjacent values of the function. This results in the removal of common part between the two values. As a consequence, we end up removing the unchanging part of the signal. If we now think in terms of frequencies, differentiation removes low frequencies, or slow changes. That is, differentiation acts as a high pass filter.</p>
<p>Integration does the opposite because in the estimation of an integral we keep adding adjacent values of the signal. So, again thinking in terms of frequencies, integration is akin to the removal of high frequencies or fast changes (low-pass filter). The shock absorbers in your bike are an example of integrators.</p>
<p>We can see this behavior the demo below. Here we will not work with functions, but with signals. As such, functions and signals are the same. Just that in most cases our signals are measurements with respect to time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to see visualization</span>
<span class="n">h</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">tx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">h</span><span class="p">)</span>
<span class="n">noise_signal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,(</span><span class="nb">len</span><span class="p">(</span><span class="n">tx</span><span class="p">)))</span><span class="o">*</span><span class="mf">0.5</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">tx</span><span class="p">)</span> <span class="o">+</span> <span class="n">noise_signal</span> <span class="c1"># This will generate a 1 Hz sin wave</span>
<span class="c1"># In the signal x1 we have added random noise which contributs the high frequencies</span>

<span class="c1"># Take the derivative equivalent of the signal i.e. subtract the adjacent values</span>
<span class="n">x1_diff</span> <span class="o">=</span> <span class="p">(</span><span class="n">x1</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">x1</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># Take the integration equivalent of the signal i.e. sum the adjacent values. Ans divide by 2 (take average essentially)</span>
<span class="n">x1_integrate</span> <span class="o">=</span> <span class="p">(</span><span class="n">x1</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">x1</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">x1</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Original Signal&#39;</span><span class="p">)</span>
<span class="c1">#plt.xlabel(&#39;Time (sec)&#39;)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Signal Value(au)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tx</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">x1_diff</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Differentiated Signal&#39;</span><span class="p">)</span>
<span class="c1"># plt.xlabel(&#39;Time (sec)&#39;)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Differentiated Value(au)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tx</span><span class="p">,</span><span class="n">x1</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Original Signal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tx</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">x1_integrate</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Integrate Signal&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time (sec)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Integrate Value(au)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Notice how the differentiation operation amplifies the fast changes which were contributed by noise. By contrast, the integration operation supresses the fast changing noise. Such sums and subtractions form the basis of digital filters.
Vary the signal characteristic to see how fast you can use these operations to enhance or supress noise.</p>
<p>Also if you want to be adventurous, you may try to use these operations in series and see what happens.</p>
</div>
<hr class="docutils" />
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Geometrically, integration is the area under the curve and differentiation is the slope of the function</p></li>
<li><p>The concepts of slope and area can be easily extended to higher dimensions. We saw this when we took the derivative of a 2-dimensional transfer function of a neuron</p></li>
<li><p>Numerical estimates of both derivatives and integrals require us to choose a time step <span class="math notranslate nohighlight">\(h\)</span>. The smaller the <span class="math notranslate nohighlight">\(h\)</span>, the better the estimate, but for small values of <span class="math notranslate nohighlight">\(h\)</span>, more computations are needed. So there is always some tradeoff.</p></li>
<li><p>Partial derivatives are just the estimate of the slope along one of the many dimensions of the function. We can combine the slopes in different directions using vector sum to find the direction of the slope.</p></li>
<li><p>Because the derivative of a function is zero at the local peak or trough, derivatives are used to solve optimization problems.</p></li>
<li><p>When thinking of signal, integration operation is equivalent to smoothening the signals (i.e. remove fast changes)</p></li>
<li><p>Differentiation operations remove slow changes and enhance high frequency content of a signal</p></li>
</ul>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W0D4_Calculus/student"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../chapter_title.html" title="previous page">Calculus</a>
    <a class='right-next' id="next-link" href="W0D4_Tutorial2.html" title="next page">Tutorial 2: Differential Equations</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Neuromatch<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>