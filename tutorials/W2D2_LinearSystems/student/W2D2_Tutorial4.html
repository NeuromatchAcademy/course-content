
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Tutorial 4: Autoregressive models &#8212; Neuromatch Computational Neuroscience</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Outro Video" href="../outro_vid.html" />
    <link rel="prev" title="Tutorial 3: Combining determinism and stochasticity" href="W2D2_Tutorial3.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      <img src="../../../_static/nma-logo-square-4xp.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Neuromatch Computational Neuroscience</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../../intro.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Pre-reqs Refresher
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D1_PythonWorkshop1/intro_text.html">
   Python Workshop 1 (W0D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D1_PythonWorkshop1/student/W0D1_Tutorial1.html">
     Tutorial: LIF Neuron - Part I
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D2_PythonWorkshop2/intro_text.html">
   Python Workshop 2 (W0D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D2_PythonWorkshop2/student/W0D2_Tutorial1.html">
     Tutorial 1: LIF Neuron Part II
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D3_LinearAlgebra/intro_text.html">
   Linear Algebra (W0D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial1.html">
     Tutorial 1: Vectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial2.html">
     Tutorial 2: Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial3.html">
     Bonus Tutorial: Discrete Dynamical Systems
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D4_Calculus/intro_text.html">
   Calculus (W0D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial1.html">
     Tutorial 1: Basics of Differential and Integral Calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial2.html">
     Tutorial 2: Differential Equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial3.html">
     Tutorial 3: Numerical Methods
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D5_Statistics/intro_text.html">
   Statistics (W0D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial1.html">
     Neuromatch Academy: Precourse Week, Day 5, Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial2.html">
     Tutorial 2: Statistical Inference
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Intro to Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D1_ModelTypes/intro_text.html">
   Model Types (W1D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial1.html">
     Tutorial 1: “What” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial2.html">
     Tutorial 2: “How” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial3.html">
     Tutorial 3: “Why” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/outro_vid.html">
     Outro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D2_ModelingPractice/intro_text.html">
   Modeling Practice (W1D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_ModelingPractice/intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_ModelingPractice/student/W1D2_Tutorial1.html">
     Tutorial: Framing the Question
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_ModelingPractice/outro_vid.html">
     Outro Video
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D3_ModelFitting/intro_text.html">
   Model Fitting (W1D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial1.html">
     Tutorial 1: Linear regression with MSE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial2.html">
     Tutorial 2: Linear regression with MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial3.html">
     Tutorial 3: Confidence intervals and bootstrapping
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial4.html">
     Tutorial 4: Multiple linear regression and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial5.html">
     Tutorial 5: Model Selection: Bias-variance trade-off
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial6.html">
     Tutorial 6: Model Selection: Cross-validation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/outro_vid.html">
     Outro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/intro_text.html">
   Generalized Linear Models (W1D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/student/W1D4_Tutorial1.html">
     Tutorial 1: GLMs for Encoding
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/student/W1D4_Tutorial2.html">
     Tutorial 2: Classifiers and regularizers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/outro_vid.html">
     Outro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D4_GeneralizedLinearModels/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D5_DimensionalityReduction/intro_text.html">
   Dimensionality Reduction (W1D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial1.html">
     Tutorial 1: Geometric view of data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial2.html">
     Tutorial 2: Principal Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial3.html">
     Tutorial 3: Dimensionality Reduction &amp; Reconstruction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial4.html">
     Tutorial 4:  Nonlinear Dimensionality Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/outro_vid.html">
     Outro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D1_DeepLearning/intro_text.html">
   Deep Learning (W2D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial3.html">
     Tutorial 2: Building and Evaluating Normative Encoding Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/outro_vid.html">
     Outro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Dynamical Systems
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../intro_text.html">
   Linear Systems (W2D2)
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="W2D2_Tutorial1.html">
     Tutorial 1: Linear dynamical systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="W2D2_Tutorial2.html">
     Tutorial 2: Markov Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="W2D2_Tutorial3.html">
     Tutorial 3: Combining determinism and stochasticity
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Tutorial 4: Autoregressive models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../outro_vid.html">
     Outro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/intro_text.html">
   Biological Neuron Models (W2D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial1.html">
     Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial2.html">
     Tutorial 2: Effects of Input Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial3.html">
     Tutorial 3: Synaptic transmission - Models of static and dynamic synapses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/student/W2D3_Tutorial4.html">
     Tutorial 4: Spike-timing dependent plasticity (STDP)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/outro_vid.html">
     Outro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_BiologicalNeuronModels/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D4_DynamicNetworks/intro_text.html">
   Dynamic Networks (W2D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial1.html">
     Tutorial 1: Neural Rate Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial2.html">
     Tutorial 2: Wilson-Cowan Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/outro_vid.html">
     Outro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Stochastic Processes
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D1_BayesianDecisions/intro_text.html">
   Bayesian Decisions (W3D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial1.html">
     Tutorial 1: Bayes with a binary hidden state
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial2.html">
     Tutorial 2: Bayesian inference and decisions with continuous hidden state
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial3.html">
     Bonus Tutorial:Fitting to data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/outro_vid.html">
     Outro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D2_HiddenDynamics/intro_text.html">
   Hidden Dynamics (W3D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial1.html">
     Tutorial 1: Sequential Probability Ratio Test
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial2.html">
     Tutorial 2: Hidden Markov Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial3.html">
     Tutorial 3: 1D Kalman Filter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial4.html">
     Tutorial 4: 2D Kalman Filter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/outro_vid.html">
     Outro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D3_OptimalControl/intro_text.html">
   Optimal Control (W3D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial1.html">
     Tutorial 1: Optimal Control for Discrete States
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial2.html">
     Tutorial 2: Optimal Control for Continuous State
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/outro_vid.html">
     Outro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D4_ReinforcementLearning/intro_text.html">
   Reinforcement Learning (W3D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial4.html">
     Tutorial 4: From Reinforcement Learning to Planning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/outro_vid.html">
     Outro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D5_NetworkCausality/intro_text.html">
   Network Causality (W3D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial1.html">
     Tutorial 1: Interventions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial2.html">
     Tutorial 2: Correlations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial3.html">
     Tutorial 3: Simultaneous fitting/regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial4.html">
     Tutorial 4: Instrumental Variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/outro_vid.html">
     Outro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/further_reading.html">
     Suggested further readings
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../../_sources/tutorials/W2D2_LinearSystems/student/W2D2_Tutorial4.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/NeuromatchAcademy/course_content/blob/master/book/tutorials/W2D2_LinearSystems/student/W2D2_Tutorial4.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Tutorial 4: Autoregressive models
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-1-fitting-data-to-the-ou-process">
   Section 1: Fitting data to the OU process
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-1-4a-residuals-of-the-autoregressive-model">
     Exercise 1 (4A): Residuals of the autoregressive model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#section-2-higher-order-autoregressive-models">
   Section 2: Higher order autoregressive models
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#think">
     Think:
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-2-4b-fitting-ar-models">
     Exercise 2 (4B): Fitting AR models
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/master/tutorials/W2D2_LinearSystems/student/W2D2_Tutorial4.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<div class="section" id="tutorial-4-autoregressive-models">
<h1>Tutorial 4: Autoregressive models<a class="headerlink" href="#tutorial-4-autoregressive-models" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 2, Day 2: Linear Systems</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content Creators</strong>: Bing Wen Brunton, Biraj Pandey</p>
<p><strong>Content Reviewers</strong>: Norma Kuhn, John Butler, Matthew Krause, Ella Batty, Richard Gao, Michael Waskom</p>
</div>
<hr class="docutils" />
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p>The goal of this tutorial is to use the modeling tools and intuitions developed in the previous few tutorials and use them to <em>fit data</em>. The concept is to flip the previous tutorial – instead of generating synthetic data points from a known underlying process, what if we are given data points measured in time and have to learn the underlying process?</p>
<p>This tutorial is in two sections.</p>
<p><strong>Section 1</strong> walks through using regression of data to solve for the coefficient of an OU process from Tutorial 3. Next, <strong>Section 2</strong> generalizes this auto-regression framework to high-order autoregressive models, and we will try to fit data from monkeys at typewriters.</p>
</div>
<hr class="docutils" />
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Figure settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>       <span class="c1"># interactive display</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper Functions</span>
<span class="c1"># drift-diffusion model, from Tutorial 3</span>
<span class="k">def</span> <span class="nf">ddm</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">xinfty</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">sig</span><span class="p">):</span>
  <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">  Samples a trajectory of a drift-diffusion model.</span>

<span class="sd">  args:</span>
<span class="sd">  T (integer): length of time of the trajectory</span>
<span class="sd">  x0 (float): position at time 0</span>
<span class="sd">  xinfty (float): equilibrium position</span>
<span class="sd">  lam (float): process param</span>
<span class="sd">  sig: standard deviation of the normal distribution</span>

<span class="sd">  returns:</span>
<span class="sd">  t (numpy array of floats): time steps from 0 to T sampled every 1 unit</span>
<span class="sd">  x (numpy array of floats): position at every time step</span>
<span class="sd">  &#39;&#39;&#39;</span>
  <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
  <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">x0</span>

  <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
      <span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">xinfty</span> <span class="o">+</span> <span class="n">lam</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">-</span> <span class="n">xinfty</span><span class="p">)</span> <span class="o">+</span> <span class="n">sig</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">build_time_delay_matrices</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Builds x1 and x2 for regression</span>

<span class="sd">    Args:</span>
<span class="sd">    x (numpy array of floats): data to be auto regressed</span>
<span class="sd">    r (scalar): order of Autoregression model</span>

<span class="sd">    Returns:</span>
<span class="sd">    (numpy array of floats) : to predict &quot;x2&quot;</span>
<span class="sd">    (numpy array of floats) : predictors of size [r,n-r], &quot;x1&quot;</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># construct the time-delayed data matrices for order-r AR model</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="n">r</span><span class="p">)</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">x1</span><span class="p">,</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="n">r</span><span class="p">]))</span>
    <span class="n">xprime</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">r</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">xprime</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">xprime</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">x1</span><span class="p">,</span> <span class="n">xprime</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="n">r</span><span class="p">]))</span>

    <span class="n">x2</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">r</span><span class="p">:]</span>

    <span class="k">return</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span>

<span class="k">def</span> <span class="nf">AR_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Solves Autoregression problem of order (r) for x</span>

<span class="sd">    Args:</span>
<span class="sd">    x (numpy array of floats): data to be auto regressed</span>
<span class="sd">    r (scalar): order of Autoregression model</span>

<span class="sd">    Returns:</span>
<span class="sd">    (numpy array of floats) : to predict &quot;x2&quot;</span>
<span class="sd">    (numpy array of floats) : predictors of size [r,n-r], &quot;x1&quot;</span>
<span class="sd">    (numpy array of floats): coefficients of length [r] for prediction after</span>
<span class="sd">    solving the regression problem &quot;p&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span> <span class="o">=</span> <span class="n">build_time_delay_matrices</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>

    <span class="c1"># solve for an estimate of lambda as a linear regression problem</span>
    <span class="n">p</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">rnk</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">x1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span>

<span class="k">def</span> <span class="nf">AR_prediction</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the prediction for test data &quot;x_test&quot; with the regression</span>
<span class="sd">    coefficients p</span>

<span class="sd">    Args:</span>
<span class="sd">    x_test (numpy array of floats): test data to be predicted</span>
<span class="sd">    p (numpy array of floats): regression coefficients of size [r] after</span>
<span class="sd">    solving the autoregression (order r) problem on train data</span>

<span class="sd">    Returns:</span>
<span class="sd">    (numpy array of floats): Predictions for test data. +1 if positive and -1</span>
<span class="sd">    if negative.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span> <span class="o">=</span> <span class="n">build_time_delay_matrices</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Evaluating the AR_model function fit returns a number.</span>
    <span class="c1"># We take the sign (- or +) of this number as the model&#39;s guess.</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">error_rate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the error of the Autoregression model. Error is the number of</span>
<span class="sd">    mismatched predictions divided by total number of test points.</span>

<span class="sd">    Args:</span>
<span class="sd">    x_test (numpy array of floats): data to be predicted</span>
<span class="sd">    p (numpy array of floats): regression coefficients of size [r] after</span>
<span class="sd">    solving the autoregression (order r) problem on train data</span>

<span class="sd">    Returns:</span>
<span class="sd">    (float): Error (percentage).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span> <span class="o">=</span> <span class="n">build_time_delay_matrices</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">x2</span> <span class="o">-</span> <span class="n">AR_prediction</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_residual_histogram</span><span class="p">(</span><span class="n">res</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Helper function for Exercise 4A&quot;&quot;&quot;</span>
  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;error in linear model&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;stdev of errors = </span><span class="si">{std:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">std</span><span class="o">=</span><span class="n">res</span><span class="o">.</span><span class="n">std</span><span class="p">()))</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">plot_training_fit</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Helper function for Exercise 4B&quot;&quot;&quot;</span>
  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x2</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x2</span><span class="p">))</span><span class="o">*</span><span class="mf">0.02</span><span class="p">,</span>
              <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training fit, order </span><span class="si">{r:d}</span><span class="s1"> AR model&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r</span><span class="o">=</span><span class="n">r</span><span class="p">))</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;estimated x&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="section-1-fitting-data-to-the-ou-process">
<h1>Section 1: Fitting data to the OU process<a class="headerlink" href="#section-1-fitting-data-to-the-ou-process" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 1: Autoregressive models</span>
<span class="c1"># Insert the ID of the corresponding youtube video</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;VdiVSTPbJ7I&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>To see how this works, let’s continue the previous example with the drift-diffusion (OU) process. Our process had the following form:</p>
<p><span class="math notranslate nohighlight">\(x_{k+1} = x_{\infty} + \lambda(x_k - x_{\infty}) + \sigma \eta\)</span></p>
<p>where <span class="math notranslate nohighlight">\(\eta\)</span> is sampled from a standard normal distribution.</p>
<p>For simplity, we set <span class="math notranslate nohighlight">\(x_\infty = 0\)</span>. Let’s plot a trajectory for this process again below. Take note of the parameters of the process because they will be important later. <strong>Run the code cell below.</strong></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Simulating the drift diffusion model</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2020</span><span class="p">)</span> <span class="c1"># set random seed</span>

<span class="c1"># parameters</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">x0</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">xinfty</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">lam</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">sig</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="c1"># drift-diffusion model from tutorial 3</span>
<span class="n">t</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">ddm</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">xinfty</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">sig</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;$x_0=</span><span class="si">%d</span><span class="s1">, x_{\infty}=</span><span class="si">%d</span><span class="s1">, \lambda=</span><span class="si">%0.1f</span><span class="s1">, \sigma=</span><span class="si">%0.1f</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">xinfty</span><span class="p">,</span> <span class="n">lam</span><span class="p">,</span> <span class="n">sig</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="s1">&#39;k.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;time&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;position x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>What if we were given these positions <span class="math notranslate nohighlight">\(x\)</span> as they evolve in time as data, how would we get back out the dynamics of the system <span class="math notranslate nohighlight">\(\lambda\)</span>?</p>
<p>Since a little bird told us that this system takes on the form</p>
<p><span class="math notranslate nohighlight">\(x_{k+1} = \lambda x_k + \eta\)</span>,</p>
<p>where <span class="math notranslate nohighlight">\(\eta\)</span> is noise from a normal distribution, our approach is to solve for <span class="math notranslate nohighlight">\(\lambda\)</span> as a <strong>regression problem</strong>.</p>
<p>As a check, let’s plot every pair of points adjacent in time (<span class="math notranslate nohighlight">\(x_{k+1}\)</span> vs. <span class="math notranslate nohighlight">\(x_k\)</span>) against eachother to see if there is a linear relationship between them. <strong>Run the code cell below.</strong></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title X(k) vs. X(k+1)</span>
<span class="c1"># make a scatter plot of every data point in x</span>
<span class="c1"># at time k versus time k+1</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$x_{k+1} = x_k$ line&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$x_k$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$x_{k+1}$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Hooray, it’s a line! This is evidence that that the <em>dynamics that generated the data</em> is <strong>linear</strong>. We can now reformulate this task as a regression problem.</p>
<p>Let <span class="math notranslate nohighlight">\(\mathbf{x_1} = x_{0:T-1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{x_2} = x_{1:T}\)</span> be vectors of the data indexed so that they are shifted in time by one. Then, our regression problem is</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}_2 = \lambda \mathbf{x}_1\]</div>
<p>This model is <strong>autoregressive</strong>, where <em>auto</em> means self. In other words, it’s a regression of the time series on itself from the past. The equation as written above is only a function of itself from <em>one step</em> in the past, so we can call it a <em>first order</em> autoregressive model.</p>
<p>Now, let’s set up the regression problem below and solve for <span class="math notranslate nohighlight">\(\lambda.\)</span> We will plot our data with the regression line to see if they agree. <strong>Run the code cell below.</strong></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Solving for lambda through autoregression</span>
<span class="c1"># build the two data vectors from x</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">x1</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">**</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">x2</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># solve for an estimate of lambda as a linear regression problem</span>
<span class="n">p</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">rnk</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># here we&#39;ve artificially added a vector of 1&#39;s to the x1 array,</span>
<span class="c1"># so that our linear regression problem has an intercept term to fit.</span>
<span class="c1"># we expect this coefficient to be close to 0.</span>
<span class="c1"># the second coefficient in the regression is the linear term:</span>
<span class="c1"># that&#39;s the one we&#39;re after!</span>
<span class="n">lam_hat</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># plot the data points</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$x_k$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$x_{k+1}$&#39;</span><span class="p">)</span>

<span class="c1"># plot the 45 degree line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$x_{k+1} = x_k$ line&#39;</span><span class="p">)</span>


<span class="c1"># plot the regression line on top</span>
<span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">sig</span><span class="o">*</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">yy</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">lam_hat</span> <span class="o">*</span> <span class="n">xx</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;regression line&#39;</span><span class="p">)</span>

<span class="n">mytitle</span> <span class="o">=</span> <span class="s1">&#39;True $\lambda$ = </span><span class="si">{lam:.4f}</span><span class="s1">, Estimate $\lambda$ = </span><span class="si">{lam_hat:.4f}</span><span class="s1">&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">mytitle</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lam</span><span class="o">=</span><span class="n">lam</span><span class="p">,</span> <span class="n">lam_hat</span><span class="o">=</span><span class="n">lam_hat</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Pretty cool! So now we have a way to predict <span class="math notranslate nohighlight">\(x_{k+1}\)</span> if given any data point <span class="math notranslate nohighlight">\(x_k\)</span>. Let’s take a look at how accurate this one-step prediction might be by plotting the residuals.</p>
<div class="section" id="exercise-1-4a-residuals-of-the-autoregressive-model">
<h2>Exercise 1 (4A): Residuals of the autoregressive model<a class="headerlink" href="#exercise-1-4a-residuals-of-the-autoregressive-model" title="Permalink to this headline">¶</a></h2>
<p>Plot a histogram of residuals of our autoregressive model, by taking the difference between the <em>data</em> <span class="math notranslate nohighlight">\(\mathbf{x_2}\)</span> and the <em>model</em> prediction. Do you notice anything about the standard deviation of these residuals and the equations that generated this synthetic dataset?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">##############################################################################</span>
<span class="c1">## Insert your code here take to compute the residual (error)</span>
<span class="c1">##############################################################################</span>
<span class="c1"># compute the predicted values using the autoregressive model (lam_hat), and</span>
<span class="c1"># the residual is the difference between x2 and the prediction</span>
<span class="c1"># res = ...</span>

<span class="c1"># Uncomment once you fill out above</span>
<span class="c1">#plot_residual_histogram(res)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W2D2_LinearSystems/solutions/W2D2_Tutorial4_Solution_cd2c0633.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=560 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W2D2_LinearSystems/static/W2D2_Tutorial4_Solution_cd2c0633_0.png>
</div>
</div>
<hr class="docutils" />
<div class="section" id="section-2-higher-order-autoregressive-models">
<h1>Section 2: Higher order autoregressive models<a class="headerlink" href="#section-2-higher-order-autoregressive-models" title="Permalink to this headline">¶</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 2: Monkey at a typewriter</span>
<span class="c1"># Insert the ID of the corresponding youtube video</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;f2z0eopWB8Y&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtu.be/&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we have established the autoregressive framework, generalizing for dependence on data points from the past is straightfoward. <strong>Higher order</strong> autoregression models a future time point based on <em>more than one points in the past</em>.</p>
<p>In one dimension, we can write such an order-<span class="math notranslate nohighlight">\(r\)</span> model as</p>
<p><span class="math notranslate nohighlight">\(x_{k+1} = \alpha_0 + \alpha_1 x_k + \alpha_2 x_{k-1} + \alpha_3 x_{k-2} + \dots + \alpha_{r+1} x_{k-r}\)</span>,</p>
<p>where the <span class="math notranslate nohighlight">\(\alpha\)</span>’s are the <span class="math notranslate nohighlight">\(r+1\)</span> coefficients to be fit to the data available.</p>
<p>These models are useful to account for some <strong>history dependence</strong> in the trajectory of timeseries. This next part of the tutorial will explore one such timeseries, and you can do an experiment on yourself!</p>
<p>In particular, we will explore a binary random sequence of 0’s and 1’s that would occur if you flipped a coin and jotted down the flips.</p>
<p>The difference is that, instead of actually flipping a coin (or using code to generate such a sequence), you – yes you, human – are going to generate such a random Bernoulli sequence as best as you can by typing in 0’s and 1’s. We will then build higher-order AR models to see if we can identify predictable patterns in the time-history of digits you generate.</p>
<p><strong>But first</strong>, let’s try this on a sequence with a simple pattern, just to make sure the framework is functional. Below, we generate an entirely predictable sequence and plot it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this sequence is entirely predictable, so an AR model should work</span>
<span class="n">monkey_at_typewriter</span> <span class="o">=</span> <span class="s1">&#39;1010101010101010101010101010101010101010101010101&#39;</span>

<span class="c1"># Bonus: this sequence is also predictable, but does an order-1 AR model work?</span>
<span class="c1">#monkey_at_typewriter = &#39;100100100100100100100100100100100100100&#39;</span>

<span class="c1"># function to turn chars to numpy array,</span>
<span class="c1"># coding it this way makes the math easier</span>
<span class="c1"># &#39;0&#39; -&gt; -1</span>
<span class="c1"># &#39;1&#39; -&gt; +1</span>
<span class="k">def</span> <span class="nf">char2array</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">s</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">char2array</span><span class="p">(</span><span class="n">monkey_at_typewriter</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;.-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;time&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;random variable&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Now, let’s set up our regression problem (order 1 autoregression like above) by defining <span class="math notranslate nohighlight">\(\mathbf{x_1}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{x_2}\)</span> and solve it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># build the two data vectors from x</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">x1</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">**</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">x2</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># solve for an estimate of lambda as a linear regression problem</span>
<span class="n">p</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">rnk</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># take a look at the resulting regression coefficients</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;alpha_0 = </span><span class="si">{a0:.2f}</span><span class="s1">, alpha_1 = </span><span class="si">{a1:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">a0</span><span class="o">=</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">a1</span><span class="o">=</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="think">
<h2>Think:<a class="headerlink" href="#think" title="Permalink to this headline">¶</a></h2>
<p>Do the values we got for <span class="math notranslate nohighlight">\(\alpha_0\)</span> and <span class="math notranslate nohighlight">\(\alpha_1\)</span> make sense? Write down the corresponding autoregressive model and convince yourself that it gives the alternating 0’s and 1’s we asked it to fit as data.</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W2D2_LinearSystems/solutions/W2D2_Tutorial4_Solution_3568b621.py"><em>Click for solution</em></a></p>
<p>Truly random sequences of numbers have no structure and should not be predictable by an AR or any other models.</p>
<p>However, humans are notoriously terrible at generating random sequences of numbers! (Other animals are no better…)</p>
<p>To test out an application of higher-order AR models, let’s use them to <strong>model a sequence of 0’s and 1’s that a human tried to produce at random</strong>. In particular, I convinced my 9-yr-old monkey to sit at a typewriter (my laptop) and enter some digits as randomly as he is able. The digits he typed in are in the code, and we can plot them as a timeseries of digits here.</p>
<p>If the digits really have no structure, then we expect our model to do about as well as guessing, producing an error rate of 0.5. Let’s see how well we can do!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># data generated by 9-yr-ld JAB:</span>
<span class="c1"># we will be using this sequence to train the data</span>
<span class="n">monkey_at_typewriter</span> <span class="o">=</span> <span class="s1">&#39;10010101001101000111001010110001100101000101101001010010101010001101101001101000011110100011011010010011001101000011101001110000011111011101000011110000111101001010101000111100000011111000001010100110101001011010010100101101000110010001100011100011100011100010110010111000101&#39;</span>

<span class="c1"># we will be using this sequence to test the data</span>
<span class="n">test_monkey</span> <span class="o">=</span> <span class="s1">&#39;00100101100001101001100111100101011100101011101001010101000010110101001010100011110&#39;</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">char2array</span><span class="p">(</span><span class="n">monkey_at_typewriter</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">char2array</span><span class="p">(</span><span class="n">test_monkey</span><span class="p">)</span>

<span class="c1">## testing: machine generated randint should be entirely unpredictable</span>
<span class="c1">## uncomment the lines below to try random numbers instead</span>
<span class="c1"># np.random.seed(2020) # set random seed</span>
<span class="c1"># x = char2array(np.random.randint(2, size=500))</span>
<span class="c1"># test = char2array(np.random.randint(2, size=500))</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;.-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="exercise-2-4b-fitting-ar-models">
<h2>Exercise 2 (4B): Fitting AR models<a class="headerlink" href="#exercise-2-4b-fitting-ar-models" title="Permalink to this headline">¶</a></h2>
<p>Fit a order-5 (<span class="math notranslate nohighlight">\(r=5\)</span>) AR model to the data vector <span class="math notranslate nohighlight">\(x\)</span>. To do this, we have included some helper functions, including <code class="docutils literal notranslate"><span class="pre">AR_model</span></code>.</p>
<p>We will then plot the observations against the trained model. Note that this means we are using a sequence of the previous 5 digits to predict the next one.</p>
<p>Additionally, output from our regression model are continuous (real numbers) whereas our data are scalar (+1/-1). So, we will take the sign of our continuous outputs (+1 if positive and -1 if negative) as our predictions to make them comparable with data. Our error rate will simply be the number of mismatched predictions divided by the total number of predictions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s see what our function AR model entails</span>
<span class="n">help</span><span class="p">(</span><span class="n">AR_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">##############################################################################</span>
<span class="c1">## TODO: Insert your code here for fitting the AR model</span>
<span class="c1">##############################################################################</span>
<span class="c1"># define the model order, and use AR_model() to generate the model and prediction</span>
<span class="c1"># r = ...</span>
<span class="c1"># x1, x2, p = AR_model(...)</span>


<span class="c1"># Uncomment below once you&#39;ve completed above</span>
<span class="c1"># Plot the Training data fit</span>
<span class="c1"># Note that this adds a small amount of jttter to horizontal axis for visualization purposes</span>
<span class="c1"># plot_training_fit(x1, x2, p)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W2D2_LinearSystems/solutions/W2D2_Tutorial4_Solution_7171e02c.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=560 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W2D2_LinearSystems/static/W2D2_Tutorial4_Solution_7171e02c_0.png>
<p>Let’s check out how the model does on the test data that it’s never seen before!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x1_test</span><span class="p">,</span> <span class="n">x2_test</span> <span class="o">=</span> <span class="n">build_time_delay_matrices</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x2_test</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x2_test</span><span class="p">))</span><span class="o">*</span><span class="mf">0.02</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x1_test</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">mytitle</span> <span class="o">=</span> <span class="s1">&#39;Testing fit, order </span><span class="si">{r:d}</span><span class="s1"> AR model, err = </span><span class="si">{err:.3f}</span><span class="s1">&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">mytitle</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">err</span><span class="o">=</span><span class="n">error_rate</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">p</span><span class="p">)))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;test x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;estimated x&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Not bad! We’re getting errors that are smaller than 0.5 (what we would have gotten by chance).</p>
<p>Let’s now try <strong>AR models of different orders</strong> systematically, and plot the test error of each.</p>
<p><em>Remember</em>: The model has never seen the test data before, and random guessing would produce an error of <span class="math notranslate nohighlight">\(0.5\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># range of r&#39;s to try</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>
<span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">r</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">rr</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">r</span><span class="p">):</span>
    <span class="c1"># fitting the model on training data</span>
    <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">AR_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">rr</span><span class="p">)</span>
    <span class="c1"># computing and storing the test error</span>
    <span class="n">test_error</span> <span class="o">=</span> <span class="n">error_rate</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
    <span class="n">err</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_error</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">err</span><span class="p">,</span> <span class="s1">&#39;.-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">r</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;random chance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Order r of AR model&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Test error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Notice that there’s a sweet spot in the test error! The 6th order AR model does a really good job here, and for larger <span class="math notranslate nohighlight">\(r\)</span>’s, the model starts to overfit the training data and does not do well on the test data.</p>
<p>In summary:</p>
<p>“<strong>I can’t believe I’m so predictable!</strong>” - JAB</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, we learned:</p>
<ul class="simple">
<li><p>How learning the parameters of a linear dynamical system can be formulated as a regression problem from data.</p></li>
<li><p>Time-history dependence can be incorporated into the regression framework as a multiple regression problem.</p></li>
<li><p>That humans are no good at generating random (not predictable) sequences. Try it on yourself!</p></li>
</ul>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W2D2_LinearSystems/student"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="W2D2_Tutorial3.html" title="previous page">Tutorial 3: Combining determinism and stochasticity</a>
    <a class='right-next' id="next-link" href="../outro_vid.html" title="next page">Outro Video</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Neuromatch<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>