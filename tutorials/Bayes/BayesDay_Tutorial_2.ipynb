{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hKBTPqcHykZk"
   },
   "source": [
    "## Neuromatch Academy 2020 -- Bayes Day (dry run)\n",
    "# Tutorial 2 - Causal Inference (mixture of Gaussians)\n",
    "\n",
    "Please execute the cell below to initialize the notebook environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "SBSQMfkZykZl"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "\n",
    "import time                        # import time \n",
    "import numpy as np                 # import numpy\n",
    "import scipy as sp                 # import scipy\n",
    "import math                        # import basic math functions\n",
    "import random                      # import basic random number generator functions\n",
    "\n",
    "import matplotlib.pyplot as plt    # import matplotlib\n",
    "from IPython import display        \n",
    "\n",
    "fig_w, fig_h = (6, 4)\n",
    "plt.rcParams.update({'figure.figsize': (fig_w, fig_h)})\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1kGSaKhXykZs"
   },
   "source": [
    "---\n",
    "\n",
    "### Tutorial objectives\n",
    "  \n",
    "In this notebook we'll look at creating mixtures of Gaussian distributions by applying a mixing weight to the distributions. \n",
    "    \n",
    "Mathematically, if we can control how the Gaussians are mixed by summing them and using a mixing parameter $\\alpha$:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "    \\text{Mixture} = \\left[ \\alpha \\times \\mathcal{N_1}(\\mu_{1},\\sigma_{1}) \\right] + \\left[ \\left( 1 - \\alpha \\right) \\times \\mathcal{N_2}(\\mu_{2},\\sigma_{2}) \\right]\n",
    "\\end{eqnarray}\n",
    "\n",
    "where $\\mathcal{N_{1}}$ and $\\mathcal{N_{2}}$ are the first and second Gaussian distributions used for the mixture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M6II_9AmykZt"
   },
   "source": [
    "---\n",
    "### EXERCISE 1: Mixture of Gaussians prior\n",
    "   \n",
    "We now want to create a prior that is the result of a mixture of gaussians.\n",
    "\n",
    "We provide you with a ready-to-use plotting functions, and a code skeleton to plot the resulting prior\n",
    "\n",
    "**Suggestions**\n",
    "* Using the equation for the un-normalised Gaussian `my_gaussian`:\n",
    "  * Generate a Gaussian with mean 0 and standard deviation 0.5\n",
    "  * Generate another Gaussian with mean 0 and standard deviation 10\n",
    "   * Combine the two Gaussians to make a new prior by mixing the two Gaussians with mixing parameter $\\alpha$ = 0.05. Make it such that the peakier Gaussian has 95% of the weight (don't forget to normalize afterwards)\n",
    "* Using the function `plot_my_composed_prior` provided, plot the resulting mixture of gaussian\n",
    "* Play with the means and variance of the two Gaussians and observe the resulting distribution to get an intuition of how the parameters affect the mixture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y34EhXtnykZu"
   },
   "outputs": [],
   "source": [
    "def my_dynamic_plot(x, prior, likelihood, posterior_pointwise):\n",
    "    \"\"\"\n",
    "    DO NOT EDIT THIS FUNCTION !!!\n",
    "\n",
    "    Plots the prior, likelihood and posterior distributions and update the figure\n",
    "    \n",
    "    Args: \n",
    "      x (numpy array of floats):         points at which the likelihood has been evaluated\n",
    "      auditory (numpy array of floats):  normalized probabilities for auditory likelihood evaluated at each `x`\n",
    "      visual (numpy array of floats):    normalized probabilities for visual likelihood evaluated at each `x`\n",
    "      posterior (numpy array of floats): normalized probabilities for the posterior evaluated at each `x`\n",
    "      \n",
    "    Returns: \n",
    "      Nothing\n",
    "    \"\"\"\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(x, prior, '-r', LineWidth=2, label='Prior')\n",
    "    plt.plot(x, likelihood, '-b', LineWidth=2, label='Likelihood')\n",
    "    plt.plot(x, posterior_pointwise, '-g', LineWidth=2, label='Posterior')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel('Orientation (Degrees)')\n",
    "    plt.legend()\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    time.sleep(0.2)\n",
    "\n",
    "def plot_my_composed_prior(x, gaussian1, gaussian2, combined):\n",
    "    \"\"\"\n",
    "    DO NOT EDIT THIS FUNCTION !!!\n",
    "\n",
    "    Plots a prior made of a mixture of gaussians\n",
    "    \n",
    "    Args: \n",
    "      x (numpy array of floats):         points at which the likelihood has been evaluated\n",
    "      gaussian1 (numpy array of floats): normalized probabilities for auditory likelihood evaluated at each `x`\n",
    "      gaussian2 (numpy array of floats): normalized probabilities for visual likelihood evaluated at each `x`\n",
    "      posterior (numpy array of floats): normalized probabilities for the posterior evaluated at each `x`\n",
    "             \n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    plt.plot(x, gaussian1, '--b', LineWidth=2, label='Gaussian 1')\n",
    "    plt.plot(x, gaussian2, '-.b', LineWidth=2, label='Gaussian 2')\n",
    "    plt.plot(x, combined, '-r', LineWidth=2, label='Gaussian Mixture')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel('Orientation (Degrees)')\n",
    "    \n",
    "    \n",
    "def my_gaussian(x_points, mu, sigma):\n",
    "    \"\"\"\n",
    "    DO NOT EDIT THIS FUNCTION !!!\n",
    "\n",
    "    Returns un-normalized Gaussian estimated at points `x_points`, with parameters `mu` and `sigma`\n",
    "    \n",
    "    Args: \n",
    "      x_points (numpy array of floats) - points at which the gaussian is evaluated\n",
    "      mu (scalar) - mean of the Gaussian\n",
    "      sigma (scalar) - standard deviation of the gaussian\n",
    "    Returns:\n",
    "      (numpy array of floats): un-normalized Gaussian (i.e. without constant) evaluated at `x`\n",
    "    \"\"\"\n",
    "    return np.exp(-(x_points-mu)**2/(2*sigma**2))\n",
    "\n",
    "x = np.arange(-10,11,0.1)\n",
    "\n",
    "###############################################################################\n",
    "## Insert your code here to:\n",
    "##        Create a Gaussian prior made of two Gaussian\n",
    "##        Both with mean 0 and variance 0.5 and 3 respectively\n",
    "##        Make the combined prior (made of the two Gaussians) by weighing it\n",
    "##        using a mixing parameter alpha = 0.05 such that the peakier Gaussian has\n",
    "##        weight 0.95\n",
    "##        Plot the two Gaussian and the resulting mixture using the function `plot_my_composed_prior`\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/static/sample_output.png\"/>\n",
    "\n",
    "<img width=\"450px\" src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/Bayes/Expected_outputs/Student_BayesDay_Tutorial_2_fig_1.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Im6Qo6_ykZ2"
   },
   "source": [
    "### EXERCISE 2: Bayes with mixture of Gaussians\n",
    "   \n",
    "We now want compute the posterior using *Bayes rule*, using the mixture of Gaussian as a prior, and a Gaussian likelihood.\n",
    "\n",
    "Using the plotting function `my_dynamic_plot` provided, see how the 'fat-tails' of the Gaussian mixture affects the linearity of the posetior mean as a function of the stimulus position.\n",
    "\n",
    "**Suggestions**\n",
    "\n",
    "   Using the Gaussian mixture from exercise 1 as a prior:\n",
    "\n",
    "* Allow the mean of the Gaussian likelihood to vary from -8 to 8 in steps of 0.2 degree, keeping $\\sigma$ of the visual stimuli to 1.\n",
    "* In a loop, calculate the posterior for each visual stimulus, and call the `my_dynamic_plot` function to plot it.\n",
    "* Calculate the mode of the posterior and plot it against the visual stimulus mean. \n",
    "   \n",
    "What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GPXs4v9hK2o6"
   },
   "outputs": [],
   "source": [
    "x = np.arange(-10,11,0.1)\n",
    "\n",
    "###############################################################################\n",
    "## Insert your code here to:\n",
    "##        Use the Gaussian mixture of Exercise 1 as your prior\n",
    "##        Create a Gaussian Likelihood with sigma = 1, and mean varying from -8 to 9 in increments of 0.2 Degrees\n",
    "##        Calculate the posterior by multiplying (pointwise) the 'auditory' and 'visual' gaussians\n",
    "##        (Hint: Do not forget to normalise the gaussians before plotting them)\n",
    "##        plot the distributions using the function `my_dynamic_plot`\n",
    "##        plot the posterior mode as a function of  visual's mean\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/static/sample_output.png\"/>\n",
    "\n",
    "<img width=\"450px\" src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/Bayes/Expected_outputs/Student_BayesDay_Tutorial_2_fig_2.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2eO6x8Q6Zh5I"
   },
   "source": [
    "---\n",
    "### EXERCISE 3: Mixture of Gaussian prior\n",
    "   \n",
    "We now want to create a prior matrix using the mixture of gaussians prior created in exercise 1.\n",
    "\n",
    "**Suggestions**\n",
    "\n",
    "  Using the prior you defined in Exercise 1: \n",
    "* The first row of your prior matrix will be your prior defined in Ex1.\n",
    "* Now repeat that row prior 20 times to make a matrix of 20 row-priors.\n",
    "* Plot the matrix using the function `plt.pcolor` already pre-written and commented-out in your script\n",
    "  - Notice how p_color displays the y-values of the matrix in reverse order (row 0 at the bottom, and row 20 at the top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ClzN22BrZmEi"
   },
   "outputs": [],
   "source": [
    "x = np.arange(-10,11,1)\n",
    "\n",
    "###############################################################################\n",
    "## Insert your code here to:\n",
    "##        Create a Gaussian prior made of two Gaussian\n",
    "##        Both with mu = 0 and sigma 0.5 and 3 respectively\n",
    "##        Make the combined prior (made of the two Gaussians) by weighing it\n",
    "##        using a mixing parameter alpha = 0.05 such that the peakier Gaussian has\n",
    "##        weight 30%\n",
    "##        This mixture will make up the first row of your matrix\n",
    "##        Now repeat this row-prior 20 times, to make up a Prior matrix of 20 identical row-priors (use the `np.tile()` function)\n",
    "##        Plot the Prior Matrix using the function `plt.pcolor` and the code snippet provided below\n",
    "###############################################################################\n",
    "\n",
    "# plt.pcolor(prior_matrix, edgecolors='w', linewidths=1)\n",
    "# plt.xticks(np.arange(x.shape[0]), x)\n",
    "# plt.title('Prior Matrix')\n",
    "# plt.ylabel('Repetitions')\n",
    "# plt.xlabel('Orientation (Degree)')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/static/sample_output.png\"/>\n",
    "\n",
    "<img width=\"450px\" src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/Bayes/Expected_outputs/Student_BayesDay_Tutorial_2_fig_3.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BS515ZBMbuwa"
   },
   "source": [
    "---\n",
    "### EXERCISE 4: Implement a Likelihood Matrix\n",
    "    \n",
    "We now want to create a Likelihood matrix that is made up of a Gaussian on each row of the matrix. Each row represents a different trial, with a different stimulus offset (i.e. a different likelihood mean).\n",
    "\n",
    "**Suggestions**\n",
    "\n",
    "  Using the equation for the un-normalised Gaussian `my_gaussian`:\n",
    "* Allow the mean of the Gaussian likelihood to vary in 21 steps spaced linearly between from -8 to 8 degree, keeping $\\sigma$ of the visual stimuli to 1.\n",
    "* Each Likelihood with a different mean will make up a different row-likelihood of your matrix, such that you end up with a Likelihood matrix made up of 20 row-Gaussians with different means\n",
    "* Plot the matrix using the function `plt.pcolor` already pre-written and commented-out in your script\n",
    "  - Notice how `p_color` displays the y-values of the matrix in reverse order (row 0 at the bottom, and row 20 at the top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b265fg7jbRoC"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Insert your code here to:\n",
    "##        Create a Gaussian Likelihood with sigma = 1, and mean varying from -8 to 9 in 21 equally spaced steps (use `np.linspace()` function)\n",
    "##        Each of the Gaussian Likelihood with a different mean will make up a different 'trial' and hence a different row of your matrix\n",
    "##        Fill in your matrix with the 20 different Gaussian likelihoods (i.e. 20 trials)\n",
    "##        Plot the Likelihood Matrix using the function `plt.pcolor` and the code snippet provided below\n",
    "###############################################################################\n",
    "\n",
    "# plt.figure()\n",
    "# plt.pcolor(likelihood_matrix, edgecolors='w', linewidths=1)\n",
    "# plt.xticks(np.arange(x.shape[0]), x)\n",
    "# plt.title('Likelihood Matrix')\n",
    "# plt.ylabel('Repetitions')\n",
    "# plt.xlabel('Orientation (Degree)')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/static/sample_output.png\"/>\n",
    "\n",
    "<img width=\"450px\" src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/Bayes/Expected_outputs/Student_BayesDay_Tutorial_2_fig_4.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rc5xpL6wcImW"
   },
   "source": [
    "---\n",
    "### EXERCISE 5: Implement the Posterior Matrix\n",
    "    \n",
    "We now want to create the Posterior matrix. To do so, we will compute the posterior using *Bayes rule* for each trial (i.e. row wise).\n",
    "\n",
    "That is, each row of the posterior matrix will be the posterior resulting from the multiplication of the prior and likelihood of the equivalent row.\n",
    "\n",
    "Mathematically:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "    Posterior\\left[i, :\\right] \\propto Likelihood\\left[i, :\\right] \\odot Prior\\left[i, :\\right]\n",
    "\\end{eqnarray}\n",
    "\n",
    "where $\\odot$ represent the [Hadamard Product](https://en.wikipedia.org/wiki/Hadamard_product_(matrices)) (i.e. the element_wise multiplication) of the Prior and Likelihood row vectors `i` from the matrix.\n",
    "\n",
    "**Suggestions**\n",
    "\n",
    "* For each row (trial) of the Prior and Likelihood matrix, calculate posterior and fill in the Posterior matrix, such that each row of the Posterior matrix represents the posterior for a different trial.\n",
    "* Plot the matrix using the function `plt.pcolor` already pre-written and commented-out in your script\n",
    "\n",
    "  - Notice how `p_color` displays the y-values of the matrix in reverse order (row 0 at the bottom, and row 20 at the top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "skouN9tZcKHQ"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Insert your code here to:\n",
    "##        For each row of the Prior & Likelihood Matrices, calculate the resulting posterior \n",
    "##        Fill the Posterior Matrix with the row_posterior\n",
    "##        Plot the Posterior Matrix using the function `plt.pcolor` and the code snippet provided below\n",
    "###############################################################################\n",
    "\n",
    "# plt.figure()\n",
    "# plt.pcolor(posterior_matrix, edgecolors='w', linewidths=1)\n",
    "# plt.xticks(np.arange(x.shape[0]), x)\n",
    "# plt.title('Posterior Matrix')\n",
    "# plt.ylabel('Repetitions')\n",
    "# plt.xlabel('Orientation (Degree)')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/static/sample_output.png\"/>\n",
    "\n",
    "<img width=\"450px\" src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/Bayes/Expected_outputs/Student_BayesDay_Tutorial_2_fig_5.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jqHxlXJtcsXN"
   },
   "source": [
    "---\n",
    "### EXERCISE 6: Implement the Binary Decision Matrix\n",
    "    \n",
    "We now want to create a Binary Decision Matrix. To do so, we will scan the Posterior matrix (i.e. row_wise), and set the matrix cell to 1 at the mode of the row posterior.\n",
    "\n",
    "This, effectively encodes the *decision* that a participant may make on a given trial (i.e. row). In this case, the modelled decision rule is to take the mode of the posterior on each trial.\n",
    "\n",
    "**Suggestions**\n",
    "\n",
    "* Create a matrix of the same size as the Posterior matrix and fill it with zeros (Hint: use `np.zeros_like()`).\n",
    "* For each row (trial) of the Posterior matrix, calculate the mode of the posterior, and set the corresponding cell of the Binary Decision Matrix to 1. (e.g. if the mode of the posterior is at position 0, then set the cell with x_column == 0 to 1).\n",
    "* Plot the matrix using the function `plt.pcolor` already pre-written and commented-out in your script\n",
    "  - Notice how `p_color` displays the y-values of the matrix in reverse order (row 0 at the bottom, and row 20 at the top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "czxaJcVtcvLL"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Insert your code here to:\n",
    "##        Create a matrix of the same size as the Posterior matrix and fill it with zeros (Hint: use np.zeros_like())\n",
    "##        For each row of the Posterior Matrix, calculate the mode of the posterior, and set the corresponding cell of the Binary Decision Matrix to 1. \n",
    "##        Plot the Posterior Matrix using the function `plt.pcolor` and the code snippet provided below\n",
    "###############################################################################\n",
    "\n",
    "# plt.figure()\n",
    "# plt.pcolor(binary_decision_matrix, edgecolors='w', linewidths=1)\n",
    "# plt.xticks(np.arange(x.shape[0]), x)\n",
    "# plt.title('Binary Decision Matrix')\n",
    "# plt.ylabel('Repetitions')\n",
    "# plt.xlabel('Orientation (Degree)')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/static/sample_output.png\"/>\n",
    "\n",
    "<img width=\"450px\" src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/Bayes/Expected_outputs/Student_BayesDay_Tutorial_2_fig_6.jpg\"/>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Shared_Tutorial2_BAYESDAY_colab",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
