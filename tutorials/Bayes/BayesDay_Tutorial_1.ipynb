{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YL2_mjdRyaSg"
   },
   "source": [
    "## Neuromatch Academy 2020 -- Bayes Day (dry run)\n",
    "# Tutorial 1 - Bayes rule with Gaussians\n",
    "\n",
    "Please execute the cell below to initialize the notebook environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "Tr8AjcsFyaSh"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import time                        # import time \n",
    "import numpy as np                 # import numpy\n",
    "import scipy as sp                 # import scipy\n",
    "import math                        # import basic math functions\n",
    "import random                      # import basic random number generator functions\n",
    "\n",
    "import matplotlib.pyplot as plt    # import matplotlib\n",
    "from IPython import display        \n",
    "\n",
    "fig_w, fig_h = (6, 4)\n",
    "plt.rcParams.update({'figure.figsize': (fig_w, fig_h)})\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTnwS5ZOyaSm"
   },
   "source": [
    "---\n",
    "\n",
    "## Tutorial objectives\n",
    "  \n",
    "In this notebook we'll look at using *Bayes rule* with *Gaussian distributions*. That is, given a prior probability distribution, and a likelihood distribution, we will compute the posterior using Bayes rule and play with different Likelihoods and Priors to get a good intuition of how it affects the posterior distribution. \n",
    "    \n",
    "* Given Bayes rule, a Gaussian Likelihood and Prior, calculate the posterior distribution.\n",
    "* Change the Likelihood mean, and variance and observe how Posterior changes.\n",
    "* Advanced: Observe what happens if the prior is a mixture of two gaussians?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PouDgJahyaSn"
   },
   "source": [
    "__Insert cover story here with figures, potentially with a GIF__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HB2U9wCNyaSo"
   },
   "source": [
    "## Bayes rule\n",
    "\\begin{eqnarray}\n",
    "Posterior = \\frac{ Likelihood \\quad \\times \\quad Prior}{ Normalization \\quad constant}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Mathematically, if both the Likelihood and the Prior are Gaussian, this translates into:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "    Likelihood = \\mathcal{N}(\\mu_{likelihood},\\sigma_{likelihood}^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_{likelihood}}}\\exp\\left(\\frac{-(x-\\mu_{likelihood})^2}{2\\sigma^2_{likelihood}}\\right)\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\begin{eqnarray}\n",
    "    Prior = \\mathcal{N}(\\mu_{prior},\\sigma_{prior}^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_{prior}}}\\exp\\left(\\frac{-(x-\\mu_{prior})^2}{2\\sigma^2_{prior}}\\right)\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\begin{eqnarray}\n",
    "    Posterior \\propto \\mathcal{N}(\\mu_{likelihood},\\sigma_{likelihood}^2) \\times \\mathcal{N}(\\mu_{prior},\\sigma_{prior}^2) = \\mathcal{N}\\left( \\frac{\\sigma^2_{likelihood}\\mu_{prior}+\\sigma^2_{prior}\\mu_{likelihood}}{\\sigma^2_{likelihood}+\\sigma^2_{prior}}, \\frac{\\sigma^2_{likelihood}\\sigma^2_{prior}}{\\sigma^2_{likelihood}+\\sigma^2_{prior}} \\right)\n",
    "\\end{eqnarray}\n",
    "\n",
    "where $\\mathcal{N}(\\mu,\\sigma^2)$ denotes a Gaussian distribution with parameters $\\mu_{likelihood}$ and $\\sigma^2_{likelihood}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjknQx1EyaSo"
   },
   "source": [
    "---\n",
    "<div class=\"badges\" style=\"display:inline-block\">\n",
    "    <div style=\"float:left;margin-top:10px;margin-right:10px;\">\n",
    "        <img src=\"https://github.com/mpbrigham/course-content/raw/master/tutorials/static/importance_1_badge.png\" style=\"height:100px\" />\n",
    "    </div>\n",
    "    <div style=\"float:left;margin-top:10px;margin-right:10px;\">\n",
    "        <img class=\"middle-img\" src=\"https://github.com/mpbrigham/course-content/raw/master/tutorials/static/python_1_badge.png\" style=\"height:100px\" />\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "### EXERCISE 1: Bayes rule with Gaussians: Computation\n",
    "\n",
    "We have a Gaussian auditory Likelihood (in red), and a Gaussian visual likelihood (in blue), and we want to combine the two to generate our posterior using Bayes rule.\n",
    "\n",
    "We provide you with a ready-to-use plotting function, and a code skeleton.\n",
    "\n",
    "**Suggestions**\n",
    "* Fill in the equation for the un-normalised (without the constant) Gaussian in the function skeleton function `my_gaussian`\n",
    "* Generate an auditory likelihood with parameters $\\mu$ = 3 and $\\sigma$ = 1.5\n",
    "* Generate a visual likelihood with parameters $\\mu$ = -1 and $\\sigma$ = 1.5\n",
    "* Calculate the posterior using pointwise multiplication of the auditory and visual likelihoods (don't forget to normalize)\n",
    "* Plot the Likelihoods and Posterior using the predefined function `my_plot`\n",
    "* Now change the variance of the visual likelihood to 0.5. \n",
    "\n",
    "   See how a more precise (tighter) visual likelihood relative to auditory results in a posterior that is weighted more heavily towards the most precise source of information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KqOpye6JyaSp"
   },
   "outputs": [],
   "source": [
    "def my_plot(x, auditory=None, visual=None, posterior_pointwise=None):\n",
    "    \"\"\"\n",
    "    Plots normalized Gaussian distributions and posterior \n",
    "\n",
    "    DO NOT EDIT THIS FUNCTION !!!\n",
    "    \n",
    "    Args:\n",
    "      x (numpy array of floats):         points at which the likelihood has been evaluated\n",
    "      auditory (numpy array of floats):  normalized probabilities for auditory likelihood evaluated at each `x`\n",
    "      visual (numpy array of floats):    normalized probabilities for visual likelihood evaluated at each `x`\n",
    "      posterior (numpy array of floats): normalized probabilities for the posterior evaluated at each `x`\n",
    "             \n",
    "    Returns:\n",
    "      Nothing.\n",
    "    \"\"\"\n",
    "    if auditory is None:\n",
    "        auditory = np.zeros_like(x)\n",
    "\n",
    "    if visual is None:\n",
    "        visual = np.zeros_like(x)\n",
    "\n",
    "    if posterior_pointwise is None:\n",
    "        posterior_pointwise = np.zeros_like(x)\n",
    "\n",
    "    plt.plot(x, auditory, '-r', LineWidth=2, label='Auditory')\n",
    "    plt.plot(x, visual, '-b', LineWidth=2, label='Visual')\n",
    "    plt.plot(x, posterior_pointwise, '-g', LineWidth=2, label='Posterior')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel('Orientation (Degrees)')\n",
    "\n",
    "def my_gaussian(x_points, mu, sigma):\n",
    "    \"\"\"\n",
    "    Returns un-normalized Gaussian estimated at points `x_points`, with parameters: mean `mu` and std `sigma`\n",
    "    \n",
    "    Args:\n",
    "      x_points (numpy array of floats): points at which the gaussian is evaluated\n",
    "      mu (scalar): mean of the Gaussian\n",
    "      sigma (scalar): std of the gaussian\n",
    "    \n",
    "    Returns: \n",
    "      (numpy array of floats) : un-normalized Gaussian (i.e. without constant) evaluated at `x`\n",
    "    \"\"\"\n",
    "\n",
    "    ###################################################################\n",
    "    ## Insert your code here to fill with the equation for the gaussian\n",
    "    ## Function Hints: exp -> np.exp()\n",
    "    ##                 power -> z**2       \n",
    "    ################################################################### \n",
    "        \n",
    "    # Calculate the gaussian as a function of mu and sigma, for each x (incl. hints )\n",
    "    raise NotImplementedError(\"You need to implement the Gaussian function!\")\n",
    "\n",
    "x = np.arange(-8,9,0.1)\n",
    "\n",
    "################################################################################\n",
    "## Insert your code here to:\n",
    "##      create a gaussian called 'auditory' with mean 3, and std 1.5\n",
    "##      create a gaussian called 'visual' with mean -1, and std 1.5\n",
    "##      calculate the posterior by multiplying (pointwise) the 'auditory' and 'visual' gaussians\n",
    "##      (Hint: Do not forget to normalise the gaussians before plotting them)\n",
    "##      plot the distributions using the function `my_plot`\n",
    "################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/static/sample_output.png\"/>\n",
    "<img width=\"450px\" src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/Bayes/Expected_outputs/Student_BayesDay_Tutorial_1_fig_1.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6e56uSp4yaSx"
   },
   "source": [
    "---\n",
    "<div class=\"badges\" style=\"display:inline-block\">\n",
    "    <div style=\"float:left;margin-top:10px;margin-right:10px;\">\n",
    "        <img src=\"https://github.com/mpbrigham/course-content/raw/master/tutorials/static/importance_1_badge.png\" style=\"height:100px\" />\n",
    "    </div>\n",
    "    <div style=\"float:left;margin-top:10px;margin-right:10px;\">\n",
    "        <img class=\"middle-img\" src=\"https://github.com/mpbrigham/course-content/raw/master/tutorials/static/python_2_badge.png\" style=\"height:100px\" />\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "### EXERCISE 2: Bayes rule with Gaussians: Intuition\n",
    "   \n",
    "Now that we can compute *Bayes rule* with two *Gaussians*, let's keep the auditory likelihood fixed straight ahead (mean = 0), and play around with the visual stimulus position (mean) to see how that affects the posterior.\n",
    "\n",
    "Observe how the posterior changes as a function of both the position of the likelihood with respect to the prior, and the relative weight of the likelihood with respect to the prior.\n",
    "\n",
    "**Suggestions**\n",
    "\n",
    "* Keep the prior constant with mean 0, and standard deviation 1.5\n",
    "* Keeping the standard deviation of the visual stimuli to 1, and allow the mean of the likelihood to vary from -8 to 8 in steps of 0.2 degree.\n",
    "* In a loop, calculate the posterior for each new visual stimulus, and call the `my_dynamic_plot` function to plot it.\n",
    "* Calculate the mean of the posterior and plot it against the visual stimulus mean. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xKvQrgFqyaSy"
   },
   "outputs": [],
   "source": [
    "def my_dynamic_plot(x, auditory, visual, posterior_pointwise):\n",
    "    \"\"\"\n",
    "    DO NOT EDIT THIS FUNCTION !!!\n",
    "\n",
    "    Plots the auditory, visual and posterior distributions and update the figure every .2 seconds\n",
    "    \n",
    "    Args: \n",
    "      x (numpy array of floats):         points at which the likelihood has been evaluated\n",
    "      auditory (numpy array of floats):  normalized probabilities for auditory likelihood evaluated at each `x`\n",
    "      visual (numpy array of floats):    normalized probabilities for visual likelihood evaluated at each `x`\n",
    "      posterior (numpy array of floats): normalized probabilities for the posterior evaluated at each `x`\n",
    "             \n",
    "    Returns:\n",
    "      Nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.plot(x, auditory, '-r', LineWidth=2, label='Auditory')\n",
    "    plt.plot(x, visual, '-b', LineWidth=2, label='Visual')\n",
    "    plt.plot(x, posterior_pointwise, '-g', LineWidth=2, label='Posterior')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel('Orientation (Degrees)')\n",
    "    plt.legend()\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    time.sleep(0.2)\n",
    "\n",
    "x = np.arange(-10,11,0.1)\n",
    "\n",
    "###############################################################################\n",
    "##  Insert your code here to:\n",
    "##      create a gaussian called 'auditory' with mean 0, and std 1.5\n",
    "##      create a gaussian called 'visual' with std 1.5, and mean varying from -8 to 9 in increments of 0.2 Degrees\n",
    "##      calculate the posterior by multiplying (pointwise) the 'auditory' and 'visual' gaussians\n",
    "##      (Hint: Do not forget to normalise the gaussians before plotting them)\n",
    "##      plot the distributions using the function `my_dynamic_plot`\n",
    "##      plot the posterior mean as a function of  visual's mean\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "JAM-cG9rg53X",
    "outputId": "1b56f5a3-af12-4144-e7d7-9560fc6f7a29"
   },
   "source": [
    "<img src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/static/sample_output.png\"/>\n",
    "<img width=\"450px\" src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/Bayes/Expected_outputs/Student_BayesDay_Tutorial_1_fig_2.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0IQkuPayaS5"
   },
   "source": [
    "---\n",
    "<div class=\"badges\" style=\"display:inline-block\">\n",
    "    <div style=\"float:left;margin-top:10px;margin-right:10px;\">\n",
    "        <img src=\"https://github.com/mpbrigham/course-content/raw/master/tutorials/static/importance_2_badge.png\" style=\"height:100px\" />\n",
    "    </div>\n",
    "    <div style=\"float:left;margin-top:10px;margin-right:10px;\">\n",
    "        <img class=\"middle-img\" src=\"https://github.com/mpbrigham/course-content/raw/master/tutorials/static/python_1_badge.png\" style=\"height:100px\" />\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "### ADVANCED Exercise: Multimodal priors\n",
    "\n",
    "Bayes rule works similarly for cue combination (auditory + visual) as it would with a prior and likelihood.\n",
    "What do you think is going to happen to the posterior if we were to use a multimodal prior instead of a single Gaussian (i.e. a prior with multiple peaks)?\n",
    "\n",
    "**Suggestions**\n",
    "\n",
    "* Create a bi-modal prior by summing two Gaussians centered on -3 and 3 respectively, with $\\sigma_{prior}$ = 1\n",
    "* Similarly to the previous exercise, allow the mean of the likelihood to vary and plot the prior, likelihood and posterior over time using the function `my_dynamic_plot`. \n",
    "   \n",
    "   - Observe what happens to the posterior as the likelihood gets closer to the different peaks of the prior.\n",
    "   - Notice what happens to the posterior when the likelihood is exactly in between the two modes of the prior (i.e. $\\mu_{Likelihood}$ = 0)\n",
    "\n",
    "* Plot the mode of the posterior as a function of the visual stimulus mean. \n",
    "   - What to you observe? How does it compare to the previous exercise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tzl8NFl3yaS6"
   },
   "outputs": [],
   "source": [
    "x = np.arange(-10,11,0.1)\n",
    "\n",
    "################################################################################\n",
    "## Insert your code here\n",
    "## Reuse your code from Exercise 2, but replace the prior with a bimodal prior \n",
    "## by summing two Gaussians with variance = 1, and means [-3, 3] respectively\n",
    "################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "colab_type": "code",
    "id": "F6ov7ISgjGtA",
    "outputId": "e536449b-8dab-4f62-ce16-1d279659440f"
   },
   "source": [
    "<img src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/static/sample_output.png\"/>\n",
    "<img width=\"450px\" src=\"https://github.com/NeuromatchAcademy/course-content/raw/master/tutorials/Bayes/Expected_outputs/Student_BayesDay_Tutorial_1_fig_3.jpg\"/>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Shared_Tutorial1_BAYESDAY_colab",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
