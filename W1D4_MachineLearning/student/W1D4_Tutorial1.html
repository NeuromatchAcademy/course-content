
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Tutorial 1: GLMs for Encoding &#8212; Neuromatch Computational Neuroscience</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Tutorial 2: Classifiers and regularizers" href="W1D4_Tutorial2.html" />
    <link rel="prev" title="W1D4 - Machine Learning (GLMs)" href="../intro_text.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      <img src="../../_static/nma-logo-square-4xp.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Neuromatch Computational Neuroscience</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Pre-reqs Refresher
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D1_PythonWorkshop1/intro_text.html">
   Python Workshop 1 (W0D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D1_PythonWorkshop1/student/W0D1_Tutorial1.html">
     Tutorial: LIF Neuron - Part I
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D2_PythonWorkshop2/intro_text.html">
   Python Workshop 2 (W0D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D2_PythonWorkshop2/student/W0D2_Tutorial1.html">
     Neuromatch Academy: Week 0, Day 2, Tutorial 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D3_LinearAlgebra/intro_text.html">
   Linear Algebra (W0D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial1.html">
     Tutorial 1: Vectors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial2.html">
     Tutorial 2: Matrices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D3_LinearAlgebra/student/W0D3_Tutorial3.html">
     Bonus Tutorial: Discrete Dynamical Systems
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D4_Calculus/intro_text.html">
   Calculus (W0D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial1.html">
     Tutorial 1: Basics of Differential and Integral Calculus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial2.html">
     Tutorial 2: Differential Equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D4_Calculus/student/W0D4_Tutorial3.html">
     Tutorial 3: Numerical Methods
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W0D5_Statistics/intro_text.html">
   Statistics (W0D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial1.html">
     Tutorial 1: Probability Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W0D5_Statistics/student/W0D5_Tutorial2.html">
     Tutorial 2: Statistical Inference
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Intro to Modeling
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D1_ModelTypes/intro_text.html">
   Model Types (W1D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/intro_vid.html">
     Intro Video
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial1.html">
     Tutorial 1: “What” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial2.html">
     Tutorial 2: “How” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/student/W1D1_Tutorial3.html">
     Tutorial 3: “Why” models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D1_ModelTypes/outro_vid.html">
     Intro Video
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D2_ModelingPractice/intro_text.html">
   Modeling Practice (W1D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D2_ModelingPractice/student/W1D2_Tutorial1.html">
     Tutorial: Framing the Question
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D3_ModelFitting/intro_text.html">
   Model Fitting (W1D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial1.html">
     Tutorial 1: Linear regression with MSE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial2.html">
     Tutorial 2: Linear regression with MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial3.html">
     Tutorial 3: Confidence intervals and bootstrapping
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial4.html">
     Tutorial 4: Multiple linear regression and polynomial regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial5.html">
     Tutorial 5: Model Selection: Bias-variance trade-off
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D3_ModelFitting/student/W1D3_Tutorial6.html">
     Tutorial 6: Model Selection: Cross-validation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../intro_text.html">
   Machine Learning (W1D4)
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Tutorial 1: GLMs for Encoding
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="W1D4_Tutorial2.html">
     Tutorial 2: Classifiers and regularizers
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W1D5_DimensionalityReduction/intro_text.html">
   Dimensionality Reduction (W1D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial1.html">
     Tutorial 1: Geometric view of data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial2.html">
     Tutorial 2: Principal Component Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial3.html">
     Tutorial 3: Dimensionality Reduction &amp; Reconstruction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W1D5_DimensionalityReduction/student/W1D5_Tutorial4.html">
     Tutorial 4:  Nonlinear Dimensionality Reduction
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D1_DeepLearning/intro_text.html">
   Deep Learning (W2D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D1_DeepLearning/student/W2D1_Tutorial3.html">
     Tutorial 2: Building and Evaluating Normative Encoding Models
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Dynamical Systems
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D2_LinearSystems/intro_text.html">
   Linear Systems (W2D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial1.html">
     Tutorial 1: Linear dynamical systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial2.html">
     Tutorial 2: Markov Processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial3.html">
     Tutorial 3: Combining determinism and stochasticity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D2_LinearSystems/student/W2D2_Tutorial4.html">
     Tutorial 4: Autoregressive models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D3_RealNeurons/intro_text.html">
   Real Neurons (W2D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_RealNeurons/student/W2D3_Tutorial1.html">
     Tutorial 1: The Leaky Integrate-and-Fire (LIF) Neuron Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_RealNeurons/student/W2D3_Tutorial2.html">
     Tutorial 2: Effects of Input Correlation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_RealNeurons/student/W2D3_Tutorial3.html">
     Tutorial 3: Synaptic transmission - Models of static and dynamic synapses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D3_RealNeurons/student/W2D3_Tutorial4.html">
     Tutorial 4: Spike-timing dependent plasticity (STDP)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W2D4_DynamicNetworks/intro_text.html">
   Dynamic Networks (W2D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial1.html">
     Tutorial 1: Neural Rate Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W2D4_DynamicNetworks/student/W2D4_Tutorial2.html">
     Tutorial 2: Wilson-Cowan Model
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Stochastic Processes
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D1_BayesianDecisions/intro_text.html">
   Bayesian Decisions (W3D1)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial1.html">
     Tutorial 1: Bayes with a binary hidden state
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial2.html">
     Tutorial 2: Bayesian inference and decisions with continuous hidden state
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D1_BayesianDecisions/student/W3D1_Tutorial3.html">
     Bonus Tutorial:Fitting to data
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D2_HiddenDynamics/intro_text.html">
   Hidden Dynamics (W3D2)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial1.html">
     Tutorial 1: Sequential Probability Ratio Test
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial2.html">
     Tutorial 2: Hidden Markov Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial3.html">
     Tutorial 3: 1D Kalman Filter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D2_HiddenDynamics/student/W3D2_Tutorial4.html">
     Tutorial 4: 2D Kalman Filter
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D3_OptimalControl/intro_text.html">
   Optimal Control (W3D3)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial1.html">
     Neuromatch Academy: Week 3, Day 3, Tutorial 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D3_OptimalControl/student/W3D3_Tutorial2.html">
     Tutorial 2: Optimal Control for Continuous State
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D4_ReinforcementLearning/intro_text.html">
   Reinforcement Learning (W3D4)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Learning to Predict
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Learning to Act: Multi-Armed Bandits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial3.html">
     Tutorial 3: Learning to Act: Q-Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D4_ReinforcementLearning/student/W3D4_Tutorial4.html">
     Tutorial 4: From Reinforcement Learning to Planning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../W3D5_NetworkCausality/intro_text.html">
   Network Causality (W3D5)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial1.html">
     Tutorial 1: Interventions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial2.html">
     Tutorial 2: Correlations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial3.html">
     Tutorial 3: Simultaneous fitting/regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../W3D5_NetworkCausality/student/W3D5_Tutorial4.html">
     Tutorial 4: Instrumental Variables
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/W1D4_MachineLearning/student/W1D4_Tutorial1.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/NeuromatchAcademy/course_content/blob/master/book/W1D4_MachineLearning/student/W1D4_Tutorial1.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Tutorial 1: GLMs for Encoding
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#setup">
   Setup
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-1-1-load-retinal-ganglion-cell-activity-data">
     Section 1.1: Load retinal ganglion cell activity data
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#exercise-1-create-design-matrix">
       Exercise 1: Create design matrix
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#exercise-2-predict-spike-counts-with-linear-gaussian-model">
       Exercise 2: Predict spike counts with Linear-Gaussian model
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bonus-challenge">
       Bonus challenge
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#section-2-1-nonlinear-optimization-with-scipy-optimize">
     Section 2.1: Nonlinear optimization with
     <code class="docutils literal notranslate">
      <span class="pre">
       scipy.optimize
      </span>
     </code>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#exercise-3-fitting-the-poisson-glm-and-prediction-spikes">
       Exercise 3: Fitting the Poisson GLM and prediction spikes
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary">
     Summary
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/master/tutorials/W1D4_MachineLearning/student/W1D4_Tutorial1.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<div class="section" id="tutorial-1-glms-for-encoding">
<h1>Tutorial 1: GLMs for Encoding<a class="headerlink" href="#tutorial-1-glms-for-encoding" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 1, Day 4: Machine Learning (GLMs)</strong></p>
<p><strong>By Neuromatch Academy</strong>
<strong>Content creators:</strong> Pierre-Etienne H. Fiquet, Ari Benjamin, Jakob Macke</p>
<p><strong>Content reviewers:</strong> Davide Valeriani, Alish Dipani, Michael Waskom</p>
<p>This is part 1 of a 2-part series about Generalized Linear Models (GLMs), which are a fundamental framework for supervised learning.</p>
<p>In this tutorial, the objective is to model a retinal ganglion cell spike train by fitting a temporal receptive field. First with a Linear-Gaussian GLM (also known as ordinary least-squares regression model) and then with a Poisson GLM (aka “Linear-Nonlinear-Poisson” model). In the next tutorial, we’ll extend to a special case of GLMs, logistic regression, and learn how to ensure good model performance.</p>
<p>This tutorial is designed to run with retinal ganglion cell spike train data from <a class="reference external" href="https://journals.physiology.org/doi/full/10.1152/jn.01171.2003?url_ver=Z39.88-2003&amp;rfr_id=ori:rid:crossref.org&amp;rfr_dat=cr_pub%20%200pubmed">Uzzell &amp; Chichilnisky 2004</a>.</p>
<p><em>Acknowledgements:</em></p>
<ul class="simple">
<li><p>We thank EJ Chichilnisky for providing the dataset. Please note that it is provided for tutorial purposes only, and should not be distributed or used for publication without express permission from the author (<a class="reference external" href="mailto:ej&#37;&#52;&#48;stanford&#46;edu">ej<span>&#64;</span>stanford<span>&#46;</span>edu</a>).</p></li>
<li><p>We thank Jonathan Pillow, much of this tutorial is inspired by exercises asigned in his ‘Statistical Modeling and Analysis of Neural Data’ class.</p></li>
</ul>
</div>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
<span class="kn">from</span> <span class="nn">scipy.io</span> <span class="kn">import</span> <span class="n">loadmat</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Figure settings</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Helper functions</span>

<span class="k">def</span> <span class="nf">plot_stim_and_spikes</span><span class="p">(</span><span class="n">stim</span><span class="p">,</span> <span class="n">spikes</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">nt</span><span class="o">=</span><span class="mi">120</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Show time series of stim intensity and spike counts.</span>

<span class="sd">  Args:</span>
<span class="sd">    stim (1D array): vector of stimulus intensities</span>
<span class="sd">    spikes (1D array): vector of spike counts</span>
<span class="sd">    dt (number): duration of each time step</span>
<span class="sd">    nt (number): number of time steps to plot</span>

<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">timepoints</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">120</span><span class="p">)</span>
  <span class="n">time</span> <span class="o">=</span> <span class="n">timepoints</span> <span class="o">*</span> <span class="n">dt</span>

  <span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax_stim</span><span class="p">,</span> <span class="n">ax_spikes</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
    <span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
  <span class="p">)</span>
  <span class="n">ax_stim</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">stim</span><span class="p">[</span><span class="n">timepoints</span><span class="p">])</span>
  <span class="n">ax_stim</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Stimulus intensity&#39;</span><span class="p">)</span>

  <span class="n">ax_spikes</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">spikes</span><span class="p">[</span><span class="n">timepoints</span><span class="p">])</span>
  <span class="n">ax_spikes</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Time (s)&#39;</span><span class="p">)</span>
  <span class="n">ax_spikes</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Number of spikes&#39;</span><span class="p">)</span>

  <span class="n">f</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_glm_matrices</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">nt</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Show X and Y as heatmaps.</span>

<span class="sd">  Args:</span>
<span class="sd">    X (2D array): Design matrix.</span>
<span class="sd">    y (1D or 2D array): Target vector.</span>

<span class="sd">  &quot;&quot;&quot;</span>
  <span class="kn">from</span> <span class="nn">matplotlib.colors</span> <span class="kn">import</span> <span class="n">BoundaryNorm</span>
  <span class="kn">from</span> <span class="nn">mpl_toolkits.axes_grid1</span> <span class="kn">import</span> <span class="n">make_axes_locatable</span>
  <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">y</span><span class="p">]</span>  <span class="c1"># Ensure Y is 2D and skinny</span>

  <span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">ax_x</span><span class="p">,</span> <span class="n">ax_y</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
    <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
    <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">gridspec_kw</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">width_ratios</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
  <span class="p">)</span>
  <span class="n">norm</span> <span class="o">=</span> <span class="n">BoundaryNorm</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-.</span><span class="mi">2</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="mi">256</span><span class="p">)</span>
  <span class="n">imx</span> <span class="o">=</span> <span class="n">ax_x</span><span class="o">.</span><span class="n">pcolormesh</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="n">nt</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;coolwarm&quot;</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>

  <span class="n">ax_x</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;X</span><span class="se">\n</span><span class="s2">(lagged stimulus)&quot;</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Time lag (time bins)&quot;</span><span class="p">,</span>
    <span class="n">xticks</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">24</span><span class="p">],</span>
    <span class="n">xticklabels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;-20&#39;</span><span class="p">,</span> <span class="s1">&#39;-10&#39;</span><span class="p">,</span> <span class="s1">&#39;0&#39;</span><span class="p">],</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Time point (time bins)&quot;</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">ax_x</span><span class="o">.</span><span class="n">spines</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">visible</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="n">divx</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">ax_x</span><span class="p">)</span>
  <span class="n">caxx</span> <span class="o">=</span> <span class="n">divx</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s2">&quot;right&quot;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s2">&quot;5%&quot;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
  <span class="n">cbarx</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">imx</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">caxx</span><span class="p">)</span>
  <span class="n">cbarx</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">([</span><span class="o">-.</span><span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">.</span><span class="mi">6</span><span class="p">])</span>
  <span class="n">cbarx</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>

  <span class="n">norm</span> <span class="o">=</span> <span class="n">BoundaryNorm</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">256</span><span class="p">)</span>
  <span class="n">imy</span> <span class="o">=</span> <span class="n">ax_y</span><span class="o">.</span><span class="n">pcolormesh</span><span class="p">(</span><span class="n">Y</span><span class="p">[:</span><span class="n">nt</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;magma&quot;</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>
  <span class="n">ax_y</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Y</span><span class="se">\n</span><span class="s2">(spike count)&quot;</span><span class="p">,</span>
    <span class="n">xticks</span><span class="o">=</span><span class="p">[]</span>
  <span class="p">)</span>
  <span class="n">ax_y</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">ax_y</span><span class="o">.</span><span class="n">spines</span><span class="o">.</span><span class="n">values</span><span class="p">(),</span> <span class="n">visible</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="n">divy</span> <span class="o">=</span> <span class="n">make_axes_locatable</span><span class="p">(</span><span class="n">ax_y</span><span class="p">)</span>
  <span class="n">caxy</span> <span class="o">=</span> <span class="n">divy</span><span class="o">.</span><span class="n">append_axes</span><span class="p">(</span><span class="s2">&quot;right&quot;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s2">&quot;30%&quot;</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
  <span class="n">cbary</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">imy</span><span class="p">,</span> <span class="n">cax</span><span class="o">=</span><span class="n">caxy</span><span class="p">)</span>
  <span class="n">cbary</span><span class="o">.</span><span class="n">set_ticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">max</span><span class="p">())</span> <span class="o">+</span> <span class="o">.</span><span class="mi">5</span><span class="p">)</span>
  <span class="n">cbary</span><span class="o">.</span><span class="n">set_ticklabels</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">max</span><span class="p">()))</span>

<span class="k">def</span> <span class="nf">plot_spike_filter</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="o">**</span><span class="n">kws</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Plot estimated weights based on time lag model.</span>

<span class="sd">  Args:</span>
<span class="sd">    theta (1D array): Filter weights, not including DC term.</span>
<span class="sd">    dt (number): Duration of each time bin.</span>
<span class="sd">    kws: Pass additional keyword arguments to plot()</span>

<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">d</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
  <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">d</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dt</span>

  <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kws</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;.2&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Time before spike (s)&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Filter weight&quot;</span><span class="p">,</span>
  <span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_spikes_with_prediction</span><span class="p">(</span>
    <span class="n">spikes</span><span class="p">,</span> <span class="n">predicted_spikes</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">nt</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">t0</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span> <span class="o">**</span><span class="n">kws</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Plot actual and predicted spike counts.</span>

<span class="sd">  Args:</span>
<span class="sd">    spikes (1D array): Vector of actual spike counts</span>
<span class="sd">    predicted_spikes (1D array): Vector of predicted spike counts</span>
<span class="sd">    dt (number): Duration of each time bin.</span>
<span class="sd">    nt (number): Number of time bins to plot</span>
<span class="sd">    t0 (number): Index of first time bin to plot.</span>
<span class="sd">    kws: Pass additional keyword arguments to plot()</span>

<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">t0</span><span class="p">,</span> <span class="n">t0</span> <span class="o">+</span> <span class="n">nt</span><span class="p">)</span> <span class="o">*</span> <span class="n">dt</span>

  <span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">lines</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">spikes</span><span class="p">[:</span><span class="n">nt</span><span class="p">],</span> <span class="n">use_line_collection</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">setp</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;.5&quot;</span><span class="p">)</span>
  <span class="n">lines</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_zorder</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">kws</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;linewidth&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
  <span class="n">yhat</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">predicted_spikes</span><span class="p">[:</span><span class="n">nt</span><span class="p">],</span> <span class="o">**</span><span class="n">kws</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
      <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Time (s)&quot;</span><span class="p">,</span>
      <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Spikes&quot;</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_locator</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">MaxNLocator</span><span class="p">(</span><span class="n">integer</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="n">lines</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">yhat</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Spikes&quot;</span><span class="p">,</span> <span class="s2">&quot;Predicted&quot;</span><span class="p">])</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Data retrieval and loading</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">hashlib</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">fname</span> <span class="o">=</span> <span class="s2">&quot;RGCdata.mat&quot;</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://osf.io/mzujs/download&quot;</span>
<span class="n">expected_md5</span> <span class="o">=</span> <span class="s2">&quot;1b2977453020bce5319f2608c94d38d0&quot;</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">fname</span><span class="p">):</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
  <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">ConnectionError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;!!! Failed to download data !!!&quot;</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">r</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="n">requests</span><span class="o">.</span><span class="n">codes</span><span class="o">.</span><span class="n">ok</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;!!! Failed to download data !!!&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">hashlib</span><span class="o">.</span><span class="n">md5</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span> <span class="o">!=</span> <span class="n">expected_md5</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;!!! Data download appears corrupted !!!&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fid</span><span class="p">:</span>
        <span class="n">fid</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p>#Section 1: Linear-Gaussian GLM</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 1: General linear model</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;Yv89UHeSa9I&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtube.com/watch?v=&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="section-1-1-load-retinal-ganglion-cell-activity-data">
<h2>Section 1.1: Load retinal ganglion cell activity data<a class="headerlink" href="#section-1-1-load-retinal-ganglion-cell-activity-data" title="Permalink to this headline">¶</a></h2>
<p>In this exercise we use data from an experiment that presented a screen which randomly alternated between two luminance values and recorded responses from retinal ganglion cell (RGC), a type of neuron in the retina in the back of the eye. This kind of visual stimulus is called a “full-field flicker”, and it was presented at ~120Hz (ie. the stimulus presented on the screen was refreshed about every 8ms). These same time bins were used to count the number of spikes emitted by each neuron.</p>
<p>The file <code class="docutils literal notranslate"><span class="pre">RGCdata.mat</span></code> contains three variablies:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Stim</span></code>, the stimulus intensity at each time point. It is an array with shape <span class="math notranslate nohighlight">\(T \times 1\)</span>, where <span class="math notranslate nohighlight">\(T=144051\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SpCounts</span></code>, the binned spike counts for 2 ON cells, and 2 OFF cells. It is a <span class="math notranslate nohighlight">\(144051 \times 4\)</span> array, and each column has counts for a different cell.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dtStim</span></code>, the size of a single time bin (in seconds), which is needed for computing model output in units of spikes / s. The stimulus frame rate is given by <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">/</span> <span class="pre">dtStim</span></code>.</p></li>
</ul>
<p>Because these data were saved in MATLAB, where everything is a matrix, we will also process the variables to more Pythonic representations (1D arrays or scalars, where appropriate) as we load the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">loadmat</span><span class="p">(</span><span class="s1">&#39;RGCdata.mat&#39;</span><span class="p">)</span>  <span class="c1"># loadmat is a function in scipy.io</span>
<span class="n">dt_stim</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;dtStim&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># .item extracts a scalar value</span>

<span class="c1"># Extract the stimulus intensity</span>
<span class="n">stim</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Stim&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>  <span class="c1"># .squeeze removes dimensions with 1 element</span>

<span class="c1"># Extract the spike counts for one cell</span>
<span class="n">cellnum</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">spikes</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;SpCounts&#39;</span><span class="p">][:,</span> <span class="n">cellnum</span><span class="p">]</span>

<span class="c1"># Don&#39;t use all of the timepoints in the dataset, for speed</span>
<span class="n">keep_timepoints</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">stim</span> <span class="o">=</span> <span class="n">stim</span><span class="p">[:</span><span class="n">keep_timepoints</span><span class="p">]</span>
<span class="n">spikes</span> <span class="o">=</span> <span class="n">spikes</span><span class="p">[:</span><span class="n">keep_timepoints</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Use the <code class="docutils literal notranslate"><span class="pre">plot_stim_and_spikes</span></code> helper function to visualize the changes in stimulus intensities and spike counts over time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_stim_and_spikes</span><span class="p">(</span><span class="n">stim</span><span class="p">,</span> <span class="n">spikes</span><span class="p">,</span> <span class="n">dt_stim</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="exercise-1-create-design-matrix">
<h3>Exercise 1: Create design matrix<a class="headerlink" href="#exercise-1-create-design-matrix" title="Permalink to this headline">¶</a></h3>
<p>Our goal is to predict the cell’s activity from the stimulus intensities preceding it. That will help us understand how RGCs process information over time. To do so, we first need to create the <em>design matrix</em> for this model, which organizes the stimulus intensities in matrix form such that the <span class="math notranslate nohighlight">\(i\)</span>th row has the stimulus frames preceding timepoint <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>In this exercise, we will create the design matrix <span class="math notranslate nohighlight">\(X\)</span> using <span class="math notranslate nohighlight">\(d=25\)</span> time lags. That is, <span class="math notranslate nohighlight">\(X\)</span> should be a <span class="math notranslate nohighlight">\(T \times d\)</span> matrix. <span class="math notranslate nohighlight">\(d = 25\)</span> (about 200 ms) is a choice we’re making based on our prior knowledge of the temporal window that influences RGC responses. In practice, you might not know the right duration to use.</p>
<p>The last entry in row <code class="docutils literal notranslate"><span class="pre">t</span></code> should correspond to the stimulus that was shown at time <code class="docutils literal notranslate"><span class="pre">t</span></code>, the entry to the left of it should contain the value that was show one time bin earlier, etc. Specifically, <span class="math notranslate nohighlight">\(X_{ij}\)</span> will be the stimulus intensity at time <span class="math notranslate nohighlight">\(i + d - 1 - j\)</span>.</p>
<p>Note that for the first few time bins, we have access to the recorded spike counts but not to the stimulus shown in the recent past. For simplicity we are going to assume that values of <code class="docutils literal notranslate"><span class="pre">stim</span></code> are 0 for the time lags prior to the first timepoint in the dataset. This is known as “zero-padding”, so that the design matrix has the same number of rows as the response vectors in <code class="docutils literal notranslate"><span class="pre">spikes</span></code>.</p>
<p>Your task is is to complete the function below to:</p>
<ul class="simple">
<li><p>make a zero-padded version of the stimulus</p></li>
<li><p>initialize an empty design matrix with the correct shape</p></li>
<li><p><strong>fill in each row of the design matrix, using the zero-padded version of the stimulus</strong></p></li>
</ul>
<p>To visualize your design matrix (and the corresponding vector of spike counts), we will plot a “heatmap”, which encodes the numerical value in each position of the matrix as a color. The helper functions include some code to do this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_design_matrix</span><span class="p">(</span><span class="n">stim</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">25</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Create time-lag design matrix from stimulus intensity vector.</span>

<span class="sd">  Args:</span>
<span class="sd">    stim (1D array): Stimulus intensity at each time point.</span>
<span class="sd">    d (number): Number of time lags to use.</span>

<span class="sd">  Returns</span>
<span class="sd">    X (2D array): GLM design matrix with shape T, d</span>

<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1"># Create version of stimulus vector with zeros before onset</span>
  <span class="n">padded_stim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">d</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stim</span><span class="p">])</span>

  <span class="c1">#####################################################################</span>
  <span class="c1"># Fill in missing code (...),</span>
  <span class="c1"># then remove or comment the line below to test your function</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Complete the make_design_matrix function&quot;</span><span class="p">)</span>
  <span class="c1">#####################################################################</span>


  <span class="c1"># Construct a matrix where each row has the d frames of</span>
  <span class="c1"># the stimulus proceeding and including timepoint t</span>
  <span class="n">T</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>  <span class="c1"># Total number of timepoints (hint: number of stimulus frames)</span>
  <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
      <span class="n">X</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">X</span>

<span class="c1"># Uncomment and run to test your function</span>
<span class="c1"># X = make_design_matrix(stim)</span>
<span class="c1"># plot_glm_matrices(X, spikes, nt=50)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W1D4_MachineLearning/solutions/W1D4_Tutorial1_Solution_3eaecf0a.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=415 height=558 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W1D4_MachineLearning/static/W1D4_Tutorial1_Solution_3eaecf0a_0.png>
<p>##Section 1.2: Fit Linear-Gaussian regression model</p>
<p>First, we will use the design matrix to compute the maximum likelihood estimate for a linear-Gaussian GLM (aka “general linear model”). The maximum likelihood estimate of <span class="math notranslate nohighlight">\(\theta\)</span> in this model can be solved analytically using the equation you learned about on Day 3:</p>
<div class="math notranslate nohighlight">
\[\hat \theta = (X^TX)^{-1}X^Ty\]</div>
<p>Before we can apply this equation, we need to augment the design matrix to account for the mean of <span class="math notranslate nohighlight">\(y\)</span>, because the spike counts are all <span class="math notranslate nohighlight">\(\geq 0\)</span>. We do this by adding a constant column of 1’s to the design matrix, which will allow the model to learn an additive offset weight. We will refer to this additional weight as <span class="math notranslate nohighlight">\(b\)</span> (for bias), although it is alternatively known as a “DC term” or “intercept”.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Build the full design matrix</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">spikes</span>
<span class="n">constant</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">constant</span><span class="p">,</span> <span class="n">make_design_matrix</span><span class="p">(</span><span class="n">stim</span><span class="p">)])</span>

<span class="c1"># Get the MLE weights for the LG model</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>
<span class="n">theta_lg</span> <span class="o">=</span> <span class="n">theta</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<p>Plot the resulting maximum likelihood filter estimate (just the 25-element weight vector <span class="math notranslate nohighlight">\(\theta\)</span> on the stimulus elements, not the DC term <span class="math notranslate nohighlight">\(b\)</span>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_spike_filter</span><span class="p">(</span><span class="n">theta_lg</span><span class="p">,</span> <span class="n">dt_stim</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="exercise-2-predict-spike-counts-with-linear-gaussian-model">
<h3>Exercise 2: Predict spike counts with Linear-Gaussian model<a class="headerlink" href="#exercise-2-predict-spike-counts-with-linear-gaussian-model" title="Permalink to this headline">¶</a></h3>
<p>Now we are going to put these pieces together and write a function that outputs a predicted spike count for each timepoint using the stimulus information.</p>
<p>Your steps should be:</p>
<ul class="simple">
<li><p>Create the complete design matrix</p></li>
<li><p>Obtain the MLE weights (<span class="math notranslate nohighlight">\(\hat \theta\)</span>)</p></li>
<li><p>Compute <span class="math notranslate nohighlight">\(\hat y = X\hat \theta\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_spike_counts_lg</span><span class="p">(</span><span class="n">stim</span><span class="p">,</span> <span class="n">spikes</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">25</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Compute a vector of predicted spike counts given the stimulus.</span>

<span class="sd">  Args:</span>
<span class="sd">    stim (1D array): Stimulus values at each timepoint</span>
<span class="sd">    spikes (1D array): Spike counts measured at each timepoint</span>
<span class="sd">    d (number): Number of time lags to use.</span>

<span class="sd">  Returns:</span>
<span class="sd">    yhat (1D array): Predicted spikes at each timepoint.</span>

<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1">##########################################################################</span>
  <span class="c1"># Fill in missing code (...) and then comment or remove the error to test</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Complete the predict_spike_counts_lg function&quot;</span><span class="p">)</span>
  <span class="c1">##########################################################################</span>

  <span class="c1"># Create the design matrix</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">spikes</span>
  <span class="n">constant</span> <span class="o">=</span> <span class="o">...</span>
  <span class="n">X</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># Get the MLE weights for the LG model</span>
  <span class="n">theta</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># Compute predicted spike counts</span>
  <span class="n">yhat</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">theta</span>
  <span class="k">return</span> <span class="n">yhat</span>

<span class="c1"># Uncomment and run to test your function and plot prediction</span>
<span class="c1"># predicted_counts = predict_spike_counts_lg(stim, spikes)</span>
<span class="c1"># plot_spikes_with_prediction(spikes, predicted_counts, dt_stim)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W1D4_MachineLearning/solutions/W1D4_Tutorial1_Solution_6576a3e7.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=560 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W1D4_MachineLearning/static/W1D4_Tutorial1_Solution_6576a3e7_0.png>
<p>Is this a good model? The prediction line more-or-less follows the bumps in the spikes, but it never predicts as many spikes as are actually observed. And, more troublingly, it’s predicting <em>negative</em> spikes for some time points.</p>
<p>The Poisson GLM will help to address these failures.</p>
</div>
<div class="section" id="bonus-challenge">
<h3>Bonus challenge<a class="headerlink" href="#bonus-challenge" title="Permalink to this headline">¶</a></h3>
<p>The “spike-triggered average” falls out as a subcase of the linear Gaussian GLM: <span class="math notranslate nohighlight">\(\mathrm{STA} = X^T y \,/\, \textrm{sum}(y)\)</span>, where <span class="math notranslate nohighlight">\(y\)</span> is the vector of spike counts of the neuron. In the LG GLM, the term <span class="math notranslate nohighlight">\((X^TX)^{-1}\)</span> corrects for potential correlation between the regressors. Because the experiment that produced these data used a white noise stimulus, there are no such correlations. Therefore the two methods are equivalent. (How would you check the statement about no correlations?)</p>
<p>#Section 2: Linear-Nonlinear-Poisson GLM</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Video 2: Generalized linear model</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">YouTubeVideo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s2">&quot;wRbvwdze4uE&quot;</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">854</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">480</span><span class="p">,</span> <span class="n">fs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Video available at https://youtube.com/watch?v=&quot;</span> <span class="o">+</span> <span class="n">video</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
<span class="n">video</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="section-2-1-nonlinear-optimization-with-scipy-optimize">
<h2>Section 2.1: Nonlinear optimization with <code class="docutils literal notranslate"><span class="pre">scipy.optimize</span></code><a class="headerlink" href="#section-2-1-nonlinear-optimization-with-scipy-optimize" title="Permalink to this headline">¶</a></h2>
<p>Before diving into the Poisson GLM case, let us review the use and importance of convexity in optimization:</p>
<ul class="simple">
<li><p>We have seen previously that in the Linear-Gaussian case, maximum likelihood  parameter estimate can be computed analytically. That is great because it only takes us a single line of code!</p></li>
<li><p>Unfortunately in general there is no analytical solution to our statistical estimation problems of interest. Instead, we need to apply a nonlinear optimization algorithm to find the parameter values that minimize some <em>objective function</em>. This can be extremely tedious because there is no general way to check whether we have found <em>the optimal solution</em> or if we are just stuck in some local minimum.</p></li>
<li><p>Somewhere in between theses two extremes, the spetial case of convex objective function is of great practical importance. Indeed, such optimization problems can be solved very reliably (and usually quite rapidly too!) using some standard software.</p></li>
</ul>
<p>Notes:</p>
<ul class="simple">
<li><p>a function is convex if and only if its curve lies below any chord joining two of its points</p></li>
<li><p>to learn more about optimization, you can consult the book of Stephen Boyd and Lieven Vandenberghe <a class="reference external" href="https://web.stanford.edu/~boyd/cvxbook/">Convex Optimization</a>.</p></li>
</ul>
<p>Here we will use the <code class="docutils literal notranslate"><span class="pre">scipy.optimize</span></code> module, it contains a function called <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html"><code class="docutils literal notranslate"><span class="pre">minimize</span></code></a> that provides a generic interface to a large number of optimization algorithms. This function expects as argument an objective function and an “initial guess” for the parameter values. It then returns a dictionary that includes the minimum function value, the parameters that give this minimum, and other information.</p>
<p>Let’s see how this works with a simple example. We want to minimize the function <span class="math notranslate nohighlight">\(f(x) = x^2\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
  <span class="sa">f</span><span class="s2">&quot;Minimum value: </span><span class="si">{</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;fun&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4g</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
  <span class="sa">f</span><span class="s2">&quot;at x = </span><span class="si">{</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>When minimizing a <span class="math notranslate nohighlight">\(f(x) = x^2\)</span>, we get a minimum value of <span class="math notranslate nohighlight">\(f(x) \approx 0\)</span> when <span class="math notranslate nohighlight">\(x \approx 0\)</span>. The algorithm doesn’t return exactly <span class="math notranslate nohighlight">\(0\)</span>, because it stops when it gets “close enough” to a minimum. You can change the <code class="docutils literal notranslate"><span class="pre">tol</span></code> parameter to control how it defines “close enough”.</p>
<p>A point about the code bears emphasis. The first argument to <code class="docutils literal notranslate"><span class="pre">minimize</span></code> is not a number or a string but a <em>function</em>. Here, we used <code class="docutils literal notranslate"><span class="pre">np.square</span></code>. Take a moment to make sure you understand what’s going on, because it’s a bit unusual, and it will be important for the exercise you’re going to do in a moment.</p>
<p>In this example, we started at <span class="math notranslate nohighlight">\(x_0 = 2\)</span>. Let’s try different values for the starting point:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">start_points</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.5</span>

<span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">xx</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;.2&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$x$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$f(x)$&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x0</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">start_points</span><span class="p">):</span>
  <span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x0</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">x0</span><span class="p">),</span> <span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Start </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;fun&quot;</span><span class="p">],</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;End </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The runs started at different points (the dots), but they each ended up at roughly the same place (the cross): <span class="math notranslate nohighlight">\(f(x_\textrm{final}) \approx 0\)</span>. Let’s see what happens if we use a different function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">/</span> <span class="mi">5</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">start_points</span> <span class="o">=</span> <span class="o">-.</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1.5</span>

<span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">g</span><span class="p">(</span><span class="n">xx</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;.2&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$x$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$f(x)$&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x0</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">start_points</span><span class="p">):</span>
  <span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">x0</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">g</span><span class="p">(</span><span class="n">x0</span><span class="p">),</span> <span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Start </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;fun&quot;</span><span class="p">],</span> <span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;C</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;End </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Unlike <span class="math notranslate nohighlight">\(f(x) = x^2\)</span>, <span class="math notranslate nohighlight">\(g(x) = \frac{x}{5} + \cos(x)\)</span> is not <em>convex</em>. We see that the final position of the minimization algorithm depends on the starting point, which adds a layer of comlpexity to such problems.</p>
<div class="section" id="exercise-3-fitting-the-poisson-glm-and-prediction-spikes">
<h3>Exercise 3: Fitting the Poisson GLM and prediction spikes<a class="headerlink" href="#exercise-3-fitting-the-poisson-glm-and-prediction-spikes" title="Permalink to this headline">¶</a></h3>
<p>In this exercise, we will use <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html"><code class="docutils literal notranslate"><span class="pre">scipy.optimize.minimize</span></code></a> to compute maximum likelihood estimates for the filter weights in the Poissson GLM model with an exponential nonlinearity (LNP: Linear-Nonlinear-Poisson).</p>
<p>In practice, this will involve filling out two functions.</p>
<ul class="simple">
<li><p>The first should be an <em>objective function</em> that takes a design matrix, a spike count vector, and a vector of parameters. It should return a negative log likelihood.</p></li>
<li><p>The second function should take <code class="docutils literal notranslate"><span class="pre">stim</span></code> and <code class="docutils literal notranslate"><span class="pre">spikes</span></code>, build the design matrix and then use <code class="docutils literal notranslate"><span class="pre">minimize</span></code> internally, and return the MLE parameters.</p></li>
</ul>
<p>What should the objective function look like? We want it to return the negative log likelihood: <span class="math notranslate nohighlight">\(-\log P(y \mid X, \theta).\)</span></p>
<p>In the Poisson GLM,</p>
<div class="math notranslate nohighlight">
\[
\log P(\mathbf{y} \mid X, \theta) = \sum_t \log P(y_t \mid \mathbf{x_t},\theta),
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[ P(y_t \mid \mathbf{x_t}, \theta) = \frac{\lambda_t^{y_t}\exp(-\lambda_t)}{y_t!} \text{, with rate } \lambda_t = \exp(\mathbf{x_t}^{\top} \theta).\]</div>
<p>Now, taking the log likelihood for all the data we obtain:
<span class="math notranslate nohighlight">\(\log P(\mathbf{y} \mid X, \theta) = \sum_t( y_t \log(\lambda_t) - \lambda_t - \log(y_t !)).\)</span></p>
<p>Because we are going to minimize the negative log likelihood with respct to the parameters <span class="math notranslate nohighlight">\(\theta\)</span>, we can ignore the last term that does not depend on <span class="math notranslate nohighlight">\(\theta\)</span>. For faster implementation, let us rewrite this in matrix notation:</p>
<div class="math notranslate nohighlight">
\[\mathbf{y}^T \log(\mathbf{\lambda}) - \mathbf{1}^T \mathbf{\lambda} \text{, with  rate } \mathbf{\lambda} = \exp(X^{\top} \theta)\]</div>
<p>Finally, don’t forget to add the minus sign for your function to return the negative log likelihood.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">neg_log_lik_lnp</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Return -loglike for the Poisson GLM model.</span>

<span class="sd">  Args:</span>
<span class="sd">    theta (1D array): Parameter vector.</span>
<span class="sd">    X (2D array): Full design matrix.</span>
<span class="sd">    y (1D array): Data values.</span>

<span class="sd">  Returns:</span>
<span class="sd">    number: Negative log likelihood.</span>

<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1">#####################################################################</span>
  <span class="c1"># Fill in missing code (...), then remove the error</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Complete the neg_log_lik_lnp function&quot;</span><span class="p">)</span>
  <span class="c1">#####################################################################</span>

  <span class="c1"># Compute the Poisson log likeliood</span>
  <span class="n">rate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">theta</span><span class="p">)</span>
  <span class="n">log_lik</span> <span class="o">=</span> <span class="n">y</span> <span class="o">@</span> <span class="o">...</span> <span class="o">-</span> <span class="o">...</span>

  <span class="k">return</span> <span class="o">...</span>


<span class="k">def</span> <span class="nf">fit_lnp</span><span class="p">(</span><span class="n">stim</span><span class="p">,</span> <span class="n">spikes</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">25</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Obtain MLE parameters for the Poisson GLM.</span>

<span class="sd">  Args:</span>
<span class="sd">    stim (1D array): Stimulus values at each timepoint</span>
<span class="sd">    spikes (1D array): Spike counts measured at each timepoint</span>
<span class="sd">    d (number): Number of time lags to use.</span>

<span class="sd">  Returns:</span>
<span class="sd">    1D array: MLE parameters</span>

<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1">#####################################################################</span>
  <span class="c1"># Fill in missing code (...), then remove the error</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Complete the fit_lnp function&quot;</span><span class="p">)</span>
  <span class="c1">#####################################################################</span>

  <span class="c1"># Build the design matrix</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">spikes</span>
  <span class="n">constant</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
  <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">constant</span><span class="p">,</span> <span class="n">make_design_matrix</span><span class="p">(</span><span class="n">stim</span><span class="p">)])</span>

  <span class="c1"># Use a random vector of weights to start (mean 0, sd .2)</span>
  <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="n">d</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

  <span class="c1"># Find parameters that minmize the negative log likelihood function</span>
  <span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

  <span class="k">return</span> <span class="o">...</span>


<span class="c1"># Uncomment and run to test your function</span>
<span class="c1"># theta_lnp = fit_lnp(stim, spikes)</span>
<span class="c1"># plot_spike_filter(theta_lg[1:], dt_stim, color=&quot;.5&quot;, label=&quot;LG&quot;)</span>
<span class="c1"># plot_spike_filter(theta_lnp[1:], dt_stim, label=&quot;LNP&quot;)</span>
<span class="c1"># plt.legend(loc=&quot;upper left&quot;);</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W1D4_MachineLearning/solutions/W1D4_Tutorial1_Solution_c0c87e2d.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=558 height=413 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W1D4_MachineLearning/static/W1D4_Tutorial1_Solution_c0c87e2d_0.png>
<p>Plotting the LG and LNP weights together, we see that they are broadly similar, but the LNP weights are generally larger. What does that mean for the model’s ability to <em>predict</em> spikes? To see that, let’s finish the exercise by filling out the <code class="docutils literal notranslate"><span class="pre">predict_spike_counts_lnp</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_spike_counts_lnp</span><span class="p">(</span><span class="n">stim</span><span class="p">,</span> <span class="n">spikes</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">25</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Compute a vector of predicted spike counts given the stimulus.</span>

<span class="sd">  Args:</span>
<span class="sd">    stim (1D array): Stimulus values at each timepoint</span>
<span class="sd">    spikes (1D array): Spike counts measured at each timepoint</span>
<span class="sd">    theta (1D array): Filter weights; estimated if not provided.</span>
<span class="sd">    d (number): Number of time lags to use.</span>

<span class="sd">  Returns:</span>
<span class="sd">    yhat (1D array): Predicted spikes at each timepoint.</span>

<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1">###########################################################################</span>
  <span class="c1"># Fill in missing code (...) and then remove the error to test</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Complete the predict_spike_counts_lnp function&quot;</span><span class="p">)</span>
  <span class="c1">###########################################################################</span>

  <span class="n">y</span> <span class="o">=</span> <span class="n">spikes</span>
  <span class="n">constant</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">spikes</span><span class="p">)</span>
  <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">constant</span><span class="p">,</span> <span class="n">make_design_matrix</span><span class="p">(</span><span class="n">stim</span><span class="p">)])</span>
  <span class="k">if</span> <span class="n">theta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># Allow pre-cached weights, as fitting is slow</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">fit_lnp</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>

  <span class="n">yhat</span> <span class="o">=</span> <span class="o">...</span>
  <span class="k">return</span> <span class="n">yhat</span>

<span class="c1"># Uncomment and run to test predict_spike_counts_lnp</span>
<span class="c1"># yhat = predict_spike_counts_lnp(stim, spikes, theta_lnp)</span>
<span class="c1"># plot_spikes_with_prediction(spikes, yhat, dt_stim)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content/tree/master//tutorials/W1D4_MachineLearning/solutions/W1D4_Tutorial1_Solution_8fbc44cf.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<img alt='Solution hint' align='left' width=560 height=416 src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/tutorials/W1D4_MachineLearning/static/W1D4_Tutorial1_Solution_8fbc44cf_0.png>
<p>We see that the LNP model does a better job of fitting the actual spiking data. Importantly, it never predicts negative spikes!</p>
<p><em>Bonus:</em> Our statement that the LNP model “does a better job” is qualitative and based mostly on the visual appearance of the plot. But how would you make this a quantitative statement?</p>
</div>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>In this first tutorial, we used two different models to learn something about how retinal ganglion cells respond to a flickering white noise stimulus. We learned how to construct a design matrix that we could pass to different GLMs, and we found that the Linear-Nonlinear-Poisson (LNP) model allowed us to predict spike rates better than a simple Linear-Gaussian (LG) model.</p>
<p>In the next tutorial, we’ll extend these ideas further. We’ll meet yet another GLM — logistic regression — and we’ll learn how to ensure good model performance even when the number of parameters <code class="docutils literal notranslate"><span class="pre">d</span></code> is large compared to the number of data points <code class="docutils literal notranslate"><span class="pre">N</span></code>.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./W1D4_MachineLearning/student"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../intro_text.html" title="previous page">W1D4 - Machine Learning (GLMs)</a>
    <a class='right-next' id="next-link" href="W1D4_Tutorial2.html" title="next page">Tutorial 2: Classifiers and regularizers</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Neuromatch<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>